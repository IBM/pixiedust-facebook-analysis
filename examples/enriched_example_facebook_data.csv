Link,Post ID,Permalink,Text,Type,Countries,Languages,Posted,Audience Targeting,Lifetime Post Total Reach,Lifetime Post organic reach,Lifetime Post Paid Reach,Lifetime Post Total Impressions,Lifetime Post Organic Impressions,Lifetime Post Paid Impressions,Lifetime Engaged Users,Lifetime Matched Audience Targeting Consumers on Post,Lifetime Matched Audience Targeting Consumptions on Post,Lifetime Negative Feedback from Users,Lifetime Negative Feedback,Lifetime Post Impressions by people who have liked your Page,Lifetime Post reach by people who like your Page,Lifetime Post Paid Impressions by people who have liked your Page,Lifetime Paid reach of a post by people who like your Page,Lifetime People who have liked your Page and engaged with your post,Lifetime Organic views to 95%,Lifetime Organic views to 95%.1,Lifetime Paid views to 95%,Lifetime Paid views to 95%.1,Lifetime Organic Video Views,Lifetime Organic Video Views.1,Lifetime Paid Video Views,Lifetime Paid Video Views.1,Lifetime Average time video viewed,Lifetime Video length,Lifetime Talking About This (Post) by action type - share,Lifetime Talking About This (Post) by action type - like,Lifetime Talking About This (Post) by action type - comment,Lifetime Post Stories by action type - share,Lifetime Post Stories by action type - like,Lifetime Post Stories by action type - comment,Lifetime Post Audience Targeting Unique Consumptions by Type - other clicks,Lifetime Post Audience Targeting Unique Consumptions by Type - link clicks,Lifetime Post Audience Targeting Unique Consumptions by Type - photo view,Lifetime Post Audience Targeting Unique Consumptions by Type - video play,Lifetime Matched Audience Targeting Consumptions by Type - other clicks,Lifetime Matched Audience Targeting Consumptions by Type - link clicks,Lifetime Matched Audience Targeting Consumptions by Type - photo view,Lifetime Matched Audience Targeting Consumptions by Type - video play,Lifetime Negative Feedback from Users by Type - hide_all_clicks,Lifetime Negative Feedback from Users by Type - hide_clicks,Lifetime Negative Feedback from Users by Type - report_spam_clicks,Lifetime Negative Feedback by Type - hide_all_clicks,Lifetime Negative Feedback by Type - hide_clicks,Lifetime Negative Feedback by Type - report_spam_clicks,Thumbnails,Image,Extended Links,TextHighestEmotion,TextHighestEmotionScore,TextOverallSentimentType,TextOverallSentimentScore,TextKeywords,TextEntities,MaxTextKeywords,MaxTextEntity,ThumbnailHighestEmotion,ThumbnailHighestEmotionScore,ThumbnailOverallSentimentType,ThumbnailOverallSentimentScore,ThumbnailKeywords,ThumbnailEntities,MaxThumbnailKeywords,MaxThumbnailEntity,LinkHighestEmotion,LinkHighestEmotionScore,LinkOverallSentimentType,LinkOverallSentimentScore,LinkKeywords,LinkEntities,Article Text,MaxLinkKeywords,MaxLinkEntity,Image Color,Image Class,Image Type,Image Subtype,Image Subtype2
https://ibm.co/2SVpbno,187446750783_10156099244995784,https://www.facebook.com/ibmwatson/posts/10156099244995784,"In 2018, IBM has made significant strides toward broadening AI and will continue to work towards advancing the technology in the new year. Watch the video via ABC7: ",Link,,,12/26/18 9:22, ,13560,13560,0,18814,18814,0,219,116,137,7,7,15645,11367,0,0,187,0,0,0,0,0,0,0,0,0,0,31,118.0,3.0,31,119.0,3.0,42,80.0,,,53,84.0,,,3,4.0,,3,4.0,,"For over 70 years, IBM Research has been inventing, exploring, and imagining for the future.","https://cdn.abcotvs.com/dip/images/4914235_121618-kgo-bal-ibm-img_Image_18-48-13,06.jpg?w=1600",https://abc7news.com/technology/ibm-ai-helping-people-and-the-planet/4912146/,joy,0.499828,positive,0.644405,"significant strides, IBM","Company, Person",significant strides,Company,joy,0.261203,positive,0.750613,IBM Research,"Quantity, Company",IBM Research,Quantity,joy,0.345885,positive,0.819656,"SAN FRANCISCO, IBM Research, computer engineers","Company, Quantity, Location, Location","SAN FRANCISCO (KGO) -- For over 70 years, IBM Research has been inventing, exploring, and imagining for the future. Located in San Jose, California, IBM Research - Almaden is one of 12 labs in IBM's global research division. The scientists, computer engineers, and designers at Almaden cultivate promising and disruptive technologies that direct the future of AI, quantum computing, and more.
",SAN FRANCISCO,Company,pink,weatherman,person,weatherman,-
https://ibm.co/2ExlKA9,187446750783_10156082794855784,https://www.facebook.com/ibmwatson/posts/10156082794855784,"Available now on IBM Cloud and Cloud Private, Watson OpenScale is ready to help you scale AI and improve business confidence in its outcomes. Watson OpenScale is open-by-design, automates your AI and infuses it with trust, transparency and explainability. Get started. ",Photo,,,12/18/18 7:15, ,7837,7837,0,10101,10101,0,96,67,89,4,4,9085,7002,0,0,63,0,0,0,0,0,0,0,0,0,0,7,32.0,1.0,9,33.0,4.0,20,16.0,33.0,,25,17.0,47.0,,4,,,4,,,"IBM Watson OpenScale is the open platform that helps businesses manage production AI wherever their data lives, with trust and confidence in outcomes.",https://1.cms.s81c.com/sites/default/files/2019-11-19/001.jpg,https://www.ibm.com/cloud/watson-openscale,joy,0.291603,positive,0.936676,"IBM Cloud, Watson OpenScale, Cloud Private","Person, Company",IBM Cloud,Person,joy,0.436868,positive,0.840297,"IBM Watson OpenScale, open platform","Company, Company",IBM Watson OpenScale,Company,joy,0.536787,positive,0.699844,,"Person, Person, Company, Company","  See how IBM Watson® OpenScale™ tracks and measures outcomes from AI across its lifecycle, and adapts and governs AI to changing business situations — for models built and running anywhere. 
         451 Research recognizes Watson OpenScale for innovation     
         Business users can now examine models without the help of data scientists. Learn how in the report.     
         KPMG: Stewarding responsible AI with Watson OpenScale     
         Kelly Combs, an IBM Women Leader in AI honoree, on how Watson OpenScale helps govern and scale AI for KPMG clients.     
         See how to unlock the value of your data     
         Watch a keynote on an architecture to trust and control the business impact and risks of AI.     
         Track performance of production AI and its impact on business goals, with actionable metrics, in a single console.     
         Apply business results to create a continuous feedback loop that improves and sustains AI outcomes.      
         Maintain regulatory compliance by tracing and explaining AI decisions across workflows, and intelligently detect and correct bias to improve outcomes.     
  Credit lenders can monitor risk models for performance, bias and explainability to limit risk exposure from regulations and create more fair and explainable outcomes for customers. 
  Insurance underwriters can use machine learning to more consistently and accurately assess claims risk, ensure fair outcomes for customers and explain AI recommendations for regulatory and business intelligence purposes. 
  Data scientists can build machine-learning models and work with their IT operations teams to confidently recommend proactive asset maintenance for communications service providers (CSPs).  
         Watch a demo of Watson OpenScale detecting and mitigating AI model bias in a credit risk scenario.     
         Watch a demo of Watson OpenScale monitoring and comparing data to alert users to AI model drift.     
Increase fairness of predictions and improve accuracy by following this new framework.
""IBM’s work in explainable AI should improve … acceptance and adoption of artificial intelligence,"" according to Pund-IT.
Explore reference materials to get started and see what you can do in Watson OpenScale.
Understand how Watson OpenScale can help manage trusted AI at scale and increase confidence in business outcomes.
IBM offers end-to-end model management and helps companies operationalize AI, according to Bloor Research.
  Build and train AI models and prepare and analyze your data — all in a single, integrated environment. 
  Deploy machine-learning models into production at scale and manage model performance. 
  Use this flexible multicloud data platform to integrate all your data on premises or from any cloud, while keeping it secure at its source. Simplify and automate how you collect, organize, analyze and govern data to rapidly innovate your business with AI. 
Explore the capabilities of Watson OpenScale — the open platform that helps enable businesses to automate and operate AI at scale, wherever it resides. Get insights into every stage of the AI lifecycle and give your business greater confidence in AI outcomes.
",,Person, , , , , 
https://ibm.co/2QAlo29,187446750783_10156079731075784,https://www.facebook.com/ibmwatson/posts/10156079731075784,A year in review in AI: ,Link,,,12/16/18 14:54, ,10727,10727,0,14902,14900,0,195,150,168,7,7,12896,9205,0,0,174,0,0,0,0,0,0,0,0,0,0,27,57.0,1.0,27,60.0,1.0,31,126.0,,,39,129.0,,,3,4.0,,3,4.0,,"Highlights from IBM Research AI in 2018 in three key areas - advancing, scaling and trusting AI - and predictions about what's to come in 2019.",https://www.ibm.com/blogs/research/wp-content/uploads/2017/12/iloveaEYE_small.jpg,https://www.ibm.com/blogs/research/2018/12/ai-year-review/,joy,0.342064,neutral,0,review,Person,review,Person,joy,0.124912,neutral,0,"IBM Research, Highlights, key areas","Company, Person",IBM Research,Company,joy,0.554465,positive,0.557017,,"Person, Company, Person","For more than seventy years, IBM Research has been inventing, exploring, and imagining the future. We have been pioneering the field of artificial intelligence (AI) since its inception. We were there when the field was launched at the famous 1956 Dartmouth workshop. Just three years later, an IBMer and early computer pioneer, Arthur Samuel, coined the term machine learning. And ever since, our gaze has always been fixed on what’s next for the field, and how we’ll get there.
Today we released a 2018 retrospective that provides a sneak-peek into the future of AI. We have curated a collection of one hundred IBM Research AI papers we have published this year, authored by talented researchers and scientists from our twelve global Labs. These scientific advancements are core to our mission to invent the next set of fundamental AI technologies that will take us from today’s “narrow” AI to a new era of “broad” AI, where the potential of the technology can be unlocked across AI developers, enterprise adopters and end-users. Broad AI will be characterized by the ability to learn and reason more broadly across tasks, to integrate information from multiple modalities and domains, all while being more explainable, secure, fair, auditable and scalable.
Here, we highlight some of this year’s work in three key areas – advancing, scaling and trusting AI – and, as we focus on the future, a few predictions around what’s to come.
The battle to banish bias: As AI systems are increasingly used for decision support, it is imperative that AI systems are fair and unbiased. However, eliminating bias is challenging, since the data used to train AI systems often contains intrinsic societal and institutional biases and correlations that statistical learning methods capture and recapitulate. IBM Research AI outlined a new approach for combating bias, wherein training data are transformed so as to minimize bias, such that any AI algorithm that later learns from it will perpetuate as little inequity as possible. In applying this method to two large, public datasets, our team was able to substantially reduce unwanted group discrimination, without significant reduction in the system’s accuracy.
Breaking down the “black box”: Deep neural networks are in many ways black boxes—even when a network arrives at a correct decision, it is often difficult to understand why that decision was made. This inherent lack of explainability presents a barrier to user trust in AI systems and makes it difficult to reason about potential failure modes. To tackle these problems, IBM Research AI scientists developed a new machine learning methodology called ProfWeight, which probes a deep network and constructs a simpler model that can reach similar performance as the original network. By virtue of their reduced complexity, these simpler models can provide insights into how the original network worked and why it made one decision versus another. In testing this methodology on two massive datasets, the ProfWeight model was able to produce more explainable decisions, while maintaining a high level of accuracy.
Anticipating adversarial attacks: Today’s state-of-the-art machine learning models can achieve unprecedented prediction accuracy, but they are also surprisingly vulnerable to being fooled by carefully-crafted malicious inputs called “adversarial examples.” For instance, a hacker can imperceptibly alter an image such that a deep learning model is fooled into classifying it into any category the attacker desires. New attacks of this sort are being developed every day across a wide range of tasks, from speech recognition to natural language processing.  As a key step toward safeguarding against these attacks, IBM Research AI has proposed a new attack-agnostic, certified robustness measure called CLEVER (Cross Lipschitz Extreme Value for nEtwork Robustness) that can be used to evaluate the robustness of a neural network against attack. The CLEVER score estimates the minimum attack “strength” required for an attack to be successful at fooling a given deep network model, making it easier to reason about the security of AI models, and providing directions for detecting and defending against attacks in deployed systems.
8-bit precision accelerates training: Deep learning models are extremely powerful, but training them requires enormous computational resources. In 2015, IBM presented a landmark paper describing how to train deep learning models using 16-bit precision (half the more typically used 32-bit precision) with no loss of accuracy. IBM researchers have now demonstrated for the first time the ability to train deep learning models with just 8-bits of precision, while fully preserving model accuracy across all major AI dataset categories, including image, speech, and text. These techniques accelerate training time for deep neural networks by 2-4x over today’s 16-bit systems. Although it was previously considered infeasible to further reduce precision for training, we expect our 8-bit training platform to become a widely adopted industry standard in the coming years.
New neural net approach on the Block: BlockDrop, a new way to speed up inference in very deep neural networks, learns to choose which layers or “blocks” of the deep network to skip, reducing the total computation while retaining accuracy. Using BlockDrop, an inference speedup of twenty percent is attained on average, going as high as thirty-six percent for some inputs, while maintaining the same top-1 accuracy on ImageNet.
Causality will increasingly replace correlations: Everyone knows that the rooster’s crowing at dawn does not “cause” the sun to rise, and that conversely, flipping a switch does cause a light to turn on. While such intuitions about the causal structure of the world are integral to our everyday actions and judgments, most of our AI methods today are fundamentally based on correlations and lack a deep understanding of causality. Emerging causal inference methods allow us to infer causal structures from data, to efficiently select interventions to test putative causal relationships, and to make better decisions by leveraging knowledge of causal structure. In 2019, expect causal modeling techniques to emerge as central players in the world of AI.
Trusted AI will take center stage: This year, a number of organizations responded to data breaches and consumer privacy concerns by establishing ethics advisory boards, and we’ve seen increased research investment in the “pillars of trust” (algorithmic fairness, explainability, robustness, transparency), along with increased efforts in deploying AI for social good. In 2019, we’ll begin to see these efforts become central to how companies build, train and deploy AI technologies. We expect to see special focus on transferring research advances in this space into real products and platforms, along with an emphasis on encouraging diversity and inclusion on technical teams, to ensure that many voices and perspectives guide technological progress.
Quantum could give AI an assist: In 2019 we’ll see accelerated traction in quantum experimentation and research, and new research on how quantum computing can potentially play a role in training and running AI models. A core element of quantum algorithms is the exploitation of exponentially large quantum state spaces through controllable entanglement and interference. As the complexity of AI problems grows, quantum computing—which thousands of organizations are already accessing via IBM’s cloud quantum computing services—could potentially change how we approach AI computational tasks.
",,Person,coal black,backrest,support,backrest,-
,187446750783_10156067568775784,https://www.facebook.com/ibmwatson/posts/10156067568775784,IBM Watson,SharedVideo,,,12/10/18 14:06, ,7937,7937,0,10836,10836,0,238,207,271,5,5,9909,7285,0,0,224,0,0,0,0,1422,1581,0,0,0,10143,,42.0,1.0,,42.0,2.0,156,77.0,,,191,80.0,,,1,4.0,,1,4.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2GhZPhy,187446750783_10156061701585784,https://www.facebook.com/ibmwatson/posts/10156061701585784,"Using Watson, a digital-only bank created a chatbot called RoboBrain that improved response rates for customers by more than 40%: ",Link,,,12/7/18 19:57, ,8806,8806,0,12115,12115,0,217,144,197,5,5,8654,6167,0,0,150,0,0,0,0,0,0,0,0,0,0,25,91.0,7.0,36,91.0,11.0,74,85.0,,,107,90.0,,,2,3.0,,2,3.0,,"Customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank",https://d1902livswy8rb.cloudfront.net/dimg/800x800/dimg/dreamstime_s_34490308-2.jpg,https://www.cmo.com.au/article/635526/ubank-ai-vision-expands-rollout-robobrain/,joy,0.091405,positive,0.832449,response rates,Person,response rates,Person,joy,0.124299,positive,0.566024,"IBM Watson capabilities, one-stop, one-screen solution, solution","Person, Company",IBM Watson capabilities,Person,joy,0.57428,positive,0.701942,launch of RoboBrain,"Person, Company, Person, Person, Company, Person, Company, Location","UBank’s CMO says the launch of RoboBrain, a hyper-personalised cognitive assistant, is dramatically improving customer response times and a massive leap forward in the bank’s AI journey.   
The digital-only banking group took its first steps into AI last year with the launch of RoboChat, a chatbot designed to help customers through the home loan application process. In less than 12 months, RoboChat has been asked more than 22,000 questions, with over 80 per cent answered correctly on the first attempt.   
“After the success of RoboChat, we wanted to find a solution that our people could use and benefit from directly,” UBank CMO, Jo Kelly, told CMO. 
This led to RoboBrain, designed and developed by UBank’s North Sydney-based team in collaboration with IBM. The customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank.   
In the past, the UBank team had to move between a handful of different platforms in order to find the answer to customer questions, Kelly explained. Consolidating a number of the bank’s knowledge bases, RoboBrain provides immediate information for employees in one spot.   
“Now, thanks to RoboBrain, we’ve got a one-stop portal of information where we can search information and find the answer almost instantly,” she said.     
By typing in a question in natural language, the UBank team on the phone or on LiveChat can find answers in approximately two seconds to thousands of questions asked by customers, such as “what was the interest rate in June 2011?” or “how do I set up a regular transfer?”.    
Kelly said RoboBrain improves on the overall customer experience by making interactions as convenient as possible.    
“Customers don’t want to spend their time talking to their bank, so when they get in touch with us over LiveChat, Secure Mail, Facebook or on the phone, we need to meet their expectations and help them as quickly as we can,” she said.   
Since going live, RoboBrain has sped up processes for more than 40 per cent of UBank’s 200 employees, and improved response time for more than 400,000 Australian customers, cutting down search time by 33 per cent.   
For Kelly, AI is a major focus area - and a key to marketing success - at the digital bank.   
“We see AI as a key enabler in disrupting the home loan market and changing the end to end process of buying a home from applying to approval and then settlement. We believe it’s important to embrace technologies to adapt to the ever-increasing expectations of our customers and create a more personalised experience,” she said.   
Asked what’s next in terms of AI, Kelly said UBank flagged more innovation around customer service. RoboBrain has been trained to display and share complex information in real-time, and like any AI-based solution, the more it’s used, the smarter it gets, she noted.   
RoboBrain will learn and improve by adapting to the search terms used, based on the rating applied, and through ongoing training by UBank experts.   
",launch of RoboBrain,Person,blue,liquid metal reactor,apparatus,nuclear reactor,liquid metal reactor
https://ibm.co/2SjM5oe,187446750783_10156052501725784,https://www.facebook.com/ibmwatson/posts/10156052501725784,How does AI make its decisions?  How does the technology explain reasoning behind its choices? Read more via PCMag: ,Link,,,12/3/18 10:41, ,9321,9321,0,12186,12186,0,543,99,124,10,10,10479,7993,0,0,145,0,0,0,0,0,0,0,0,0,0,33,414.0,1.0,36,414.0,1.0,30,74.0,,,48,76.0,,,2,8.0,,2,8.0,,"In numerous scenarios, the opacity of deep-learning algorithms causes trouble. A clearer understanding of how AI decisions are made is crucial to moving the technology forward. 

",https://i.pcmag.com/imagery/articles/01DRGuhZFU4gzkMLBGY4CMZ-9.fit_lim.size_1200x630.v_1569485083.png,https://www.pcmag.com/news/the-next-step-toward-improving-ai,fear,0.28589,neutral,0,technology,Person,technology,Person,sadness,0.444406,positive,0.507703,"clearer understanding, numerous scenarios",Person,clearer understanding,Person,joy,0.515401,positive,0.308187,,"Person, Person, Company, Person","In 2017, a Palestinian construction worker in the West Bank settlement of Beiter Illit, Jerusalem, posted a picture of himself on Facebook in which he was leaning against a bulldozer. Shortly after, Israeli police arrested him on suspicions that he was planning an attack, because the caption of his post read ""attack them.""
Except that it didn't. The real caption of the post was ""good morning"" in Arabic. But for some unknown reason, Facebook's artificial intelligence–powered translation service translated the text to ""hurt them"" in English or ""attack them"" in Hebrew. The Israeli Defense Force uses Facebook's automated translation to monitor the accounts of Palestinian users for possible threats. In this case, they trusted Facebook's AI enough not to have the post checked by an Arabic-speaking officer before making the arrest.
The Palestinian worker was eventually released after the mistake came to light—but not before he underwent hours of questioning. Facebook apologized for the mistake and said that it took steps to correct it.
Advances in deep learning and neural networks have improved the precision of AI algorithms and enabled the automation of tasks that were previously thought to be the exclusive domain of human intelligence. But the precision in performance comes at a cost to transparency. Unlike with traditional software, we don't always have an exact idea of how deep-learning algorithms work. Troubleshooting them is very difficult, and they often fail in unanticipated and unexplainable ways. Even the creators of deep-learning algorithms are often hard-pressed to investigate and interpret the logic behind their decisions.
The failure of Facebook's machine-translation system is just one of the many cases in which the opacity of deep-learning algorithms has caused larger troubles.
What's widely known as the AI ""black box"" problem has become the focus of academic institutions, government agencies, and tech companies that are researching methods to explain AI decisions   or to create AI that is more transparent and open to investigation.
Their efforts will be crucial to the development of the AI industry—especially as deep learning finds its way into critical domains where mistakes can have life-changing consequences.
The Rise of Deep Learning
In classical approaches to creating software, developers meticulously specify the rules that define the behavior of a system. In contrast, deep-learning algorithms develop their behavior by examining and comparing numerous examples. The concept and science behind deep learning has existed for decades, but only in recent years has the abundance of data and compute resources pushed it from research labs and academic papers into practical domains. And with its rise in popularity, deep learning has introduced changes in the way developers create software.
For Kate Saenko, who has been involved in computer vision since the early 2000s, those changes are very tangible. Computer vision is a field of artificial intelligence that enables computers to process and understand the context and content of digital images and videos. It is the technology used in a wide range of fields, including image classification, facial recognition, and the automated diagnosis of MRI and X-ray images. It's one of the fields where rules-based programming has historically struggled, because the number of rules developers have to write down are virtually endless.
""Back in those days, we had a very different approach, where first you designed your features, and a lot of thought and design process went into that,"" said Saenko, an associate professor at the Department of Computer Science at Boston University.
For instance, if developers wanted to detect cats, they had to write code manually that could probe pictures for cat features such as heads or tails. ""You designed these features first, and then you designed methods to extract those features. And then you would do machine learning on top of the features,"" Saenko said.
The process was arduous and lengthy because each of those features can vary in shape and size, depending on the species of the animal and the angle at which the picture was taken.
In contrast, a deep-learning algorithm that is meant to classify pictures as ""cat"" or ""not cat"" only needs to be given many cat pictures. It will create its own rules to determine how to detect cats in pictures and performs much better than previous methods that involved a lot of manually written features. In 2012, researchers from the University of Toronto used deep learning for the first time to win a famous computer-vision competition   and improve the field by a large margin. Deep learning has since found its way into many other fields, including voice recognition,  natural language processing  , fraud detection and  arts  .
""The reason deep learning is so successful is because there's very little design that goes into neural networks,"" said Saenko. ""We just let the machine discover the most useful pattern from raw data. We're not going to tell it what to look for. We're not going to tell it any high-level features. We let it search through all of its training data and find those patterns that lead to the highest accuracy in solving the problem.""
The Challenges of Debugging Deep-Learning Software
The benefits in accuracy that deep learning provides is not without its trade-offs.
""In classical computer programming, you have precision with the algorithm. You know exactly in mathematical terms what you are doing,"" said Sheldon Fernandez, CEO of DarwinAI, an Ontario-based AI company. ""With deep learning, the behavior is data driven. You are not prescribing behavior to the system. You are saying, 'here's the data, figure out what the behavior is.' That is an inherently fuzzy and statistical approach.""
This means that when you let a neural network develop its own behavioral model, you are basically losing visibility into its reasoning process. And mostly, the inner parameters and connections that neural networks develop are so numerous and complex that they become too difficult for humans to understand.
A simplified view of how data flows in neural networks (Source: Wikipedia)
As Saenko explained, when using deep learning, engineers must choose ""between how much human-imposed, top-down design you put into something to make it more interpretable versus how much performance you lose as a result of that.""
Also, the reasoning that a neural network develops does not necessarily reflect that of humans  , even though it produces accurate results most of the time.
""The real challenge of deep learning is that it's not modeling, necessarily, the world around it. It's modeling the data it's getting,"" Fernandez said. ""And that modeling often includes bias and problematic correlations. It can include nonsensical correlations. And all those things can find [their] way into the behavior of the system.""
A while ago, Seanko developed a deep-learning algorithm that captioned images and videos with impressive accuracy. The problem was that her captioning application had developed a bias toward certain types of decisions, a problem that is common in deep-learning algorithms  . For instance, in cooking videos, it often captioned kitchen workers as women—even when they were men. On the other hand, in science videos, the algorithm was more inclined to label scientists as men. But she couldn't determine for certain why the network was making the mistakes. And without being able to find the reasons of those errors, she couldn't fix them.
In some cases, the opacity of AI algorithms can cause frustration. But in other cases, not being able to explain the reasoning behind AI decisions can have more serious consequences.
In 2017, Fernandez, then a computer scientist at Avande, an IT consulting company, was using deep learning to help a bank in the UK detect fraudulent transactions. They basically trained the deep neural network with all the historical data of the bank and let it figure out for itself the patterns that defined fraudulent transactions.
Their algorithm was able to detect fraud 3 or 4 percent better than the client's best-in-class system. The problem was that they had no idea why it was performing better. ""We had no insight into what data the neural network was triggering off in order to make better predictions,"" Fernandez said.
Naturally, the client could not confer sensitive financial decision-making onto an automated system if they couldn't understand the logic behind its decisions.
The financial industry is one of several domains where interpretability has become a requirement for the use of AI algorithms in critical decisions. Other fields where the opacity of deep learning has become a hurdle include health care and medicine, hiring and human resources, criminal justice, and the military. In all these domains, a bad decision can have a negative and irreversible effect on the career, health, or life of one or many humans and can have severe legal consequences for the person who makes those decision. That's why experts are generally skeptical about trusting an automated system to make decisions on their behalf.
Moreover, European Union's General Data Protection Regulation   (GDPR), which went into effect in May, requires organizations that use automated decision-making to provide meaningful information about the information and logic involved in those decisions when users or customers demand it. The GDPR, which is legally binding for any company and organization that does business in the EU zone, is considered a  de facto  gold standard for all tech companies handling personal information.
""One of the real powers of explainable AI is to illustrate how the AI is triggering data points to reach a decision, and surfacing those data points to a human for verification,"" Fernandez said.
Investigating the AI Black Box
There are generally two pathways toward making decisions made by neural networks interpretable. The first, called ""local explanations,"" tries to understand the motives and parameters behind individual decisions made by an AI algorithm. ""Global explanations"" try to describe the general reasoning logic of an AI model.
After her neural networks failed to reveal the reasons they were mislabelling videos and pictures, Saenko and a team of researchers at Boston University engaged in a project to find the parameters that influenced those decisions.
What came out of the effort was RISE, a method   that tries to explain to interpret decisions made by AI algorithms .  Short for "" randomized input sampling for explanation of black-box models  ,"" RISE is a local explanation model.
When you provide an image-classification network with an image input, what it returns is a set of classes, each associated with a probability. Normally, you'd have no insight into how the AI reached that decision. But RISE provides you with a heatmap that describes which parts of the image are contributing to each of those output classes.
For instance, in the above image, it's clear that the network in question is mistaking brown sheep for cows, which might mean that it hasn't been trained on enough examples of brown sheep. This type of problem happens often. Using the RISE method, Saenko was able to discover that her neural networks were specifying the gender of the people in the cooking videos based on pots and pans and other objects that appeared in the background instead of examining their facial and physical features.
The idea behind RISE is to randomly obscure parts of the input image and run it through the neural network to observe how the changes affect the output weights. By repeating the masking process multiple times, RISE is able to discern which parts of the image are more important to each output class.
Since RISE works by manipulating inputs, it is a ""black box"" explanation method, which means it is model-agnostic: It can work with any AI model, without the need to access its inner workings or its training examples.
Methods such as RISE can also help build trust with the end users of AI algorithms in fields such as radiology. ""When you give a doctor and AI image model that can look at a medical image or an MRI and detect cancer with very high accuracy, they often still don't trust it because they don't know why it's making that decision,"" Saenko said. RISE can clarify why an AI is making a diagnosis by pointing out which parts of the image it is considering relevant to the symptoms it is reporting.
Looking for What Isn't There
Most AI explanation methods focus on what's present in the input. But sometimes, focusing on what's missing can provide a better picture of the reasoning behind AI decisions.
""If you want to describe a colleague to me, a very natural kind of explanation you might use is 'He has long hair and is tall, but he doesn't wear glasses ,'"" said Amit Dhurandhar, scientist at IBM Research. ""However, none of the methods that do local explanations of AI models explicitly capture this idea.""
Contrastive Explainable Method   (CEM), a joint project by researchers at IBM and the University of Michigan, tries to describe decisions made by neural networks by pointing out what it's not seeing in the input. Like RISE, CEM is a local explanation method, which means it tries to interpret individual decisions made by an AI algorithm.
Basically, like other local explanation methods, CEM tries to tell you why a certain neural network has classified your input in a particular way. But it also tells you what could be added to the input to change its class. For instance, the image below was extracted from a classifier for digits that was run through the CEM probe. On the left is the original input image and the original prediction of the neural network. The middle images highlight in cyan which parts of the image contributed to the original prediction. On the right, the pink highlights show the minimal additions that could lead to a change in prediction.
As Dhurandhar explained, medical diagnosis is one of the fields that stands to benefit much from this explanation method, because doctors reach conclusions not only by looking for the symptoms that are present but also by looking for those that are absent.
""If you go to a doctor, they will register facts such as whether your heart rate was normal. But they will also write things like arrhythmia was absent and a bunch of things that were not present,"" Dhurandhar said. ""The reason is that in your next checkup, if you have an issue, the doctor will know what you were checked for. Also, if you switch a doctor, it's easy for the other person to know your diagnosis process.""
Therefore, with methods like CEM, a doctor will be better positioned to probe an automated decision both for the positive and negative contributing factors.
Understanding the General Behavior of AI Models
While local models are helpful in investigating individual AI decisions, some domains require full transparency of the behavioral model of the software they use.
A few years ago, Dhurandhar developed a deep-learning model that helped a semiconductor-chip-manufacturing company predict which chips would likely become defective further down the production line. The model performed much better than the company's previous prediction software and enabled it to discard or fix chips at early production stages and improve its yield by several percent, which translated to millions of dollars in costs savings per year.
But the engineers controlling the system, whose jobs were on the line, weren't willing to let the AI make decisions without knowing exactly how it worked. What they wanted was to improve their original software, not to replace it with a black box that, albeit more accurate, would not provide them with insights on how it worked.
""Since in many domains, there's a human making the final decision—even if you have a higher performing model, if the person doesn't understand, the overall performance of the system might be lower than a lower-performing model that the person is able to understand,"" Dhurandhar said.
Improving Simple Models with Confidence Profiles  , another AI-explanation method Dhurandhar helped develop with other researchers at IBM, addresses this issue by trying to transfer the behavior of neural networks to interpretable software structures. This is a global explanation model, which means instead of trying to interpret individual decisions, it tries to paint a general picture of how an AI model works.
Dhurandhar describes the ""improving simple models"" method as trying to achieve ""best of both worlds,"" which means to benefit from the improvements that a neural network provides while adhering to other constraints that domain experts impose.
The method involves inserting software probes in the various layers of a neural network and monitoring its behavior as it trains on examples and evolves. In later stages, those probes try to replicate the observed behavior of the network on a decision tree, rule-based structure, or another model that is interpretable. In the case of the semiconductor company, Dhurandhar was able to map the behavior of the neural network on the software structure that the company already used.
The resulting model did not perform as well as the neural network but managed to improve the performance of the company's original software considerably while also maintaining its interpretability. Effectively, the engineers were willing to trade some of the accuracy of the neural network; instead, they gained full visibility and control on how their prediction software worked.
Using AI to Understand AI
Fernandez, who co-founded DarwinAI with University of Waterloo professor Alex Wong, reached AI explainability through a different approach. As an academic, Wong, who had years of experience in computer vision, had worked on a technique called evolutionary synthesis  , (it's where the name DarwinAI comes from). Evolutionary synthesis is meant to make neural networks more efficient by treating them like organisms that evolve over time and shed their redundant components to become efficient.
At DarwinAI, Wong helped develop Generative Synthesis, a new technology that builds on the ideas of evolutionary synthesis and takes it a step further.
""The idea behind Generative Synthesis is to take artificial intelligence itself and see if we can better understand and develop neural networks,"" Fernandez said.
Generative Synthesis uses machine learning to probe and understand neural networks in a fundamental way. It then develops a complex mathematical representation of the model, which it uses to generate a second neural network that is just as accurate as the first one but is also more compact and faster. Making neural networks smaller makes them deployable in UAVs (unmanned aerial vehicles), driverless cars, and other edge environments   that are resource-constrained or need real-time access to AI functionality.
But a byproduct of this approach is a thorough understanding of the way the neural network operates. By having monitored and documented the entire evolution of a neural network, DarwinAI's Generative Synthesis approach was able to point out the factors and data points that influenced each of the decisions its neural networks made.
""We had a kind of roundabout way of getting to the technology, but it's really powerful in trying to understand how these neural networks are making decisions,"" Fernandez said.
""There are correlations that are demonstrably bad, that just shouldn't happen, such as bias. We need to recognize it in the system and eradicate it,"" Fernandez said. In the future, explainability methods can help find and fix those errors before they lead to an unjustified arrest or an unfairly declined loan.
But the benefits of interpreting deep-learning models expand beyond troubleshooting and fixing errors. In some cases, they can help shed light on previously unknown aspects of the domains they're deployed in.
""Explainability can also work in another direction. It can also give you insights into correlations that you didn't know existed,"" Fernandez said. During his work on applying deep learning to the banking sector, Fernandez's exploration of interpretable networks helped uncovered new insights on the characteristics of fraudulent transactions.
For example, thanks to explainable AI, they discovered that if a person is using the Chrome browser, the chances of a transaction being fraudulent is higher than if they're using Internet Explorer or Safari. And that's because as technical people, cybercriminals are much more likely to use Chrome rather than their operating system's preinstalled browser.
In another case, a travel agency was able to discover that some people were interested in hotels located on street corners. They later added this as an option for their clients.
""Getting these insights is just as important as eradicating bias, because these insights are valuable to business,"" Fernandez said.
",,Person,blue,zodiac,measuring instrument,meter,odometer
,187446750783_10156047958000784,https://www.facebook.com/ibmwatson/posts/10156047958000784,&quot;I really believe we are the leader in AI for business. Our specialization is to know what it takes for the enterprise to operate in the world.&quot; – IBM CEO Ginni Rometty via The Wall Street Journal.,Link,,,12/1/18 9:14, ,11796,11796,0,16509,16509,0,330,216,246,5,6,11419,8193,0,0,251,0,0,0,0,0,0,0,0,0,0,24,134.0,2.0,24,138.0,2.0,140,88.0,,,156,90.0,,,3,3.0,,2,3.0,,,,,joy,0.465361,positive,0.844502,"IBM CEO Ginni Rometty, Wall Street Journal, specialization","Person, Person, Company",IBM CEO Ginni Rometty,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2FOVHWw,187446750783_10156043872625784,https://www.facebook.com/ibmwatson/posts/10156043872625784,Is AI technology ableist? Take a look at how IBM researcher Shari Trewin is helping her team develop an initiative exploring new design processes and technical methods to mitigate machine bias against people with disabilities. ,Link,,,11/29/18 10:20, ,7286,7286,0,9422,9422,0,88,51,56,7,7,8517,6566,0,0,70,0,0,0,0,0,0,0,0,0,0,6,38.0,,6,38.0,,25,28.0,,,28,28.0,,,4,3.0,,4,3.0,,IBM researcher Shari Trewin on why bias against disability is much harder to squash than discrimination based on gender or race.,https://cdn.technologyreview.com/i/images/doug-maloney-468778-unsplash.jpg?cx=0&cy=103&cw=2000&ch=1125&sw1200,https://www.technologyreview.com/s/612489/can-you-make-an-ai-that-isnt-ableist/,anger,0.110956,positive,0.550527,"IBM researcher Shari Trewin, new design processes","Person, Person, Company",IBM researcher Shari Trewin,Person,sadness,0.365034,negative,-0.830281,IBM researcher Shari Trewin,"Person, Company",IBM researcher Shari Trewin,Person,joy,0.530996,negative,-0.517577,group of people,"Person, Company","Artificial intelligence has a well-known bias problem, particularly when it comes to race and gender. You may have seen some of the headlines: facial recognition systems that fail to recognize black women, or automated recruiting tools that pass over female candidates. 
But while researchers have tried hard to address some of the most egregious issues, there’s one group of people they have overlooked: those with disabilities. Take self-driving cars. Their algorithms rely on training data to learn what pedestrians look like so the vehicles won’t run them over. If the training data doesn’t include people in wheelchairs, the technology could put those people in life-threatening danger. 
For Shari Trewin, a researcher on IBM’s accessibility leadership team, this is unacceptable. As part of a new initiative, she is now exploring new design processes and technical methods to mitigate machine bias against people with disabilities. She talked to us about some of the challenges—as well as some possible solutions. 
The following has been edited for length and clarity. 
Why is fairness to people with disabilities a different problem from fairness concerning other protected attributes like race and gender? 
Disability status is much more diverse and complex in the ways that it affects people. A lot of systems will model race or gender as a simple variable with a small number of possible values. But when it comes to disability, there are so many different forms and different levels of severity. Some of them are permanent, some are temporary. Any one of us might join or leave this category at any time in our lives. It’s a dynamic thing. 
About one in five people in the US currently have a disability of some kind. So it’s really prevalent but hard to pin down into a simple variable with a small number of possible values. There might be a system that discriminates against blind people but not against deaf people. So testing for fairness becomes much harder. 
Disability information is also very sensitive. People are much more reluctant to reveal it than gender or age or race information, and in some situations it’s even illegal to ask for this information. So a lot of times in the data you’re much less likely to know anything about disabilities that a person may or may not have. That also makes it much harder to know if you have a fair system. 
I wanted to ask you about that. As humans, we decided the best way to avoid disability discrimination is to not reveal disability status. Why wouldn’t that hold true for machine-learning systems? 
Yeah, that’s the first thing people think of: if the system doesn’t know anything about individuals’ disability status, surely it will be fair. But the problem is that the disability often impacts other bits of information that are being fed into the model. For example, say I am a person that uses a screen reader to access the web, and I’m doing an online test for a job application. If that test program isn’t well designed and accessible to my screen reader, it’s going to take me longer to navigate around the page before I can answer the question. If that time isn’t taken into consideration in assessing me, then anybody who’s using that same tool with a similar disability is at a systematic disadvantage—even if the system doesn’t know that I’m blind. 
So if there are so many different nuances to disability, is it actually possible to achieve fairness? 
I think the more general challenge for the AI community is how to handle outliers, because machine-learning systems—they learn norms, right? They optimize for norms and don’t treat outliers in any special way. But oftentimes people with disabilities don’t fit the norm. The way that machine learning judges people by who it thinks they’re similar to—even when it may never have seen anybody similar to you—is a fundamental limitation in terms of fair treatment for people with disabilities. 
What would work a lot better would be a method that combines machine learning with some additional solution, like logical rules that are implemented in a layer above. There are also some situations where more attention to gathering a more diverse data set would definitely help. Some people are experimenting with techniques where you take out the core of the data and try to train for the outliers. Others are experimenting with different learning techniques that might optimize better for outliers rather than the norm. 
I think it’s only when you start thinking about disability that you start thinking about the diversity of individuals and the importance of outliers. If you don’t have enough gender diversity in your data set, you can fix that. It’s not so easy to fix disability diversity. 
How do you get over the problem of people being private about their disability status? 
Yeah, in order to test a system for fairness, you need some data. And people with disabilities providing that data is a social good, but it’s a personal risk. People with disabilities are often easily identified even in anonymous data, just because they’re so unique. So how do we mitigate that? We’re still figuring that out. 
What are your greatest concerns about this problem? 
Oftentimes AI systems are optimizing something that is not the wellbeing of the people who are affected by the decisions. That impact needs to have much more prominence in the design process, so that we’re not just introducing a system that looks at how much money we’re saving or how efficiently we’re processing people. We need new ways of measuring systems that incorporate the aspect of impact on the end users, especially if it’s a disadvantaged group. 
How would we do that? 
Testing for fairness is one way of measuring that impact. Including the disadvantaged group in the design process and hearing their concerns is another. Even explicitly including some metric for stakeholder satisfaction that you could measure through interviews or surveys—that sort of thing. 
What are the things that you’re excited about in this area of research? 
AI technologies are already changing the world for people with disabilities by providing them with new capabilities, like applications that tell you what’s in your field of view when you point your phone. 
I think that if we do it right, there’s a real opportunity for AI systems to improve on previous human-only systems. There’s a lot of discrimination and bias and misunderstanding of people with disabilities in society today. If we can find a way to produce AI systems that eliminate that kind of bias, then we can start to change the treatment of people with disabilities and reduce discrimination. 
",group of people,Person,gray,wheelchair,furniture,seat,chair
https://ibm.co/2EvG5GH,187446750783_10156039897825784,https://www.facebook.com/ibmwatson/posts/10156039897825784,"It's here – IBM's biggest conference of the year is open for registration. At Think 2019, explore the technologies that are redefining industries. From captivating solutions to transformative outcomes, technical deep dives to expert round tables, we're offering more ways to learn about your favorite topics through a personalized journey.  Get your ticket today: ",Video,,,11/27/18 10:02, ,9374,9374,0,12439,12439,0,281,193,248,2,2,8742,6686,0,0,172,216,232,0,0,2181,2439,0,0,4116,32937,36,92.0,4.0,39,93.0,5.0,91,34.0,,88.0,105,35.0,,108.0,,2.0,,,2.0,,Think 2020 is the IBM premier client and developer conference that will be held May 5-7.,https://www.ibm.com/events/shared/img/think2020/think-og.jpg,https://www.ibm.com/events/think/register/?cm_mmc=OSocial_Facebook-_-Watson+and+Cloud+Platform_Watson+Core+-+Platform-_-WW_WW-_-Watson+FB&cm_mmca1=000030JN&cm_mmca2=10001383&cm_mmca3=M00027224,joy,0.66413,positive,0.998502,"technical deep dives, transformative outcomes, expert round tables, IBM's biggest conference",Company,technical deep dives,Company,joy,0.121322,neutral,0,IBM premier client,Company,IBM premier client,Company,joy,0.173878,positive,0.521615,"IBM Think, health of IBM, Business Partners","Company, Company, Organization","The health of IBM's clients, employees and partners is our primary concern. In light of global precautions for the COVID-19 Coronavirus, and building upon recommendations from the World Health Organization, IBM is taking a new approach to its signature events.
""IBM Think 2020,"" the company's premier client and developer conference, and PartnerWorld for our Business Partners, will be recreated as a global, digital-first event, to still be held on May 5-7.
Think 2020 will be an exciting combination of live streamed content, interactive sessions and certifications and locally hosted events, which will highlight IBM's technology and industry expertise for developers and clients without the risk of travel. We will share updates here: ibm.com/events/think 
IBMers are keeping those directly affected by this virus in our thoughts.
Will IBM refund my registration fees?
Attendees who were registered for Think will be issued a full refund and automatically be registered for Think Digital Event Experience at no charge.
Attendees who were registered for Think 2020 will automatically be registered for the Think 2020 Digital Event Experience at no charge. If you had not yet registered, you can register for the Digital Event Experience now 
Yes. PartnerWorld content will be integrated into the overall program and will take place on May 5.
What happens if a Business Partner registered with a 2020 or 2019 voucher?
Business Partner attendees who registered for Think with a 2020 or 2019 voucher will be issued a refund for any portion of the tuition they paid after the voucher discount was applied (i.e., Server Systems Competency, Storage Systems Competency, PGI, PartnerWorld and Value Pack vouchers). They will also be automatically registered for Think 2020 Virtual Experience at no charge. In addition, vouchers will be reinstated for those Business Partners who registered with a 2020 voucher. However, 2019 vouchers that were used to register for the event will not be reinstated because they expired on December 31, 2019.
Will I be able to apply my conference pass to Think 2021?
Unfortunately, we cannot transfer your registration to Think 2021.
Yes. IBM will reimburse our partners for their sponsorship fees.
If you booked a hotel in the IBM block as part of registration, IBM will automatically cancel your hotel reservation. You will receive a cancellation notice via email. There is no need to contact the hotel directly to confirm the cancellation.
Important note: if you booked a hotel outside of the IBM block you are responsible for contacting the hotel directly.
",IBM Think,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2qCKw8I,187446750783_10156037908200784,https://www.facebook.com/ibmwatson/posts/10156037908200784,Tomorrow at 11:30am ET: AI is changing the way professionals do work by streamlining repetitive tasks to let you focus on what's important. Join WIRED Editor in Chief Nicholas Thompson and a series of panelists from IBM Watson leaders and clients in a virtual summit to learn how industries of all kinds are finding productivity and more efficient results with AI. REGISTER: ,Video,,,11/26/18 11:27, ,6093,6093,0,8005,8005,0,131,103,136,2,2,7187,5470,0,0,107,156,163,0,0,1126,1221,0,0,4035,25982,5,31.0,,5,31.0,,60,9.0,,54.0,69,10.0,,57.0,,2.0,,,2.0,,"Tuesday, November 27, 2018 at 11:30 AM Eastern Standard Time. ",,https://event.on24.com/wcc/r/1847677/235C0438C88FC04E670CC0597D1551CB?partnerref=Facebook,joy,0.477136,positive,0.602327,"Chief Nicholas Thompson, IBM Watson leaders","Person, Company",Chief Nicholas Thompson,Person,joy,0.2755,neutral,0,"Eastern Standard Time, November",,Eastern Standard Time,,joy,0.177795,neutral,0,Future of Work Virtual Summit,,"AI & the Future of Work Virtual Summit: REPLAY: www.ibm.com/watson/future-of-work-full
",Future of Work Virtual Summit,, , , , , 
,187446750783_10156035934220784,https://www.facebook.com/ibmwatson/posts/10156035934220784,IBM Watson,SharedVideo,,,11/25/18 10:03, ,6678,6678,0,8857,8857,0,186,170,218,6,6,8247,6173,0,0,167,0,0,0,0,1071,1121,0,0,0,116350,,23.0,1.0,,23.0,1.0,169,1.0,,,217,1.0,,,4,2.0,,4,2.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2yg49qQ,187446750783_10156033920505784,https://www.facebook.com/ibmwatson/posts/10156033920505784,"In a recent IBM report, business leaders explained just how they see AI infiltrating their organization. Here are the top five areas where business executives said AI would drive the most value this year via TechRepublic: ",Link,,,11/24/18 10:18, ,9292,9292,0,12255,12255,0,182,131,145,7,7,10714,8228,0,0,161,0,0,0,0,0,0,0,0,0,0,16,51.0,1.0,16,54.0,1.0,25,110.0,,,32,113.0,,,4,3.0,,4,3.0,,"A recent IBM study focused on the business importance of IT, and how AI is growing in the workplace.",https://tr1.cbsistatic.com/hub/i/r/2018/09/27/d26d3e2d-c0ec-4551-ad45-e5953a32ac78/thumbnail/770x578/e640750a63ba7d799b23269669582d77/ceotech.jpg,https://www.techrepublic.com/article/ceos-5-areas-where-ai-will-drive-the-most-value-in-2018/,anger,0.270172,neutral,0,"recent IBM report, business leaders, business executives","Person, Company",recent IBM report,Person,joy,0.364615,positive,0.617477,recent IBM study,"Company, Person",recent IBM study,Company,joy,0.419643,positive,0.435501,Customer service,"Person, Company, Quantity, Organization"," 	As artificial intelligence (AI) matures and makes good on its promises, the technology is rapidly finding its way into more and more enterprise organizations. As hardware becomes commoditized, AI is emerging as the competitive differentiator for consumer-facing and B2B businesses alike.
 	In a  	recent IBM report, conducted in partnership with Oxford Economics, business leaders explained just how they see AI infiltrating their organization. According to the report, some 93% of outperforming businesses are considering AI adoption, and many organizations are moving beyond the question of whether or not to adopt the technology, to how they'll implement it.
 	However, AI won't have an equal impact across all business functions. Here are the top five areas where business executives said AI would drive the most value in 2018 (and the percentage of leaders who listed it):
 	 	SEE: 2019 IT Budget Research Report: IT spending increases due to business conditions, security, and revenue opportunities (Tech Pro Research)
 	In areas like IT, AI-enabled assistants could help perform help desk operations, while threat detection algorithms could improve the effectiveness of security, the report said. Customer service is a common pilot area for AI projects, as virtual chat bots streamline the process. Innovation will serve as a center of excellence for AI, and the technology will help with fraud detection and risk management.
 	However, challenges to AI adoption do exist. Primarily, this will show itself in the poor availability of skilled resources or employees with the proper technical skills, as noted by 63% of those surveyed.
 	""As the demand for data scientists and other AI experts increases, employee retention risks
 	also rise,"" the report said. ""Startups are aggressively poaching AI talent from academia and established corporations. And while constrained candidate pools do not necessarily equate to a zero-sum game, organizations also will need to make more with what they already have.""
 	Regulatory constraints were cited by 60% of respondents, while legal and privacy concerns over the use of customer data were top of mind for 55%. One of the biggest challenges, the report noted, was that businesses must be transparent and open with their processes while protecting their users' privacy as strongly as they can.
 	In order to get started on your AI journey, IBM shared four steps from a previous implementation guide:
",Customer service,Person,blue,fountain,platform,stage,-
https://ibm.co/2TvRGZH,187446750783_10156026646880784,https://www.facebook.com/ibmwatson/posts/10156026646880784,VMWare is integrating IBM Watson across its support portals to transform customer support. Learn more about what the collaboration entails from our blog: ,Link,,,11/20/18 18:11, ,6841,6841,0,8805,8805,0,90,57,63,4,4,7939,6075,0,0,73,0,0,0,0,0,0,0,0,0,0,6,34.0,,6,34.0,,19,40.0,,,22,41.0,,,1,3.0,,1,3.0,,We are proud to announce VMWare is integrating IBM Watson Assistant and Machine Learning across its support portals to transform customer support.,https://www.ibm.com/blogs/watson/wp-content/uploads/2019/05/GettyImages-1035834404.jpg,https://www.ibm.com/blogs/watson/2018/11/vmware-global-services-chooses-ibm-watson-to-improve-customer-service/,joy,0.248565,positive,0.775454,"IBM Watson, customer support, support portals, VMWare","Company, Company",IBM Watson,Company,joy,0.62533,positive,0.979956,"Machine Learning, IBM Watson Assistant, customer support","Company, Company",Machine Learning,Company,joy,0.648785,positive,0.744173,,"Person, Company","When technical issues arise, customers expect immediate results. Time is a factor, and it’s critical to locate the correct engineer to find the appropriate solution for your business need. At VMworld 2018 Europe, we are proud to announce that VMWare is integrating Watson across its support portals to transform customer support.
Using artificial intelligence capabilities from Watson Assistant and Watson Machine Learning, VMware clients needing technical support can get a better support experience, helping them rapidly go from case submission to technical solution.
Instead of static drop downs, VMware customers can leverage Watson to quickly and easily communicate with the portal in natural language. Watson will detect product type and version, analyze issues and match those issues with an expert engineer for faster resolution and a better customer experience.
For example, let’s say your business is having an issue updating your vSphere environment. To find an engineer to match with your case, you would enter MyVMware and immediately start explaining your issue. As you indicate key pieces of information pertaining to your issue, Watson works to identify what could be the cause. Instead of static drop downs, businesses needing technical support can simply communicate within the portal in natural language, as you would ask a question to another person.
Watson is improving the engineer’s experience as well. By understanding cases and logging similarities through learning more over time, Watson will provide engineers with a range of similar cases and their resolutions. This helps to ensure that engineers have all necessary information and background at their fingertips enabling them to resolve issues for clients faster.
IBM Watson and VMware remain committed to delivering new solutions and services to help enterprises advance their cloud journey. In fact, at VMWorld Europe 2018 this week, IBM is announcing new offerings to accelerate enterprise hybrid cloud adoption and help clients unlock new business value.
",,Person,reddish orange,medical practitioner,person,medical practitioner,-
https://ibm.co/2zh2XVv,187446750783_10156025186395784,https://www.facebook.com/ibmwatson/posts/10156025186395784,"To create an ad using artificial intelligence, the creative agency behind Lexus leveraged IBM Watson Visual Recognition to develop the work. Get behind the scenes: ",Link,,,11/19/18 18:04, ,10383,10383,0,13963,13963,0,425,291,328,10,11,11067,8390,0,0,328,0,0,0,0,0,0,0,0,0,0,30,161.0,7.0,31,165.0,10.0,83,219.0,,,103,225.0,,,5,5.0,1.0,5,5.0,1.0,The Japanese innovator teams up with an Oscar-winning director to craft a tale of machines coming to life.,https://cdn.mos.cms.futurecdn.net/QZLsZVyDta83YgaTDCQ7hA-1200-80.jpg,https://www.techradar.com/news/lexus-creates-the-worlds-first-filmed-advert-entirely-scripted-by-ai,joy,0.126609,positive,0.815657,"artificial intelligence, creative agency, IBM Watson Visual Recognition","Company, Company",artificial intelligence,Company,joy,0.670117,positive,0.966827,Japanese innovator teams,Award,Japanese innovator teams,Award,joy,0.616769,positive,0.490883,,"Person, Company, Facility, Person, Company, Person, Person, Organization, Quantity, Person, Person, Location, Person, Person, Person, Person, Person, Person, Quantity, Location","Is there such a thing as the perfect advertisement? We’ve all got our own personal favourites, but Japanese car manufacturer Lexus has taken things up a notch or two by scripting its latest advert using artificial intelligence. And where better to unveil this unorthodox idea than during London’s Social Media Week activities held at the Queen Elizabeth II Conference Centre (QEII) recently, just across from Westminster.
The commercial, Driven by Intuition, is being used as part of the launch campaign for the new Lexus ES executive saloon and was shot by director Kevin Macdonald, whose credits include The Last King of Scotland and the Whitney Houston biopic Whitney. That was the organic part of the process, whereas the storyline itself along with the script was concocted using AI in a collaboration between technical partner Visual Voice, IBM and creative agency The&Partnership.
The end result is an interesting mix and match of ideas, which is hardly surprising as the production process involved the use of IBM’s question-answering computer system Watson to crunch a mountain of data that included 15 years of award-winning luxury adverts. From that, the system was able to construct the framework of the commercial and distill what was needed as the vital ingredients for creating the ‘perfect’ car advertisement. 
Early skepticism
That might sound a bit crazy, but this mash-up of ideas kind of works, much to the relief of all concerned as the bold move is seemingly at odds with much of the Japanese ethos. For director Macdonald the 60-second film was initially a curiosity, but he was lured in by the quirky nature of the project. He’d initially been asked to have a look at the idea on a consultancy basis.
“I was quite skeptical that the computer would write something good, that would make sense,” he says. “In the back of my mind I thought we would end up having to rewrite it. But what came out is what you see.
“A lot of the script was described in great detail too,” adds the director. “It was very different to the way I’d direct something normally. It was an interesting experiment, which is why I did it, one of the first things written by a computer. The thing that struck me most was the AI had written a script about being a machine that’s trying to come alive. It was quite surreal.”
Macdonald says it made him think of Pinocchio and Frankenstein. “You’ve got the Takumi, the Japanese craftsman who’s making the ‘puppet’ whose got to go out into the world, but who doesn’t really understand that world. There was something kind of touching about that. It’s surprising that the computer came up with something quite so full-bodied and emotional. If it had been written by someone at the agency then it would probably have come across as too sentimental, with the tears and the hugging.”
Oddly enough, Macdonald was inadvertently put in quite a good position because ultimately he could always turn around and say to people that the computer told him to do things the way he did. “When you’re making a film there’s that pressure on you because you’re spending peoples money. This was fun because you’re just doing what the computer is telling you to do. It actually made it a much more relaxed and fun shoot than a normal film project.”
The director says that initially there had been approaches to more conventional car advert directors and most had been too scared of the concept. So in the end they asked Macdonald to direct and he decided to go for it. “I thought it seemed like fun and was a bit unusual, whereas a lot of people didn’t really understand it. I think they were worried about something that might not have worked in the conventional sense. To me it was an adventure.” 
“I think it was a bold thing for Lexus to do because it really is an experiment,” adds the director. “I’m sure they’re not going to go on and do every ad that they do like this, but I think it obviously makes a certain degree of sense when you see what they’re trying to communicate about these cars with man and machine working in harmony. To create a commercial that was written by a machine and directed by a human being… there’s something rather nice about that as an idea.”
Pushing boundaries
Michael Tripp, Lexus general manager, quips that when he first saw the footage he thought it might have gone a little too far. The ad is certainly offbeat, thought-provoking and, in many ways, full of contradictions for a Japanese luxury car brand. A good example of this is the tearful Takumi bidding a solemn farewell to the car.
“The initial reaction was interesting,” he says on showing it for the first time to the Lexus bosses over in Japan. “But I think the beauty with this company is that they trust us in our discipline to try and push boundaries without stopping us along the way.”
Alex Newland and Will Nutbrown, the AI developers from Visual Voice look both pleased and a little bit relieved that the commercial has turned out as well they’d hoped for.
“IBM turned out to be a really great partner for this because what AI relies upon is having lots of training data,” says Nutbrown. “So before it can do anything it has to be shown many hundreds of pictures of cars and bicycles and roads to know what they are. That is really only economical for a large organisation like IBM or Google to spend hundreds of thousands of dollars doing that kind of training exercise.”
With only around three months to play with the team didn’t have time on their side either. Which is where having the ability to locate the best tools for the job, in this case IBM’s Watson, allowed them to work smart. “If you’d started this from scratch as a brand new platform then obviously that would not have been possible,” says Newland. “But we’re in this brilliant exciting place where there are lots of people out there doing really great work and that enables us to integrate all sorts of technology to get us to the place we need to be.”
However, after analyzing all of the subsequent data, Newland explains that they realised they were in danger of producing a very dull, formulaic car advert, which wasn't what anybody wanted to do. “It’s a luxury brand, so we also looked at Burberry, Louis Vuitton, Mulberry and analyzed that data too, which allowed us to look at things another way.”
Inherent need for emotion
One of the most interesting things that also came out during the research, which included a study that was commissioned in collaboration with MindX; the applied science division of the University of New South Wales, was the inherent need for emotion. “Although there are things in the advert that are unusual,” says Nutbrown, “and don’t necessarily gel together, they do stimulate an emotional response, which I think is what the AI was attempting to do.”
“I think that was the thing – the machine told us that it wanted to see the Takumi cry,” notes Newland. “Now, culturally, Takumis don’t cry. And I don’t think there are many engineers who cry when they see their cars leave the factory. So that was one thing that left the Lexus people feeling a little bit uncomfortable. But because this whole thing was about being as true to the output as we could be they were brave enough to go with that.”
Did they succeed? Well, take a look for yourself. Following the premiere the film was released across digital, social and cinema channels in Europe to herald the launch of the all-new ES executive saloon early next year.
The launch of the Driven by Intuition advertisement formed just one part of the 9th Annual SMW London Social Media Week activities. A whole raft of talks and networking events covered everything from AI versus Humanity through to Future Tech and all points in between. But, it was that slightly bonkers AI-scripted commercial that really got people talking.
",,Person,ash grey,sedan,vehicle,wheeled vehicle,car
,187446750783_10156022067510784,https://www.facebook.com/ibmwatson/posts/10156022067510784,What is deep learning? How does this subset of AI continue to learn while improving the quality of results? Learn in just two minutes by watching our video.,Video,,,11/18/18 10:20, ,7588,7588,0,10871,10871,0,517,439,694,3,3,6273,4399,0,0,323,254,274,0,0,2772,3168,0,0,6874,116350,53,95.0,2.0,57,108.0,2.0,326,2.0,,250.0,417,2.0,,275.0,,3.0,,,3.0,,,,,joy,0.589888,positive,0.632214,"subset of AI, deep learning","Person, Quantity",subset of AI,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2QuyskO,187446750783_10156020097160784,https://www.facebook.com/ibmwatson/posts/10156020097160784,"A year ago, IBM and MIT joined forces to establish the MIT-IBM Watson AI Lab, a first-of-its-kind industry-academic collaboration backed by a $240m commitment from IBM, founded with the goal of charting the future of AI. Take a look back at the shared history of MIT and IBM, and look forward to where the partnership aims to take AI in the future via Medium: ",Link,,,11/17/18 13:26, ,10379,10379,0,14118,14118,0,233,129,145,4,4,12117,8922,0,0,188,0,0,0,0,0,0,0,0,0,0,24,115.0,1.0,24,120.0,1.0,70,62.0,,,81,64.0,,,2,2.0,,2,2.0,,"Artificial Intelligence (AI), perhaps more than any human invention before it, holds the potential to reshape our world. In just the last few years, we have seen a new explosion of AI development…",https://miro.medium.com/max/1200/1*eC5DmkuyxVI8j-QY4az1jQ.jpeg,https://medium.com/@MITIBMLab/the-shared-history-and-vision-behind-the-mit-ibm-watson-ai-lab-405ce4032013,joy,0.131496,positive,0.732236,"MIT-IBM Watson, shared history of MIT, kind industry-academic collaboration","Company, Organization, Facility, Quantity",MIT-IBM Watson,Company,joy,0.433928,positive,0.809938,"Artificial Intelligence, human invention",Person,Artificial Intelligence,Person,joy,0.627323,positive,0.723822,,"Person, Organization, Company, Person","Artificial Intelligence (AI), perhaps more than any human invention before it, holds the potential to reshape our world. In just the last few years, we have seen a new explosion of AI development, fueled by increased computational power and data availability, and the power of deep learning. New AI methods and startups are springing up daily, and the excitement around AI is palpable. At the same time, as in any scientific endeavor, there are many paths forward and challenges that remain. AI is poised to touch almost every aspect of our lives, but, for it to do so, we must sustain the pace of discovery and steer that progress in ways that serve us all.
It is against this backdrop that IBM and MIT have joined forces to establish the MIT-IBM Watson AI Lab, a first-of-its-kind industry-academic collaboration backed by a $240m commitment from IBM, founded with the goal of charting the future of AI. Today, as we celebrate the one year anniversary of the Lab’s announcement, we take a moment to both look back at the shared history of MIT and IBM, and to look forward to where we aim to take AI in the future.
What has brought us here: From 1955 to 2018
The term “artificial intelligence” was coined in a 1955 workshop proposal by IBMers Nathaniel Rochester and John McCarthy, along with Claude Shannon and Marvin Minsky — all of whom would go on to become iconic MIT faculty. At the time, IBM was building some of the earliest practical computers and, together with their MIT colleagues, they dreamed about how they could be used. Their work, standing on the shoulders of Charles Babbage, Ada Lovelace, Alan Turing, and others, established AI as a field of science.
Despite its initial promise and projections of rapid progress, AI research has experienced alternating periods of excitement and disillusionment over its sixty-plus year history. Within this period, we have experienced several “AI winters,” when hype outstripped reality and technological progress stalled, causing research investment to dry up, sometimes for up to decades at a time.
In this decade, AI has re-emerged with a new vigor, ushering in a new “AI Spring.” While previous cycles of excitement for AI have been promising but brief, this moment is arguably different. Today, AI technology has reached a new threshold of maturity that allows the business world to derive real and measurable value from it, and where applications are being deployed at scale in the real world. The field has moved beyond mere promise to create genuine disruption beyond the walls of the research lab.
At the same time, AI is still in its infancy. Today’s AI systems, while tremendously powerful, remain limited in important ways. These systems largely require enormous amounts of carefully annotated data to train, and they struggle when confronted with inputs that look very different from their training. Today’s AI systems are also vulnerable to new forms of hacking, where bad actors can trick AI systems into making mistakes. What’s more, current systems can rarely give satisfying human-understandable explanations for their decisions. Each of these weaknesses limits the broad applicability of AI, particularly in mission-critical functions within business enterprise. The potential for AI to impact our lives is great, but this potential will not be realized without a concerted effort to look ahead to what is next in AI.
An integrated worldview, a collaborative model
Our Lab was founded with the goal of asking what’s next and then building that future. Our joint effort marks a new kind of collaboration between industry and academia, and is built on a shared vision and a set of values for how AI should advance. Key among these values is the recognition of the power of interdisciplinarity. Intelligence is one of the great mysteries of the universe. To approach it requires a mind for biology as much as computer science, for ethics as much as mathematics, for economics as much as physics. Universities such as MIT embody the spirit of interdisciplinary investigation.
Another core value of our Lab is stewardship. AI technology is too powerful for a move-fast-and-break-things approach. Achieving true human-machine partnership in the coming age of AI requires prudence as much as technical ingenuity. Now more than ever, we need an integrated worldview that prompts us to consider not only what can we do, but what we should we do. Like the invention of the computer or the Internet, the impact of AI will be profound and complex. It’s up to us — all of us — to harness this technology for good.
Our vision is to cultivate an interdisciplinary community of scientists committed to advanced AI research that is neither purely theoretical nor prematurely commercial. We seek to undertake fundamental science that is deeply connected to everyday people, businesses, and the problems they face. Rather than asking how today’s AI can have impact, we instead ask what fundamental advances are needed for tomorrow’s AI to change our world for the better.
Just one year in, our community is already flourishing, with nearly 50 joint projects led by the brightest minds from our respective institutions. Each project is a collaboration between MIT and IBM research scientists, who collaborate shoulder-to-shoulder on fundamental AI research. Our project portfolio spans a spectrum of fields, with all five MIT schools (and over 20 unique departments and centers) represented. Despite being just over six months into our first cycle of funded projects, our teams are already making important headway on hard problems and publishing in top academic venues.
Examples of the research we are undertaking include:
• Building a new generation of neural-symbolic hybrid systems that embrace the statistical learning capabilities of today’s neural networks, and combine them with powerful symbolic reasoning techniques. Josh Tenenbaum (MIT), together with Chuang Gan (IBM), used these best-of-breed hybrids to, in effect, completely solve a tough benchmark task in visual question answering, which has eluded pure neural network-based approaches.
• Developing tools for detecting and defending against so-called “adversarial example” attacks on AI systems, which make subtle, hard-to-detect perturbations of an input (e.g. an image or passage of text) in ways that cause AI systems to dramatically fail (e.g. misclassifying an image of a cat as a typewriter, or causing a captioning system to produce a dramatically wrong caption, even when the perturbed image is virtually indistinguishable from the original). Pin-yu Chen (IBM) and Luca Daniel (MIT) recently designed techniques for providing precise, certifiable guarantees about the robustness of neural networks against specific attacks. This research is an important early step towards improving the robustness of AI systems.
• Mitigating our reliance on enormous amounts of hand labeled data. Many big problems lack big data. A team of IBM researchers led by Abhishek Kumar (IBM) joined forces with Greg Wornell (MIT), Antonio Torralba (MIT), and William Freeman (MIT) to build new deep learning systems that can leverage learning from one domain to learn efficiently in new domain where large amounts of labeled training data is not available.
An invitation
These are exciting times. Although IBM competes with other tech giants in the enterprise AI space, we also believe in the importance of creating time and space for open scientific collaboration, particularly around enabling fundamental advances in science through AI. That is why IBM is one of the founding members of the MIT Quest for Intelligence, the university’s broader alliance for academic-industry research. We also seek to partner with our vast array of business customers, who represent every facet and corner of the global economy. We recognize that the greatest advances in AI will come from the collective ideas and energy of researchers and stakeholders from across academia and industry.
The MIT-IBM Watson AI Lab is hiring, and we invite you to join us in Cambridge. We welcome good people and bold thinkers who connect dots across disciplines. We come from countries around the world and share an inclusive culture and a global mindset. We bring together diverse backgrounds and perspectives for greater impact. We believe in tight feedback loops between our research in the lab and those closest to the problems we endeavor to solve. We embrace collaboration and celebrate the success of others. We are committed to the scientific method and the integrity of our work.
AI may indeed transform nearly every aspect of our society. Let us work together to ensure it is a force for good.
",,Person,ultramarine,person,building,office,jobcentre
https://ibm.co/2JqmN6W,187446750783_10156018282160784,https://www.facebook.com/ibmwatson/posts/10156018282160784,"Lingmo uses Watson to take 30-second blocks of conversation in English, Japanese, French, Chinese, Italian, Spanish, German, Portuguese and Arabic and return it to the One2One earpiece coherently in any of those languages via Business Insider: ",Link,,,11/16/18 15:23, ,9265,9265,0,13396,13396,0,136,93,114,7,7,11068,7810,0,0,108,0,0,0,0,0,0,0,0,0,0,12,53.0,1.0,12,53.0,1.0,33,64.0,,,50,64.0,,,3,4.0,,3,4.0,,  The Australian startup which launched an earpiece that can instantly translate nine languages now has a smartwatch and a messaging service.,https://edge.alluremedia.com.au/uploads/businessinsider/2018/03/two-watches.jpg,https://www.businessinsider.com.au/lingmo-smartwatch-translates-languages-2018-3,joy,0.293939,neutral,0,30-second blocks of conversation,"Quantity, Person",30-second blocks of conversation,Quantity,joy,0.490414,positive,0.586758,Australian startup,,Australian startup,,joy,0.586879,positive,0.590356,Lingmo International,"Company, Person, Person, Quantity, Company, Person, Quantity, Quantity, Quantity, Organization, Location, Person, Company, Quantity, Quantity, Location, Quantity","The Australian startup which launched an earpiece that can instantly translate nine languages now has a smartwatch and a messaging service.
In less than a year since he launched the TranslateOne2One device at a United Nations event in Switzerland, former plumber Danny May has become an unlikely, but extremely busy, advocate for IBM’s AI technology, Watson.
Watson takes 30-second blocks of conversation in English, Japanese, French, Chinese, Italian, Spanish, German, Portuguese and Arabic and returns it to the One2One earpiece coherently in any of those languages.
May began working on the technology five years ago when he struggled to communicate effectively while on a business trip to China.
His startup, Lingmo International, released the $279 earpiece in October last year, even beating Google’s Pixel Bud translation service to the market, with the major advantage over its competitors of using a SIM card to operate independently of a phone.
But by December, feedback proved to May that an earpiece isn’t a good fit for everybody. So here’s another way to chat with someone in nine different languages:
It’s called the Time2Translate and you can buy it tomorrow, with delivery expected in April, anywhere in the world.
“People loved the One2One tech and loved what it was doing, but some people found it hard to use on the ears,” May says. “The tech was never in question, it was always just a matter of how we could put it into a better user experience.”
The smartwatch also knocks out some extra features that people weren’t really using on the earpiece.
“There was too much going on, people just wanted a translation device,” May says.
Lingmo kept Google Maps — it is essentially a travel accessory — and Bluetooth capability if people don’t want to connect to Lingmo’s prepaid SIM network. Google Play is available for downloads, but other app stores have been axed.
In return, the Time2Translate gets a four-hour constant use battery life (14 hours standby) and extra memory.
And most importantly, it’s on your wrist.
As if speaking into a watch like you have in all your spy film dreams isn’t impressive enough, Lingmo is also launching new software along with the Time2Translate which enables real-time messaging in nine languages.
So you can send a voice message in English on your watch and the recipient will receive it in Chinese. But what is truly extrordinary is the watch will enable up to 1,000 users to converse in a group chat across all nine languages.
Those languages represent 90% of the world’s spoken words.
May said Lingmo burned through five protoypes to find speakers for the side of the watch that met the standard required for speaking English into, and hearing Arabic out of up to two metres away. 
And because Lingmo is working with Watson every second to improve its service, the translation is far beyond the typical clunky word-for-word systems you might be used to online.
But for a premium service, expect to pay a premium price – the watch starts from $US699 for the Lifestyle model. Here’s the complete spec rundown: 
“We just wanted to turn those (earpiece) negatives into positives,” May says about developing the smartwatch. “Interest has been really positive around the world, and we’re now dealing with some proof of concepts with major airlines and US multinationals. 
“We’re slowly getting there; it’s just about doing it right and being a startup it’s just about focusing on the little things and getting them right first.”
 Yes, it has speakers. Loud ones. Picture: Supplied
Since the October rollout of One2One, Lingmo International has moved into new office on the NSW central coast and grown its staff from three to more than 20. It also now has offices in the Middle East and China, and a virtual office in Silicon Valley which it is looking to make permanent.
May says it’s been a challenging time in his life, but he doesn’t miss sticking his hand down the toilet.
“It’s what you start a company for. You have your hard times but you just have to keep pushing on and that’s what it’s all about with the watch.
“You just have to keep innovating.”
His ultimate goal is to see Lingmo’s product line include the “holy grail”, where anyone can pick up a phone and make a call which instantly translates to the other end and back again.
“We’re making slow inroads,” he says. “The software on the watch is a significant step towards that.”
Follow Business Insider Australia on Facebook, Twitter, LinkedIn, and Instagram.
",Lingmo International,Company,charcoal,addiction,person,person,addiction
https://ibm.co/2J5NTwv,187446750783_10156016510720784,https://www.facebook.com/ibmwatson/posts/10156016510720784,"With over 5,200 branches, Bradesco is one of Brazil’s largest banks. So how are they able to pay attention to each one of their 65 million customers? Learn how they trained Watson to answer questions with accuracy: ",Link,,,11/15/18 19:40, ,7929,7929,0,11087,11087,0,129,87,114,9,9,8682,6219,0,0,80,0,0,0,0,0,0,0,0,0,0,13,52.0,,14,56.0,,54,38.0,,,75,39.0,,,2,7.0,,2,7.0,,How a Brazilian bank pays personal attention to each of their 65 million customers,,https://www.ibm.com/watson/stories/bradesco/,sadness,0.11589,neutral,0,Brazil’s largest banks,"Company, Location",Brazil’s largest banks,Company,sadness,0.452632,neutral,0,"Brazilian bank, personal attention",,Brazilian bank,,joy,0.487799,positive,0.683831,,"Person, Company, Company, Person, Person","Watson is AI from IBM that seamlessly embeds into your workflows while integrating with the leading platforms and tools enterprises already use. Putting AI at your employees' fingertips when they need it - and where they need it - means empowering your teams to focus on what they do best.
There’s even one inside a boat on the Amazon. When branch employees had questions about products or services, they called a central office, but there was often a long wait for answers. This meant the client was also left waiting, and as one manager put it, “No one likes to wait.”
In a business as competitive as banking, if your customers don’t have a great experience, they may not be your customers for long. So Bradesco started looking for a way to increase the speed of service and also improve the level of personalization for each client. That’s when they turned to IBM and Watson.
Their first task was to teach Watson Portuguese, but initially there were some doubts. “It’s more than just learning the language,” said IBM Managing Director Katia Vaskys. “You also need to understand Brazil’s culture, and the regional accents, and the way each region asks a question.”
But after mastering the nuances of Portuguese, Watson was ready to be trained on the business of banking. To do this, Bradesco and IBM worked together to develop a team that taught Watson about the bank’s products and services by asking and answering questions for Watson in natural language—the same way a customer would. 
“Yes, Watson can learn,” said one IBMer, “but it needs people to teach people who are committed and patient.” Because of this team effort, Watson could understand 100% of written questions and 83% of spoken ones after just 5 months of training. And after 10 months, the system was answering 96% of all questions correctly.
Now Watson is trained on 62 products and answers 283,000 questions a month with a 95% accuracy rate, with just 5% requiring calls for further assistance. In some cases, response times have been reduced from 10 minutes to just seconds. “It’s a real wow factor,” exclaimed one manager.
This helps employees have more enriching interactions with clients, because they have time to dedicate to providing the best possible customer experience. “This is when growth happens,” said the Bradesco AI Lead, Marcelo Camara. “Our current clients notice the improved service, which in turn attracts new clients, and this is what helps the bank scale.”
",,Person, , , , , 
,187446750783_10156014392665784,https://www.facebook.com/ibmwatson/posts/10156014392665784,IBM Watson,SharedVideo,,,11/14/18 20:52, ,7651,7651,0,10014,10014,0,224,205,273,4,4,9436,7070,0,0,212,0,0,0,0,1489,1575,0,0,0,39214,,34.0,4.0,,34.0,6.0,199,15.0,,,257,16.0,,,1,3.0,,1,3.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2B2bgpd,187446750783_10156010942880784,https://www.facebook.com/ibmwatson/posts/10156010942880784,Watch IBM CEO Ginni Rometty discuss the impact of AI and automation in the workforce and the future of &quot;new-collar&quot; jobs via CBS This Morning: ,Link,,,11/13/18 9:39, ,17968,17968,0,25122,25122,0,1033,811,1153,11,11,16648,12398,0,0,611,0,0,0,0,0,0,0,0,0,0,43,256.0,14.0,48,262.0,20.0,531,398.0,,,734,419.0,,,5,6.0,,5,6.0,,"IBM may be at another turning point in its storied history. In October, IBM announced it was buying the cloud software provider Red Hat for $34 billion, and it&#039;s also investing $1 billion in initiatives like apprenticeships to train workers for what it calls &quot;new collar&quot; jobs. IBM president and CEO Ginni Rometty, who coined the term for workers who have technology skills but not a four-year degree, joins &quot;CBS This Morning&quot; to discuss how AI will impact jobs and how the new collar skills can help bridge the digital divide.",https://cbsnews2.cbsistatic.com/hub/i/r/2018/11/13/0bfeb893-2e5c-4c92-84f5-dac5b8e3b375/thumbnail/1200x630/ad9aa505f74f8780e66aff4c4157aefb/1113-ctm-ibmceoromettyqa-1710700-640x360.jpg,https://www.cbsnews.com/video/ibm-ceo-ginni-rometty-hopes-new-collar-skills-will-bridge-digital-ai-divide/,joy,0.524472,neutral,0,"Watch IBM CEO Ginni Rometty, impact of AI","Person, Company",Watch IBM CEO Ginni Rometty,Person,joy,0.413072,positive,0.412574,"cloud software provider Red Hat, IBM president","Company, Quantity, Quantity, Person, Company",cloud software provider Red Hat,Company,joy,0.341409,negative,-0.335947,"IBM CEO Ginni Rometty, cloud software provider Red Hat, IBM president","Person, Company, Quantity, Quantity, Broadcaster","IBM CEO Ginni Rometty hopes ""new collar"" skills will bridge digital, AI divide - CBS News
               IBM may be at another turning point in its storied history. In October, IBM announced it was buying the cloud software provider Red Hat for $34 billion, and it's also investing $1 billion in initiatives like apprenticeships to train workers for what it calls ""new collar"" jobs. IBM president and CEO Ginni Rometty, who coined the term for workers who have technology skills but not a four-year degree, joins ""CBS This Morning"" to discuss how AI will impact jobs and how the new collar skills can help bridge the digital divide.                       
",IBM CEO Ginni Rometty,Person,jade green,television reporter,person,television reporter,-
https://ibm.co/2qHDJL6,187446750783_10156008698730784,https://www.facebook.com/ibmwatson/posts/10156008698730784,"AI is transforming the world, impacting the way people and businesses are thinking and working towards a smarter future. 

Learn everything there is to know about the technology that makes up IBM Watson AI in our brand-new video: ",Link,,,11/12/18 10:45, ,6046,6046,0,8456,8456,0,124,81,98,2,2,7117,4785,0,0,108,0,0,0,0,0,0,0,0,0,0,18,50.0,,20,50.0,,27,61.0,,,36,62.0,,,1,1.0,,1,1.0,,"What is Watson? How is AI helping businesses across the globe to build a smarter future? Watch the complete video to learn about our technology, or discover ...",https://i.ytimg.com/vi/r7E1TJ1HtM0/hqdefault.jpg,https://www.youtube.com/watch?v=r7E1TJ1HtM0&t=23s,joy,0.546422,positive,0.816825,way people,Person,way people,Person,joy,0.567674,positive,0.861085,complete video,"Person, Person",complete video,Person,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
            

",YouTube,Company,ultramarine,monitor,electronic device,video display,monitor
,187446750783_10156007711630784,https://www.facebook.com/ibmwatson/posts/10156007711630784,IBM Watson updated their status.,Status,,,11/11/18 20:34, ,4891,4891,0,6543,6543,0,150,133,182,1,1,6268,4714,0,0,142,97,98,0,0,426,0,0,0,0,0,,27.0,1.0,24,29.0,1.0,129,8.0,,,172,10.0,,,,1.0,,,1.0,,,,,sadness,0.036517,neutral,0,IBM Watson,"Company, Person",IBM Watson,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2DNYtFb,187446750783_10156004492935784,https://www.facebook.com/ibmwatson/posts/10156004492935784,"Earlier this year, we released Watson Visual Recognition Service for Core ML, combining enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI. ",Link,,,11/10/18 9:26, ,11853,11853,0,16540,16540,0,314,145,169,6,6,12918,9457,0,0,239,0,0,0,0,0,0,0,0,0,0,37,186.0,1.0,38,190.0,2.0,80,74.0,,,92,77.0,,,1,5.0,,1,5.0,,"Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity. Consider three distinct examples – 1. Fixing issues with Visual Diagnosis User: A person in the field equipped with an iPhone trying to visually diagnose a problem. Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage. 2. Recommendations based on Visual analysis User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations. Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/03/GettyImages-1086731554.jpg,https://www.ibm.com/blogs/watson/2018/03/ai-everywhere-ibm-watson-apple-core-ml/,joy,0.081124,neutral,0,"Watson Visual Recognition Service, Core ML, enterprise-grade IBM Watson","Person, Company, Company",Watson Visual Recognition Service,Person,sadness,0.551904,negative,-0.449804,Visual Diagnosis User,Person,Visual Diagnosis User,Person,joy,0.548225,positive,0.631349,number of users,"Person, HealthCondition, Company, Person, Company","Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity.
Consider three distinct examples –
1. Fixing issues with Visual Diagnosis
User: A person in the field equipped with an iPhone trying to visually diagnose a problem.
Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage.
2. Recommendations based on Visual analysis
User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations.
Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying unknown or complex machine parts to classifying plants or food.
3. Visual triggers for a business process
User: An end user and a trigger for a downstream business process
Usage: Business processes range from creating a work order for repair to updating a shopping cart for purchase; from intervening in quality control to safety procedure in manufacturing; from initiating an insurance claim to a collaborative analysis for experts in medicine.
These are a diverse set of scenarios with a common thread running through them: the need for a low-latency and rich insight for a human or a downstream process.
Imagine a scenario where a user is trying to access results while on-the-go (changing network speeds), or in hard-to-reach places (manufacturing plants, buildings, store interiors, remote areas, etc.). This impacts the user’s ability to do the job, which can have a domino effect on business processes and the bottom line for companies.
The most compelling way to empower that user combines relevant AI insights, at the time of need, without the user having to worry about network connectivity issues.
To set this in motion, you need:
1. A technique to handle tradeoffs between immediate insights, irrespective of connectivity, with richer insights from the cloud, allowing the user to focus on the task at hand.
2. Collaborative methods and tools for users, developers and/or data scientists to build solutions in a way that allows them to focus on the higher end of the solution spectrum.
3. An approach with associated technology that enables a process of rapid iteration to keep up with constantly changing data and other surrounding factors.
Components of this solution are being successfully used by enterprises and consumers across industries and geographies.
Watson services on the IBM Cloud provide rich and relevant insights from a variety of public and enterprise data sources to applications. IBM’s approach to data and privacy with Watson ensures that client data and insights are not shared with IBM or third parties, and that client data does not contribute to training a centralized knowledge graph.
Apple Core ML is a foundational machine learning (ML) framework that lets you integrate ML models into your app. Core ML delivers optimized performance for Apple products with minimal memory footprint and battery consumption impact. User privacy is protected as data is stored locally and encrypted by default.
What’s new – Bringing it together with a seamless experience
Available today, Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI.
These are key aspects of what is now available to the ecosystem of users and developers. Read more about the partnership here.
1. Watson SDK low latency, and offline process for custom Visual Recognition models using Core ML with the rich insights from the Watson services on the cloud.
2. Watson Studio provides a low-code, end-to-end collaborative environment that enables developers to quickly and easily catalog, classify, provision, and train their data and models.
3. Developer assets and best practices including Code Patterns for developers to get started, starter kits to quickly build iOS apps that combine these Watson services with other components, and code examples to get started now.
These offerings are the first step towards mitigating challenges for users, developers, and enterprises. Companies have already started building enhancements to applications that leverage Watson Visual Recognition Service for Core ML.
For the developer, this drives a paradigm for building once and deploying at heterogeneous endpoints. For the user, this translates to growth in the expertise spectrum and higher productivity. For the enterprise, this is an inevitable step toward mobile and AI revolutionizing how we work.
Watch the demo to see how this all comes together for part and issue identification on Arduino boards, a representative for any component.
",number of users,Person,blue,X-ray film,photographic equipment,photographic film,X-ray film
https://ibm.co/2qCKw8I,187446750783_10156002126890784,https://www.facebook.com/ibmwatson/posts/10156002126890784:0,"Join WIRED Editor in Chief Nicholas Thompson and IBM Watson's Rob High and Beth Smith to learn how AI is helping professionals produce better, faster work in industries like legal and media to banking and insurance. 

Register now for our AI and the Future of Work Virtual Summit: ",Photo,,,11/9/18 9:30, ,9708,9708,0,13349,13349,0,143,99,122,3,3,11695,8707,0,0,101,0,0,0,0,0,0,0,0,0,0,13,54.0,1.0,16,58.0,2.0,49,29.0,33.0,,57,30.0,35.0,,1,2.0,,1,2.0,,"Tuesday, November 27, 2018 at 11:30 AM Eastern Standard Time. ",,https://event.on24.com/wcc/r/1847677/235C0438C88FC04E670CC0597D1551CB?partnerref=Facebook,joy,0.207958,positive,0.94129,"IBM Watson's Rob High, Chief Nicholas Thompson","Person, Company, Person, Person, PrintMedia, Person",IBM Watson's Rob High,Person,joy,0.2755,neutral,0,"Eastern Standard Time, November",,Eastern Standard Time,,joy,0.177795,neutral,0,Future of Work Virtual Summit,,"AI & the Future of Work Virtual Summit: REPLAY: www.ibm.com/watson/future-of-work-full
",Future of Work Virtual Summit,, , , , , 
https://ibm.co/2kjaPxR,187446750783_10156000717920784,https://www.facebook.com/ibmwatson/posts/10156000717920784,"AI is opening doors to limitless possibilities  – but how ready are we for them? 

Watch IBM Watson's Chief Architect Ruchir Puri debate the future of this technology in a panel hosted by Neil deGrasse Tyson: ",Link,,,11/8/18 18:30, ,6718,6718,0,9054,9054,0,93,57,66,2,2,8037,5990,0,0,77,0,0,0,0,0,0,0,0,0,0,11,41.0,,13,41.0,,26,32.0,,,33,33.0,,,1,1.0,,1,1.0,,"Isaac Asimov’s famous Three Laws of Robotics might be seen as early safeguards for our reliance on artificial intelligence, but as Alexa guides our homes and...",https://i.ytimg.com/vi/gb4SshJ5WOY/maxresdefault.jpg,https://www.youtube.com/watch?v=gb4SshJ5WOY&feature=youtu.be,joy,0.223256,neutral,0,future of this technology,"Person, Person, Company",future of this technology,Person,joy,0.325221,positive,0.642521,"Isaac Asimov, artificial intelligence, Laws of Robotics",Person,Isaac Asimov,Person,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
            

",YouTube,Company,coal black,aperture  (camera),controller,aperture  (camera),-
https://ibm.co/2PkuyPt,187446750783_10155998183415784,https://www.facebook.com/ibmwatson/posts/10155998183415784,,Link,,,11/7/18 19:30, ,8635,8635,0,11860,11860,0,112,75,87,7,7,10763,7865,0,0,104,0,0,0,0,0,0,0,0,0,0,9,38.0,1.0,9,39.0,1.0,21,55.0,,,28,59.0,,,3,4.0,,3,4.0,,"To teach artificial intelligence how to argue, it must understand both sides. That&#039;s helpful for humans, says IBM&#039;s Ranit Aharonov.","https://content.fortune.com/wp-content/uploads/2018/11/45700208332_96c1af02b3_o.jpg?resize=1200,600",https://fortune.com/2018/11/06/artificial-intelligence-ibm-project-debater/,,,0,0,,,,,anger,0.169281,positive,0.741956,artificial intelligence,"Company, Person",artificial intelligence,Company,sadness,0.546627,negative,-0.844934,"trademark of Fortune Media IP Limited, FORTUNE","Location, Company, Quantity"," FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.S. and other countries. FORTUNE may receive compensation for some links to products and services on this website. Offers may be subject to change without notice.
 Quotes delayed at least 15 minutes. Market data provided by Interactive Data. ETF and Mutual Fund data provided by Morningstar, Inc. Dow Jones Terms & Conditions: http://www.djindexes.com/mdsidx/html/tandc/indexestandcs.html.
",trademark of Fortune Media IP Limited,Location,Tyrian purple,dance,person,dance,-
https://ibm.co/2JJhTPX,187446750783_10155994676345784,https://www.facebook.com/ibmwatson/posts/10155994676345784,Big news: We're partnering with VMware to transform their customer service experience with Watson AI and machine learning. Learn more: ,Link,,,11/6/18 9:20, ,8108,8108,0,11487,11487,0,135,87,111,5,8,9581,6749,0,0,107,0,0,0,0,0,0,0,0,0,0,14,71.0,,14,73.0,,43,49.0,,,54,57.0,,,1,7.0,,1,4.0,,We are proud to announce VMWare is integrating IBM Watson Assistant and Machine Learning across its support portals to transform customer support.,https://www.ibm.com/blogs/watson/wp-content/uploads/2019/05/GettyImages-1035834404.jpg,https://www.ibm.com/blogs/watson/2018/11/vmware-global-services-chooses-ibm-watson-to-improve-customer-service/?cm_mmc=OSocial_Facebook-_-Watson+and+Cloud+Platform_Watson+Core+-+Conversation-_-WW_WW-_-VMWare+Chooses+Watson+for+Customer+Service&cm_mmca1=000018SW&cm_mmca2=10004432,joy,0.213172,positive,0.885724,"Big news, machine learning","Company, Person, Person",Big news,Company,joy,0.62533,positive,0.979956,"Machine Learning, IBM Watson Assistant, customer support","Company, Company",Machine Learning,Company,joy,0.648785,positive,0.744173,,"Person, Company","When technical issues arise, customers expect immediate results. Time is a factor, and it’s critical to locate the correct engineer to find the appropriate solution for your business need. At VMworld 2018 Europe, we are proud to announce that VMWare is integrating Watson across its support portals to transform customer support.
Using artificial intelligence capabilities from Watson Assistant and Watson Machine Learning, VMware clients needing technical support can get a better support experience, helping them rapidly go from case submission to technical solution.
Instead of static drop downs, VMware customers can leverage Watson to quickly and easily communicate with the portal in natural language. Watson will detect product type and version, analyze issues and match those issues with an expert engineer for faster resolution and a better customer experience.
For example, let’s say your business is having an issue updating your vSphere environment. To find an engineer to match with your case, you would enter MyVMware and immediately start explaining your issue. As you indicate key pieces of information pertaining to your issue, Watson works to identify what could be the cause. Instead of static drop downs, businesses needing technical support can simply communicate within the portal in natural language, as you would ask a question to another person.
Watson is improving the engineer’s experience as well. By understanding cases and logging similarities through learning more over time, Watson will provide engineers with a range of similar cases and their resolutions. This helps to ensure that engineers have all necessary information and background at their fingertips enabling them to resolve issues for clients faster.
IBM Watson and VMware remain committed to delivering new solutions and services to help enterprises advance their cloud journey. In fact, at VMWorld Europe 2018 this week, IBM is announcing new offerings to accelerate enterprise hybrid cloud adoption and help clients unlock new business value.
",,Person,reddish orange,medical practitioner,person,medical practitioner,-
https://ibm.co/2QI1NIO,187446750783_10155990013245784,https://www.facebook.com/ibmwatson/posts/10155990013245784,"In case you missed it: AIConics, the worlds’ only independently judged enterprise AI awards, named Watson Discovery the winner for “Best Innovation in NLP.” 

NLP, or Natural Language Processing is the area of computer science and artificial intelligence that focuses on the interaction between computers and human languages. Learn more: ",Link,,,11/4/18 9:43, ,13322,13322,0,18490,18490,0,340,208,231,6,6,14069,10136,0,0,227,0,0,0,0,0,0,0,0,0,0,34,158.0,3.0,37,167.0,4.0,120,95.0,,,134,97.0,,,4,2.0,,4,2.0,,The AIconics named Watson Discovery winner for “Best Innovation in NLP.” The AIconics celebrate innovation of the international A.I. community.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/10/f3157e0a-c7d0-11e8-8ed0-3dc066795427.jpg,https://www.ibm.com/blogs/watson/2018/10/aiconics-names-ibm-watson-best-innovator-in-natural-language-processing/?cm_mmc=OSocial_Facebook-_-Watson+and+Cloud+Platform_Watson+Core+-+Discovery-_-WW_WW-_-AIConics+Named+Watson+Best+Innovator+In+NLP+Oct+2018&cm_mmca1=000016UP&cm_mmca2=10009360,joy,0.714038,positive,0.74762,"Natural Language Processing, artificial intelligence, area of computer science, Watson Discovery","Person, Person",Natural Language Processing,Person,joy,0.754413,positive,0.976374,Watson Discovery winner,"Person, Location",Watson Discovery winner,Person,joy,0.62318,positive,0.779721,Watson Discovery,"Company, Person, Person, Company, Person, Quantity, Quantity","On September 18, the worlds’ only independently judged enterprise AI awards –the AIconics–named Watson Discovery the winner for “Best Innovation in NLP.” NLP, or Natural Language Processing is the area of computer science and artificial intelligence that focuses on the interaction between computers and human languages. Specifically, NLP concerns how computers process and analyze unstructured natural language data.
The AIconics celebrate the drive, innovation and hard work done throughout the international artificial intelligence community. This year’s awards recognized industry leaders across a broad spectrum of AI technologies and were judged by a panel of world class AI experts, including senior leaders from venture capital firms, academia and enterprise end-users. In his kickoff speech, AIconics Awards Curator Edward Beecham said, “With over 300 entries from around the world, the 3rd Annual Edition of The AIconicsreflect the strength and progress of a rapidly expanding and evolving sector. Artificial Intelligence is now beginning to dominate conversations in the technology sphere.”
Watson Discovery’s leading NLP understands the meaning and the structure of data to help businesses increase productivity, allowing teams to focus on more interesting, higher value work. Clients like LegalMation and KPMG have used Watson Discovery to tap into enterprise knowledge spread across the organization to help facilitate tasks like creating early response drafts, reviewing intricate documents, and getting answers to complex questions.
Leaders from Woodside, an Australian oil and gas company, have said that “Employees used to spend 80% of their time researching problems and 20% fixing it. Watson has reversed that.” With Watson Discovery, teams can ask questions in natural language to both uncover the information they are looking for and to pinpoint new patterns that point to where incremental innovation can happen.
Currently available on IBM Cloud, Watson Discovery is an out-of-the box solution, so users don’t need to understand how to use APIs to configure and populate the service. It’s a one-of-a-kind cloud native AI powered insight engine that extracts meaningful insights from structured and unstructured content to help teams be more efficient and more discerning, ultimately driving more value for the business.
",Watson Discovery,Company,light brown,person,indoors,lecture room,-
https://ibm.co/2yiAX3h,187446750783_10155987442400784,https://www.facebook.com/ibmwatson/posts/10155987442400784,,Link,,,11/3/18 8:13, ,12004,12004,0,17009,17009,0,543,459,625,8,8,12226,8817,0,0,291,0,0,0,0,0,0,0,0,0,0,10,105.0,25.0,11,115.0,34.0,279,217.0,,,384,241.0,,,5,3.0,,5,3.0,,"Speaking to CIOs, IBM Chief Executive Ginni Rometty outlined how the company is positioning itself as businesses industry-wide ramp up their use of cloud, big data and artificial intelligence.",https://images.wsj.net/im-31236,https://blogs.wsj.com/cio/2018/10/16/ibm-ceo-ginni-rometty-sharpens-focus-on-emerging-tech-for-business/,,,0,0,,,,,anger,0.086397,neutral,0,"IBM Chief Executive Ginni Rometty, businesses industry-wide ramp, big data","Person, Company",IBM Chief Executive Ginni Rometty,Person,joy,0.493408,positive,0.589799,,"Person, Company","ORLANDO, Fla. -- For most companies, the start and endpoints of any major strategic shift are the easy part, it’s the middle that can make or break a business, says Ginni Rometty, president and chief executive officer of International Business Machines Corp.
How does she know? It’s a journey IBM itself embarked on over six years ago, when Ms. Rometty took on the top job at the technology firm, which traces its origins to the late-19th Century.
Speaking to chief information officers and other senior enterprise IT managers gathered here for Gartner’s annual IT industry conference, Ms. Rometty outlined the many ways IBM has shifted within the enterprise technology market in recent years, as businesses across all industries ramp up their use of cloud computing, big data, artificial intelligence, blockchain and other emerging digital tools.
“This has clearly been the time of rapid change,” Ms. Rometty said, “and it isn’t going to stop.”
Her remarks Tuesday came ahead of IBM’s third-quarter earnings, which the company is set to report after markets close at the end of the day.
Analysts surveyed by S&P Global Market Intelligence are expecting a decline in revenue, to $19.04 billion from $19.15 billion over the same period a year ago, following three consecutive quarters of growth. Amid ups and downs, revenue has been shrinking over the past six years.
Over that time, Ms. Rometty has led the company’s re-positioning from selling workhorse legacy IT tools, to focusing on growth markets and emerging digital tools, like cloud, AI, quantum computing and blockchain. She predicted that blockchain would have an impact on business in five years and urged companies to prioritize their preparation now.
In her first two years as CEO, she said, “we could see the market was changing and we needed to change faster,” taking a cue from the agility of tech startups: “I think we learned a lot from startup companies,” she added.
And while the consumer tech market is booming, Ms. Rometty said, as a company, “you have to decide what you are and what you are not, and we are not a direct to consumer company.” AI for business is different, she said. The big challenge, in her view, isn’t technology, but change management. Beyond that, AI for business must be explainable and adjusted for bias, and be able to scale. Also, it is often domain-specific, focused on a particular problem or set of data. It is crucial that companies that provide AI to enterprises safeguard data from their customers’ rivals in the market.
“I really believe we are the leader in AI for business. Our specialization is to know what it takes for the enterprise to operate in the world,” Ms. Rometty said.
This week alone in the enterprise space, IBM launched a new multi-cloud tool designed to help firms manage a growing number of apps and workloads spread across different cloud environments, regardless of vendor.
It also released similar AI technology that allows the deployment of AI models, regardless of vendor or cloud platform, along with new security tools.
Each of the tools seeks to address a lack of interoperability among many emerging technology systems, even as businesses increasingly take a mix-and-match approach to IT, Ms. Rometty said.
IBM’s corporate customers on average operate with six clouds and roughly one thousand apps, according to Ms. Rometty. “That’s the context when we think of cloud,” she said.
With those capabilities in place, AI increasingly will take on a key role in the way businesses make decisions about services and products in the years ahead. IBM already has some 25,000 AI engagements with customers, Ms. Rometty said.
The broader goal is to offer end-to-end enterprise tech capabilities, with the common currency being data, she said.
“Data will be at the heart of these disruptions for a long time,” Ms. Rometty said.
",,Person,purplish blue,person,sport,gymnastics,-
https://twitter.com/IBMWatson,187446750783_10155983110875784,https://www.facebook.com/ibmwatson/posts/10155983110875784,"We're on Twitter! Follow us to stay informed on the latest news, announcements, partnerships and much more from IBM Watson: ",Link,,,11/1/18 13:58, ,6155,6155,0,8337,8337,0,51,33,40,2,2,7715,5697,0,0,44,0,0,0,0,0,0,0,0,0,0,2,23.0,1.0,2,25.0,1.0,17,16.0,,,22,18.0,,,,2.0,,,2.0,,"The latest Tweets from IBM Watson (@IBMWatson). Watson is AI for professionals, designed for your business. New York, NY",,https://twitter.com/IBMWatson,fear,0.065953,neutral,0,latest news,Company,latest news,Company,anger,0.068927,neutral,0,"latest Tweets, IBM Watson, New York","Company, Person, Person",latest Tweets,Company,sadness,0.505754,negative,-0.814708,,,"                                                                                            
Something went wrong, but don’t fret — let’s give it another shot. 





          

",,, , , , , 
https://ibm.co/2ATiL3L,187446750783_10155980889445784,https://www.facebook.com/ibmwatson/posts/10155980889445784,"If a person is talking to you and you smile, they will register this subconsciously and there’s a good chance that they will smile back without even thinking about it. How can you make a similar emotional connection with a chatbot? How one technology company is giving AI a human face: ",Link,,,10/31/18 18:02, ,8051,8051,0,10947,10947,0,148,108,127,5,5,9710,7126,0,0,132,0,0,0,0,0,0,0,0,0,0,17,49.0,,18,51.0,,43,71.0,,,53,74.0,,,3,2.0,,3,2.0,,"Soul Machines creates sophisticated “artificial humans” that use biology-inspired models of the human brain to speak, move and express themselves.",,https://www.ibm.com/blogs/cloud-computing/2018/08/02/soul-machines-ai-watson/,joy,0.776987,positive,0.988383,"technology company, good chance, human face",,technology company,,joy,0.815918,positive,0.959246,"Soul Machines, artificial humans",,Soul Machines,,joy,0.622886,positive,0.811283,IBM Watson Assistant,"Company, Person, Person, Quantity","Share this post:
From talking watches to AI-powered financial advisors, a world where people routinely speak to machines is shifting from science fiction to everyday reality.
Artificial intelligence (AI) is no longer in the realm of academic research. It is becoming extremely useful for enterprises, especially in business functions such as AI customer service. Chatbots are the obvious example. By building an AI-powered chatbot that can respond intelligently to most day-to-day customer service requests, organizations can free up human staff to focus on more complex problems.
But that doesn’t mean it always feels natural. While talking to chatbots can be great to get information or make transactions quickly, a text prompt can’t convey all the subtle nuances of a face-to-face interaction.
If a person is talking to you and you smile, they will register this subconsciously, and there’s a good chance that they will smile back without even thinking about it. These subtle reactions are a big part of how we connect with people on an emotional level, which is valuable in building customer relationships. But how can you make a similar emotional connection with a chatbot?
At Soul Machines, we solve this exact problem by giving AI a human face, literally. We create sophisticated “artificial humans” that use biology-inspired models of the human brain to speak, move and express themselves just like real people.
To take a simple example, when a customer is talking to one of our artificial humans and smiles into their webcam, our solution registers the image of a happy face and generates the virtual equivalent of dopamine and serotonin in the artificial human’s brain. This causes the artificial human to reciprocate the emotion and smile back at the customer. We adapt tone of voice in a similar way, enabling our artificial humans to communicate in a way that harmonizes with the customer’s mood.
We provide the user-friendly interface that helps AI-powered representatives interact in a realistic, emotionally intelligent way, delivering answers in a manner that makes the customer feel comfortable. But that’s only half the story. To make sure answers are correct and helpful, we also need to give our artificial humans the ability to learn from our clients’ domain-specific data.
IBM Watson Assistant does just that. The enterprise-level AI assistant can be trained to answer customer queries for any business while continuously learning and improving its performance.
Many of our clients were already working with IBM Watson to handle customer queries through text-based chatbot interfaces. In each case, we were able to integrate our artificial human with the existing IBM solution to create a new user experience layer. For a company that already has Watson Assistant set up, it only takes eight to 12 weeks to add a Soul Machines artificial human to their solution.
The integration between our platform and IBM Watson Assistant is relatively straightforward to set up. The Watson solution runs in the IBM Cloud—so there’s no infrastructure for us to manage—and provides a simple API that we can call from our application. We send audio of the customer’s voice via this API, and Watson converts it into text, then searches a corpus of knowledge for relevant answers to the customer’s question, ranks the results and returns the top-ranked answer to us.
Meanwhile, our platform is analyzing the audiovisual input for emotional cues from the customer’s tone of voice and their facial micro-expressions. It then converts the answer into modulated, emotionally inflected speech for the artificial human to deliver, matched with appropriately generated facial expressions.
All the evidence suggests that customers enjoy interacting with our artificial humans, and one of our banking clients has found that it can already satisfy 40 percent of their customer queries without any kind of human intervention. We expect that number to climb even higher as the solution continues to learn.
Our experience working with IBM has been great and has boosted our reach as a business. The scale of the IBM Global Services team means they have deep relationships with clients around the world that we can easily build upon.
From a technical perspective, I would recommend IBM Watson Assistant to our customers. We have had success working with Watson, and we’ve now introduced it to several of our newer clients.
As digital transformation gets underway across businesses in every industry, getting the most out of AI solutions will become more and more important. Unlike traditional applications, AI-powered solutions continue to learn and improve over time, so the companies that get AI to market first will have a significant advantage. Their competitors will find it difficult to catch up. We’re proud to be working with IBM to help our clients gain that competitive edge.
",IBM Watson Assistant,Company, , , , , 
https://ibm.co/2CUb0tI,187446750783_10155977982590784,https://www.facebook.com/ibmwatson/posts/10155977982590784,"The winner for IBM's Call for Code challenge has been announced: congratulations to Project Owl! 

The team build a solution addressing a fundamental question that arises in the wake of a natural disaster: How do you maintain critical operations and communications when the power is cut and cell connectivity fails? Learn more: ",Link,,,10/30/18 10:50, ,9466,9466,0,12617,12617,0,288,208,259,9,9,9717,7205,0,0,202,0,0,0,0,0,0,0,0,0,0,13,106.0,4.0,15,109.0,6.0,125,109.0,,,147,112.0,,,2,7.0,,2,7.0,,"The 2018 Call for Code winner, Project Owl is a hardware and software solution that simplifies disaster management.",https://s3.us.cloud-object-storage.appdomain.cloud/ibmdevwp/icons/social/blogs.jpg,https://developer.ibm.com/blogs/with-project-owl-a-smart-network-of-rubber-ducks-can-save-lives/,joy,0.362185,positive,0.384586,"fundamental question, wake of a natural disaster",Company,fundamental question,Company,anger,0.359923,neutral,0,"Code winner, disaster management, Project Owl",,Code winner,,joy,0.570736,positive,0.421023,,"Person, Facility, Person, Company, Company, Person, Person, Person, Person, Person, Person, Facility, NaturalEvent, Location, Location","Project OWL, an IoT and software solution that keeps first responders and victims connected in a natural disaster, has won the 2018 Call for Code Global Challenge. A panel of eminent judges that included former President Bill Clinton awarded the five-person, U.S.-based team the Call for Code Global Prize at a gala event Monday at San Francisco’s Regency Ballroom.
The team takes home the USD$200,000 grand prize and the opportunity to deploy the solution through the IBM Corporate Service Corps, among other benefits.
“We don’t view this as the finish line for our work but a checkpoint in a journey,” said Bryan Knouse, Project OWL team lead. “I can’t wait to get home so we can get back to work on the technology and the solutions for those who need it most.”
Knouse knew he wanted to develop solutions to help people cope after natural disasters, but he had trouble finding venture capitalists willing to invest in these projects. When he learned about Call for Code, he jumped at the opportunity to get involved and join the affiliated Slack community.
There, he met a group of like-minded individuals — Magus Pereira, Nicholas Feuer, Charlie Evans, and Taraqur Rahman — and Project OWL was born.
The team addresses a fundamental question that arises in the wake of a natural disaster: How do you maintain critical operations and communications when the power is cut and cell connectivity fails?
“We really were inspired by the whole hurricane situation in Puerto Rico,” Feuer said. “All communication was down. It was completely dark for not just one week, but weeks and into months.”
Project OWL, which stands for Organization, Whereabouts, and Logistics, is a two-part hardware/software solution. It provides an offline communication infrastructure that gives first responders a simple interface for managing all aspects of a disaster.
The physical “clusterduck” network is made of hubs resembling rubber ducks, which can float in flooded areas if needed. Only five are needed to cover a square mile, and they create a mesh network that can send speech-based communications using conversational systems (like Alexa and Facebook Messenger) to a central application. This application, the OWL software incident management system, uses predictive analytics and multiple data sources to build a dashboard for first responders.
“Once this network of ducks is deployed and then clustered, civilians are able to basically get on the devices through a really intuitive interface and contact first responders with a list of things that are really essential to them,” Pereira said.
With this information, Project OWL allows first responders to manage a disaster, coordinate resources, learn about weather patterns and get information data analytics through the cloud. The solution bakes in the latest IBM Watson Studio, Watson Cloud APIs, and Weather Company APIs — all built on the IBM Cloud.
Weather data forms a core part of the application, with the ability to ask questions like “Which direction is the nearest tropical storm is headed?” and “What conditions can you expect tomorrow night?” after hurricane flooding.
“In the worst disasters, chaos and misinformation are pervasive,” Knouse said. “With better information and better analytics, you can get the resources you need to the places that need it most. This type of efficiency can dramatically impact the number of people that can be saved in a disaster.”
The team is working on testing OWL in simulated environments with response teams. They plan to roll out to small incidents before deploying in full-scale disasters. Their goal is to focus on regions where annual weather patterns consistently impact communities negatively, such as India, China, the Philippines, and parts of the U.S.
In addition to the cash prize and support from the IBM Corporate Service Corps, the team members, who hail from New York and North Carolina, will have the opportunity to pitch OWL to venture capitalist firm NEA for potential funding.
“Throughout its history, IBM has believed in the ingenuity of curious people to improve humanity with forward-thinking technology. Moreover, from driving collaboration on Linux and Java to Kubernetes and Hyperledger, IBM has strongly believed in the importance of working openly so that everyone can benefit from the best ideas,” said IBM Chief Digital Officer Bob Lord. “Today, with the ability to safely process data at scale using sophisticated tools like AI, cloud, blockchain, and IoT, developers are unleashing the power of IBM’s open code to effect change faster, in more places, and in more meaningful ways than ever before.”
Daryl Pereira, Kevin Allen and Liz Klipp contributed reporting to this article.
",,Person,coal black,keyboard,keyboard,computer keyboard,-
https://ibm.co/2ynM8aY,187446750783_10155976291835784,https://www.facebook.com/ibmwatson/posts/10155976291835784,Got time for a podcast this afternoon? Tune into Quizlet CEO Matthew Glotzbach discussing how teachers can utilize #AI to find and address learning gaps: ,Link,,,10/29/18 13:07, ,5737,5737,0,7700,7700,0,27,20,23,4,4,7209,5352,0,0,24,0,0,0,0,0,0,0,0,0,0,1,9.0,,1,9.0,,14,6.0,,,17,6.0,,,2,2.0,,2,2.0,,"Stream AI: Helping Teachers Sleep at Night feat. Matthew Glotzbach, CEO, Quizlet by IBM thinkLeaders from desktop or your mobile device",https://i1.sndcdn.com/artworks-000413539941-7ub0y5-t500x500.jpg,https://soundcloud.com/ibmthinkleaders/ai-helping-teachers-sleep-at-night-feat-matthew-glotzbach-ceo-quizlet,fear,0.274302,neutral,0,"Quizlet CEO Matthew Glotzbach, Tune","Company, Person, Hashtag",Quizlet CEO Matthew Glotzbach,Company,joy,0.297308,neutral,0,"Matthew Glotzbach, mobile device","Person, Company",Matthew Glotzbach,Person,fear,0.121326,neutral,0,current browser,,"     Your current browser isn't compatible with SoundCloud. 
     Please download one of our supported browsers. Need help?   
",current browser,,coal black,plow,tool,plow,-
,187446750783_10155973946585784,https://www.facebook.com/ibmwatson/posts/10155973946585784,IBM Watson,SharedVideo,,,10/28/18 9:57, ,2052,2052,0,2530,2530,0,119,112,140,5,5,2305,1902,0,0,107,0,0,0,0,1339,1419,0,0,0,30393,,14.0,,,14.0,,112,,,,140,,,,3,2.0,,3,2.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2Au0zvi,187446750783_10155970091425784,https://www.facebook.com/ibmwatson/posts/10155970091425784,The future of efficient customer service lies in introducing artificial intelligence to call centers. Learn about IBM and Lenovo's $240 million partnership to do just that. ,Link,,,10/26/18 11:28, ,9733,9733,0,13677,13677,0,336,227,287,12,12,10433,7691,0,0,222,0,0,0,0,0,0,0,0,0,0,28,126.0,9.0,29,128.0,11.0,110,139.0,,,141,146.0,,,4,8.0,,4,8.0,,"IBM announced that it will supply field services and remote call center solutions to enhance the commercial customer experience for Lenovo in its North America, EMEA, and Latin America markets.",https://martechseries.com/wp-content/uploads/2018/10/IBM.jpg,https://martechseries.com/sales-marketing/customer-experience-management/ibm-services-signs-240-million-agreement-lenovo-help-drive-future-call-centers-artificial-intelligence/,sadness,0.068695,positive,0.799008,"future of efficient customer service, artificial intelligence","Quantity, Company, Company",future of efficient customer service,Quantity,sadness,0.170894,positive,0.859158,"remote call center solutions, North America, field services, IBM","Company, Company",remote call center solutions,Company,sadness,0.55554,positive,0.833064,field services,"Company, Company, Quantity, Quantity, Quantity, Quantity, Quantity, Company","IBM Solution Offers Global Reach of Cognitive Solutions, Augmented Reality and Weather Alerting Technologies
IBM announced that it will supply field services and remote call center solutions to enhance the commercial customer experience for Lenovo in its North America, EMEA, and Latin America markets.
The $240M USD multi-year agreement continues to build on the success of the IBM-Lenovo relationship that began in 2005. 
Today’s customers’ expectations for service are changing, and they want to have everything inter-connected, 24×7 with one swipe at a high level of speed and accessibility. In fact, according to IBM’s research, more than $1 trillion is spent on 265 billion customer service calls each year industry-wide, with 50% of those calls going unresolved. That data, compounded by a recent report, revealed that poor customer service is costing businesses more than $75 billion a year – up $13 billion since 2016.
Also Read: Ahalogy Named an Influencer Marketing Solutions ‘Leader’ by Top Independent Research Firm
Meanwhile, information overload is a huge issue, with support agents sorting through a deluge of technical documentation on the spot like new product releases, updated technical info, machine data, service history and client-specific instructions. The pressure is on to fix issues quickly and accurately and to improve customer experience and evolve the call center to one that is faster, better quality, cheaper and more predictable.
This agreement takes customer care to the next level. Now, when a customer connects with an agent for Lenovo Think-branded PCs and monitors, not only does the agent already know who they are talking to and the issue they are calling about, IBM’s Virtual Assistant for Technical Support uses its natural language capabilities and contextual recognition, to personalize the conversation by asking the right questions about service issues and obtaining solution advice, while also accessing key customer information.
“Providing customers with leading edge technology solutions and offering great support services go hand-in-hand with the customers’ total experience,” said Jammi Tu, senior vice president and chief operating officer of Lenovo Intelligent Devices. “Through our work with IBM, we are increasing our service capabilities through IBM’s Virtual Assistant for Technical Support, Augmented Reality and weather technology, helping us deliver the fast, personalized and consistent care customers expect from their trusted technology brand.”
Also Read: Businesses Breathe the Open Air with simPRO’s Latest Field Sales Solution
The solution, facilitated by IBM, is designed to decrease service costs for Lenovo while growing profitability by integrating the global coverage and capacity of IBM’s Customer Engagement Centers (CEC) and field service solutions around the world, with its standard package of cognitive solutions including: 
Also Read: DataRobot Introduces DataRobot Insights, a New Tableau Extension
“Data is having an unprecedented impact on call centers with artificial intelligence taking customer service to a whole new level of personalization,” said Martin Jetter, senior vice president of Global Technology Services, IBM. “This global collaboration with Lenovo further strengthens our long-standing relationship, empowering every single call center and field service agent at Lenovo to deliver service excellence using the power of Watson AI.”
IBM Technology Support Services delivers world-class service with presence in over 200 countries, speaking 127 languages, 57 remote support centers, managing 6 million service requests, with more than 19,000 support professionals and services over 30,000 products.
PR Newswire, a Cision company, is the premier global provider of multimedia platforms and distribution that marketers, corporate communicators, sustainability officers, public affairs and investor relations officers leverage to engage key audiences. Having pioneered the commercial news distribution industry over 60 years ago, PR Newswire today provides end-to- end solutions to produce, optimize and target content -- and then distribute and measure results. Combining the world's largest multi-channel, multi-cultural content distribution and optimization network with comprehensive workflow tools and platforms, PR Newswire powers the stories of organizations around the world. PR Newswire serves tens of thousands of clients from offices in the Americas, Europe, Middle East, Africa and Asia-Pacific regions.
",field services,Company,pink,breathalyzer,measuring instrument,densitometer measuring instrument,-
,187446750783_10155966204625784,https://www.facebook.com/ibmwatson/posts/10155966204625784,IBM Watson,SharedVideo,,,10/24/18 9:05, ,2497,2497,0,2910,2910,0,95,78,93,3,3,2670,2285,0,0,88,0,0,0,0,1056,1162,0,0,0,58238,,22.0,,,22.0,,77,4.0,,,88,5.0,,,,3.0,,,3.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2yg49qQ,187446750783_10155965145120784,https://www.facebook.com/ibmwatson/posts/10155965145120784,"In a recent IBM report, business leaders explained just how they see AI infiltrating their organization. Here are the top five areas where business executives said AI would drive the most value this year via TechRepublic: ",Link,,,10/23/18 18:35, ,7068,7068,0,9964,9964,0,131,98,123,4,4,8773,6278,0,0,106,0,0,0,0,0,0,0,0,0,0,11,40.0,1.0,12,41.0,1.0,40,65.0,,,52,71.0,,,1,3.0,,1,3.0,,"A recent IBM study focused on the business importance of IT, and how AI is growing in the workplace.",https://tr1.cbsistatic.com/hub/i/r/2018/09/27/d26d3e2d-c0ec-4551-ad45-e5953a32ac78/thumbnail/770x578/e640750a63ba7d799b23269669582d77/ceotech.jpg,https://www.techrepublic.com/article/ceos-5-areas-where-ai-will-drive-the-most-value-in-2018/,anger,0.270172,neutral,0,"recent IBM report, business leaders, business executives","Person, Company",recent IBM report,Person,joy,0.364615,positive,0.617477,recent IBM study,"Company, Person",recent IBM study,Company,joy,0.419643,positive,0.435501,Customer service,"Person, Company, Quantity, Organization"," 	As artificial intelligence (AI) matures and makes good on its promises, the technology is rapidly finding its way into more and more enterprise organizations. As hardware becomes commoditized, AI is emerging as the competitive differentiator for consumer-facing and B2B businesses alike.
 	In a  	recent IBM report, conducted in partnership with Oxford Economics, business leaders explained just how they see AI infiltrating their organization. According to the report, some 93% of outperforming businesses are considering AI adoption, and many organizations are moving beyond the question of whether or not to adopt the technology, to how they'll implement it.
 	However, AI won't have an equal impact across all business functions. Here are the top five areas where business executives said AI would drive the most value in 2018 (and the percentage of leaders who listed it):
 	 	SEE: 2019 IT Budget Research Report: IT spending increases due to business conditions, security, and revenue opportunities (Tech Pro Research)
 	In areas like IT, AI-enabled assistants could help perform help desk operations, while threat detection algorithms could improve the effectiveness of security, the report said. Customer service is a common pilot area for AI projects, as virtual chat bots streamline the process. Innovation will serve as a center of excellence for AI, and the technology will help with fraud detection and risk management.
 	However, challenges to AI adoption do exist. Primarily, this will show itself in the poor availability of skilled resources or employees with the proper technical skills, as noted by 63% of those surveyed.
 	""As the demand for data scientists and other AI experts increases, employee retention risks
 	also rise,"" the report said. ""Startups are aggressively poaching AI talent from academia and established corporations. And while constrained candidate pools do not necessarily equate to a zero-sum game, organizations also will need to make more with what they already have.""
 	Regulatory constraints were cited by 60% of respondents, while legal and privacy concerns over the use of customer data were top of mind for 55%. One of the biggest challenges, the report noted, was that businesses must be transparent and open with their processes while protecting their users' privacy as strongly as they can.
 	In order to get started on your AI journey, IBM shared four steps from a previous implementation guide:
",Customer service,Person,blue,fountain,platform,stage,-
https://ibm.co/2AnAv5k,187446750783_10155962552790784,https://www.facebook.com/ibmwatson/posts/10155962552790784,"Learn how IBM is creating AI models that are making decisions and automatically detecting and mitigating bias to produce fair, trusted outcomes with AI OpenScale. Read more in Forbes : ",Link,,,10/22/18 10:49, ,10539,10539,0,14367,14367,0,214,138,171,4,4,12721,9439,0,0,182,0,0,0,0,0,0,0,0,0,0,13,103.0,2.0,16,109.0,2.0,71,75.0,,,87,84.0,,,1,3.0,,1,3.0,,"IBM AI OpenScale provides explanations into how AI models are making decisions, and automatically detect and mitigate bias to produce fair, trusted outcomes. It also marks IBM's entry into the AutoML market.",https://thumbor.forbes.com/thumbor/fit-in/1200x0/filters%3Aformat%28jpg%29/https%3A%2F%2Fblogs-images.forbes.com%2Fjanakirammsv%2Ffiles%2F2018%2F10%2Fai-openscale-1200x745.jpg,https://www.forbes.com/sites/janakirammsv/2018/10/21/ibm-wants-to-make-artificial-intelligence-fair-and-transparent-with-ai-openscale/#7bbc4066790c,joy,0.283563,neutral,0,,"Company, Person, Person",,Company,anger,0.2446,positive,0.46331,"IBM's entry, IBM",Company,IBM's entry,Company,joy,0.520546,positive,0.618972,Janakiram MSV,"Company, Person, Person, Company, Company, Company, Company, Company, Company, Company, Company, Company","IBM has announced AI OpenScale, a service that aims to bring visibility and explainability of AI models for enterprises.
When it comes to adopting AI for business use, there are multiple concerns among enterprise customers. Lack of visibility of the model, unwanted bias, interoperability among tools and frameworks, compliance in building and consuming AI models are some of the critical issues with AI.
IBM AI OpenScale provides explanations into how AI models are making decisions, and automatically detects and mitigates bias to produce fair, trusted outcomes. It attempts to bring confidence to enterprises by addressing the challenges involved in adopting artificial intelligence. The service is available within the IBM Cloud Watson product portfolio.
AI OpenScale acts as an intermediary layer positioning itself between the application and the machine learning models that deliver predictions. Each time an application consumes the model, the inbound (data points) and output data (predictions) are logged in a centralized database. The service also comes with a database to store training and feedback data which is used to retrain and deploy the models. AI OpenScale uses both the databases to analyze bias, accuracy, and explainability of models. Users can zoom into a specific transaction to understand the factors that influenced the outcome from predictive analytics. The service continually monitors AI applications to prevent bias through an automated de-biasing technology.
The service supports models deployed within IBM Watson along with 3rd party platforms such as Amazon SageMaker and Azure ML. AI OpenScale can be integrated with  models developed in TensorFlow, Keras, Scikit-Learn, SparkML and PMML. The service logs the input and output from both internal and external services for further analysis.
AI OpenScale logs every prediction, every model version, and all the training data used, together with all metrics to help businesses comply with regulations such as GDPR.
The other important component of AI OpenScale is NeuNetS – an automated machine learning service that will allow businesses to rapidly and automatically build neural networks from scratch. NeuNetS looks similar to AutoML services such as CustomVision from Microsoft and AutoML Vision from Google.
AutoML significantly reduces the time and effort required to generate sophisticated machine learning models dealing with natural language processing and computer vision. Based on techniques such as transfer learning, AutoML leverages existing neural networks to accelerate the training process to deliver accurate predictions. AutoML can generate models even from smaller datasets making it an attractive choice for enterprises.
According to IBM, NeuNetS can help businesses reach accuracy similar to that of an expert-designed AI model in a matter of hours, rather than weeks and months. An expert data scientist can then further tune the model.
Janakiram MSV is an analyst, advisor and an architect at Janakiram & Associates. He was the founder and CTO of Get Cloud Ready Consulting, a niche cloud migration and cloud operations firm that got acquired by Aditi Technologies. Through his speaking, writing and analysis, he helps businesses take advantage of the emerging technologies.
Janakiram is one of the first few Microsoft Certified Azure Professionals in India. He is one of the few professionals with Amazon Certified Solution Architect, Amazon Certified Developer and Amazon Certified SysOps Administrator credentials. Janakiram is a Google Certified Professional Cloud Architect. He is recognised by Google as the Google Developer Expert (GDE) for his subject matter expertise in cloud and IoT technologies. He is awarded the title of Most Valuable Professional and Regional Director by Microsoft Corporation. Janakiram is an Intel Software Innovator, an award given by Intel for community contributions in AI and IoT. Janakiram is a guest faculty at the International Institute of Information Technology (IIIT-H) where he teaches Big Data, Cloud Computing, Containers, and DevOps to the students enrolled for the Master's course. He is an Ambassador for The Cloud Native Computing Foundation.
Janakiram was a senior analyst with Gigaom Research analyst network where he analyzed the cloud services landscape. During his 18 years of corporate career, Janakiram worked at world-class product companies including Microsoft Corporation, Amazon Web Services and Alcatel-Lucent. His last role was with AWS as the technology evangelist where he joined them as the first employee in India. Prior to that, Janakiram spent over 10 years at Microsoft Corporation where he was involved in selling, marketing and evangelizing the Microsoft application platform and tools. At the time of leaving Microsoft, he was the cloud architect focused on Azure.
",Janakiram MSV,Company,sage green,person,building,control center,-
https://ibm.co/2CTnaUJ,187446750783_10155960453940784,https://www.facebook.com/ibmwatson/posts/10155960453940784,"Given only a high-level task—identify an important concept in AI, create an original image that captures it, and present it in a way that fits with the visual style of The New York Times— IBM Research developed a new process that perfectly combines AI and human creativity. ",Link,,,10/21/18 9:02, ,11752,11752,0,16225,16225,0,144,94,122,2,2,14196,10167,0,0,120,0,0,0,0,0,0,0,0,0,0,24,58.0,1.0,24,61.0,1.0,38,58.0,,,57,65.0,,,,2.0,,,2.0,,"What does AI look like? To find out, IBM Research asked AI to draw a self-portrait then taught it how via a new process that unites AI and human creativity.",https://www.ibm.com/blogs/research/wp-content/uploads/2018/10/AIselfportrait-768x768.png,https://www.ibm.com/blogs/research/2018/10/ai-creativity/,joy,0.75307,positive,0.988667,"important concept, original image, high-level task, visual style of The New York Times","PrintMedia, Company",important concept,PrintMedia,joy,0.412449,positive,0.766071,"self-portrait, IBM Research","Person, Company",self-portrait,Person,joy,0.655721,positive,0.749102,New York Times today,"Person, PrintMedia","Share this post:
What does AI look like? You might say it looks like a robot, or flashing LEDs, or a waveform on a screen. But what would AI say AI looks like? To find out, IBM Research asked AI to draw us a picture… of itself. AI’s self-portrait was published in The New York Times today and, looking at the image, I am amazed not only with the result, but also the journey we took to get there.
The New York Times contacted IBM Research in late September asking for our help to use AI in a clever way to create art for the coming special section on AI. With a very short timeline and no guarantee of success, we set out to teach AI to create original art. Given only a high-level task—identify an important concept in AI, create an original image that captures it, and present it in way that fits with the visual style of The New York Times—we developed a new process that perfectly combines AI and human creativity.
Why would drawing a self-portrait be such a challenge for AI? After all, AI can drive cars, play video games, even produce a movie trailer. The difference is that these tasks don’t require AI to create new material, just to analyze the information at hand and make decisions or selections based on its training. We already know that AI can perform exceptionally well at language and image analysis. Creating new content, on the other hand, is a much more experimental activity.
To take on this challenge, we quickly assembled a multidisciplinary team within IBM Research that included Alfio Gliozzo, Mauro Martino, Michele Merler, and Cicero Nogueira dos santos. The range of expertise required speaks to the nature of the task: deep science thinking, hands-on technical and engineering skills, and design and visualization talent were essential to our effort. In essence, we needed to explicitly define the creative process. The result is a nuanced pipeline in which AI performs critical functions in both analysis and synthesis to create something truly novel and captivating.
The process included the following three major steps:
This pipeline gives us a compelling new capability for collaborative creativity that could be applied to other tasks as well. Imagine using AI to design artwork for a new album based on the musicians’ songs, lyrics, and history.
More importantly, the results show how AI and humans can work hand in hand to explore entirely new territory. We’ve seen this synergy in diverse settings from drug discovery to financial market prediction to malware detection. Extending this paradigm to the realm of creativity underscores the many ways that AI can augment human abilities.
",New York Times today,Person,lemon yellow,toyshop,building,retail store,shop
https://ibm.co/2QWofhz,187446750783_10155958448160784,https://www.facebook.com/ibmwatson/posts/10155958448160784,"On Bloomberg Television, watch IBM's Director of Research and SVP of Hybrid Cloud Arvind Krishna discuss the next level of cloud technology and IBM's announcement on AI OpenScale. ",Link,,,10/20/18 9:44, ,14685,14685,0,20533,20533,0,490,355,494,7,7,17068,12197,0,0,395,0,0,0,0,0,0,0,0,0,0,29,184.0,4.0,31,186.0,5.0,151,259.0,,,195,299.0,,,4,3.0,,4,3.0,,,,https://www.bloomberg.com/tosv2.html?vid=&uuid=5b0b3830-63af-11ea-838f-7b3c308ebc4f&url=L25ld3MvdmlkZW9zLzIwMTgtMTAtMTYvaWJtLXVudmVpbHMtYS1uZXctZ2VuZXJhdGlvbi1vZi1jbG91ZC10ZWNobm9sb2d5LXZpZGVv,joy,0.075082,neutral,0,"Bloomberg Television, SVP of Hybrid Cloud Arvind Krishna","Person, Broadcaster, Company",Bloomberg Television,Person, , , , , , , , ,joy,0.049334,neutral,0,support team,,"To continue, please click the box below to let us know you're not a robot.
Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.
For inquiries related to this message please contact our support team and provide the reference ID below.
",support team,, , , , , 
https://ibm.co/2pT2d3R,187446750783_10155957305030784,https://www.facebook.com/ibmwatson/posts/10155957305030784,How IBM Watson Speech to Text is helping teachers in Japan use AI to thrive in a new kind of classroom: ,Link,,,10/19/18 18:14, ,8126,8126,0,11223,11223,0,107,75,84,5,5,10044,7284,0,0,90,0,0,0,0,0,0,0,0,0,0,14,33.0,,15,36.0,,25,52.0,,,31,53.0,,,,5.0,,,5.0,,The AI technology has become an essential piece of our strategy for rolling out the Knowledge Constructive Jigsaw method to a wider network of schools.,https://www.ibm.com/blogs/client-voices/wp-content/uploads/2018/10/TokyoCoRef_staticjpg4_v1.jpg,https://www.ibm.com/blogs/client-voices/how-ai-is-helping-transform-education-in-japan/,joy,0.268004,positive,0.634282,IBM Watson Speech,"Person, Company",IBM Watson Speech,Person,joy,0.465881,positive,0.956717,"essential piece of our strategy, technology",,essential piece of our strategy,,joy,0.652469,positive,0.726523,,"Organization, Organization, Location, Organization, Person, Quantity, Company","A fourth-grade science class is just beginning. Students are settling into their seats as the teacher poses a question: Why does a heated aluminum can collapse when it is rapidly cooled?
Instead of consulting a textbook or listening to a lecture, students are assigned to one of three experiments. One experiment involves cooling a bag of vapor. Another involves heating and cooling a bottle of milk with a balloon attached to the opening. The third involves cooling a heated conical flask with a hard-boiled egg perched on top. The classroom buzzes with energy.
Next, students discuss their results in small groups, sharing their own observations while integrating the ideas of classmates. They question, compare, explore, speculate and reflect. Their voices fill the room, challenging the idea that classrooms should be quiet. Natural curiosity drives them toward an answer and helps them retain the information longer.
What I just described is not a typical Japanese classroom. It’s part of a growing network of schools across Japan adopting a new method—one that encourages creativity, collaboration and problem-solving rather than uniformity and memorization.
At the Consortium for Renovating Education of the Future (CoREF)—launched at the University of Tokyo in 2008—we’re helping to transform Japan’s educational system by applying the latest research in the cognitive and learning sciences.
What we’ve found is that an active, collaborative approach to learning can dramatically improve education quality. The method we promote—the Knowledge Constructive Jigsaw method—encourages students to piece together a deeper understanding of a topic by considering it from multiple angles, working as part of a group.
It’s a big departure from traditional education in Japan. Which is why we must consider every aspect of implementation—not only the effect on students, but also the impact on teachers, lesson plans, resources and technology.
To use the Knowledge Constructive Jigsaw method in their classrooms, teachers must adapt. Instead of delivering static curriculum to a group of passive students, they should follow an “Anticipation-Action-Reflection” cycle—designing student-centric lessons, monitoring and providing feedback on student activity, and collaborating with colleagues to continuously improve.
In theory, this is a great idea. In practice, it’s difficult. Teachers simply cannot monitor all student conversations, as there are likely to be multiple small groups working simultaneously.
Given the constraints of the traditional classrooms, we saw technology as the best option for overcoming the challenge. We introduced IBM Watson Speech to Text technology in the IBM Cloud to help monitor the quality of student interactions, fueling the planning and feedback cycle. The AI technology has become an essential piece of our strategy for rolling out the Knowledge Constructive Jigsaw method to a wider network of schools.
Here’s how it works:
Imagine how far education can progress with evidence-based learning methods and AI-powered assistive tools. Instead of teaching to a test, teachers can work to inspire creativity and a love of learning. Students can strengthen their capacity for independence and collaboration. Society can benefit from new generations of active learners who are motivated to solve problems and try new things, driving economic innovation and growth.
CoREF is one piece of a larger effort to achieve this educational transformation in Japan. With a widespread interest in the topic, from the cabinet of the prime minister and advanced learning institutions to cognitive researchers and industry at large, the revitalization project is a promising vision on the horizon. We look forward to exploring how AI and other emerging technologies might help us get there.
",,Organization,azure,semaphore,apparatus,semaphore,-
https://ibm.co/2Puy4D8,187446750783_10155954277620784,https://www.facebook.com/ibmwatson/posts/10155954277620784,The MIT-IBM Watson AI Lab collaboration offers a new model for engaging between academia and industry. Here are 5 key ways the relationship is advancing transformational progress in AI research. ,Link,,,10/18/18 8:49, ,5674,5674,0,8003,8003,0,136,71,93,4,4,6803,4560,0,0,109,0,0,0,0,0,0,0,0,0,0,16,70.0,,16,74.0,,30,46.0,,,47,46.0,,,,4.0,,,4.0,,Continued broad development of AI technologies and concepts require new approaches to collaboration between industry organizations and academia.,https://img.deusm.com/informationweek/Oct/David_Cox_IBM.jpg ,https://www.informationweek.com/big-data/how-artificial-intelligence-will-go-to-the-next-level/a/d-id/1333000,joy,0.326012,positive,0.738496,"MIT-IBM Watson, key ways","Organization, Company",MIT-IBM Watson,Organization,sadness,0.155798,neutral,0,"broad development, new approaches",Company,broad development,Company,joy,0.625469,positive,0.8438,,Person,"Industry and academia have collaborated in artificial intelligence research for decades, but in recent years the power balance in this relationship has shifted in ways that are detrimental to AI progress and the sustainability of the field.
Most existing arrangements between industry and academia are either “work for hire,” which often is too narrowly defined to attract the brightest minds in academia to participate, or “buy the lab,” which effectively end collaborations by hiring researchers away from academia and prevent the next generation of AI talent from receiving the education and research opportunities that will lead to AI progress in the future, cannibalizing the future pipeline to serve the needs of the present.
A new working model between industry and academia is needed, one in which stable, long-term industry-academic partnerships enable continued AI advancement while preserving our society’s capacity to conduct fundamental research and train future generations of AI experts.
In a long-term partnership, academic and industry researchers must work collaboratively as equals, rather than industry merely sponsoring research or pulling faculty or students out of academia.
Instead of traditional top-down or single-organization decision-making, successful partnerships should be guided by more inclusive decision-making approaches – for example, through joint committees, with equal representation of academic and industry members, each of whom feels a strong responsibility to the collaboration and to the advancement of AI.
We believe our MIT-IBM Watson AI Lab collaboration offers a new model for engaging between academia and industry. Below are five key advantages to such a model, and an explanation of why it’s the surest path to transformational progress in AI research.
AI is exploding with new and expanding subfields, and conducting rapid and meaningful AI research demands cross-disciplinary knowledge, along with intense focus. Strong long-term partnerships between academia and industry are positioned to integrate a broad range of academic disciplines -- from computer science, mathematics and logic to biology, linguistics, economics and even the arts -- with industry’s real-world perspective, domain knowledge, and access to data. Furthermore, advances in AI demand new ideas and a creative, ambitious workforce, along with substantial computational and financial resources. With academia being a fertile source for the former and industry uniquely positioned to provide the latter, unifying the two takes full advantage of their complementary strengths.
Because expansion of AI has broad implications for all people and communities, its creation and development should reflect a diversity of backgrounds and viewpoints. Part of the value of a peer research approach is in the variety of perspectives, expertise, and experience levels it offers. Students bring fresh ideas and eagerness to immerse and learn quickly, to experiment and take risks, to deeply focus on a novel problem or solution, and to earn a scientific reputation (and a degree) for themselves. Experienced academic and industry researchers share deep expertise in their chosen areas that comes from years, potentially decades, of focus, failures, and breakthroughs; scientific rigor and principled approaches; and an understanding of the broader context in which technology can be brought into service.
One of the greatest accelerators in AI progress is the openness with which academic and industry players have shared the fruits of their research. Yet it is not uncommon that when talented AI researchers leave academia and join industry, their research becomes more closed and less accessible to the field, slowing the overall development of AI as a field. We recognize that there is substantial value in an open ecosystem in which industry and academia work in close collaboration with one another, sharing their results and technologies with the wider AI community. By publishing in top scientific conferences and journals, and open-sourcing data and code, we can feed the research ecosystem and accelerate rather than stifle the development of AI.
Radical ideas and growth
Scientific discoveries are sparked by creativity and curiosity as much as rigor and discipline. In AI, this calls for an entrepreneurial research model that welcomes new projects, sets them up for success by establishing milestones, and iterates on promising work. Our collaboration with MIT is designed to nurture radical ideas, encouraging them to take root and grow into breakthroughs.
Identifying and meeting marketplace needs are key to the success of a business endeavor, as those familiar with start-ups know well. Why? Because targeting market needs leads to investment, which is essential to further develop emerging technologies. By pursuing opportunities to commercialize AI discoveries and inventions, we can encourage a healthy growing climate for AI research.
Bringing industry and academia together creates the ideal environment for incubating the new breakthroughs needed to realize broad AI for enterprise and the increases in value and productivity it promises. Now is the time to align across sectors and the entire AI ecosystem to accelerate our progress. AI has unprecedented potential to benefit enterprises and the societies they serve. We must work together to fuel the innovations that will deliver on that potential.
David Cox is director of the MIT-IBM Watson AI Lab, IBM Research.
 The InformationWeek community brings together IT practitioners and industry experts with IT advice, education, and opinions. We strive to highlight technology executives and subject matter experts and use their knowledge and experiences to help our audience of IT ... View Full Bio  
We welcome your comments on this topic on our social media channels, or [contact us directly] with questions about the site.
",,Person, , , , , 
https://ibm.co/2yiAX3h,187446750783_10155952525015784,https://www.facebook.com/ibmwatson/posts/10155952525015784,"“I really believe we are the leader in AI for business. Our specialization is to know what it takes for the enterprise to operate in the world.&quot; 

Read more on The Wall Street Journal's story of IBM CEO Ginni Rometty's talk at the Gartner Symposium this week. ",Link,,,10/17/18 11:33, ,8992,8992,0,12012,12012,0,250,138,169,8,8,9852,7374,0,0,213,0,0,0,0,0,0,0,0,0,0,16,128.0,,16,130.0,,43,100.0,,,57,112.0,,,5,3.0,,5,3.0,,"Speaking to CIOs, IBM Chief Executive Ginni Rometty outlined how the company is positioning itself as businesses industry-wide ramp up their use of cloud, big data and artificial intelligence.",https://images.wsj.net/im-31236,https://blogs.wsj.com/cio/2018/10/16/ibm-ceo-ginni-rometty-sharpens-focus-on-emerging-tech-for-business/,joy,0.541785,positive,0.959618,"Wall Street Journal's story, IBM CEO Ginni Rometty's talk","Person, Person, PrintMedia, Company",Wall Street Journal's story,Person,anger,0.086397,neutral,0,"IBM Chief Executive Ginni Rometty, businesses industry-wide ramp, big data","Person, Company",IBM Chief Executive Ginni Rometty,Person,joy,0.493408,positive,0.589799,,"Person, Company","ORLANDO, Fla. -- For most companies, the start and endpoints of any major strategic shift are the easy part, it’s the middle that can make or break a business, says Ginni Rometty, president and chief executive officer of International Business Machines Corp.
How does she know? It’s a journey IBM itself embarked on over six years ago, when Ms. Rometty took on the top job at the technology firm, which traces its origins to the late-19th Century.
Speaking to chief information officers and other senior enterprise IT managers gathered here for Gartner’s annual IT industry conference, Ms. Rometty outlined the many ways IBM has shifted within the enterprise technology market in recent years, as businesses across all industries ramp up their use of cloud computing, big data, artificial intelligence, blockchain and other emerging digital tools.
“This has clearly been the time of rapid change,” Ms. Rometty said, “and it isn’t going to stop.”
Her remarks Tuesday came ahead of IBM’s third-quarter earnings, which the company is set to report after markets close at the end of the day.
Analysts surveyed by S&P Global Market Intelligence are expecting a decline in revenue, to $19.04 billion from $19.15 billion over the same period a year ago, following three consecutive quarters of growth. Amid ups and downs, revenue has been shrinking over the past six years.
Over that time, Ms. Rometty has led the company’s re-positioning from selling workhorse legacy IT tools, to focusing on growth markets and emerging digital tools, like cloud, AI, quantum computing and blockchain. She predicted that blockchain would have an impact on business in five years and urged companies to prioritize their preparation now.
In her first two years as CEO, she said, “we could see the market was changing and we needed to change faster,” taking a cue from the agility of tech startups: “I think we learned a lot from startup companies,” she added.
And while the consumer tech market is booming, Ms. Rometty said, as a company, “you have to decide what you are and what you are not, and we are not a direct to consumer company.” AI for business is different, she said. The big challenge, in her view, isn’t technology, but change management. Beyond that, AI for business must be explainable and adjusted for bias, and be able to scale. Also, it is often domain-specific, focused on a particular problem or set of data. It is crucial that companies that provide AI to enterprises safeguard data from their customers’ rivals in the market.
“I really believe we are the leader in AI for business. Our specialization is to know what it takes for the enterprise to operate in the world,” Ms. Rometty said.
This week alone in the enterprise space, IBM launched a new multi-cloud tool designed to help firms manage a growing number of apps and workloads spread across different cloud environments, regardless of vendor.
It also released similar AI technology that allows the deployment of AI models, regardless of vendor or cloud platform, along with new security tools.
Each of the tools seeks to address a lack of interoperability among many emerging technology systems, even as businesses increasingly take a mix-and-match approach to IT, Ms. Rometty said.
IBM’s corporate customers on average operate with six clouds and roughly one thousand apps, according to Ms. Rometty. “That’s the context when we think of cloud,” she said.
With those capabilities in place, AI increasingly will take on a key role in the way businesses make decisions about services and products in the years ahead. IBM already has some 25,000 AI engagements with customers, Ms. Rometty said.
The broader goal is to offer end-to-end enterprise tech capabilities, with the common currency being data, she said.
“Data will be at the heart of these disruptions for a long time,” Ms. Rometty said.
",,Person,purplish blue,person,sport,gymnastics,-
https://ibm.co/2PBptP5,187446750783_10155948827635784,https://www.facebook.com/ibmwatson/posts/10155948827635784,"Introducing IBM AI OpenScale, the new open, intelligent AI platform designed to enable your organization to operate and automate your AI at scale – all with trust and transparency. Learn more: ",Link,,,10/15/18 12:11, ,110901,19866,90587,473312,28163,445149,3770,3444,4143,6,7,15331,8609,3844,537,169,0,0,0,0,0,0,0,0,0,0,42,314.0,19.0,43,329.0,26.0,286,3192.0,,,344,3799.0,,,1,2.0,4.0,1,2.0,3.0,"Available later this year via the IBM Cloud and IBM Cloud Private, AI OpenScale provides businesses with confidence in AI decisions.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/10/image-5.png,https://www.ibm.com/blogs/watson/2018/10/ibm-ai-openscale-operate-and-automate-ai-with-trust/?cm_mmc=OSocial_Facebook-_-Watson+and+Cloud+Platform_Watson+Core+-+Platform-_-WW_WW-_-OpenScale+announcement+FB+blog&cm_mmca1=000033SC&cm_mmca2=10009389,joy,0.211816,positive,0.731555,,Company,,Company,joy,0.207985,neutral,0,"IBM Cloud, IBM Cloud Private",Company,IBM Cloud,Company,joy,0.55419,positive,0.787269,IBM Watson OpenScale,"Person, Person, Company","Innovative organizations understand that AI offers competitive advantage and is already a driving force in the evolution of their industries. Many have started this journey by implementing successful AI projects – from chatbots that help brands personalize conversations with their customers, to systems that make decades of institutional knowledge immediately accessible to a subject matter expert.
However, for every successful implementation, there are many AI models that fail to make it out of the lab and into production. At IBM, we understand the roadblocks to full AI adoption – from trust and transparency concerns with the ‘black box’ of AI, to problems of scale and automation – and we are working with enterprises to provide the tools needed to overcome these roadblocks and deliver real business value. To that end, today we’re excited to announce our next, critical move in helping businesses accelerate the adoption of AI: IBM Watson OpenScale.
AI OpenScale allows businesses to operate and automate AI at scale, – irrespective of how the AI was built and where it runs. Bridging the gap between the teams that operate AI and those that manage business applications, Watson OpenScale provides businesses with confidence in AI decisions. Available later this year via the IBM Cloud and IBM Cloud Private, it infuses AI throughout its full lifecycle with trust and transparency, explains outcomes and automatically mitigates bias.
AI has tremendous potential. Businesses, however, face a critical AI skills gap. To address that gap, we developed Neural Network Synthesis (NeuNetS). As part of Watson OpenScale, NeuNetS is a beta feature that automatically creates customized neural network models using the latest training data from businesses.
Watson OpenScale provides enterprises visibility into how AI is built, used, and performs. With Watson OpenScale, businesses can embed AI into new or existing business applications and functions with the freedom to use the environment of their choice. Specifically, it supports:
As more applications make use of AI, businesses need visibility into the recommendations made by their AI applications. In the case of certain industries like finance and healthcare, in which adherence to GDPR and other comprehensive regulations present significant barriers to widespread AI adoption, applications must explain their outcomes in order to be used in production situations.
It is critical to ensure AI recommendations or decisions are fully traceable – enabling enterprises to audit the lineage of the models and the associated training data, along with the inputs and outputs for each AI recommendation.
Watson OpenScale significantly expands the Trust and Transparency capabilities we announced last month. Building on these capabilities, we’re also introducing explainability for black box models and functions, automatic bias detection and mitigation, auditability, and traceability on AI applications – regardless of whether they run on a company’s private cloud, on IBM Cloud, or on other vendors’ cloud environments.
NeuNetS is an AI technology that automatically configures itself to specific business data, helping organizations quickly scale AI across their workflows, while making their data science team more productive. This revolutionary technology automatically builds customized neural networks for text and vision models and recommends new models, thereby reducing the complexity and skills required to build AI models.
The technology is still evolving. Benchmarks show that NeuNetS can help businesses reach accuracy similar to that of an expert-designed AI model in a matter of hours, rather than weeks and months. An expert data scientist can then further tune the model. That’s a huge win in terms of productivity and cost-efficiency – a real win in addressing the critical AI skills gap enterprises face today.
IBM Watson OpenScale extends the breadth and depth of IBM capabilities to help businesses accelerate AI – ringing their projects out of the lab and into production.
Watson OpenScale provides visibility and explainability into AI outcomes, helping to ensure fair outcomes while giving business-process owners greater trust in AI’s ability to augment decision-making, and confidence to scale it across their workflows. At the same time, the solution provides a robust framework to ensure AI maintains compliance with corporate policies and regulatory requirements. It also helps remove barriers to AI adoption by empowering users to deploy and manage models across projects, at whatever scale the business requires.
AI OpenScale will be available later this year on the IBM Cloud or IBM Cloud Private.
",IBM Watson OpenScale,Person,ultramarine,laser,optical device,laser,-
,187446750783_10155946562940784,https://www.facebook.com/ibmwatson/posts/10155946562940784,"Got a few minutes? BBC iPlayer's recent &quot;The Why Factor&quot; episode discusses the art of persuasion, or rhetoric. Tune in to listen as it delves into Project Debater, AI that IBM trained to debate humans on complex issues.",Link,,,10/14/18 9:48, ,9335,9335,0,13166,13166,0,103,76,90,3,3,11838,8443,0,0,87,0,0,0,0,0,0,0,0,0,0,9,32.0,1.0,9,33.0,1.0,40,40.0,,,49,41.0,,,1,2.0,,1,2.0,,,,,anger,0.359561,positive,0.65784,"BBC iPlayer, Project Debater","Company, Person",BBC iPlayer,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2ysv5nl,187446750783_10155942234080784,https://www.facebook.com/ibmwatson/posts/10155942234080784,"If we accept that AI is going to be a relevant part of our future, it is important to establish the foundations of trust in AI systems. This blog describes the four pillars we need to build that trust: ",Link,,,10/12/18 11:22, ,8632,8632,0,12043,12043,0,157,86,102,5,5,9501,6680,0,0,118,0,0,0,0,0,0,0,0,0,0,22,80.0,1.0,23,81.0,1.0,29,59.0,,,36,66.0,,,3,2.0,,3,2.0,,"Trust is a foundational building block of human socio-economic dynamics. In software development, during the last few decades, we steadily built mechanisms for asserting trust on specific…",https://miro.medium.com/max/1200/1*z6rmRTWCQcgkXBcB8LgG4A.png,https://towardsdatascience.com/towards-ai-transparency-four-pillars-required-to-build-trust-in-artificial-intelligence-systems-d1c45a1bdd59,joy,0.655673,positive,0.970186,relevant part of our future,Person,relevant part of our future,Person,sadness,0.33141,positive,0.892691,software development,,software development,,joy,0.501167,positive,0.495602,,Person,"Trust is a foundational building block of human socio-economic dynamics. In software development, during the last few decades, we steadily built mechanisms for asserting trust on specific applications. When we get on planes that fly on auto-pilot or cars completely driven by robots we are intrinsically expressing trust on the creators of a specific software application. In software, trust mechanisms are fundamentally based on the deterministic nature of most software applications in which their behavior is uniquely determine by the code workflow which makes it intrinsically predictable. The non-deterministic nature of artificial intelligence(AI) systems breaks the pattern of traditional software applications and introduces new dimensions to enable trust in AI agents. Recently, researchers from IBM proposed a new methodology for establishing trust in AI systems.
Trust is a dynamic derived from the process of minimizing risk. In software development, trust is built through mechanisms such as testability, auditability, documentation and many other elements that help establish the reputation of a piece of software. While all those mechanisms are relevant to AI systems, they are notoriously difficult to implement. In traditional software applications, their behavior is dictated by explicit rules expressed in the code; in the case of AI agents, their behavior is based on knowledge that evolves over time. The former approach is deterministic and predictable, the latter is non-deterministic and difficult to understand.
If we accept that AI is going to be a relevant part of our future, it is important to establish the foundations of trust in AI systems. Today, we regularly rely on AI models without having a clear understanding of their capabilities, knowledge or training processes. The concept of trust in AI systems remains highly subjective and hasn’t been incorporated as part of popular machine learning frameworks or platforms. What is AI trust and how can we measure it?
Trust in human interaction is not only based on our interpretation of specific actions but it considers social knowledge built throughout centuries. We understand that a behavior is discriminatory not only by judging it on real time by also by factoring in a socially-accepted concept that discrimination is derogatory to human beings. How can we extrapolate these ideas to the world of artificial intelligence(AI). In their paper , the IBM team proposed four fundamental pillars to trusted AI:
· Fairness: AI systems should use training data and models that are free of bias, to avoid unfair treatment of certain groups.
· Robustness: AI systems should be safe and secure, not vulnerable to tampering or compromising the data they are trained on.
· Explainability: AI systems should provide decisions or suggestions that can be understood by their users and developers.
· Lineage: AI systems should include details of their development, deployment, and maintenance so they can be audited throughout their lifecycle.
AI fairness is typically associated with the minimization of bias in AI agents. Bias can be described as the mismatch between the training data distribution and a desired fair distribution. Unwanted bias in training data can result on unfair results. Establishing tests for identifying, curating and minimizing bias in training datasets should be a key element to establish fairness in AI systems. Obviously, fairness is more relevant in AI apps with a tangible social impact such as credit or legal applications.
Understanding how AI models arrive to specific decisions is another key principle of trusted AI. Arriving to meaningful explanations about the knowledge of AI models reduces uncertainty and helps to quantify their accuracy. While explainability might be seen as an obvious factor to improve the trust in AI systems, its implementation is far from trivial. There is a natural tradeoff between the explainability of AI models and their accuracy. Highly explainable AI models tend to be very simple and, therefore, not incredibly accurate. From that perspective, establishing the right balance between explainability and accuracy is essential to improve the trust on an AI model.
The concept of AI robustness is determined by two underlying factors: safety and security.
An AI system might be fair and explainable but still unsafe to use. AI safety is typically associated with the ability of an AI model to build knowledge that incorporates societal norms, policies, or regulations that correspond to well-established safe behaviors. Increasing the safety of AI models is another key element of trusted AI systems.
AI models are highly susceptible to all sorts of attacks including many based on adversarial AI methods. The accuracy of AI models is directly correlated to their vulnerability to small perturbations on the input dataset. That relationship is often exploited by malicious actors that can try to alter specific datasets in order to alter/influence the behavior of an AI models. Testing and benchmarking AI models against adversarial attacks is key to establish trust in AI systems. IBM has been doing some interesting work in this area.
AI models are constantly evolving making it challenging to trace its history. Establishing and tracking the provenance of training datasets, hyperparameter configurations and other metadata artifacts overtime is important to establish the lineage of an AI model. Understanding the lineage of AI models helps us establish trust from a historical perspective that is different to achieve by just factoring fairness, explainability and robustness alone.
The subject of disclosures and transparency in AI systems is a very nascent area of research but one that is key to the mainstream adoption of AI. Just like we use information sheets for hardware appliances or nutrition labels in foods, we should consider establishing a factsheet for AI models. In their paper, IBM proposes a Supplier’s Declaration of Conformity (SDoC, or factsheet, for short) that helps to provide information about the four key pillars of trusted AI. IBM’s SDoC methodology should help answer basic questions about AI models such as the following:
· Does the dataset used to train the service have a datasheet or data statement?
· Was the dataset and model checked for biases? If “yes” describe bias policies that were checked, bias checking methods, and results.
· Was any bias mitigation performed on the dataset? If “yes” describe the mitigation method.
· Are algorithm outputs explainable/interpretable? If yes, explain how is explainability achieved (e.g. directly explainable algorithm, local explainability, explanations via examples).
· Describe the testing methodology.
· Was the service checked for robustness against adversarial attacks? If “yes” describe robustness policies that were checked, checking methods, and results.
· Is usage data from service operations retained/stored/kept?
The idea of establishing a factsheet for AI models is as simple as it is relevant to establish trusted AI systems. IBM’s SDoC is far from perfect but it’s a welcomed step in the right direction.
",,Person, ,magnetic stripe,memory device,magnetic stripe,-
https://ibm.co/2PPSohX,187446750783_2003478259713098,https://www.facebook.com/ibmwatson/videos/2003478259713098/,"In case you missed it: IBM recently announced new trust and transparency capabilities for AI to help organizations achieve visibility into AI and deliver more fair, accurate outcomes. Learn more: ",Video,,,10/11/18 10:44, ,8737,8737,0,12192,12187,0,290,269,342,4,4,8550,6227,0,0,115,156,156,0,0,2121,2272,0,0,4394,38803,10,31.0,2.0,12,32.0,3.0,191,7.0,,108.0,220,9.0,,113.0,4,,,4,,,See the resources and related products helping IBM lead the way in explainable AI.,https://1.cms.s81c.com/sites/default/files/2019-04-22/explainable-ai.jpg,https://www.ibm.com/watson/explainable-ai,joy,0.48427,positive,0.921742,"new trust, transparency capabilities, case","Company, Person",new trust,Company,sadness,0.090954,positive,0.616457,"related products, resources",Company,related products,Company,joy,0.201531,positive,0.472378,IBM Watson OpenScale,"Person, Company, Person","                          Assess risk and enhance AI to maintain regulatory compliance and drive fair, explainable outcomes. Learn more about IBM's leadership in explainable AI.                   
IBM Watson OpenScale™ tracks and measures outcomes from AI across its lifecycle, and adapts and governs AI to changing business situations - for models built and running anywhere.
For both regulatory and business reasons, lenders need to understand why their credit risk models are making specific recommendations, and must ensure models are running without bias against certain groups. Watch this demo to learn how IBM Watson OpenScale can provide insights into a credit risk model in production and help lenders avoid black box AI.
Build and train AI models and prepare and analyze your data, all in one integrated environment.
Deploy machine learning models into production at scale and manage model performance.
A flexible multicloud data platform that integrates all your data, on premises or from any cloud while keeping it secure at its source. Simplify and automate how you collect, organize, analyze and govern data to rapidly innovate your business with AI.
",IBM Watson OpenScale,Person, , , , , 
https://ibm.co/2QI1NIO,187446750783_10155938622865784,https://www.facebook.com/ibmwatson/posts/10155938622865784,"AIConics, the worlds’ only independently judged enterprise AI awards, named Watson Discovery the winner for “Best Innovation in NLP.” 

NLP, or Natural Language Processing is the area of computer science and artificial intelligence that focuses on the interaction between computers and human languages. Learn more: ",Link,,,10/10/18 18:19, ,10205,10205,0,13907,13907,0,247,139,164,3,3,11016,8221,0,0,191,0,0,0,0,0,0,0,0,0,0,23,118.0,,23,126.0,,65,78.0,,,82,82.0,,,1,2.0,,1,2.0,,The AIconics named Watson Discovery winner for “Best Innovation in NLP.” The AIconics celebrate innovation of the international A.I. community.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/10/f3157e0a-c7d0-11e8-8ed0-3dc066795427.jpg,https://www.ibm.com/blogs/watson/2018/10/aiconics-names-ibm-watson-best-innovator-in-natural-language-processing/?cm_mmc=OSocial_Facebook-_-Watson+and+Cloud+Platform_Watson+Core+-+Discovery-_-WW_WW-_-AIConics+Named+Watson+Best+Innovator+In+NLP+Oct+2018&cm_mmca1=000016UP&cm_mmca2=10009360,joy,0.747685,positive,0.737892,"Natural Language Processing, artificial intelligence, area of computer science, Watson Discovery","Person, Person",Natural Language Processing,Person,joy,0.754413,positive,0.976374,Watson Discovery winner,"Person, Location",Watson Discovery winner,Person,joy,0.62318,positive,0.779721,Watson Discovery,"Company, Person, Person, Company, Person, Quantity, Quantity","On September 18, the worlds’ only independently judged enterprise AI awards –the AIconics–named Watson Discovery the winner for “Best Innovation in NLP.” NLP, or Natural Language Processing is the area of computer science and artificial intelligence that focuses on the interaction between computers and human languages. Specifically, NLP concerns how computers process and analyze unstructured natural language data.
The AIconics celebrate the drive, innovation and hard work done throughout the international artificial intelligence community. This year’s awards recognized industry leaders across a broad spectrum of AI technologies and were judged by a panel of world class AI experts, including senior leaders from venture capital firms, academia and enterprise end-users. In his kickoff speech, AIconics Awards Curator Edward Beecham said, “With over 300 entries from around the world, the 3rd Annual Edition of The AIconicsreflect the strength and progress of a rapidly expanding and evolving sector. Artificial Intelligence is now beginning to dominate conversations in the technology sphere.”
Watson Discovery’s leading NLP understands the meaning and the structure of data to help businesses increase productivity, allowing teams to focus on more interesting, higher value work. Clients like LegalMation and KPMG have used Watson Discovery to tap into enterprise knowledge spread across the organization to help facilitate tasks like creating early response drafts, reviewing intricate documents, and getting answers to complex questions.
Leaders from Woodside, an Australian oil and gas company, have said that “Employees used to spend 80% of their time researching problems and 20% fixing it. Watson has reversed that.” With Watson Discovery, teams can ask questions in natural language to both uncover the information they are looking for and to pinpoint new patterns that point to where incremental innovation can happen.
Currently available on IBM Cloud, Watson Discovery is an out-of-the box solution, so users don’t need to understand how to use APIs to configure and populate the service. It’s a one-of-a-kind cloud native AI powered insight engine that extracts meaningful insights from structured and unstructured content to help teams be more efficient and more discerning, ultimately driving more value for the business.
",Watson Discovery,Company,light brown,person,indoors,lecture room,-
https://ibm.co/2yg49qQ,187446750783_10155935389260784,https://www.facebook.com/ibmwatson/posts/10155935389260784,"According to a recent IBM report, in partnership with Oxford Economics, 93% of outperforming businesses are considering AI adoption, and many organizations are moving beyond the question of whether or not to adopt the technology, to how they'll implement it. – via TechRepublic: ",Link,,,10/9/18 11:21, ,7778,7778,0,10542,10542,0,101,68,85,2,2,9196,6796,0,0,81,0,0,0,0,0,0,0,0,0,0,14,32.0,,16,34.0,,26,44.0,,,38,47.0,,,2,,,2,,,"A recent IBM study focused on the business importance of IT, and how AI is growing in the workplace.",https://tr1.cbsistatic.com/hub/i/r/2018/09/27/d26d3e2d-c0ec-4551-ad45-e5953a32ac78/thumbnail/770x578/e640750a63ba7d799b23269669582d77/ceotech.jpg,https://www.techrepublic.com/article/ceos-5-areas-where-ai-will-drive-the-most-value-in-2018/,joy,0.114306,positive,0.743197,"recent IBM report, Oxford Economics","Company, Quantity, Company",recent IBM report,Company,joy,0.364615,positive,0.617477,recent IBM study,"Company, Person",recent IBM study,Company,joy,0.419643,positive,0.435501,Customer service,"Person, Company, Quantity, Organization"," 	As artificial intelligence (AI) matures and makes good on its promises, the technology is rapidly finding its way into more and more enterprise organizations. As hardware becomes commoditized, AI is emerging as the competitive differentiator for consumer-facing and B2B businesses alike.
 	In a  	recent IBM report, conducted in partnership with Oxford Economics, business leaders explained just how they see AI infiltrating their organization. According to the report, some 93% of outperforming businesses are considering AI adoption, and many organizations are moving beyond the question of whether or not to adopt the technology, to how they'll implement it.
 	However, AI won't have an equal impact across all business functions. Here are the top five areas where business executives said AI would drive the most value in 2018 (and the percentage of leaders who listed it):
 	 	SEE: 2019 IT Budget Research Report: IT spending increases due to business conditions, security, and revenue opportunities (Tech Pro Research)
 	In areas like IT, AI-enabled assistants could help perform help desk operations, while threat detection algorithms could improve the effectiveness of security, the report said. Customer service is a common pilot area for AI projects, as virtual chat bots streamline the process. Innovation will serve as a center of excellence for AI, and the technology will help with fraud detection and risk management.
 	However, challenges to AI adoption do exist. Primarily, this will show itself in the poor availability of skilled resources or employees with the proper technical skills, as noted by 63% of those surveyed.
 	""As the demand for data scientists and other AI experts increases, employee retention risks
 	also rise,"" the report said. ""Startups are aggressively poaching AI talent from academia and established corporations. And while constrained candidate pools do not necessarily equate to a zero-sum game, organizations also will need to make more with what they already have.""
 	Regulatory constraints were cited by 60% of respondents, while legal and privacy concerns over the use of customer data were top of mind for 55%. One of the biggest challenges, the report noted, was that businesses must be transparent and open with their processes while protecting their users' privacy as strongly as they can.
 	In order to get started on your AI journey, IBM shared four steps from a previous implementation guide:
",Customer service,Person,blue,fountain,platform,stage,-
,187446750783_10155932947270784,https://www.facebook.com/ibmwatson/posts/10155932947270784,IBM Watson,SharedVideo,,,10/8/18 8:35, ,1865,1865,0,2286,2286,0,216,171,246,2,2,2081,1686,0,0,209,0,0,0,0,468,479,0,0,0,269865,,73.0,,,73.0,,171,2.0,,,244,2.0,,,1,1.0,,1,1.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2QuyskO,187446750783_10155928134410784,https://www.facebook.com/ibmwatson/posts/10155928134410784,"One year ago, IBM and MIT joined forces to establish the MIT-IBM Watson AI Lab, a first-of-its-kind industry-academic collaboration backed by a $240m commitment from IBM, founded with the goal of charting the future of AI. Take a look back at the shared history of MIT and IBM, and look forward to where the partnership aims to take AI in the future via Medium: ",Link,,,10/6/18 10:11, ,10637,10637,0,15082,15082,0,222,134,154,4,4,12544,8852,0,0,187,0,0,0,0,0,0,0,0,0,0,23,106.0,,23,106.0,,72,66.0,,,84,70.0,,,3,1.0,,3,1.0,,"Artificial Intelligence (AI), perhaps more than any human invention before it, holds the potential to reshape our world. In just the last few years, we have seen a new explosion of AI development…",https://miro.medium.com/max/1200/1*eC5DmkuyxVI8j-QY4az1jQ.jpeg,https://medium.com/@MITIBMLab/the-shared-history-and-vision-behind-the-mit-ibm-watson-ai-lab-405ce4032013,joy,0.151504,positive,0.718132,"MIT-IBM Watson, shared history of MIT, kind industry-academic collaboration","Company, Organization, Facility, Quantity, Quantity",MIT-IBM Watson,Company,joy,0.433928,positive,0.809938,"Artificial Intelligence, human invention",Person,Artificial Intelligence,Person,joy,0.627323,positive,0.723822,,"Person, Organization, Company, Person","Artificial Intelligence (AI), perhaps more than any human invention before it, holds the potential to reshape our world. In just the last few years, we have seen a new explosion of AI development, fueled by increased computational power and data availability, and the power of deep learning. New AI methods and startups are springing up daily, and the excitement around AI is palpable. At the same time, as in any scientific endeavor, there are many paths forward and challenges that remain. AI is poised to touch almost every aspect of our lives, but, for it to do so, we must sustain the pace of discovery and steer that progress in ways that serve us all.
It is against this backdrop that IBM and MIT have joined forces to establish the MIT-IBM Watson AI Lab, a first-of-its-kind industry-academic collaboration backed by a $240m commitment from IBM, founded with the goal of charting the future of AI. Today, as we celebrate the one year anniversary of the Lab’s announcement, we take a moment to both look back at the shared history of MIT and IBM, and to look forward to where we aim to take AI in the future.
What has brought us here: From 1955 to 2018
The term “artificial intelligence” was coined in a 1955 workshop proposal by IBMers Nathaniel Rochester and John McCarthy, along with Claude Shannon and Marvin Minsky — all of whom would go on to become iconic MIT faculty. At the time, IBM was building some of the earliest practical computers and, together with their MIT colleagues, they dreamed about how they could be used. Their work, standing on the shoulders of Charles Babbage, Ada Lovelace, Alan Turing, and others, established AI as a field of science.
Despite its initial promise and projections of rapid progress, AI research has experienced alternating periods of excitement and disillusionment over its sixty-plus year history. Within this period, we have experienced several “AI winters,” when hype outstripped reality and technological progress stalled, causing research investment to dry up, sometimes for up to decades at a time.
In this decade, AI has re-emerged with a new vigor, ushering in a new “AI Spring.” While previous cycles of excitement for AI have been promising but brief, this moment is arguably different. Today, AI technology has reached a new threshold of maturity that allows the business world to derive real and measurable value from it, and where applications are being deployed at scale in the real world. The field has moved beyond mere promise to create genuine disruption beyond the walls of the research lab.
At the same time, AI is still in its infancy. Today’s AI systems, while tremendously powerful, remain limited in important ways. These systems largely require enormous amounts of carefully annotated data to train, and they struggle when confronted with inputs that look very different from their training. Today’s AI systems are also vulnerable to new forms of hacking, where bad actors can trick AI systems into making mistakes. What’s more, current systems can rarely give satisfying human-understandable explanations for their decisions. Each of these weaknesses limits the broad applicability of AI, particularly in mission-critical functions within business enterprise. The potential for AI to impact our lives is great, but this potential will not be realized without a concerted effort to look ahead to what is next in AI.
An integrated worldview, a collaborative model
Our Lab was founded with the goal of asking what’s next and then building that future. Our joint effort marks a new kind of collaboration between industry and academia, and is built on a shared vision and a set of values for how AI should advance. Key among these values is the recognition of the power of interdisciplinarity. Intelligence is one of the great mysteries of the universe. To approach it requires a mind for biology as much as computer science, for ethics as much as mathematics, for economics as much as physics. Universities such as MIT embody the spirit of interdisciplinary investigation.
Another core value of our Lab is stewardship. AI technology is too powerful for a move-fast-and-break-things approach. Achieving true human-machine partnership in the coming age of AI requires prudence as much as technical ingenuity. Now more than ever, we need an integrated worldview that prompts us to consider not only what can we do, but what we should we do. Like the invention of the computer or the Internet, the impact of AI will be profound and complex. It’s up to us — all of us — to harness this technology for good.
Our vision is to cultivate an interdisciplinary community of scientists committed to advanced AI research that is neither purely theoretical nor prematurely commercial. We seek to undertake fundamental science that is deeply connected to everyday people, businesses, and the problems they face. Rather than asking how today’s AI can have impact, we instead ask what fundamental advances are needed for tomorrow’s AI to change our world for the better.
Just one year in, our community is already flourishing, with nearly 50 joint projects led by the brightest minds from our respective institutions. Each project is a collaboration between MIT and IBM research scientists, who collaborate shoulder-to-shoulder on fundamental AI research. Our project portfolio spans a spectrum of fields, with all five MIT schools (and over 20 unique departments and centers) represented. Despite being just over six months into our first cycle of funded projects, our teams are already making important headway on hard problems and publishing in top academic venues.
Examples of the research we are undertaking include:
• Building a new generation of neural-symbolic hybrid systems that embrace the statistical learning capabilities of today’s neural networks, and combine them with powerful symbolic reasoning techniques. Josh Tenenbaum (MIT), together with Chuang Gan (IBM), used these best-of-breed hybrids to, in effect, completely solve a tough benchmark task in visual question answering, which has eluded pure neural network-based approaches.
• Developing tools for detecting and defending against so-called “adversarial example” attacks on AI systems, which make subtle, hard-to-detect perturbations of an input (e.g. an image or passage of text) in ways that cause AI systems to dramatically fail (e.g. misclassifying an image of a cat as a typewriter, or causing a captioning system to produce a dramatically wrong caption, even when the perturbed image is virtually indistinguishable from the original). Pin-yu Chen (IBM) and Luca Daniel (MIT) recently designed techniques for providing precise, certifiable guarantees about the robustness of neural networks against specific attacks. This research is an important early step towards improving the robustness of AI systems.
• Mitigating our reliance on enormous amounts of hand labeled data. Many big problems lack big data. A team of IBM researchers led by Abhishek Kumar (IBM) joined forces with Greg Wornell (MIT), Antonio Torralba (MIT), and William Freeman (MIT) to build new deep learning systems that can leverage learning from one domain to learn efficiently in new domain where large amounts of labeled training data is not available.
An invitation
These are exciting times. Although IBM competes with other tech giants in the enterprise AI space, we also believe in the importance of creating time and space for open scientific collaboration, particularly around enabling fundamental advances in science through AI. That is why IBM is one of the founding members of the MIT Quest for Intelligence, the university’s broader alliance for academic-industry research. We also seek to partner with our vast array of business customers, who represent every facet and corner of the global economy. We recognize that the greatest advances in AI will come from the collective ideas and energy of researchers and stakeholders from across academia and industry.
The MIT-IBM Watson AI Lab is hiring, and we invite you to join us in Cambridge. We welcome good people and bold thinkers who connect dots across disciplines. We come from countries around the world and share an inclusive culture and a global mindset. We bring together diverse backgrounds and perspectives for greater impact. We believe in tight feedback loops between our research in the lab and those closest to the problems we endeavor to solve. We embrace collaboration and celebrate the success of others. We are committed to the scientific method and the integrity of our work.
AI may indeed transform nearly every aspect of our society. Let us work together to ensure it is a force for good.
",,Person,ultramarine,person,building,office,jobcentre
https://ibm.co/2lrav0s,187446750783_10155925529625784,https://www.facebook.com/ibmwatson/posts/10155925529625784,"With the advent of machine learning and deep learning, AI has changed from a sci-fi fantasy to an inherent part of everyday life, from reading news to fighting cancer and detecting fraud and more.

However, developing artificial intelligence and machine learning applications remains elusive to most organizations. Here's how one IBMer is working to make AI productive: ",Link,,,10/5/18 10:16, ,5178,5178,0,7182,7182,0,83,55,64,0,0,6401,4425,0,0,75,0,0,0,0,0,0,0,0,0,0,6,34.0,1.0,6,35.0,1.0,32,24.0,,,39,25.0,,,,,,,,,"AI will transform our world and the businesses leading the future, but only if it is easily accessible to everyone",https://i2.wp.com/bdtechtalks.com/wp-content/uploads/2018/04/Armand-Ruiz-1-1926873092-1523178431937.png?fit=1048%2C853&ssl=1,https://bdtechtalks.com/2018/04/09/ibm-watson-democratizing-ai-deep-learning/,joy,0.446035,positive,0.726933,"advent of machine learning, deep learning, artificial intelligence, sci-fi fantasy","Person, HealthCondition",advent of machine learning,Person,joy,0.66247,positive,0.931904,"world, businesses",Person,world,Person,joy,0.589151,positive,0.68033,,"Person, Person","Years ago, when I was taking my first steps in computer programming, coding was for geeks and computer programs had limited use. Development tools were very crude, writing code was hard (remember Assembly, C, Pascal?), compiling and linking was a nightmare (MAKE files anyone?), and debugging was even worse. Long story short, programming was not for the faint of heart. You needed nerves of steel and had to patiently fail over and over before you got the hang of writing good code.
But as software gradually rose in prominence, the entry barrier to programming lowered. Presently computer software has found an important role in almost everything we do, from shopping to applying for university course and communicating with friends and family and whatnot. Accordingly, the tools to create software, the programming languages and Integrated Development Environments (IDEs) have become more intuitive and easy to learn. If in my days, it took an average of two jam-packed years to become a decent developer, today the same can be achieved in a fraction of the time.
We’re seeing the same trend happen in artificial intelligence. With the advent of machine learning and deep learning, AI has changed from a sci-fi fantasy to an inherent part of everyday life, from reading news to fighting cancer and detecting fraud and more.
However, like in the early days of software, developing artificial intelligence and machine learning applications remains elusive to most organizations and people, and only large tech companies can make productive use of it.
A number of experts and companies are leading efforts to address this issue. Among them is Armand Ruiz, Product Manager at IBM Watson, whose team is working on tools that not only make data scientists more productive, but also make data science, AI and deep learning more accessible to the enterprise. In an interview with TechTalks, Ruiz shared insights and experience on the challenges of the AI industry and solutions to democratize it.
The challenges of developing AI applications
A recent Gartner survey of CIOs ranked artificial intelligence as one of the hardest technologies to implement. “While the level of difficulty varies with the type of AI technology being implemented and the process it is being deployed into, there are several key barriers to adoption: skills, standardization, complexity and a lack of collaboration,” says Ruiz, adding that many challenges are specific to deep learning, which is a relatively recent innovation that increases the amount and type of data that can be tapped by an AI system.
When creating deep learning applications, developers build and train “neural networks,” a software structure that is roughly inspired by the human brain. These neural networks can accomplish a variety of tasks, such as identifying the content of images, performing face recognition or analyzing the meaning and intent of human language.
But developing deep learning models is a very painstaking and expensive process. “First, deep learning is a computationally intensive and highly specialized field,” Ruiz says. “It requires a highly tuned system with the right combination of software, drivers, compute, memory, network, and storage resources,” the combinations of which can reach thousands or millions of dollars in costs.
In fact, deep learning as a concept has been around for a long while, but only became a reality with the explosion of availability of storage and compute resources, mostly held by big cloud providers. While many of these companies make their AI tools available to developers and companies, they remain the exclusive gatekeepers to those platforms.
Ruiz also points to the lack of skilled engineers to develop AI applications. “While formalized education in deep learning is growing, the talent pool is still limited,” he says.
The acquisition of scarce AI talent become an arms race between large tech companies, which sometimes pay their engineers salaries that reach millions of dollars per year. This makes it very difficult for smaller companies and organizations to gain access to talent and innovation and compete in the space.
“There is also a lack of standardization across deep learning teams, with different data scientists preferring different open source frameworks to build their models,” Ruiz says. This can make it increasingly challenging for data scientists to share and re-use models within their own teams.
Another fact worth considering is that neural network design is just one stage of a much larger workflow, Ruiz notes, which also encompasses the training, evaluation, deployment, monitoring and enhancement of deep learning models. “Data scientists must understand many functional areas beyond design. This includes being familiar with, and able to work on, various infrastructures and architectures that differ widely in their use and application,” Ruiz says.
Finally, Ruiz points to the disconnect in many organizations between IT (those with the technical expertise to analyze the data) and domain experts (those able to glean insights from it) as a barrier to the adoption of AI across organizations. “These teams often work in siloes, with differing tools and little visibility into each other’s work. The result is AI that falls short in its promise to augment people’s expertise,” Ruiz says. “This is an issue I’ve seen personally in my experience in data science and is a challenge I am passionate about working with my team to overcome.”
There’s an analogy worth reminding here. In its earlier days, plain-old programming was a deeply technical endeavor that only highly skilled engineers and developers could engage in. A large part of their time would have to go into understanding the problem space they were developing for and bridging the gap between domain experts and computer code. But as programming tools became easier to use and Application Programming Interfaces (APIs) became more capable, software development became democratized and more and more people from diverse backgrounds became able to transform their domain expertise into software. AI needs to go through a similar process.
These elements can make it challenging for organizations to deploy deep learning on an enterprise-wide basis, hindering them from maximizing the business value they get from their data, Ruiz says.
How do you democratize AI and deep learning?
“To realize the full potential of AI, we need tools that make it easier for today’s data science teams to develop AI systems that can help glean insights from data,” Ruiz says.
For this to happen, deep learning solutions and frameworks must enable data professionals to more quickly and precisely design new neural networks, optimize their training models, understand, re-use and enhance the networks that their peers have already created, and collaborate across the organization. “At IBM, we are already doing this by offering tools that make deep learning accessible to individuals of varying skill levels,” Ruiz says.
Ruiz is working with a team of product managers who formerly worked as data scientists. So they understand the challenges that various users face when working with data and AI, and they’re focused on building tools that make data science and other complex technologies accessible to everyone, from scientists to the average enterprise user.
One of their notable efforts is Watson Studio’s Deep Learning as a Service solution, which recently made its debut. Deep Learning as a Service draws from advances made at IBM Research to enable organizations to overcome the common barriers to deep learning deployment, including skills, standardization, and complexity. Among the features of Deep Learning as a Service is a Neural Network Modeler, an intuitive drag-and-drop interface that enables non-programmers to build models by visually selecting, configuring, designing and auto-coding their neural network using popular deep learning frameworks such as TensorFlow, Caffe and PyTorch.
“Our goal is to make it much easier for enterprises, along with data scientists and developers, to cost-effectively build, optimize, and train neural networks at scale, using well-known frameworks with minimal code,” Ruiz says.
The future of AI depends on democratizing it
As data scientist Doug Rose pointed out in this column not long ago, AI needs greater representation of the humanities in order to overcome its hurdles and challenges. And as acclaimed historian rightly pointed out in the annual World Economic Forum Davos, the future of humanity might depend on how distributed AI and big data become. So the efforts of Ruiz and his colleagues to democratize AI might be more significant than they seem.
“AI holds enormous power to transform our world and the businesses leading the future, including how we consume information, how we shape communication, and how we engage with technology,” Ruiz notes. “However, AI can only have this impact if it is easily accessible and can be applied with purpose. The democratization of AI technology, combined with improved widespread understanding of its usage and growing consumer trust, will help to break down current barriers that make it difficult to integrate AI into enterprise workflows. Organizations deploying AI technologies at scale will see significant increases in productivity and efficiency, allowing employees to focus on more complex, creative, and higher-impact tasks.”
",,Person,light brown,person,plant,weed,tumbleweed
https://ibm.co/2OzcP5U,187446750783_10155923447635784,https://www.facebook.com/ibmwatson/posts/10155923447635784,"How did IBM teach its AI how to debate humans?

Get behind the scenes with researchers who helped build Project Debater via Axios: ",Link,,,10/4/18 11:12, ,10097,10097,0,13707,13707,0,214,130,173,2,2,11342,8438,0,0,162,0,0,0,0,0,0,0,0,0,0,23,106.0,6.0,23,112.0,6.0,72,71.0,,,100,73.0,,,,2.0,,,2.0,,Researchers want machines that humans can converse knowledgeably with.,https://images.axios.com/t5_Q7J3X_pt5cyben0_gH9j4Qkc=/2018/10/03/1538601637559.jpg,https://www.axios.com/projet-debater-ibms-argumentative-ai-13e0ae3c-1c38-4700-b7de-3f4c790fe2a5.html,disgust,0.413531,neutral,0,build Project Debater,Company,build Project Debater,Company,sadness,0.169981,neutral,0,"Researchers, machines",,Researchers,,joy,0.487798,negative,-0.318066,,"Company, Person, Person, Person, Company, Person","Siri or Alexa can get you the weather, but don’t expect a conversation. Neither can chatbots (once the next big thing) hold a back-and-forth. But researchers are now developing systems that leapfrog chit-chat to the next frontier: They can argue and play devil's advocate.
Why it matters: Whenever artificial intelligence reaches an advanced stage, far beyond current capabilities, researchers want machines that humans can converse knowledgeably with, and can explain how they reach their conclusions.
What's going on: The field that works on such systems is called ""computational argumentation."" This summer, a roomful of journalists watched a demonstration in which two human debaters argued with a talking computer, produced by IBM, that used AI-infused computational argumentation to deliver speeches and rebut its opponents’ claims.
Axios spoke with six researchers behind IBM's ""Project Debater"" to learn how it works, and to track the state of the art in language understanding.
The context: AI researchers are prone to using games to measure their progress. In 2011, Watson beat a pair of humans at Jeopardy. In 2016, a Google-developed AI system beat the reigning human champion at Go. 
A live debate has no clear rules, nor a point system to determine a winner. At best, you can poll a human audience to see which side was most convincing.
""Humans invented language and it's probably the most sophisticated thing we've done so far,"" said Salim Roukos, an IBM researcher focused on natural language processing.
How it works: The IBM machine picks out factual statements from academic journals and news stories, and arranges them into themes and whether they support or oppose a particular stance.
The entire system is a hodgepodge that combines AI techniques with an extensive collection of knowledge and rules. Some experts say such hybrid systems are the future of AI.
To make its case, Project Debater can choose from a long list of ""principled arguments"" that supposedly appeal to human nature. For instance, when the question at hand is about banning something, it can argue that it would spark a black market. If it’s about requiring that people do something, the debater can warn of a resulting backlash.
The result can seem mechanical and reflexive. To know when to deploy which argument, the system relies on pattern-matching, reaching into its database of recorded debates to guess which argument a human would choose in each situation.
IBM’s work on detecting claims and points of view is promising, said Sean Gourley, a former NASA engineer who founded a company focused on natural language.
Reality check: The debater, while handy at marshaling and conveying arguments, is not *intelligent"" in a human sense. It does not reason. Like the machines that beat humans at chess, Go, and Jeopardy, it rather muscles its way through mounds of data, without any real thinking at all.
Editor’s note: An earlier version of this article said Project Debater was developed by IBM Watson. It was developed by IBM Research.
",,Company,ultramarine,stun gun,weapon,stun gun,-
https://ibm.co/2NZ3957,187446750783_10155920826605784,https://www.facebook.com/ibmwatson/posts/10155920826605784,"From automotive to human resources, learn how the use of Watson AI is impacting 10 different industries via TechRepublic: ",Link,,,10/3/18 10:40, ,7076,7076,0,9812,9812,0,143,93,107,5,5,8559,6294,0,0,119,0,0,0,0,0,0,0,0,0,0,13,50.0,,14,52.0,,26,72.0,,,33,74.0,,,5,,,5,,,The use of artificial intelligence and Internet of Things is increasingly becoming a reality for businesses. Here are ways IBM Watson AI and IoT are being put into practice in 10 industries.,https://tr1.cbsistatic.com/hub/i/r/2015/12/18/43d46a9c-9d73-4029-87a9-f3c776461dcb/thumbnail/770x578/9378ca3489b8f0eee474d4ef04a7fd67/ibm-watson-121815.jpg,https://www.techrepublic.com/article/how-ibm-watson-is-revolutionizing-10-industries/,joy,0.115447,neutral,0,"human resources, different industries","Person, Person",human resources,Person,anger,0.171597,positive,0.644732,"use of artificial intelligence, ways IBM Watson, Internet of Things",Company,use of artificial intelligence,Company,joy,0.160618,positive,0.726321,"IBM's Watson supercomputer, IBM Watson products","Company, Company, Company"," 	 	 	More and more industries are turning to artificial intelligence (AI) and the Internet of Things (IoT) to enhance their businesses like never before; at the forefront of that effort is IBM's Watson supercomputer. Find out how IBM Watson products are transforming these 10 industries: Manufacturing, supply chain, human resources, customer service, marketing, advertising, building management, medicine, automotive, and agriculture.
 	SEE: Artificial intelligence: Trends, obstacles, and potential wins (Tech Pro Research)
 	 	 	Manufacturing can be inefficient (even when machines do some of the labor), as well as dangerous for assembly line workers.  	IBM Industry 4.0 uses Watson AI and IoT in a threefold method to make the manufacturing process easier and safer.
 	 	 	According to the IBM Watson site, by adding IoT sensors to manufacturing equipment, Watson reads and analyzes how machines are operating, resulting in up to 47% less downtime. Through the use of IBM Watson cognitive processes and operation, defect rates can be reduced by up to 48%, improving product yield. The smarter resource and optimization function improves efficiency in the areas of energy consumption and worker output, resulting in up to 50% reduction in costs.
 	 	 	By streaming collected data and using the IBM Watson IoT platform, manufacturers can create easy-to-read dashboards for their business, produce models of predictive failure, and interface directly with IBM Watson to determine the best solutions to issues.
 	 	 	Managing an entire supply chain is tough--supply chain managers have to contend with numerous uncontrollable factors (e.g., weather, delivery delays, and unstable suppliers) that can create issues for an entire company. While efficiency is key in supply chain management, there is only so much information that can be processed at any given time. That's where AI can help.
 	 	 	With  	IBM Watson Supply Chain and Watson Supply Chain Insights, supply chain managers' job is simplified. The technology creates a transparency in the supply chain, allowing managers to see disruptions (or potential disruptions) as they happen in real time and then collaborate with experts, using the Resolution Room function to figure out the best solution for the issue. By utilizing Watson's Supply Chain Insights, data retrieval times can be reduced by 75%, and inventory and freight costs could be reduced significantly.
 	SEE: IBM launches pretrained Watson packs for industries (ZDNet)
 	 	 	Reviewing hundreds of resumes a day is a herculean task for anyone--crucial facts can be missed due to the amount of information that needs to be processed for each resume. But with  	IBM Watson Recruitment, current hiring processes may become more streamlined.
 	 	 	Not only does the Watson Recruitment tool analyze resumes and create a score for candidates, it also factors in the company's top-performing employees and offers a side-by-side comparison metric based on that information. Hiring managers are able to make more informed decisions based on statistical facts, removing the possibility of 	 bias in the hiring process.
 	 	 	Using Watson Recruitment in tandem with the  	IBM Watson Career Coach has the potential to increase retention rates and enhance employees' skill sets.
 	Watson Discovery for Salesforce is designed to revolutionize customer service. By collating and analyzing a company's data from various sources, as well as taking into account documented previous customer cases and issues, IBM Watson creates a cloud-based data source that is easily accessible to customer service representatives. Touted as more than a search engine, but rather an ""insight engine,"" IBM Watson offers answers to questions; the answers are customized to each business, making for more enriching and efficient interactions with customers.
 	 	 	With  	IBM Watson Marketing Solutions, it is easier than ever for businesses to have a lasting impact on their customer base. The marketing tools include IBM Watson Marketing Insights, which allows marketers to tap into omnichannel marketing as well as understand and predict how a customer behaves when shopping on their website. The software also gives recommendations for target audiences, which may lead to more effective marketing campaigns.
 	IBM Watson Advertising utilizes several ""dynamic creative"" tools (e.g., weather, time of day, location, consumer behavior) to deliver personalized ads to customers. For instance, by teaming up with digital marketing leader Jivox to incorporate WEATHERfx and JOURNEYfx technology into advertisements, IBM Watson Advertising creates a one-of-a-kind experience for consumers.With WEATHERfx, ads can change based on the weather in real-time, enabling businesses to direct the best product to the consumer. JOURNEYfx, a location targeting platform, is also used to help businesses discover and reach out to their primary audience; this helps advertisers know who to hone in on, as well as the optimal time to reach them. In addition, it allows advertisers to receive feedback about consumer behavior so they can tailor their ads even more effectively.
 	SEE: Harnessing IoT in the enterprise (ZDNet special report) | Download the report as a PDF (TechRepublic)
 	IBM IoT Building Insights can be used in all types of buildings to analyze how the buildings are operating. For instance, if elevators or escalators in a particular building are malfunctioning, Building Insights technology will notify management in real time so the issue can be fixed as soon as possible.
 	 	 	This innovation reduces maintenance costs, improves safety for people inside the buildings, increases sustainability by  	identifying energy waste, and optimizes the functionality of the building overall. It also means that buildings can be designed, constructed, and managed more efficiently.
 	 	 	Medical professionals are always looking for the most cutting-edge technology to help them advance their efforts, and  	IBM Watson Health has an abundance of applications for that very purpose. (One of the earliest uses for IBM Watson was in the medical field). IBM Watson Health analyzes data and cross-references it with previous cases and studies, partners with Quest Diagnostics to sequence the human genome, helps veterans with cancer, and much more.
 	 	 	IBM Watson is shaping the future of medicine in a real way, and it can be a useful resource for doctors, researchers, and patients. However,  	this doesn't mean IBM Watson is infallible or will replace physicians anytime soon.
 	SEE: Photos: 20 products you didn't know were built with IBM Watson (TechRepublic)
 	IBM Watson IoT has numerous applications in the auto industry, including the IBM Watson Assistant for Automotive digital assistant, aiding the engineering of safer, smarter vehicles, and reporting vehicle issues in real time. Golden State Foods has equipped a fleet of 2,000+ trucks with the technology. Sensors on the trucks send information back to the Watson IoT Platform, which analyzes and reports the data so that vehicle issues are addressed as quickly as possible, resulting in a more efficient delivery process.
 	 	 	The  	Watson Decision Platform for Agriculture combines IoT, analytics, predictive insights, knowledge from industry experts, and IBM research to create an electronic field record that is specific to each farm. This data set includes up-to-date weather (using IBM's The Weather Company), satellite images, soil readings, IoT-enabled equipment evaluation, and crop health analysis. The potential benefits of this information could be improved crop protection, greater crop yields, higher-quality crops, and greater profitability.
SEE: The Future of Food (ZDNet/TechRepublic special feature)
",IBM's Watson supercomputer,Company,blue,lighting,apparatus,lighting,-
https://ibm.co/2Mcl2J8,187446750783_10155919405915784,https://www.facebook.com/ibmwatson/posts/10155919405915784,"&quot;To adopt IBM Watson into your world – whether that’s putting it to work in a complex process like supply chain or something geared toward a consumer interaction, like a chatbot – you have to see and believe in its impact. I do that by showing what Watson is capable of, what it has already empowered people to accomplish, and what the possibilities of our future hold.&quot; – IBMer Rachel Liddell. Read her story on our blog: ",Link,,,10/2/18 18:19, ,5242,5242,0,7074,7074,0,92,62,79,3,3,6467,4616,0,0,86,0,0,0,0,0,0,0,0,0,0,4,37.0,,4,43.0,,38,29.0,,,46,33.0,,,1,2.0,,1,2.0,,"To Rachel Liddell, telling stories is far more than entertainment. It’s one of the most powerful tools we have to spur change and inspire action in the world. Rachel majored in literary studies at Middlebury College, exploring literature across cultures, geographies, and time. She learned how creative storytelling can shape our understanding of the world, deepen the role we take within it, and impact our behavior in ways that can drive amazing change. Now, in a storytelling plot twist, Rachel works for one of the largest technology companies in the world – IBM – applying her passion for literature, and expertise with words, to help articulate the story of our AI future. Based at IBM’s Watson Experience Center in New York City’s Astor Place, Rachel helps business leaders and influencers understand how Watson will change their organizations, their communities – and their lives – by telling stories about the real impact and exciting possibilities of AI. We…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/05/blog_watsonWomen_png_socialTile_052218.png,https://www.ibm.com/blogs/watson/2018/05/showing-telling-ibm-engagement-leader-helps-people-see-future-watson/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-How+IBM+leader+helps+people+see+future+with+Watson+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.683194,positive,0.781597,"IBM Watson, possibilities of our future hold, complex process, supply chain","Company, Person",IBM Watson,Company,joy,0.683438,positive,0.891323,"creative storytelling, Rachel Liddell, New York City’s Astor Place, IBM’s Watson Experience Center, storytelling plot twist","Person, Person, Organization, Facility, Company",creative storytelling,Person,joy,0.623288,positive,0.749295,,"Person, Company, Person, Person, Person, Facility","To Rachel Liddell, telling stories is far more than entertainment. It’s one of the most powerful tools we have to spur change and inspire action in the world. Rachel majored in literary studies at Middlebury College, exploring literature across cultures, geographies, and time. She learned how creative storytelling can shape our understanding of the world, deepen the role we take within it, and impact our behavior in ways that can drive amazing change.
Now, in a storytelling plot twist, Rachel works for one of the largest technology companies in the world – IBM – applying her passion for literature, and expertise with words, to help articulate the story of our AI future. Based at IBM’s Watson Experience Center in New York City’s Astor Place, Rachel helps business leaders and influencers understand how Watson will change their organizations, their communities – and their lives – by telling stories about the real impact and exciting possibilities of AI.
We talk with Rachel about how she helps people see – and prepare for – the future with AI.
Did you ever see yourself working for a technology company?  
Technology was one of the few subjects not on my radar while at Middlebury. I was buried in literature, studying topics like political science, sociology and physics – but technology? It wasn’t even an area of interest, or one I thought my skillset was aligned to. Looking back, I see how literature and technology have so much in common. They both require a considerable amount of creativity, collaboration and communication. Technology is both a vehicle for language, but also a language itself – and it is rapidly redefining the world as we know it today. How, when, where and what we communicate is influenced heavily by the growing repertoire of technology at our disposal.
How I wound up at IBM is a classic story itself. Throughout college I loved exploring new topics and meeting people, which is part of what drove me to take on a role in admissions where I would build relationships with prospective students and give tours to inform them about the college. Through that role, I met my now mentor. He worked for IBM and opened my eyes to the possibilities of starting my career in technology. AI has the potential to improve nearly everything we do – from how we process information, engage with one another, and how we apply creativity. That includes communication and storytelling. Looking back, I don’t see my academic experience in literature and my career choice in tech as disconnected, but instead closely aligned. I’ll always be a literary nerd at heart, so the opportunity to be on the front lines of a technology that will influence so much about our future – including how and what we tell stories about – is hugely exciting and rewarding. 
How do you help people understand AI, especially when they’re critical about the technology? 
To adopt IBM Watson into your world – whether that’s putting it to work in a complex process like supply chain or something geared toward a consumer interaction, like a chat bot – you have to see and believe in its impact. I do that by showing what Watson is capable of, what it has already empowered people to accomplish, and what the possibilities of our future hold.  
It can be difficult to articulate how a technology as complicated and all-encompassing as AI will have an impact on one person. This is why storytelling is so important. It’s my job to understand what matters to everyone I meet with – what makes them, as a character, tick – and then show them how Watson can help them be the hero in their own story, achieving great things together. That can be presenting the ways in which Watson makes sharing knowledge across an organization better and smarter, or showing how Watson analyzes tone to inform more intelligent marketing campaigns. But regardless of what the story is about, it must connect on a personal level. That’s when I see the “aha” moment. The moment people realize how AI will make them better at their job, make their information more actionable – that’s when skeptics turn into optimists. 
It’s important to note that I don’t shy away from the tough questions. One of the most exciting parts about working in the field of AI today is just how many unknowns there are. It’s still early days for this technology. IBM is developing it responsibly and carefully, but there is much we all still must learn and discover. When I meet with someone who is skeptical, or worse, afraid, I remind them that this is an exciting frontier that they not only have an opportunity – but a responsibility – to help shape.
When did Watson – and the opportunity for AI – first inspire you? 
One of the first times I truly understood the power of AI was, once again, when it became personal. Both of my parents are doctors. They’ve dedicated their careers to health and medicine, working long hours during the day and continuing to work at home in the evening – working to provide the best possible care for their patients. So, when my mother told me she struggled with her dictation software, I had my own “aha” moment –better access to information can have an enormous impact. With AI, patient insights aren’t just easier to find – they jump right off the page. Watson can analyze thousands of medical articles and studies, while nearly simultaneously comparing that data to a patient’s historic records. Things that physicians, even my parents, despite their brilliance, can’t do effectively at scale – but AI can do it for them, freeing them to deliver better care to more patients. 
That’s why I’m so excited about Watson and humbled to be part of the team building the future of AI at IBM. For me, it’s not so much about what the technology is – but what is does. IBM is transforming the world by helping people be better at what they do. Whether that’s as simple as turning my mother’s notes into immediate, actionable insight or redefining how doctors access data to inform better, potentially life-saving treatments, the opportunity AI presents is to make us better at everything we do.  
Looking ahead, five to ten years, where do you see AI having the greatest impact? 
Very soon, AI will become omnipresent throughout our personal and professional lives. It will help people, like my mother, become even better at their jobs by turning the data that surrounds us into insights we can leverage to do amazing things. At home, it will help us experience life, understand the world – and yes, tell stories – across cultures, geographies and barriers in a way we’re just starting to see a glimpse of now.
This future will be powered by businesses that empower their employees.  Which is why today we should all be looking forward – five, ten, even twenty years from now – and thinking about what our role can be in that future. I never thought my artistic and literary background would be applicable at a company like IBM. But what I realize now, and what I encourage everyone to consider, is how important creativity and communication will be to our future. Connecting the dots with this life-changing technology requires humans to work together, think outside of the box and be consistently curious. Ask questions, ponder the impossible – and always be learning. 
",,Person,blue,anchorperson,person,anchorperson,-
https://ibm.co/2IufQPe,187446750783_10155916393100784,https://www.facebook.com/ibmwatson/posts/10155916393100784,ICYMI: IBM recently launched new trust and transparency capabilities for its AI. Learn more about the tools via BBC News: ,Link,,,10/1/18 9:44, ,17667,17667,0,24021,24021,0,433,298,359,4,4,18753,13881,0,0,350,0,0,0,0,0,0,0,0,0,0,49,170.0,2.0,52,178.0,3.0,103,213.0,,,138,221.0,,,2,2.0,,2,2.0,,IBM is launching software which will monitor algorithms in real time and highlight how they make decisions.,https://ichef.bbci.co.uk/news/1024/branded_news/FFA8/production/_103484456_gettyimages-898172160.jpg,https://www.bbc.com/news/technology-45561955?_lrsc=3a4eed7f-29e5-4409-986c-e8ba793fe540,sadness,0.532629,positive,0.762014,new trust,"Company, Person",new trust,Company,joy,0.157592,positive,0.812327,"real time, IBM",Company,real time,Company,joy,0.521529,positive,0.447425,,"Company, Person, Company, Company, Person, Organization, Organization, Person, Organization","IBM is launching a tool which will analyse how and why algorithms make decisions in real time.
The Fairness 360 Kit will also scan for signs of bias and recommend adjustments.
There is increasing concern that algorithms used by both tech giants and other firms are not always fair in their decision-making.
For example, in the past, image recognition systems have failed to identify non-white faces.
However, as they increasingly make automated decisions about a wide variety of issues such as policing, insurance and what information people see online, the implications of their recommendations become broader. 
Often algorithms operate within what is known as a ""black box"" - meaning their owners can't see how they are making decisions. 
The IBM cloud-based software will be open-source, and will work with a variety of commonly used frameworks for building algorithms.
Customers will be able to see, via a visual dashboard, how their algorithms are making decisions and which factors are being used in making the final recommendations. 
It will also track the model's record for accuracy, performance and fairness over time.
""We are giving new transparency and control to the businesses who use AI and face the most potential risk from any flawed decision-making,"" said David Kenny, senior vice president of Cognitive Solutions. 
Other tech firms are also working on solutions.
Last week, Google launched a ""what-if"" tool, also designed to help users look at how their machine-learning models are working.
However, Google's tool does not operate in real time - the data can be used to build up a picture over time.
Machine-learning and algorithmic, bias is becoming a significant issue in the AI community.
Microsoft said in May that it was working on a bias detection toolkit and Facebook has also said it is testing a tool to help it determine whether an algorithm is biased.
Part of the problem is that the vast amounts of data algorithms are trained on is not always sufficiently diverse.
Joy Buolamwini launched the Algorithmic Justice League (AJL) while a postgraduate student at the Massachusetts Institute of Technology in 2016 after discovering that facial recognition only spotted her face if she wore a white mask.
And Google said it was ""appalled and genuinely sorry"" when its photo algorithm was discovered to be incorrectly identifying African-Americans as gorillas in 2015.
In 2017, the UK police were warned by human rights group Liberty about relying on algorithms to decide whether to keep an offender in prison based purely on their age, gender and postcode.
There is a growing debate surrounding artificial intelligence and ethics, said Kay Firth-Butterfield from the World Economic Forum.
""As a lawyer, some of the accountability questions of how do we find out what made [an] algorithm go wrong are going to be really interesting,"" she said in a recent interview with CNBC. 
""When we're talking about bias we are worrying first of all about the focus of the people who are creating the algorithms and so that's where we get the young white people, white men mainly, so we need to make the industry much more diverse in the West."" 
",,Company,gray,arterial road,road,arterial road,-
https://ibm.co/2LqEoIF,187446750783_10155915296530784,https://www.facebook.com/ibmwatson/posts/10155915296530784,5 reasons why an increasing number of people are opting for specialized online programs to help them transition to AI careers: ,Link,,,9/30/18 19:50, ,7562,7562,0,10261,10261,0,123,83,93,3,3,9120,6796,0,0,109,0,0,0,0,0,0,0,0,0,0,9,39.0,,10,41.0,,26,59.0,,,30,63.0,,,2,1.0,,2,1.0,,Nanodegrees launched by Udacity cover many technology areas such as AI or data science and are taught by active industry thought leaders.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/08/blog_Nanodegrees_png_socialTile_072618.png,https://www.ibm.com/blogs/watson/2018/08/preparing-for-ai-jobs-why-nanodegrees-are-the-future-of-education/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Preparing+For+AI+Jobs+Nanodegrees+Aug+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.229574,neutral,0,"increasing number of people, reasons",Person,increasing number of people,Person,joy,0.261953,neutral,0,"data science, Udacity cover, technology areas","Company, Company",data science,Company,joy,0.610259,positive,0.710882,,"Person, Company, Quantity, Quantity","Large enterprises, startups and high-performance businesses across industries are increasingly turning to Artificial Intelligence and advanced analytics to make faster, more effective, data-driven decisions. The volume of unstructured and structured data stored by enterprises is growing at an accelerating rate.
The demand for skilled data scientists and candidates with AI skills is at an all-time high. Yet developing those skills typically requires significant investments of time, energy and money. Businesses are struggling to successfully deploy and manage AI projects due to lack of resources. And employees interested in preparing for these highly-coveted jobs incur significant debt, and delay other strategic business initiatives until they completed a traditional degree after business hours.
While traditional post-secondary programs in this field still have value, many working professionals are turning to online programs for a quicker, less expensive way to get started.
In 2017, IBM predicted that by 2020, demand for these skills would grow by 28% (364,000 jobs) to over 2.7 million job listings. We’ve revised that prediction, as we see growth in this space closer to 45%. A Harvard Business Review article proclaimed there is a growing war being waged for people with skills for the “sexiest job” of the 21st century, the data scientist.
More businesses than ever before are looking to fill a suite of new roles in an AI-driven world:
There are other pressing questions, too. How can existing IT professionals build specific skills for AI platforms, while they stay at their existing jobs? How can AI neophytes build the necessary skills and understanding to enter this lucrative profession, without putting their career on hold while they retrain? Nanodegrees seem to be the perfect solution.
Here are five reasons why an increasing number of people are opting for these specialized online programs to help them transition to AI careers:
1. Nanodegrees offer hands-on experience with real-world value
Traditional classroom training is theory-based, delivered seminar-style by a career professor, from presentation slides and textbooks. By contrast, a nanodegree program uses real data science projects and machine learning models, such as:
Working through the full-lifecycle of AI projects, from planning and design to execution and results, analysis helps fledgling data scientists and researchers to hone their skills, and gain a better understanding of the strategic role AI and analytics can play in solving business challenges.
Working with real tools on realistic projects helps provide aspiring data scientists and AI developers to obtain deeper understanding into how AI platforms like Watson process data and extract insights from it. Many well-known have contributed expertise and datasets to these nanodegree programs, making the curriculum much more engaging than it would be with “dummy” data.
2. Learn from top minds in AI and data science
Nanodegrees launched by Udacity cover many technology areas such as AI or data science and are taught by active industry thought leaders. The opportunity to be coached by an accomplished data scientist like IBM’s Adam Massachi, Airbnb’s Belinda Bennett or Slack’s Stephen Morton is rare, powerful and highly sought-after. These “experts in residence in data science” answer live questions, and provide not only technical advice but also career coaching and mentorship.
Nanodegrees offered in a MOOC (Massive Open Online Course) services model empower students with the opportunity to learn from industry thought leaders, at a fraction of the cost of full degree programs. Those with a foundation of technical understanding can augment their skills at their own pace.
3. Open up new opportunities and level-up existing roles
Career paths in the digital era aren’t nearly as linear as they were even a few decades ago. A university degree would often all but guarantee a student a sustainable career for many years. Today, graduates still find it difficult to get their first job, or end up freelancing or working part-time until they get established in their field.
Those who earn nanodegrees for in-demand areas of new technology like AI, data science, advanced data analytics or related fields can augment their post-secondary education. For developers, IT architects, and data management professionals already with years of experience, these courses can build skills, which help them qualify for higher salaries with their existing employer or within their chosen industries including:
4. The age of digital transformation 
Many businesses have changed or streamlined many of their business processes by adopting forms of AI, such as virtual customer service chatbots in contact centers, and improving their marketing campaigns, and manage risk through AI.
As customers evolve to be more comfortable with bots and get help from virtual shopping assistants, the demand for skills to design, build and test these systems is increasing exponentially. Many companies that are digitally enhancing their processes are investing in nanodegrees for employees whose careers are impacted by AI. Others like Bertelsmann are providing scholarships to students to build AI skills that will support their digital transformation journey.
5. Convenient, self-paced education at the pace of innovation 
Many courses that are designed to help people who are in transitionary periods in their career may start out as practical and current, yet by the time a student graduates a few years later, the curriculum is behind the times. Nanodegrees typically last between six months and a year, and since they are delivered electronically with live experts, the curricula can be updated as new industry innovations occur.
For students that work full-time and have other responsibilities, nanodegree programs are focused, and designed to enhance the skills which solve real-world challenges companies are experiencing today. Consultants can progress through course segments on their own time and apply their learnings immediately. Mentors share their expertise in subject matter like natural language understanding, in digestible workshops. Students in post-secondary programs like mathematics, statistics and computer science can augment their existing education with nanodegrees in data science and AI.
Are you looking for ways to improve your understanding of data science, or get guidance in preparing for jobs in the AI economy?
Check out the “Become a Data Scientist” nanodegree program, and discover how you can succeed in an AI-driven world. Learn at your own pace, for a budget-friendly subscription cost, and gain access to “office hours” career mentoring from the best in the business. You can build effective machine learning models, run data pipelines, build recommendation systems, and deploy solutions to the cloud with industry-aligned projects.
",,Person,coal black,neon lamp,lamp,neon lamp,-
,187446750783_10155912851620784,https://www.facebook.com/ibmwatson/posts/10155912851620784,IBM Watson,SharedVideo,,,9/29/18 20:27, ,1865,1865,0,2235,2235,0,108,95,114,0,0,2046,1702,0,0,99,0,0,0,0,1277,1371,0,0,0,30393,,17.0,,,19.0,,95,3.0,,,111,3.0,,,,,,,,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2xtnOmQ,187446750783_10155910012175784,https://www.facebook.com/ibmwatson/posts/10155910012175784,&quot;What exactly makes a great story or a compelling character in augmented and virtual reality? And how does AI help enrich these converging new mediums?&quot; Learn more: ,Link,,,9/28/18 14:23, ,6679,6679,0,8898,8898,0,92,56,74,2,2,8075,6005,0,0,82,0,0,0,0,0,0,0,0,0,0,7,41.0,1.0,7,42.0,1.0,27,34.0,,,38,36.0,,,1,1.0,,1,1.0,,What exactly makes a great story or a compelling character in augmented and virtual reality? And how does AI help enrich these converging new mediums?,https://www.ibm.com/blogs/industries/wp-content/uploads/2018/04/Tribeca_Virtual_Reality_60185.jpeg,https://www.ibm.com/blogs/industries/how-ar-vr-and-ai-can-power-immersive-storytelling/,joy,0.774741,positive,0.985769,"great story, new mediums, virtual reality",Person,great story,Person,joy,0.724741,positive,0.964666,"great story, virtual reality",Person,great story,Person,joy,0.617748,positive,0.700133,,"Person, Movie, Person, Person, Person, Person, Person, PrintMedia, Company, Person, Company, Company","Lucy may be a VR character, but she doesn’t act like one. Like any friend, she remembers what you’ve done and uses that information to inform how she talks with you. She can express a full range of emotions. And she’s as good at hanging out as she is going on adventures.
But Lucy—a character in “Wolves in the Walls,” a Fable Studios VR adaptation of the Neil Gaiman children’s book by the same name—wasn’t always so dynamic. Initially, Lucy was designed largely to follow a script and respond to viewer actions. Then Fable decided to take full advantage of VR’s capabilities and make her a fully-formed personality, with her own interests.
“Having an interactive character enslaved to your actions stops viewers from relaxing and stops the story. She wasn’t going on a ‘hero’s journey;’ she was more of a servant,” said Edward Saatchi, co-founder of Fable, at an IBM-sponsored panel on the future of immersive storytelling at the Tribeca Film Festival.
Lucy’s evolution is symbolic of a broader evolution taking place in the XR storytelling community. As the technology grows from a gimmick to a mature medium with large audiences, creators are experimenting with new ways to take viewers on more meaningful journeys.
But what exactly makes a great story or a compelling character in augmented and virtual reality? And how does AI help enrich these converging new mediums? Asad Malik, the creator of Terminal 3, an interactive AR documentary which had its world premier at Tribeca, said that AR, more than earlier forms of media, has the capacity to break down cultural and social barriers.
What if there were a network that could think for itself?
“Imagine putting a refugee in the White House or a homeless person in the office of the CEO of Uber. We can interview real people with real stories and have you interact with them,“ Malik said. This empathy, catalyzed by the unique experience of AR/VR, is a powerful way to foster deeper emotional connections that inspire change.
Augmented reality can also correct the mistakes of the physical world. Through an AR experience at a natural history museum, Jessica Brillhart, Founder and Director of Vrai Pictures, could fix a dinosaur skeleton that had been standing on two legs—a physical impossibility noted by the staff. Through AR, she was able to correct the creature’s posture to reflect the scientific reality.
“We can build digital layers on top of the world that are quite useful,” said Brillhart.
AI will play a pivotal role when creating immersive worlds—and an ecosystem of interactive characters—from scratch.
“AI makes characters feel real. You can build a character that not only remembers things you enjoy, but also your game and story decisions,” said Saatchi.
The entertainment industry won’t have to wait for the singularity and sentient robots to start using AI. Directors will be able to take the same kind of conversational technology that powers customer service chatbots and transform it into voice-based interactions that can complement both VR and AR.
“Interactive voice recognition in VR is the fourth dimension of storytelling,” said Michael Ludden, Director of Product at IBM Watson Developer and AR/VR Labs. “The possibilities are endless.”
One example is the game Star Trek: Bridge Crew. IBM Watson’s voice functionality, embedded in the game, allows players to issue orders vocally to the crew, fulfilling a dream for many nerds. The game shows how much sense it makes to use vocal commands during VR experiences, whether it’s a game, training program, or creative work session.
Though creators are just starting to fulfill the potential of these technologies, it’s clear that AR and VR, powered by AI, will fundamentally change storytelling and society.
“We are all on the same journey. The rules haven’t been written. We are all creators and experimenters in AR and VR, especially in fields where you apply AI,” said Ludden.
",,Person,coal black,pigtail hairstyle,person,pigtail hairstyle,-
https://ibm.co/2xu9DxC,187446750783_10155908310585784,https://www.facebook.com/ibmwatson/posts/10155908310585784,One of the most important success factors in AI is a design-led approach to human change that deeply fuses new AI capabilities with how humans prefer to engage with tools. Read more: ,Link,,,9/27/18 18:02, ,8984,8984,0,11637,11637,0,147,77,101,3,3,9744,7351,0,0,122,0,0,0,0,0,0,0,0,0,0,21,73.0,,21,77.0,,39,47.0,,,54,47.0,,,,3.0,,,3.0,,"Teaching technology to relate to people, as much as training people to use technology, is the biggest factor in the success of AI-driven transformations.",https://assets.weforum.org/article/image/responsive_medium_AO4ALh9by7hHprpKzuDHaThZLVGK-WRprL3Id2bMR7s.jpg,https://www.weforum.org/agenda/2018/09/why-artificial-intelligence-is-learning-emotional-intelligence/?_lrsc=6ac3ecf8-a72f-46e3-96e5-b6b003867db9,joy,0.736249,positive,0.983591,"important success factors, human change",Person,important success factors,Person,joy,0.54007,positive,0.83551,"people, technology, biggest factor",Person,people,Person,joy,0.623653,positive,0.718847,human-centric design,Person,"I started transforming businesses with technology 35 years ago. It was as true then as it is now that the biggest risk we have to mitigate is the resistance of people and organizations to change. It is a well-known fact that three in four transformation programmes fail to achieve their intended goals because people are not prepared to adopt new processes and technology. Mitigating these risks and helping people learn new technology-enabled processes has been good for the consulting industry, and continues to be one of the keys to successful programmes. 
With artificial intelligence (AI), change management and process reengineering get reinvented. What was once a one-way street has become a two-way street: we can now teach technology to relate to people, as much as we train people to use technology. Going forward, getting this human-centric design right is the biggest factor in the success or failure of AI-driven transformations. 
In traditional technology-led transformations, the goal of change management has been to teach people to use technology, dedicating leadership and resources to ensure compliance and adoption. The direction is one way: people learn how technology works in order to give it commands or interpret results. Technology could only follow precise commands based on pre-defined rules, and, for the most part, technology produced results that required specific skills to interpret and apply to our professions.
With AI pilots sprawling everywhere, companies, consultants and technology firms need to rethink their approaches to transformation. To successfully implement AI projects that drive impact at scale, great AI models and algorithms are necessary, but not sufficient. One of the most important success factors is a design-led approach to human change that deeply fuses new AI capabilities with how humans prefer to engage with tools. Companies that ignore this are likely stuck with collections of AI pilots that don’t amount to any real impact. 
This is a key aspect that is not yet understood by companies practicing ""AI tourism"". As many programmes focus primarily on machine-learning algorithms, advanced AI models and perfecting training datasets, they fail to address the most important success factors: the design of interactions and workflows, and the choreography of processes, technologies and humans. Companies are struggling to scale AI applications and realize the expected benefits, despite the plethora of AI proofs-of-concept underway across industries. The ones that do succeed demonstrate that skilled, purposeful design of workflows and user interactions lead to faster adoption and business benefits. Here are a couple of examples:
A financial services company was implementing one of the first customer-facing AI systems in its industry. Focused on getting the AI technology right, the client spent its resources verifying the accuracy of the models and readiness of the technology. Adoption of the technology did not meet the original expectations, despite robust underlying technology and a strong business case. Insufficient focus on designing the right workflows and human-machine interfaces led to slow adoption.
In contrast, another company in the same industry made a conscious decision to embed AI into its customers’ experiences. It spent months designing for a purpose, conducting user testing, and rolled out similar AI technology with a deep focus on the orchestration of functionality and user design. Within two months, more than one million customers were using it, exceeding expectations. 
These cases should not surprise us. As humans, most of the decisions we make are based on how information is presented to us, and not on what is shown to us. We think of ourselves as rational individuals of free will. Yet science demonstrates that we make decisions based on bias and context more than analysis and content. 
If you’re still unconvinced, look at the image below containing squares A and B. On the right, you see that boxes A and B are identical in colour. On the left, these squares are untouched, and we added context that makes square A appear darker than square B. The analytical fact is that boxes A and B are still identical in colour; the human truth is that most of us would bet A is darker in the left picture. This is a simple example of how bias and context beat analysis and content when it comes to human perception.
Emotional intelligence (EI) has been known to be a critical success factor in professional success, even more than performance or qualification. Indeed, the ability to connect and perceive with deep empathy gives a clear advantage in a world where more of our success depends on influencing other people. We are presented with hundreds of ""A/B"" squares every day: sometimes the ""A/B"" is a candidate selection, or an investment, or a product selection. People with high EI naturally have empathy to understand our context, relate to us better, and persuade us to see their desired choice as our darker square. 
EI has been a hard skill to teach, and one that has not been ""programmable"" into technology – until now. Concurrent with the progress of AI in the last two decades, EI has also developed significantly with advances in neuroscience and tools, such as functional magnetic resonance imaging (fMRI). One could say we are learning to ""reverse engineer"" our own human perception rules. 
I have been so passionate about this topic that a few years ago, I started a small practice to combine design and technology-led business change in a very specific way. I wanted to use human-centric design as a business re-engineering tool, focusing on people-process and people-technology design beyond the traditional process maps and productivity indicators. The premise was simple: through design we can better engineer interactions that lead people to adopt technology and behave exactly how we intend, reducing the need for training, handling exceptions or fighting for compliance. As a result, we create both delight and productivity.
The work has evolved as we have learnt and expanded well beyond our initial scope. There are many branches of it now in progress. Some of my colleagues in IBM Design, such as Adam Cutler, have been focused on what it takes to match AI and humans emotionally, to motivate people to work with these new technologies. Many universities are now working to decode the science of building relationships, and using that to train AI to interact with us in a way we can relate to and trust. 
The use of personality insights alongside traditional demographics has been shown to improve prediction accuracy for consumer preferences. Tone analyzers can now read documents such as emails and tweets, and determine if the person is angry, frustrated or thrilled, then adapt the interaction dynamically to satisfy clients better.
Designing AI applications that take burdens off people and present fewer required steps to complete a task is a simple way to achieve better human adoption. Reducing the amount of data and the number of clicks creates a positive experience that drives adoption. Conversely, understanding the behavioural bias toward shortcuts, and designing for it, prevents vulnerability issues ranging from lost productivity to cybersecurity gaps. 
Keep in mind some simple guidelines that lead to successful AI-led business transformation:
- Re-imagine processes that leverage the capabilities of AI. Design AI-embedded tasks optimized to their purpose, and AI-powered interfaces optimized for empathy.
- In AI-human interaction design, model humans as socio-emotional entities, rather than as analytical entities. Design human interactions to optimize for behaviour, as much as for data use or task productivity. 
- Burden AI technology with elements that humans don’t like to do, such as reducing data to be memorized and clicking repeatedly to complete a task. Remember, our brains and behaviours are biased to do what is easy, more than to do what is right.
- Teach EI to your AI to create positive contexts in which human users will trust and relate naturally to make the expected choices. As many rules of behaviour are encoded into ""unconscious biases"", do more user testing in lieu of asking users what they want (hint: they may not consciously know).
- Develop competency in both AI technology and AI-efficient human interface design, and include it in the scope of every AI pilot.
We are seeing a new dawn of technologies that can massively enhance our ability to perform and deliver business outcomes. Thanks to AI and the fusion of technology and design, we can create tools to unburden and expand our cognition, similarly to how we enhanced human physical strength with levers, wheels, engines and motors. 
As we teach AI how humans behave, we improve our own understanding of human biases and our ability to relate to each other. It’s ironic that teaching technology to be more effective at relating to humans will force us to be more effective ourselves. This could create leaps forward in our ability to work with each other and achieve greater outcomes.
",human-centric design,Person,jade green,person,musical instrument,ocardina,-
https://ibm.co/2DwljpP,187446750783_10155905119580784,https://www.facebook.com/ibmwatson/posts/10155905119580784,"Customer service is critical for business success. That's why we're teaming up with Salesforce to create Watson Discovery for Salesforce, an AI-powered insight engine designed to enhance customer experiences. Learn more: ",Link,,,9/26/18 10:44, ,6381,6381,0,8663,8663,0,111,56,65,5,6,7540,5474,0,0,98,0,0,0,0,0,0,0,0,0,0,12,67.0,,12,68.0,,32,25.0,,,38,27.0,,,4,2.0,,4,2.0,,Watson Discovery for Salesforce – which will be unveiled tomorrow at Dreamforce – is the first Watson product available on Salesforce’s AppExchange.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/09/IBM-Salesforce-black_1200x628-1024x536.jpg,https://www.ibm.com/blogs/watson/2018/09/introducing-watson-discovery-for-salesforce-an-ai-powered-insight-engine-for-crm/?cm_mmc=OSocial_Facebook-_-Watson+and+Cloud+Platform_Watson+Core+-+Discovery-_-WW_WW-_-Watson+Discovery+for+Salesforce+an+AI+Powered+Insight+Engine+Sept+2018&cm_mmca1=000034NH&cm_mmca2=10009360,joy,0.519945,positive,0.82063,"Customer service, Watson Discovery",Company,Customer service,Company,joy,0.123928,neutral,0,"Watson Discovery, first Watson product","Company, Company, Person",Watson Discovery,Company,joy,0.544717,positive,0.693605,"Deluxe Corporation uses Watson Discovery, customer reps","Company, Person, Company, Company, Company","Deluxe Corporation uses Watson Discovery for Salesforce to help all customer reps provide excellent service
In January, Salesforce and IBM strengthened their strategic partnership to deliver new joint solutions that leverage the power of AI and enable companies to make smarter decisions, faster than ever before. As a continuation of their partnership, IBM is announcing Watson Discovery for Salesforce, which marries the intelligent, customer-centric power of the Salesforce Platform with Watson’s industry-leading NLP and domain mastery to create an AI-powered insight engine to help customer service agents resolve complicated cases. Watson Discovery for Salesforce – which will be unveiled tomorrow at Dreamforce – is the first Watson product available on Salesforce’s AppExchange.
On stage at Dreamforce, Deluxe Corporation – one of the largest check printers and small business marketing companies in the US – will discuss how they are already using the product. Deluxe has been serving financial institutions and small businesses for over 100 years and maintains a contact center staffed with employees of all experience levels to help their customers with a myriad of financial service questions. Now, using Watson Discovery for Salesforce, the company seeks to make their newest agents as competent and as efficient as the more seasoned staff as quickly as possible. Deluxe has laid out their vision of Watson Discovery for Salesforce becoming the de facto federated search engine across their enterprise to improve agent response times, provide more consistency across the call center, and increase net promoter scores and client satisfaction.
Additionally, systems integrators – such as Bluewolf, an IBM company – and business partners, are bringing the power of the Watson Discovery for Salesforce technology to their clients, and integrating it into clients’ existing Salesforce systems. Learn more about those certified to deliver this solution here.
Businesses like Deluxe face customer service challenges every day. No matter how mobile or connected a business is, customers are more connected and more vocal than ever. Consider that 52% of customers will stop patronizing a brand after one bad customer service interaction, and 66% of U.S. consumers say the most important thing a brand can do is value their time.
Clearly, if a business isn’t meeting the customer’s needs, then it must transform, but leveling up your entire customer service team is not an easy transformation for any company to tackle.
Your reps’ success depends on them having easy access to relevant case resolving material, but information in many companies is largely unstructured and decentralized. So, when your reps need answers to a customer’s question, the retrieval of helpful information is likely difficult and time-consuming.
Watson Discovery for Salesforce lets you easily ingest your company’s data from a variety of common enterprise data sources. Just show Watson where to look, and it will crawl your PDFs and text documents, ingesting valuable insights to create a single, cloud-based data source. Once all the knowledge of your business has been ingested, Watson Discovery for Salesforce can draw upon that information, plus past customer cases and issues, to provide agents the understanding they need to serve your customers and keep them happy. Watson uses AI to analyze unstructured data within and outside of Salesforce, and is complementary to Salesforce’s Einstein AI platform.
Watson Discovery for Salesforce is not a simple search engine – it’s an insight engine, which taps into the unified knowledge base you’ve created, and through an amalgam of AI-powered search, embedded natural language processing, domain customization, passage retrieval, semantic understanding, and machine learned relevancy, provides insightful recommendations your reps will need to resolve customer issues. It learns from past customer cases to improve with every interaction, and understands what’s relevant to your business, your customers, and your service reps, to proactively recommend pertinent solutions.
It’s also easy to configure the app with Salesforce’s drag and drop Lighting UI dashboard. Once configured, all your agents need to do is select the customer case and Watson will automatically populate augmented results, and if the rep finds the content useful, they can attach it to the case with just a click. Agents are able to manually query the system as well. While Watson learns from past customer cases it also collects that interaction data, so admins can check their dashboard to see how agents are finding information, what kind of approach is proving most useful, and gain insight into content utilization or potential issues that require action.
Watson Discovery for Salesforce is one of the many Watson solutions designed for the Salesforce ecosystem to enhance customer experiences. Independently from and complementary to Watson Discovery for Salesforce, Next Best Action allows agents to understand what to do next when resolving customer cases, and Lead Generation analyzes unstructured data sources in news articles to prioritize the best leads.
When all of your customer service reps can easily access the entire knowledge base of your organization in moments and receive clear insights, that means every one of your agents is your best agent. If you are interested in getting started with Watson Discovery for Salesforce for your Service Cloud needs, please contact us and learn more about the Watson and Salesforce solutions.
",Deluxe Corporation uses Watson Discovery,Company,coal black,coal black color,lamp,fluorescent lamp,-
https://ibm.co/2zs0LuI,187446750783_10155903051690784,https://www.facebook.com/ibmwatson/posts/10155903051690784,"Today, IBM announced its largest set of Watson AI solutions that can be used across many industries, whether it be in the office or on a farm, from agriculture to HR. Learn more: ",Link,,,9/25/18 10:02, ,25446,25446,0,35238,35238,0,649,490,600,10,11,12940,9068,0,0,352,0,0,0,0,0,0,0,0,0,0,50,201.0,7.0,52,203.0,8.0,230,296.0,,,286,314.0,,,4,7.0,,4,6.0,,"The aim is to prepackage and pretrain Watson for various verticals such as agriculture, real estate and manufacturing.",https://zdnet1.cbsistatic.com/hub/i/r/2018/04/29/0b5fc3aa-54ae-44b4-bc96-a90ae1e6e999/thumbnail/770x578/e2c6329a4d27409492d81bf08c01cd29/ziff-ibm-promo-pic-2.jpg,https://www.zdnet.com/article/ibm-launches-pretrained-watson-packs-for-industries/,joy,0.175664,positive,0.617129,"largest set of Watson, Today","Company, Person",largest set of Watson,Company,joy,0.087825,neutral,0,"various verticals, real estate, aim",Person,various verticals,Person,joy,0.1681,positive,0.657032,,"Company, Person, Person, Person, Company","IBM outlined prepackaged Watson tools pretrained for various industries use cases such as agriculture, customer service, human resources, manufacturing and marketing.
 	The move highlights a growing trend in both artificial intelligence and machine learning where technology providers are trying to provide easier-to-implement options that can be used without teams of data scientists.
 	Each Watson pack is in different states of release but take best practices and training knowledge from various IBM engagements. For instance, IBM said its Watson Decision Platform for Agriculture is generally available. IBM has integrated its weather data as well as Internet of things end points in agriculture and images to provide a ""predictive view of a farm."" Farmers would get an app for realtime decision support.
 	Primers: What is AI? Everything you need to know about Artificial Intelligence | Machine learning? | Deep learning? | Artificial general intelligence? 
 	Here's a rundown of other areas where IBM is pre-training Watson for industries and functions.
For human resources, Watson tools will analyze the background of current top performing employees from diverse backgrounds and aim to find similar traits among applicants.
IBM's Watson Assistant for marketing converts metrics to actionable information to be used for personalized campaigns. On the advertising front, Watson is using weather data to tailor ads.
Watson Supply Chain Insights is generally available and aims to couple weather data, traffic reports and regulatory changes to give enterprises a better view of a supply chain.
Toolsets based on Watson and IoT analytics are being used for manufacturing for industrial equipment with a focus on product inspection, productivity, skills gaps and material costs as well as downtime and defects.
 	Here are some screenshots of the Watson efforts tailored to agriculture.
 	Now that the services used by an enterprise and provided to its customers may be hosted on servers in the public cloud or on-premises, maybe ""hybrid cloud"" isn't an architecture any more. While that may the case, that's not stopping some in the digital transformation business from proclaiming it a way of work unto itself.
 	Want a full-featured, easy-to-run, open-source Infrastructure-as-a-Service cloud to call your own? Check out the latest version of Nextcloud.
 	Application spending has moved to the cloud fastest, but other areas of IT spending are catching up.
 	Cloud computing systems provide a distinct and measurable competitive advantage, and implementing a successful transformation can reap significant long-term benefits for any enterprise. 
",,Company,blue,stock trader,person,stock trader,-
https://ibm.co/2xPwROS,187446750783_10155900842670784,https://www.facebook.com/ibmwatson/posts/10155900842670784,"WATCH NOW: David Kenny, SVP at IBM Watson and Cloud Platform, discusses how the company is developing software to find out what leads AI to make decisions via CNBC: ",Link,,,9/24/18 9:40, ,10281,10281,0,13660,13660,0,283,215,269,5,5,11436,8529,0,0,229,0,0,0,0,0,0,0,0,0,0,19,94.0,4.0,19,95.0,4.0,93,143.0,,,115,154.0,,,1,4.0,,1,4.0,,"David Kenny, senior VP at IBM Watson and Cloud Platform, discusses how the company is developing software to find out what leads artificial intelligence to make decisions.",https://image.cnbcfm.com/api/v1/image/105459029-4ED2-SBE-091918-Kenny.jpg?v=1537348151,https://www.cnbc.com/video/2018/09/19/ibm-is-looking-to-open-the-black-box-of-ai-exec-says.html,joy,0.128643,neutral,0,"David Kenny, IBM Watson, Cloud Platform","Person, Person, Company",David Kenny,Person,sadness,0.065894,neutral,0,"David Kenny, artificial intelligence, senior VP","Person, Company",David Kenny,Person,sadness,0.461302,negative,-0.696181,"Global Business, Financial News, real-time snapshot, Data",Quantity,"Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.
",Global Business,Quantity,blue,portrait photo,person,portrait photo,-
https://ibm.co/2P29dWG,187446750783_10155898698200784,https://www.facebook.com/ibmwatson/posts/10155898698200784,"Did you know? IBM Watson has a YouTube channel. 

Immerse yourself in all things technology, from developer tutorials to Think recaps and more: ",Link,,,9/23/18 9:30, ,5623,5623,0,7717,7717,0,113,73,95,1,1,6781,4754,0,0,101,0,0,0,0,0,0,0,0,0,0,11,51.0,1.0,12,55.0,2.0,28,50.0,,,38,57.0,,,,1.0,,,1.0,,"Meet IBM Watson, the AI platform for professionals. Subscribe for tutorials for using Watson services, developer kits, educational clips, event recaps and more.",https://yt3.ggpht.com/a/AATXAJyzfGL7kUk9wfS1iX21IgoPsKOIEEqbit_r-w=s900-c-k-c0xffffffff-no-rj-mo,https://www.youtube.com/channel/UCxPJljXUHvUd9idyfEHvXqg?view_as=subscriber,anger,0.100696,positive,0.746694,"IBM Watson, YouTube channel, things technology","Person, Company, Company",IBM Watson,Person,joy,0.120566,neutral,0,"Meet IBM Watson, developer kits",Company,Meet IBM Watson,Company,anger,0.03828,neutral,0,,"Company, Company","      YouTube
                                                                               

                                                                                                                                                                                                        
    





                                                                                                          
                     
                                     IBM Watson
                                                                                                                                                                                                                                                                                                                                                                                       
                                                        
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
  

",,Company,blue,neon lamp,lamp,neon lamp,-
https://ibm.co/2ukQzjR,187446750783_10155896695755784,https://www.facebook.com/ibmwatson/posts/10155896695755784,"What is Project Debater?

Meet the AI IBM designed to challenge and create arguments for humans on complex issues. ",Link,,,9/22/18 10:43, ,10369,10369,0,14057,14057,0,243,169,208,7,8,11889,8826,0,0,215,0,0,0,0,0,0,0,0,0,0,26,82.0,1.0,27,82.0,1.0,62,124.0,,,85,123.0,,,2,6.0,,2,5.0,,IBM’s Project Debater research project is able to make real-time arguments about complicated debates like subsidizing space exploration.,https://cdn.vox-cdn.com/thumbor/xKUljgsTYgFZGcHHW6yWq56yXuk=/0x146:2040x1214/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/11561677/Project_Debater_with_human_professional.jpg,https://www.theverge.com/2018/6/18/17477686/ibm-project-debater-ai,anger,0.345334,neutral,0,"AI IBM, complex issues",Company,AI IBM,Company,anger,0.473393,positive,0.739052,"IBM’s Project Debater research project, space exploration",Company,IBM’s Project Debater research project,Company,joy,0.606543,positive,0.352065,Project Debater,"Quantity, Person, Company, Person, Person, Quantity","At a small event in San Francisco last night, IBM hosted two debate club-style discussions between two humans and an AI called “Project Debater.” The goal was for the AI to engage in a series of reasoned arguments according to some pretty standard rules of debate: no awareness of the debate topic ahead of time, no pre-canned responses. Each side gave a four-minute introductory speech, a four-minute rebuttal to the other’s arguments, and a two-minute closing statement.
Project Debater held its own.
It looks like a huge leap beyond that other splashy demonstration we all remember from IBM when Watson mopped the floor with its competition at Jeopardy. IBM’s AI demonstration today was built on that foundation. It had many corpora of data it could draw from, just like Watson did back in the day. And like Watson, it was able to analyze the contents of all that data to come up with the relevant answer. But this time, the “answer” was cogent points related to subsidizing space and telemedicine laid out in a four-minute speech defending each.
Project Debater cited sources, pandered to the audience’s affinity for children and veterans, and did a passable job of cracking a relevant joke or two in the process. 
That’s pretty impressive. It essentially created a freshman-level term paper kind of argument in just a couple of minutes when presented with a debating topic it had no specific preparation for. The system has “several hundred million articles” that it assumes are accurate in its data banks, which are about 100 areas of knowledge. When it gets a debate topic, it takes a couple of minutes to spelunk through them, decides what would make the best arguments in favor of the topic, and then creates a little speech describing those points. 
Some of the points it made were pretty facile; some quoted sources, and some were pretty clearly cribbed from articles. Still, it was able to move from the “present information” mode we usually think of when we hear AI to a “make an argument” mode. But what impressed me more was that it attempted to directly argue with points that its human opponents made, in nearly real time. (The system needed a couple minutes to analyze the human’s four-minute speech before it could respond.)
It frankly made me feel a little unsettled, but not because of the usual worries like “robots are going to become self-aware and take over” or “AI is coming for our jobs.” It was something subtler and harder to put my finger on. For maybe the first time, I felt like an AI was trying to dissemble. I didn’t see it lie, nor do I think it tried to trick us, but it did engage in a debating tactic that, if you saw a human try it, would make you trust that human a little bit less. 
Here was the scene: a human debater was arguing against the notion that the government should subsidize space exploration. She set up a framework for understanding the world, which is a pretty common debating tactic. Subsidies, she argued, should fit one of two specific criteria: fulfilling basic human needs and creating things that only could be done by the government. Space exploration didn’t fit the bill. Fair enough.
Project Debater, whose job was to respond directly to those points, didn’t quite rebut them directly. It certainly talked in the same zone. It claimed that “subsidizing space exploration usually returns the investment” in the form of economic boosts from scientific discovery, and it said that for a nation like the United States, “having a space exploration program is a critical part of being a great power.” 
What Project Debater didn’t do was directly engage the criteria set forth by its human opponent. And here’s the thing: if I were in that debate, I wouldn’t have done so either. It’s a strong debating tactic to set the framework of debate, and accepting that framework is often a recipe for losing. 
So the question is: did Project Debater simply not understand the criteria, or did it understand and choose not to engage on those terms? Watching the debate, I figured the answer was that it didn’t quite get it, but I wasn’t positive. I couldn’t tell the difference between an AI not being as smart as it could be and an AI being way smarter than I’ve seen an AI be before. It was a pretty cognitively dissonant moment. Like I said, unsettling.
Jeff Welser, the VP and lab director for IBM research at Almaden, put my mind at ease. Project Debater didn’t get it. But it didn’t get it in a really interesting and important way. “There’s been no effort to actually have it play tricky or dissembling games,” he tells me (phew). “But it does actually do … exactly what a human does, but it does it within its limitations.”
Essentially, Project Debater assigns a confidence score to every piece of information it understands. How confident is the system that it actually understands the content of what’s being discussed? “If it’s confident that it got that point right, if it really believes it understands what that opponent was saying, it’s going to try to make a very strong argument against that point specifically,” Welser explains. 
“If it’s less confident,” he says, “it’ll do its best to make an argument that’ll be convincing as an argument even if it doesn’t exactly answer that point — which is exactly what a human does, too, sometimes.”
So, the human says that government should have specific criteria surrounding basic human needs to justify subsidization. Project Debater responds that space is awesome and good for the economy. A human might choose that tactic as a sneaky way to avoid debating on the wrong terms. Project Debater had different motivations in its algorithms, but not that different.
The point of this experiment wasn’t to make me think that I couldn’t trust that a computer is arguing in good faith — though it very much did that. The point is that IBM was showing off that it can train AI in new areas of research that could eventually be useful in real, practical contexts.
The first is parsing a lot of information in a decision-making context. The same technology that can read a corpus of data and come up with a bunch of pros and cons for a debate could be (and has been) used to decide whether or not a stock might be worth investing in. IBM’s system didn’t make the value judgment, but it did provide a bunch of information to the bank showing both sides of a debate about the stock.
As for the debating part, Welser says that it “helps us understand how language is used,” by teaching a system to work in a rhetorical context that’s more nuanced than the usual “Hey Google, give me this piece of information and turn off my lights.” Perhaps it might someday help a lawyer structure their arguments, “not that Project Debater would make a very good lawyer,” Welser joked. Another IBM researcher suggested that this technology could help judge fake news. 
How close is this to being something IBM turns into a product? “This is still a research-level project,” Welser says, though “the technologies underneath it right now” are already beginning to be used in IBM projects.
In the second debate, about telemedicine, Project Debater once again had a difficult time parsing the exact nuance its human opponent was making about how important the human touch is in diagnosis. Rather than discuss that, it fell back to a broader argument, suggesting that maybe the human was just afraid of new innovations. 
”I am a true believer in the power of technology,” quipped the AI, “as I should be.”
",Project Debater,Quantity,blue,speaker,person,speaker,-
https://ibm.co/2PPSohX,187446750783_10155891620965784,https://www.facebook.com/ibmwatson/posts/10155891620965784,"IBM's new trust and transparency capabilities for AI enable your business to flag and mitigate harmful bias to deliver fair outcomes, as well as to explain how your AI decisions are reached. Try out on IBM Cloud today. ",Link,,,9/20/18 9:27, ,5699,5699,0,7460,7460,0,70,40,48,5,7,6666,5151,0,0,58,0,0,0,0,0,0,0,0,0,0,6,39.0,,6,41.0,,20,21.0,,,25,23.0,,,4,3.0,,3,3.0,,See the resources and related products helping IBM lead the way in explainable AI.,https://1.cms.s81c.com/sites/default/files/2019-04-22/explainable-ai.jpg,https://www.ibm.com/watson/explainable-ai,anger,0.134546,negative,-0.60227,IBM's new trust,Company,IBM's new trust,Company,sadness,0.090954,positive,0.616457,"related products, resources",Company,related products,Company,joy,0.201531,positive,0.472378,IBM Watson OpenScale,"Person, Company, Person","                          Assess risk and enhance AI to maintain regulatory compliance and drive fair, explainable outcomes. Learn more about IBM's leadership in explainable AI.                   
IBM Watson OpenScale™ tracks and measures outcomes from AI across its lifecycle, and adapts and governs AI to changing business situations - for models built and running anywhere.
For both regulatory and business reasons, lenders need to understand why their credit risk models are making specific recommendations, and must ensure models are running without bias against certain groups. Watch this demo to learn how IBM Watson OpenScale can provide insights into a credit risk model in production and help lenders avoid black box AI.
Build and train AI models and prepare and analyze your data, all in one integrated environment.
Deploy machine learning models into production at scale and manage model performance.
A flexible multicloud data platform that integrates all your data, on premises or from any cloud while keeping it secure at its source. Simplify and automate how you collect, organize, analyze and govern data to rapidly innovate your business with AI.
",IBM Watson OpenScale,Person, , , , , 
https://ibm.co/2PPjRQL,187446750783_10155889032610784,https://www.facebook.com/ibmwatson/posts/10155889032610784,"Building trust in the outcomes of your AI is at the forefront of business priorities. IBM has released new capabilities to help organizations build, run, and manage trusted and transparent AI. Learn more: ",Photo,,,9/19/18 7:13, ,13381,13381,0,19583,19583,0,194,134,149,4,5,8119,5908,0,0,73,0,0,0,0,0,0,0,0,0,0,21,54.0,1.0,23,57.0,1.0,51,13.0,75.0,,57,13.0,79.0,,2,3.0,,2,2.0,,We’ve announced the release of IBM’s new Trust and Transparency capabilities for AI on the IBM Cloud.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/09/898_Blog-and-social-image-for-Trust-and-Transparency-announcement1200x628-C-1024x536.jpg,https://www.ibm.com/blogs/watson/2018/09/trust-transparency-ai/?cm_mmc=OSocial_Facebook-_-Watson+and+Cloud+Platform_Watson+Core+-+Platform-_-WW_WW-_-Its+Time+To+Start+Breaking+Open+The+Black+Box+of+AI+Sept+2018&cm_mmca1=000033SC&cm_mmca2=10009389,joy,0.244804,positive,0.671708,"new capabilities, IBM","Person, Company",new capabilities,Person,joy,0.140616,neutral,0,release of IBM,Company,release of IBM,Company,joy,0.548316,positive,0.671076,,"Person, Company, Company","At IBM, we’ve seen our customers use AI as a catalyst to reimaging their workflows – transforming how customer call centers operate, how people complete their taxes, and how legal professionals make data privacy compliance decisions. However, many organizations still continue to struggle in deploying their AI into production environments across their existing applications.
For AI to thrive and for businesses to reap its benefits, executives need to trust their AI systems. They need capabilities to manage those systems and to detect and mitigate bias. It’s critical – oftentimes a legal imperative – that transparency is brought into AI decision-making. In the insurance industry, for example, claims adjusters may need to explain to a customer why their auto claim was rejected by an automated processing system.
It’s time to start breaking open the black box of AI to give organizations confidence in their ability to manage those systems and explain how decisions are being made.
This is why we’ve announced the release of IBM’s new Trust and Transparency capabilities for AI on the IBM Cloud. Built with technology from IBM Research, these capabilities provide visibility into how AI is making decisions and give recommendations on how to mitigate any potentially damaging bias. It features a visually clear dashboard that line-of-business users can easily understand, reducing the burden of accountability from data scientists and empowering business users.
Accelerating trusted AI across your business 
Our goal is to empower businesses to infuse their AI with trust and transparency, thus building confidence to deploy AI systems in production.
Our new Trust and Transparency capabilities for AI on the IBM Cloud support models built in any IDE or with popular, open source ML frameworks like TensorFlow, Keras, and SparkML, among others. Once deployed, those models can be monitored and managed by our capabilities at runtime – while the AI decisions are being made.
So, let’s say you build and deploy a system of models supporting an API your business can call whenever you need a prediction. Our new capabilities hook into those models and instrument a layer that enables you to capture every input your models receive and every output your models produce.
Our new capabilities provide a level of transparency, auditability, and explainability by logging every individual transaction throughout a model’s operational life. The lineage of these models is presented to business users at runtime in a way that’s easy to understand – something that’s unattainable with the tools available today.
Fairness is a key concern among enterprises deploying AI into apps that make decisions based on user information. The reputational damage and legal impact resulting from demonstrated bias against any group of users can be seriously detrimental to businesses. AI models are only as good as the data used to train them, and developing a representative, effective training data set is very challenging.
In addition, even if such biases are identified during training, the model may still exhibit bias in runtime. This can result from incongruities in optimization caused by assignment of different weights to different features.
As it logs each transaction, the Trust and Transparency capabilities feed inputs and outputs into a battery of state-of-the-art, bias-checking algorithms developed by IBM Research, to track bias in runtime. If bias is detected, the capabilities provide bias mitigation recommendations in the form of corrective data, which can be used to incrementally retrain the model for redeployment.
We address the problem of bias detection by automatically analyzing transactions within adaptable bias thresholds, while values of other attributes remain exactly the same. Traditional methods of measuring bias at build time require techniques that are computationally prohibitive at runtime for a complex AI system.
These capabilities incorporate novel techniques developed by IBM Research that automatically synthesize data in order to compute bias on a continuous basis. These techniques combine symbolic execution with local explainability for generations of effective test cases to create highly flexible, efficient, and comprehensive bias detection capabilities.
Explainability enables business ownership
Our Trust and Transparency capabilities bridge the gap between data scientists, developers, and business users within an organization, providing them visibility into what’s happening in their AI systems.
Through an intuitive visual dashboard, businesses can access easy-to-understand explanations of transactions. They can simply type the transaction ID – which can be passed down from an application into the user interface – to get details about the features used to make a decision, the limits, the inputs passed, and most importantly, the confidence level of each factor contributing to the decision the AI helped make.
Thus, even though the business-process owner might have minimal understanding of how the model works, they can still gain insight into the decision-making process and can easily compare the model’s performance against a human decision. As a result, they can make decisions about AI model health and recognize when the system might need help from data scientists.
Through these capabilities, data scientists and developers can obtain insights into the real-time performance of their models, which can also be measured and understood by business users. This provides visibility into whether models are making biased decisions and the effect of those decisions on the enterprise. This includes the corrective feedback data scientists can incorporate into their models to address biased behavior. IBM’s Trust and Transparency capabilities are unique in helping users understand the decisions their AI models are making during runtime – something that was not possible before.
Get started with trusted AI
If AI is truly going to augment operational decision-making, it’s critical to make AI outcomes transparent and explainable – not only to data science teams, but also to the line-of-business user responsible for those decisions.
IBM’s new Trust and Transparency capabilities for AI are available on the IBM Cloud. Learn more here.
References: 
",,Person,ultramarine,night-light,light source,night-light,-
https://ibm.co/2PFzjir,187446750783_10155885686375784,https://www.facebook.com/ibmwatson/posts/10155885686375784,IBM has developed an actionable guide for designers and developers to get intentional about ethical technology. Read more on &quot;Everyday Ethics for AI&quot; via our Medium blog: ,Link,,,9/17/18 17:45, ,8071,8071,0,10655,10655,0,100,63,71,6,6,9715,7409,0,0,90,0,0,0,0,0,0,0,0,0,0,7,41.0,,7,44.0,,33,32.0,,,38,33.0,,,3,3.0,,3,3.0,,"By: Adam Cutler, IBM Distinguished Designer, Artificial Intelligence Design; Milena Pribić, IBM Designer, Artificial Intelligence Design; and Lawrence Humphrey, IBM Designer, Artificial Intelligence…",https://miro.medium.com/max/1200/1*PP4DDiEFaEL_kDUCzzNoTg.jpeg,https://medium.com/design-ibm/everyday-ethics-for-artificial-intelligence-75e173a9d8e8,joy,0.770688,neutral,0,"actionable guide, Everyday Ethics, IBM",Company,actionable guide,Company,joy,0.226618,neutral,0,"Artificial Intelligence Design, IBM Distinguished Designer, Artificial Intelligence","Person, Company, Person, Person",Artificial Intelligence Design,Person,joy,0.558214,positive,0.759971,Artificial Intelligence Design,"Person, Company, Person, Person, Person","a Practical Guide for Designers and Developers
By: Adam Cutler, IBM Distinguished Designer, Artificial Intelligence Design; Milena Pribić, IBM Designer, Artificial Intelligence Design; and Lawrence Humphrey, IBM Designer, Artificial Intelligence Design
Artificial intelligence already touches our lives both directly and indirectly; it works in the open and it works behind filters, apps, APIs, and other processes. AI promises immense change but this evolution is also a cause for concern. When decisions are driven by black box algorithms, the ripples of AI’s influence are often difficult to measure.
AI’s new technologies and novel effects are spurring new methods of design and development. This marks the beginning of the age of relationship design. Software design and development can no longer focus on interactions alone. For AI to truly augment our intelligence, we must evolve our relationships with machines.
Fostering and protecting a relationship with AI is a brand-new concept. This type of design requires an incredible amount of trust. Trust between developer and user, between user and machine, between society and AI in general.
To address these new challenges and welcome in this era of design, we collaborated on this field guide for designers and developers working with AI. It is meant to help teams align with each other at every step of the design process.
Everyday Ethics for Artificial Intelligence is a framework for AI ethics that you and your team can immediately put into practice. We partnered with Francesca Rossi, IBM’s global leader for AI ethics, to distill a variety of information and perspectives into a digestible and actionable guide for designers and developers.
We organized this guide around five main focus areas that align with IBM’s Principles for Trust and Transparency:
1. Accountability: AI designers and developers are responsible for considering AI design, development, decision processes, and outcomes.
2. Value Alignment: AI should be designed with consideration of the norms and values of your user group.
3. Explainability: AI should be designed for humans to easily perceive, detect, and understand its decision process.
4. User Data Rights: AI should be designed to protect user data and preserve the user’s power over access and uses.
5. Fairness: AI should be designed to minimize bias and promote inclusive representation.
Each focus area includes recommended actions, necessary considerations, and questions to spark conversations.
Everyday Ethics for Artificial Intelligence is an ongoing, interdisciplinary effort. We hope it builds on public contributions concerning AI Ethics in a meaningful way and we look forward to expanding on it. Embracing a framework of ethical communication and decision-making will marry good intentions with good outcomes.
Ethical decision-making is not just another form of technical problem solving. Artificial intelligence has the potential to dramatically enrich our lives, our relationships, and ourselves. We can only get there through transparency and intentionality.
Rather than strive for perfection first, we are releasing the first iteration of the Everyday Ethics guide to allow all who read and use it to comment, critique and participate in all future iterations. So please experiment, play, use, and break what you find here and send us your feedback. You can reach us at edethics@us.ibm.com.
Download the guide: ibm.biz/everydayethics 
Say hello on Twitter: Adam Cutler: @adam_cutler Milena Pribić: @milenapribic Lawrence Humphrey: @hi_lawrence 
",Artificial Intelligence Design,Person,ivory,anechoic chamber,indoors,anechoic chamber,-
,187446750783_10155882721005784,https://www.facebook.com/ibmwatson/posts/10155882721005784:0,"IBM was recently named #1 in AI Software Platforms by IDC's Worldwide Cognitive/AI Software Platforms Market Shares, June 2018 Report.",Photo,,,9/16/18 9:40, ,7954,7954,0,10778,10778,0,173,98,148,4,4,9344,6880,0,0,135,0,0,0,0,0,0,0,0,0,0,15,91.0,3.0,17,91.0,6.0,46,29.0,34.0,,59,30.0,59.0,,,4.0,,,4.0,,,,,sadness,0.142092,neutral,0,"AI Software Platforms, IDC's Worldwide Cognitive, IBM","Company, Company",AI Software Platforms,Company, , , , , , , , , , , , , , , , , , , , , , 
,187446750783_10155880566220784,https://www.facebook.com/ibmwatson/posts/10155880566220784,"Get ready: Think 2019 is on the horizon. 
 
Watch a replay of the talk by Watson's young developer, 14-year-old Tanmay Bakshi on using deep learning to save young lives from this year's conference.",Link,,,9/15/18 10:02, ,6431,6431,0,8795,8795,0,96,52,62,3,3,7895,5804,0,0,83,0,0,0,0,0,0,0,0,0,0,8,52.0,1.0,8,54.0,1.0,26,28.0,,,31,31.0,,,3,,,3,,,,,,joy,0.600523,positive,0.913452,"deep learning, 14-year-old Tanmay Bakshi, Watson's young developer","Person, Quantity, Person",deep learning,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2KnH22N,187446750783_10155878304440784,https://www.facebook.com/ibmwatson/posts/10155878304440784,"&quot;AI is changing the world by transforming how we work. AI systems have the power to learn at incredibly fast rates —continuously sharpening their skills. They are good at what they do: processing information at a blazingly fast rate. But they don’t reason like we do. We’re creative and capable of real thought. They are there to help us to do what we do best.&quot;

Read more about Anamita Guha's experience working on the IBM Watson team and her ambitious side hustle project launching the Bot Asset Exchange community. ",Link,,,9/14/18 9:16, ,5865,5865,0,7861,7861,0,89,59,65,2,2,7072,5345,0,0,80,0,0,0,0,0,0,0,0,0,0,10,34.0,,11,34.0,,35,26.0,,,39,26.0,,,2,,,2,,,"Anamita Guhagrew launched Bot Asset Exchange, a community driven hub for enterprise bot developers to share and build bots powered by IBM Watson Assistant.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/04/blog_execWatson_socialTile_042418.jpg,https://www.ibm.com/blogs/watson/2018/04/decoding-the-brain-aiding-developers-with-watson/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Watson+Women+Blog&cm_mmca1=000000OF&cm_mmca2=10000409,joy,0.6366,positive,0.614441,"Anamita Guha's experience, IBM Watson team, ambitious side hustle project","Person, Person",Anamita Guha's experience,Person,sadness,0.169159,neutral,0,"Anamita Guhagrew, Bot Asset Exchange",Company,Anamita Guhagrew,Company,joy,0.624695,positive,0.77211,,"Person, Person, Person, Company, Company, Person","Anamita Guha grew up surrounded by coders and IPOs in the way other kids’ childhoods were filled with trips to the mall or little league. Growing up in San Francisco, where both her parents helped build the Valley we know today, Anamita developed, almost intrinsically, an understanding of the power technology has to connect people and change the world.
And by an early age –we’re talking four years old –Anamita was up and running on her own computer. At nine, she started designing websites as a side-hustle. Out of this early digital relationship and the exposure she received to a diversity of people and ideas in Silicon Valley, Anamita became increasingly intrigued by people –and how they process information, become motivated by their beliefs and ultimately make decisions.
Now at IBM Watson, Anamita has combined her aptitude for technology —along with her passion for understanding the human mind —to create the tools developers rely on to change the world with Watson. We chat with her about her unique background, path in the Valley and how she sees AI changing the world, one decision at a time.
How did you become interested in the human mind, and ultimately AI?
Technology has always fascinated me, but not for what it does –instead, for what it inspires us to do. Growing up in Silicon Valley, I learned at a pretty early age that just by giving people better access to information, it significantly opens our perspective and decision-making capabilities. This process of information to output was so fascinating to me that I actually chose a cognitive science major. I wanted to know: how does the brain work? How do we think about things? And, as interesting as those classes were, I quickly found that what I was really after was a better understanding of human cognition. So, in college, I started shifting my focus to classes in AI, machine learning and computational models of the mind.
What I learned was that these technologies, which were new and growing rapidly at the time, had the potential to extend the possibilities of what humans are capable of –in a way like we’ve never seen before. To me, AI was the next revolution of information. Much like the dot-com era expanded our access to information, and each other –AI will amplify this even further and extend human possibilities in revolutionary new ways. I just kept thinking how exciting it would to be to layer the human brain’s ability to process information, instinct and insight with the capabilities of an AI system. Combined, it’s the ultimate decision-making machine–doctors, lawyers, my barista even –will have better access to more complete and broader information, giving us the ability to make decisions with more confidence, and even greater outcomes.
What’s one example of when you saw the potential AI has to redefine human cognition?
In June 2017, I spearheaded a really exciting a side project at IBM. We launched something called the Bot Asset Exchange, which is a community driven hub for enterprise bot developers to share and build bots powered by IBM Watson Assistant. Since this was a side project, we needed to recruit various people within IBM –it became almost like a scavenger hunt in terms of putting all of the pieces together, but the outcome was hugely impactful.
The platform launched with more than 120 conversational interfaces in various categories and was easy to learn. This tool now provides more ways for developers to communicate directly with one another, so they can discuss bots they are working on and ones that might be added soon. The Bot Asset Exchange also makes it possible for these developers to quickly deploy the backend logic necessary to create conversational interfaces for multiple enterprise and consumer –like chatbots for popular messaging apps or voice apps – to more critical dialogs, like legal and government bots.
What do you think AI’s largest impact on the world will be?
AI is changing the world by transforming how we work. AI systems have the power to learn at incredibly fast rates —continuously sharpening their skills. They are good at what they do: processing information at a blazingly fast rate. But they don’t reason like we do. We’re creative and capable of real thought. They are there to help us to do what we do best.
As businesses transform, I think AI will trend toward personalization. By that, I mean users will perceive the AI systems they are interacting with as being made just for them. We’re already seeing this happen. For example, IBM Watson is helping leading European bank Crédit Mutuel’s 20,000 customer advisors maximize their time. Watson can help them handle the routine queries, giving each customer a personalized approach while giving them more time to meet the needs of customers with more complex needs. I think this kind of personalization means improved service —each customer comes away feeling valued, and like the world has almost personalized just for them.
Click here for more information on Bot Asset Exchange and be sure to follow Anamita on Twitter.
",,Person,coal black,person,person,female,woman
https://ibm.co/2piRDl0,187446750783_10155874141240784,https://www.facebook.com/ibmwatson/posts/10155874141240784,"Meet the self-driving, 3D-printed bus that uses Watson #AI technology to assist people with disabilities. ",Link,,,9/12/18 10:39, ,7471,7471,0,10485,10485,0,145,73,91,3,3,8525,6214,0,0,115,0,0,0,0,0,0,0,0,0,0,19,77.0,1.0,21,78.0,1.0,36,41.0,,,44,47.0,,,3,,,3,,,Local Motors and IBM are equipping an autonomous electric shuttle bus with technology that assists people with a range of disabilities.,https://cdn.technologyreview.com/i/images/copy-of-olli-at-phoenix-lm-2.jpg?cx=0&cy=458&cw=3000&ch=1687&sw1200,https://www.technologyreview.com/s/604116/a-self-driving-bus-that-can-speak-sign-language/,disgust,0.163349,negative,-0.636199,"self-driving, 3D","Hashtag, Person",self-driving,Hashtag,sadness,0.092443,negative,-0.625597,"Local Motors, autonomous electric shuttle bus",Company,Local Motors,Company,sadness,0.461357,negative,-0.297226,city buses,"Person, Person, Company, Company, Company, HealthCondition, Person","It’s been 15 years since a degenerative eye disease forced Erich Manser to stop driving. Today, he commutes to his job as an accessibility consultant via commuter trains and city buses, but he has trouble locating empty seats sometimes and must ask strangers for guidance. 
A step toward solving Manser’s predicament could arrive as soon as next year. Manser’s employer, IBM, and an independent carmaker called Local Motors are developing a self-driving, electric shuttle bus that combines artificial intelligence, augmented reality, and smartphone apps to serve people with vision, hearing, physical, and cognitive disabilities. The buses, dubbed “Olli,” are designed to transport people around neighborhoods at speeds below 35 miles per hour and will be sold to cities, counties, airports, companies, and universities. If the buses enter production in summer 2018, as planned, they could be among the earliest self-driving vehicles on U.S. roads. 
Since Olli is fully autonomous and does not have a human driver, it uses IBM’s AI-powered Watson technology to converse with passengers (via voice and text displayed on an iPad). Olli navigates using radar, lidar, and optical cameras from a company called Meridian Autonomous. Before deploying in a neighborhood, Meridian Autonomous constructs 3-D maps of the area that Local Motors says are accurate to the half-inch. A human fleet manager then determines the bus route. When Olli detects an emergency via its various sensors, it will stop, notify a (human) remote supervisor, and independently run through a checklist of possible problems. “If a passenger has a medical problem or [there’s a safety issue], Olli will call the authorities or drive itself to a hospital or police station,” says Gina O’Connell, a Local Motors general manager who is leading the project. 
Local Motors and IBM started collaborating on Olli in early 2016 and produced a first iteration of the bus in June 2016. That vehicle is currently in trials in Germany and Switzerland. It is the next—second—generation of Olli that will include assistive technologies. That version, which the companies call “Accessible Olli,” will be manufactured starting in 2018, and will retain Watson as a tool for communicating with passengers and add additional Watson features. 
Local Motors and IBM are still testing technologies, but have already identified some capabilities they are likely to add. Future Ollis, for example, might direct visually impaired passengers to empty seats using machine vision to identify open spots, and audio cues and a mobile app to direct the passenger. Olli could also guide passengers via a special type of haptic feedback that uses ultrasound to project sensations through the air. An array of haptic sensors could be designed into every seat, and when people walk down the aisle they would feel a vibration on their hand or arm to alert them that they were at an empty seat, explains Drew LaHart, the program director for IBM’s accessibility division.  
For deaf people, the buses could employ machine vision and augmented reality to read and speak sign language via onboard screens or passengers’ smartphones. LaHart says that Olli could be trained to recognize sign language using machine learning and Watson’s image recognition capabilities. If the bus were equipped with AR technology, it might be able to respond via a hologram of a person signing. 
Machine vision could also enable Olli to recognize passengers waiting at bus stops who have walkers and wheelchairs. The bus would then activate an automated ramp to help them board and then deploy equipment that would secure their assistive devices, locking a wheelchair into place, for example. 
Another potential Olli technology combines machine vision and sensors to detect when passengers leave items under their seats and issues alerts so the possessions can be retrieved, a feature meant to benefit people with age-related dementia and other cognitive disabilities. 
This would all be a significant improvement over the typical bus accommodations of today, which are limited to wheelchair ramps and lifts and audible and visual bus route updates. Local Motors, IBM, and the CTA Foundation, the charitable arm of the Consumer Technology Association, a trade group for the consumer electronics industry, and a partner in Accessible Olli, have spent the past three months soliciting ideas from disability rights organizations and retirement communities, among others. Manser, who works for IBM Accessibility, has organized a workshop with blindness organizations and public transit agencies and attended an MIT assistive technologies hackathon in March to explain the challenges he encounters on public transportation. 
Local Motors plans to keep soliciting public input for several more months. In July, it will devise an engineering plan for the new version of Olli, select suppliers, and calculate the cost of fabricating the bus. It aims to sell the vehicle for about $250,000 and will also offer a leasing-subscription service that would cost $10,000 to $12,000 a month and include hardware upgrades. Because Olli is mostly manufactured on-demand, through 3-D printing, its design can be tweaked quickly in response to user feedback, says O’Connell. 
The company expects public transportation operators will be its main customers and hopes that cities will buy the buses to fill in gaps in their regular transit systems and not just as paratransit vehicles for disabled people. 
For those with disabilities, though, Olli could be a big improvement over the current options.  Door-to-door paratransit service tends to be slow, has to be scheduled ahead of time, and is only available to people who qualify for it, says Henry Claypool, who is the policy director of the Community Living Policy Center at the University of California, San Francisco, and a wheelchair user. “It’s much more reliable to be able to get on and off a bus at the same place and have a predictable schedule, especially if the bus has this type of assistive technology,” he says. 
Olli offers a way to address important limitations of public bus and train systems as well, says Susan Henderson, the executive director of the Disability Rights Education and Defense Fund. The Americans with Disabilities Act mandates only that “key” train and subway stations be accessible, which means that people with wheelchairs, walkers, and scooters often have to travel several stops out of their way to get home or to a destination, says Henderson. “If I still had 10 blocks to go after getting off at my local station, having an Olli rolling around my neighborhood would make a big difference,” she says. 
",city buses,Person,steel blue,shuttle bus, , , 
https://ibm.co/2ATiL3L,187446750783_10155870399585784,https://www.facebook.com/ibmwatson/posts/10155870399585784,"&quot;If a person is talking to you and you smile, they will register this subconsciously, and there’s a good chance that they will smile back without even thinking about it. These subtle reactions are a big part of how we connect with people on an emotional level...but how can you make a similar emotional connection with a chatbot?&quot;

Here's how one technology company is giving AI a human face: ",Link,,,9/10/18 19:43, ,9231,9231,0,12533,12533,0,176,122,147,3,3,10379,7595,0,0,141,0,0,0,0,0,0,0,0,0,0,19,68.0,1.0,22,70.0,1.0,86,48.0,,,96,51.0,,,1,2.0,,1,2.0,,"Soul Machines creates sophisticated “artificial humans” that use biology-inspired models of the human brain to speak, move and express themselves.",,https://www.ibm.com/blogs/cloud-computing/2018/08/02/soul-machines-ai-watson/,joy,0.734033,positive,0.960738,"emotional level, subtle reactions, technology company",,emotional level,,joy,0.815918,positive,0.959246,"Soul Machines, artificial humans",,Soul Machines,,joy,0.622886,positive,0.811283,IBM Watson Assistant,"Company, Person, Person, Quantity","Share this post:
From talking watches to AI-powered financial advisors, a world where people routinely speak to machines is shifting from science fiction to everyday reality.
Artificial intelligence (AI) is no longer in the realm of academic research. It is becoming extremely useful for enterprises, especially in business functions such as AI customer service. Chatbots are the obvious example. By building an AI-powered chatbot that can respond intelligently to most day-to-day customer service requests, organizations can free up human staff to focus on more complex problems.
But that doesn’t mean it always feels natural. While talking to chatbots can be great to get information or make transactions quickly, a text prompt can’t convey all the subtle nuances of a face-to-face interaction.
If a person is talking to you and you smile, they will register this subconsciously, and there’s a good chance that they will smile back without even thinking about it. These subtle reactions are a big part of how we connect with people on an emotional level, which is valuable in building customer relationships. But how can you make a similar emotional connection with a chatbot?
At Soul Machines, we solve this exact problem by giving AI a human face, literally. We create sophisticated “artificial humans” that use biology-inspired models of the human brain to speak, move and express themselves just like real people.
To take a simple example, when a customer is talking to one of our artificial humans and smiles into their webcam, our solution registers the image of a happy face and generates the virtual equivalent of dopamine and serotonin in the artificial human’s brain. This causes the artificial human to reciprocate the emotion and smile back at the customer. We adapt tone of voice in a similar way, enabling our artificial humans to communicate in a way that harmonizes with the customer’s mood.
We provide the user-friendly interface that helps AI-powered representatives interact in a realistic, emotionally intelligent way, delivering answers in a manner that makes the customer feel comfortable. But that’s only half the story. To make sure answers are correct and helpful, we also need to give our artificial humans the ability to learn from our clients’ domain-specific data.
IBM Watson Assistant does just that. The enterprise-level AI assistant can be trained to answer customer queries for any business while continuously learning and improving its performance.
Many of our clients were already working with IBM Watson to handle customer queries through text-based chatbot interfaces. In each case, we were able to integrate our artificial human with the existing IBM solution to create a new user experience layer. For a company that already has Watson Assistant set up, it only takes eight to 12 weeks to add a Soul Machines artificial human to their solution.
The integration between our platform and IBM Watson Assistant is relatively straightforward to set up. The Watson solution runs in the IBM Cloud—so there’s no infrastructure for us to manage—and provides a simple API that we can call from our application. We send audio of the customer’s voice via this API, and Watson converts it into text, then searches a corpus of knowledge for relevant answers to the customer’s question, ranks the results and returns the top-ranked answer to us.
Meanwhile, our platform is analyzing the audiovisual input for emotional cues from the customer’s tone of voice and their facial micro-expressions. It then converts the answer into modulated, emotionally inflected speech for the artificial human to deliver, matched with appropriately generated facial expressions.
All the evidence suggests that customers enjoy interacting with our artificial humans, and one of our banking clients has found that it can already satisfy 40 percent of their customer queries without any kind of human intervention. We expect that number to climb even higher as the solution continues to learn.
Our experience working with IBM has been great and has boosted our reach as a business. The scale of the IBM Global Services team means they have deep relationships with clients around the world that we can easily build upon.
From a technical perspective, I would recommend IBM Watson Assistant to our customers. We have had success working with Watson, and we’ve now introduced it to several of our newer clients.
As digital transformation gets underway across businesses in every industry, getting the most out of AI solutions will become more and more important. Unlike traditional applications, AI-powered solutions continue to learn and improve over time, so the companies that get AI to market first will have a significant advantage. Their competitors will find it difficult to catch up. We’re proud to be working with IBM to help our clients gain that competitive edge.
",IBM Watson Assistant,Company, , , , , 
https://ibm.co/2ISlEWe,187446750783_10155868042320784,https://www.facebook.com/ibmwatson/posts/10155868042320784,Watch IBM CEO Ginni Rometty address questions revolving around AI technology via CNBC: ,Link,,,9/9/18 20:28, ,15462,15462,0,21937,21937,0,693,497,585,15,15,16862,11914,0,0,564,0,0,0,0,0,0,0,0,0,0,40,242.0,8.0,43,243.0,9.0,216,319.0,,,249,336.0,,,7,8.0,,7,8.0,,"Ginni Rometty, IBM chairman and CEO, talks about privacy concerns, social justice and artificial intelligence from the VivaTech Conference in France.",https://image.cnbcfm.com/api/v1/image/105228833-5ED2-SB-052418-IBMceo.jpg?v=1529478307,https://www.cnbc.com/video/2018/05/24/ibm-ceo-we-have-to-have-trust-in-technology.html,joy,0.095594,neutral,0,Watch IBM CEO Ginni Rometty address questions,"Person, Company",Watch IBM CEO Ginni Rometty address questions,Person,sadness,0.131402,neutral,0,"Ginni Rometty, privacy concerns, social justice, artificial intelligence, IBM chairman","Person, Company",Ginni Rometty,Person,sadness,0.461302,negative,-0.696181,"Global Business, Financial News, real-time snapshot, Data",Quantity,"Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.
",Global Business,Quantity,alizarine red,champion,person,contestant,champion
https://ibm.co/2n48NDc,187446750783_10155865556465784,https://www.facebook.com/ibmwatson/posts/10155865556465784,"By infusing Watson technology into their Star Trek: Bridge Crew game, Ubisoft lets players seamlessly complete missions online, with both AI characters and human partners while staying fully engaged. ",Link,,,9/8/18 19:41, ,7726,7726,0,11214,11214,0,76,41,48,1,1,10174,7006,0,0,67,0,0,0,0,0,0,0,0,0,0,6,40.0,3.0,8,42.0,4.0,18,25.0,,,21,27.0,,,,1.0,,,1.0,,"That’s where Ubisoft’s VR game, Star Trek: Bridge Crew, is headed with the help of IBM Watson.",https://cdn.vox-cdn.com/thumbor/fIXUmNYcXN7tehfzAS6Sy0bXUXc=/0x0:3063x1604/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/9722689/IBM_150_Extra_Engineers_1951.jpg,https://www.recode.net/ad/16681044/speech-recognition-technology-ibm-watson-star-trek,joy,0.526683,positive,0.629147,"Star Trek, Watson technology, Bridge Crew game","Person, Company, Person",Star Trek,Person,joy,0.211236,neutral,0,"Star Trek, Ubisoft’s VR game",Company,Star Trek,Company,sadness,0.566006,positive,0.847809,thrill of an immersive game,"Quantity, Person, Person","For the last 60 years, researchers have continued their mission to create a computer that understands naturally spoken language. Because the thrill of an immersive game is the immersion itself, having to break away and revert to manual navigation takes away from the experience.
But thanks to voice control, the experience is seamless. That’s what Watson Speech to Text and Conversation services bring to the table. By infusing AI technology into the game, players can seamlessly complete missions online, with both AI characters and human partners while staying fully engaged. You can also experiment with voice-controlled objects and begin to develop your own game, as well as test out the same software the game uses in the IBM VR Speech Sandbox. Here is how Ubisoft’s VR game, Star Trek: Bridge Crew, is enhanced with Watson tool. 
",thrill of an immersive game,Quantity,reddish brown,ensemble of people,dress,outfit,ensemble of people
,187446750783_295220431260230,https://www.facebook.com/ibmwatson/videos/295220431260230/,"Today, we live in a world filled with smart technology. But it’s only really smart when it’s put to work at scale, from agriculture and conservation to healthcare, security and global trade. Let’s put smart to work. ibm.com/smart",Video,,,9/7/18 9:42, ,8607,8607,0,12120,12120,0,451,393,578,3,3,9446,6917,0,0,342,547,616,0,0,4010,5202,0,0,4465,30393,30,72.0,2.0,37,86.0,2.0,305,7.0,,173.0,388,7.0,,183.0,2,1.0,,2,1.0,,,,,joy,0.381686,positive,0.887076,"smart technology, global trade, Today",,smart technology,, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2LqEoIF,187446750783_10155860845045784,https://www.facebook.com/ibmwatson/posts/10155860845045784,5 reasons why people are turning to specialized online nanodegree programs to help them transition to AI careers: ,Link,,,9/6/18 16:14, ,7469,7469,0,10648,10648,0,132,101,123,3,3,9260,6655,0,0,113,0,0,0,0,0,0,0,0,0,0,13,37.0,,16,39.0,,22,86.0,,,34,89.0,,,2,1.0,,2,1.0,,Nanodegrees launched by Udacity cover many technology areas such as AI or data science and are taught by active industry thought leaders.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/08/blog_Nanodegrees_png_socialTile_072618.png,https://www.ibm.com/blogs/watson/2018/08/preparing-for-ai-jobs-why-nanodegrees-are-the-future-of-education/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Preparing+For+AI+Jobs+Nanodegrees+Aug+2018&cm_mmca1=000000OF&cm_mmca2=10000408,sadness,0.307937,neutral,0,"online nanodegree programs, reasons, people",Company,online nanodegree programs,Company,joy,0.261953,neutral,0,"data science, Udacity cover, technology areas","Company, Company",data science,Company,joy,0.610259,positive,0.710882,,"Person, Company, Quantity, Quantity","Large enterprises, startups and high-performance businesses across industries are increasingly turning to Artificial Intelligence and advanced analytics to make faster, more effective, data-driven decisions. The volume of unstructured and structured data stored by enterprises is growing at an accelerating rate.
The demand for skilled data scientists and candidates with AI skills is at an all-time high. Yet developing those skills typically requires significant investments of time, energy and money. Businesses are struggling to successfully deploy and manage AI projects due to lack of resources. And employees interested in preparing for these highly-coveted jobs incur significant debt, and delay other strategic business initiatives until they completed a traditional degree after business hours.
While traditional post-secondary programs in this field still have value, many working professionals are turning to online programs for a quicker, less expensive way to get started.
In 2017, IBM predicted that by 2020, demand for these skills would grow by 28% (364,000 jobs) to over 2.7 million job listings. We’ve revised that prediction, as we see growth in this space closer to 45%. A Harvard Business Review article proclaimed there is a growing war being waged for people with skills for the “sexiest job” of the 21st century, the data scientist.
More businesses than ever before are looking to fill a suite of new roles in an AI-driven world:
There are other pressing questions, too. How can existing IT professionals build specific skills for AI platforms, while they stay at their existing jobs? How can AI neophytes build the necessary skills and understanding to enter this lucrative profession, without putting their career on hold while they retrain? Nanodegrees seem to be the perfect solution.
Here are five reasons why an increasing number of people are opting for these specialized online programs to help them transition to AI careers:
1. Nanodegrees offer hands-on experience with real-world value
Traditional classroom training is theory-based, delivered seminar-style by a career professor, from presentation slides and textbooks. By contrast, a nanodegree program uses real data science projects and machine learning models, such as:
Working through the full-lifecycle of AI projects, from planning and design to execution and results, analysis helps fledgling data scientists and researchers to hone their skills, and gain a better understanding of the strategic role AI and analytics can play in solving business challenges.
Working with real tools on realistic projects helps provide aspiring data scientists and AI developers to obtain deeper understanding into how AI platforms like Watson process data and extract insights from it. Many well-known have contributed expertise and datasets to these nanodegree programs, making the curriculum much more engaging than it would be with “dummy” data.
2. Learn from top minds in AI and data science
Nanodegrees launched by Udacity cover many technology areas such as AI or data science and are taught by active industry thought leaders. The opportunity to be coached by an accomplished data scientist like IBM’s Adam Massachi, Airbnb’s Belinda Bennett or Slack’s Stephen Morton is rare, powerful and highly sought-after. These “experts in residence in data science” answer live questions, and provide not only technical advice but also career coaching and mentorship.
Nanodegrees offered in a MOOC (Massive Open Online Course) services model empower students with the opportunity to learn from industry thought leaders, at a fraction of the cost of full degree programs. Those with a foundation of technical understanding can augment their skills at their own pace.
3. Open up new opportunities and level-up existing roles
Career paths in the digital era aren’t nearly as linear as they were even a few decades ago. A university degree would often all but guarantee a student a sustainable career for many years. Today, graduates still find it difficult to get their first job, or end up freelancing or working part-time until they get established in their field.
Those who earn nanodegrees for in-demand areas of new technology like AI, data science, advanced data analytics or related fields can augment their post-secondary education. For developers, IT architects, and data management professionals already with years of experience, these courses can build skills, which help them qualify for higher salaries with their existing employer or within their chosen industries including:
4. The age of digital transformation 
Many businesses have changed or streamlined many of their business processes by adopting forms of AI, such as virtual customer service chatbots in contact centers, and improving their marketing campaigns, and manage risk through AI.
As customers evolve to be more comfortable with bots and get help from virtual shopping assistants, the demand for skills to design, build and test these systems is increasing exponentially. Many companies that are digitally enhancing their processes are investing in nanodegrees for employees whose careers are impacted by AI. Others like Bertelsmann are providing scholarships to students to build AI skills that will support their digital transformation journey.
5. Convenient, self-paced education at the pace of innovation 
Many courses that are designed to help people who are in transitionary periods in their career may start out as practical and current, yet by the time a student graduates a few years later, the curriculum is behind the times. Nanodegrees typically last between six months and a year, and since they are delivered electronically with live experts, the curricula can be updated as new industry innovations occur.
For students that work full-time and have other responsibilities, nanodegree programs are focused, and designed to enhance the skills which solve real-world challenges companies are experiencing today. Consultants can progress through course segments on their own time and apply their learnings immediately. Mentors share their expertise in subject matter like natural language understanding, in digestible workshops. Students in post-secondary programs like mathematics, statistics and computer science can augment their existing education with nanodegrees in data science and AI.
Are you looking for ways to improve your understanding of data science, or get guidance in preparing for jobs in the AI economy?
Check out the “Become a Data Scientist” nanodegree program, and discover how you can succeed in an AI-driven world. Learn at your own pace, for a budget-friendly subscription cost, and gain access to “office hours” career mentoring from the best in the business. You can build effective machine learning models, run data pipelines, build recommendation systems, and deploy solutions to the cloud with industry-aligned projects.
",,Person,coal black,neon lamp,lamp,neon lamp,-
http://ibm.biz/AgroPad,187446750783_324217814980921,https://www.facebook.com/ibmwatson/videos/324217814980921/,"No farms, no food: AI-powered technology will help farmers health-check soil and water. Learn more: ",Video,,,9/5/18 10:24, ,9995,9995,0,13694,13694,0,278,225,327,2,2,9414,6971,0,0,129,92,97,0,0,2598,2699,0,0,6629,105427,23,70.0,4.0,25,74.0,4.0,125,9.0,,132.0,164,9.0,,154.0,1,1.0,,1,1.0,,AgroPad: AI-powered technology will help farmers health-check soil and water,https://www.ibm.com/blogs/research/wp-content/uploads/2018/08/2018-08-13-Agropad-58.small_.jpg,https://www.ibm.com/blogs/research/2018/09/agropad/,joy,0.700735,positive,0.722884,"farmers health-check soil, farms",,farmers health-check soil,,joy,0.607686,positive,0.612292,farmers health-check soil,,farmers health-check soil,,joy,0.219716,positive,0.605619,laboratory tests,"Quantity, Person, Quantity, Quantity","Share this post:
Agriculture consumes more than 70 percent of the world’s annual water usage. With small farms producing nearly 80 percent of food for the developing world, ensuring the quality and safety of our water supply is critical. Environmental analysis for agriculture often relies on expensive and time-consuming laboratory tests performed far away from the farm. As a result, chemical analysis is quickly outdated and limited to small sample numbers.
My team set out to find a way to simplify the testing process and make it affordable for small farmers to monitor the health of their soil and water. Our prototype, the AgroPad, enables real-time, on-location, chemical analysis of a soil or water sample, using AI.
Video not working? View at the source.
So – how does it work?
A drop of water or soil sample is placed on the AgroPad, which is a paper device about the size of a business card. The microfluidics chip inside the card performs on-the-spot a chemical analysis of the sample, providing results in less than 10 seconds.
The set of circles on the back of the card provide colorimetric test results; the color of each circle represents the amount of a particular chemical in the sample. Using a smartphone, the farmer would then take a single snapshot of the AgroPad by using a dedicated mobile application and immediately receives a chemical test result.
AgroPad: “AI on the edge”
This “AI on the edge” computing approach uses machine learning and machine vision algorithms to translate the measured color composition and intensity into concentrations of chemicals in the sample, making it more reliable than tests based on human vision alone. Test data can be simultaneously streamed onto a cloud computing platform and labeled with a digital tag that uniquely identifies the time, location and results of the chemical analysis. The cloud platform allows management and integration of millions of individual tests performed at various times and locations. This is an important feature for monitoring, for example, the change in fertilizer concentration in a particular region throughout the year.
We currently have a five-parameter prototype solution for soil and water testing that measures pH, nitrogen dioxide, aluminum, magnesium and chlorine. We’re continually extending the library of chemical indicators available for deployment; each AgroPad could be personalized based on the needs of the individual user.
Since the paper-based tests can be reliably performed by non-experts, public data collection with instant digitization in chemical sensing becomes a real possibility. Along with low cost, mass production of the paper based device and large scale deployment through mobile and cloud technologies, the exploratory prototype could revolutionize digital agriculture and environmental testing.
",laboratory tests,Quantity,greenishness,person,microorganism,algae,-
https://ibm.co/2PCtylp,187446750783_10155855526465784,https://www.facebook.com/ibmwatson/posts/10155855526465784,How IBM Watson is partnering up with Apple to bring AI everywhere: ,Link,,,9/4/18 11:14, ,11512,11512,0,15723,15723,0,448,277,331,6,7,12619,9218,0,0,337,0,0,0,0,0,0,0,0,0,0,31,215.0,3.0,33,228.0,3.0,125,169.0,,,152,179.0,,,2,5.0,,2,4.0,,,,https://www.ibm.com/watson/stories/coreml/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-IBM+Watson+and+Apple+Core+ML+Stories+July+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.047915,neutral,0,IBM Watson,"Person, Company, Company",IBM Watson,Person, , , , , , , , ,sadness,0.189397,positive,0.516249,"Early exploration, Coca-Cola Company","Company, Company, Company, Company","Since 2014 Apple and IBM have been working with clients to usher in a new era of smart enterprise. The latest collaboration offers companies interested in artificial intelligence (AI) and machine learning (ML) a chance to be a part of the next big shift in enterprise mobile intelligence — by bringing the power of IBM’s Watson AI services and Apple’s machine learning framework, Core ML, to native iOS apps. IBM Watson Services for Core ML delivers native iOS apps that give developers access to vast amounts of data, both on their device and through the cloud. This means that users can access information and deep insights directly on their iPhone or iPad, even when it’s not connected to a network.
The Coca-Cola Company is always innovating across their technology landscape, and AI is a key focus area. When presented with the opportunity to explore the value of IBM Watson services and machine learning, they quickly engaged. With the Coca-Cola emphasis on quality, they are currently partnering with IBM, working on prototypes for how IBM Watson Services for Core ML may transform in-field capabilities. Initial functionalities being analyzed are visual recognition problem identification, cognitive diagnosis and augmented repair. Early exploration is promising, and Coca-Cola and IBM continue to determine next steps.
Field technicians are deployed to service and repair beverage dispensing machines at restaurants and venues around the world. Once on site, the tech must be able to diagnose and correct an enormous array of problems, relying ultimately on their personal expertise and experience. If the system is not one the technician is familiar with – an uncommon water filter, for example – then routine repairs can become frustrating and time-consuming. Adding to the challenges, many sites are in remote or rural locations with no data connectivity, meaning no access to support, and therefore limited ability to make repairs. In these cases, the tech would need to spend time searching through informational databases, product manuals, and might even need to call in or consult with a colleague or specialist – resulting in lost productivity and prolonged system downtime.
With the AI capabilities of IBM Watson and Core ML, relevant information is put directly into a tech's hands the moment she needs it, allowing her to resolve the issue quickly. Coca-Cola used Watson Services for Core ML to build an app that leverages visual recognition and augmented reality to identify equipment issues, diagnose problems, and troubleshoot repairs.
Through the app, the tech can use their iPhone or iPad camera to diagnose system problems via a virtual overlay and guided instructions pulled from the cloud, with zero latency, and even in areas with no network connectivity. Watson Visual Recognition on the device helps the technician identify older or poorly differentiated systems, or unfamiliar parts, and pinpoint the problem right away. Then, Watson Discovery Service helps identify possible solutions for the specific systems and type of malfunction.
Using ARKit, an iOS framework with resources to help create augmented reality experiences for the iPhone and iPad, developers are able to integrate apps with augmented reality models that help the technician solve complex problems on less-familiar systems.
As the technician is working on the job, data is captured. That data is then sent to the cloud once the device is back on the network, so Watson can learn from the interaction and make the learning available to other technicians in near real-time. Using the guided repair system, the technician is empowered to solve the problem the first time, increasing productivity, and elevating customer service – all without needing to call for assistance or reschedule the repair.
With Watson, the technician can identify the problem and determine a solution in less time, no matter their location. Watson Services for Core ML provides developers with the tools to build apps that can give technicians in the field the right data, knowledge, and capabilities to do their best work. Coca-Cola is piloting the app with its field technicians now.
",Early exploration,Company, , , , , 
https://ibm.co/2J2E99U,187446750783_10155851123990784,https://www.facebook.com/ibmwatson/posts/10155851123990784,"IBM is working to create 1,800 new jobs to build a stronger AI presence in France: ",Link,,,9/2/18 10:47, ,14337,14337,0,20445,20445,0,299,201,246,6,6,15214,10918,0,0,196,0,0,0,0,0,0,0,0,0,0,20,107.0,8.0,22,115.0,13.0,101,110.0,,,131,115.0,,,2,4.0,,2,4.0,,"IBM is also adding new training programs for its 'new collar' skills in AI, blockchain, cloud, and IoT.",https://tr3.cbsistatic.com/hub/i/r/2018/05/23/787708ef-be2b-4db6-a249-cbed2a7f830a/thumbnail/770x578/a7912c33feeeb174b1b7e801fbccb295/aijobs.jpg,https://www.techrepublic.com/article/ibm-to-add-1800-jobs-in-france-to-meet-growing-demand-for-ai/,joy,0.552262,positive,0.839672,"new jobs, IBM","Company, Person",new jobs,Company,joy,0.290664,neutral,0,"new training programs, new collar' skills, IBM",Company,new training programs,Company,joy,0.466737,positive,0.677622,IBM's initiative,"Company, Location, Person, Person, Person, Person"," 	IBM is working to bring 1,800 jobs to France over the next two years in effort to bolster talent in artificial intelligence, IoT, cloud, and blockchain, CEO Ginni Rometty said at the Tech for Good Summit in Paris Wednesday.
 	Also at the summit, the firm announced an expansion of its program for "" 	new collar"" skills training, IBM's initiative to train tech workers with specific high-level skills outside of a traditional four-year degree. The summit was hosted by French President Emmanuel Macron, a press release noted.
 	""President Macron is making a big bet, and a smart one, that AI is going to transform every job, every profession and every industry,"" Rometty said in the release. ""At IBM, we share this belief and see evidence of it every day with Watson driving exponential impact here in France and around the world. That is why we are bringing 1,800 new jobs to France to meet growing demand for AI from our clients.""
 	 	SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
 	Of the 1,800 jobs, IBM will hire business consultants, IT architects, developers, and technical experts the release said. Some 400 of the jobs will be certain AI roles that IBM announced back in March.
 	Utilizing local public and private partners, IBM will also use the hiring initiative to help create ""local competitiveness hubs"" to strengthen its presence in France. These are already underway in Lille and Strasbourg, the release said.
 	""IBM will continue to work with the government to make sure France has the skilled workforce necessary to take advantage of this unique era,"" Nicolas Sekkaki, general manager of IBM France, said in the release.
 	As part of the new collar training expansion, IBM will be creating roles in security, data science, AI, and more. These roles won't require a four-year degree, as noted, but employees will be prepared ""through vocational or on-the-job training,"" the release said.
 	According to the release, IBM is also working with the French government to support its P-TECH (Pathways to Technology Early College High School) education model, providing next-gen skills and job training for disadvantaged youth. More than 400 companies are now involved with P-TECH, the release said.
 	The launch of IBM France Academy was also announced at the summit in an effort to ""train IBM France employees, clients and partners to build modern skills for the AI-era,"" the release said.
 	The real impact of AI on jobs is yet to be seen. While the technology will undoubtedly eliminate some roles, some have predicted that it could  	create more jobs in place of those. Additionally, a 2018 Workplace Institute report noted that 82% of employees believe AI will improve their jobs in some way.
",IBM's initiative,Company,black,dance,person,dance,-
https://ibm.co/2kjaPxR,187446750783_10155849891720784,https://www.facebook.com/ibmwatson/posts/10155849891720784,"#AI is opening doors to limitless possibilities  – but how ready are we for them? 

Watch a panel of AI experts, including IBM Watson's Chief Architect Ruchir Puri, debate the future of this technology in a panel hosted by Neil deGrasse Tyson: ",Link,,,9/1/18 20:12, ,9499,9499,0,14001,14001,0,144,100,140,6,6,12629,8580,0,0,131,0,0,0,0,0,0,0,0,0,0,12,60.0,2.0,14,65.0,3.0,49,66.0,,,67,73.0,,,2,4.0,,2,4.0,,"Isaac Asimov’s famous Three Laws of Robotics might be seen as early safeguards for our reliance on artificial intelligence, but as Alexa guides our homes and...",https://i.ytimg.com/vi/gb4SshJ5WOY/maxresdefault.jpg,https://www.youtube.com/watch?v=gb4SshJ5WOY&feature=youtu.be,fear,0.229666,neutral,0,future of this technology,"Hashtag, Person",future of this technology,Hashtag,joy,0.325221,positive,0.642521,"Isaac Asimov, artificial intelligence, Laws of Robotics",Person,Isaac Asimov,Person,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
            

",YouTube,Company,coal black,aperture  (camera),controller,aperture  (camera),-
,187446750783_10155847527050784,https://www.facebook.com/ibmwatson/posts/10155847527050784,IBM Watson,Photo,,,8/31/18 17:51, ,2291,2291,0,2866,2866,0,180,141,186,3,3,2642,2138,0,0,168,0,0,0,0,0,0,0,0,0,0,,55.0,,8,55.0,,116,31.0,12.0,,141,33.0,12.0,,1,2.0,,1,2.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2PNBxgF,187446750783_10155844916235784,https://www.facebook.com/ibmwatson/posts/10155844916235784,How does a creative writing major put their skills to work in AI? See how one person is teaching a virtual assistant to provide customer service just like a human: ,Link,,,8/30/18 11:59, ,6077,6077,0,8291,8291,0,110,78,89,2,2,7488,5582,0,0,98,0,0,0,0,0,0,0,0,0,0,5,34.0,,6,35.0,,24,58.0,,,31,58.0,,,2,,,2,,,"During our Masterclass Episode 3, meet creative writer for conversational AI Maya Hausammann, who crafts responses for Autodesk’s Virtual Assistant, AVA.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/08/GettyImages-186823773_Autodesk.jpg,https://www.ibm.com/blogs/watson/2018/08/meet-the-faces-behind-conversational-ai/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Conversation-_-WW_WW-_-Meet+Faces+Behind+Conversational+AI+Aug+2018&cm_mmca1=000018SW&cm_mmca2=10000408,joy,0.260304,positive,0.841282,"creative writing, customer service, virtual assistant",Person,creative writing,Person,joy,0.550503,positive,0.859612,Masterclass Episode,Person,Masterclass Episode,Person,joy,0.608209,positive,0.805411,Maya Hausammann,"Person, Company, Person, Person, Person","Building an AI assistant is different from building an FAQ bot. AI assistants require interdisciplinary talent to properly build, scale and optimize. Teammates can include conversational engineers, computational linguists, UX designers and brand representatives.
So, who are the faces behind successful AI assistants? Meet one of them: creative writer for conversational AI Maya Hausammann, who crafts responses for Autodesk’s Virtual Assistant, AVA.
Maya has a BA in creative writing and literature from the University of Michigan. With a strong background in social and developmental psychology, she is particularly interested in how language influences and reflects human behavior and emotions.
As a creative writer for conversational AI, Maya’s job is to teach AVA how to communicate like a customer service employee through the assistant’s conversational flow. She works to ensure that the Autodesk brand is incorporated into the virtual agent’s “personality.”
Being responsible for an AI personality puts Maya at the forefront of one of today’s newest professions. Her daily work focuses on analyzing AVA’s conversation logs to identify miscommunications between the assistant and the customer. After a behavioral analysis of similar miscommunications, she formulates a response strategy to avoid future miscommunication, using her creative writing skills to ensure that each proposed response is aligned with AVA’s voice. In doing so, she looks for personality and linguistic patterns that can better represent human speech and improve recognition of what customers are trying to communicate.
A typical tool Maya uses to ensure her writing is data driven and research based is data classification: grouping responses and/or customer utterances that express similar intents. This helps her formulate responses that help the overall conversation flow better and more naturally.
As the official voice behind AVA, Maya pays special attention to ensuring that AVA is on brand, which means AVA needs to sound like Autodesk. Engaging in over 100,000 conversations per month, AVA has a huge impact on what customers first hear, see and experience with the brand. Maya’s job is to infuse AVA with the special attributes that make Autodesk Autodesk.
To do this, she needs to have a complete understanding of the traits that make up the Autodesk brand. How do you make a machine sound like it’s part of a company’s workforce? Your machine must have a personality with a distinct voice that isn’t exactly human but also not mechanical. That voice has to be on brand, consistent and emulate emotional intelligence—your machine may not be able to feel, but it must communicate a level of empathy and consideration for the customer it’s interacting with. For example, in order for AVA to be classified as “smart,” one of the Autodesk brand traits, she must be able to recognize what customers want and respond appropriately. If AVA knows that she won’t have the correct response, she should be able to connect customers with a human agent. To be read as “real,” or, as Maya adapted it, “authentic,” AVA has to convey her witty sense of humor, showing that she doesn’t take herself too seriously.
Although AVA has her own personality, which integrates the Autodesk brand attributes, it’s extremely important that she makes the customer aware that she’s an AI assistant, not a human. She does this at the start of each conversation.
Autodesk has partnered with Soul Machines, whose vision is to “humanize artificial intelligence to better humanity,” to design a voice and video beta version of AVA that responds in a more human-like fashion.
With this project, Maya identifies which types of emotions should be attached to specific AVA utterances, and how to emulate human reactions, making her background in psychology quite useful. Using emotional markup language developed by Soul Machines, Maya programs AVA with micro expressions, small facial movements associated with different emotions, and reactions to try to convey empathy.
Maya finds that the most interesting thing about being a creative writer for an AI solution is that any little change can shape an entire conversation.
There are many ways to get a desired result, allowing her to be truly creative with the way she designs conversations. She is also excited to see AVA expand into voice and video to meet Autodesk’s goal of creating the best possible customer experience.
In episode 3 of the Watson Masterclass, you can hear firsthand from the Autodesk Machine Assistance team. Hear the AVA business owner and strategist, creative writer for conversational AI, product manager, creative director, computational linguist and UX designer discuss how their team works to build and optimize AVA.
",Maya Hausammann,Person,blue,comb jelly,animal,invertebrate,comb jelly
https://ibm.co/2wvcANT,187446750783_10155842795265784,https://www.facebook.com/ibmwatson/posts/10155842795265784,"Imagine pointing your smartphone at an object, and having it tell you what the object is. Visual recognition is only one part of augmented reality – and it's transforming how companies work: ",Link,,,8/29/18 12:21, ,8771,8771,0,12603,12603,0,140,94,127,4,4,9562,6922,0,0,88,0,0,0,0,0,0,0,0,0,0,12,55.0,1.0,13,57.0,1.0,55,49.0,,,74,53.0,,,3,1.0,,3,1.0,,"Enterprises have long shown interest in mobile app use cases that combine Artificial Intelligence and Augmented Reality, but with very few tangible or practical implementations. Until now. Simultaneous recent changes to mobile device hardware, cloud technology and cognitive API’s mean that these types of cases can be realized at a fraction of the cost and effort that would have been required just a few years ago. Augmented reality is breaking out of consumer gaming and furniture placement apps to be at the forefront of use cases for transformational employee apps across industries. So, what can these apps do? The short answer is, whatever you can imagine. But typically the functions fall into five key areas: visual recognition, cognitive diagnosis, augmented assistance, cognitive assistance, and learning. Here’s how they break out: Visual Recognition. This enables you to point your device at something and the device tells you what it is, with a certain degree of confidence. For an…",https://www.ibm.com/blogs/think/wp-content/uploads/2018/07/500x500.png,https://www.ibm.com/blogs/think/2018/07/see-see-app/,joy,0.34514,positive,0.66759,Visual recognition,,Visual recognition,,sadness,0.466284,positive,0.599337,"mobile app use cases, Simultaneous recent changes",,mobile app use cases,,sadness,0.469427,positive,0.592693,mobile device hardware,"Company, Person, Company, Person, Company, Person","Share this post:
Enterprises have long shown interest in mobile app use cases that combine Artificial Intelligence and Augmented Reality, but with very few tangible or practical implementations. Until now.
Simultaneous recent changes to mobile device hardware, cloud technology and cognitive API’s mean that these types of cases can be realized at a fraction of the cost and effort that would have been required just a few years ago. Augmented reality is breaking out of consumer gaming and furniture placement apps to be at the forefront of use cases for transformational employee apps across industries.
So, what can these apps do? The short answer is, whatever you can imagine. But typically the functions fall into five key areas: visual recognition, cognitive diagnosis, augmented assistance, cognitive assistance, and learning. Here’s how they break out:
Visual Recognition. This enables you to point your device at something and the device tells you what it is, with a certain degree of confidence. For an engineer servicing machines that can have many thousands of components each with multiple versions, this is revolutionary. (This is a real use case for Coca-Cola engineers servicing vending machines.)
Cognitive Diagnosis. This is where the user and AI work together. For example, your device may tell you that a capacitor appears discoloured. You then tell the device that the unit is not powering on, and from this combined evidence the device suggests what the problem is, again with a degree of confidence.
Augmented Assistance. This is when your device doesn’t just tell you how to fix the problem, it shows you. It gives you instructions with augmented reality labels or highlighted components as you look through your screen at the failed circuit. And these stay in place even if you need to move around the item. And if you need both hands free, you can simply place the device next to you and view the instructions on a digital twin of your circuit.
Cognitive Assistant. This functionality allows you to just talk (or type) to converse and work through the issue, but in natural language and with natural responses.
Learn. This is critical for these types of apps. They essentially understand what just happened and use the images, actions and results to update their expert knowledge of this type of situation for future cases.
So, what’s changed? Devices for one thing. Today smartphones are equipped with two cameras on the back, one standard lens and one telephoto. This allows depth of field sensing so yes, your device can see in 3D. Cognitive technology has also advanced. Everything from speech processing to complex algorithms to visual recognition has evolved rapidly. Many services are now available via easy to consume API’s and the models are easier and faster to train, with less data.
In addition to these advances, augmented reality, like Apple’s ARKit have brought this technology out of its niche and into the realm of mainstream developers. (The next version in iOS 12 allows multiple users to view the same objects, so great for teams working through an issue)
With all of these advances, user expectations have changed. So many AI technologies have crept into our daily usage that they no longer seem alien in the workplace. Siri and Alexa have got us used to talking to our devices, Pokémon Go and other games have introduced us to AR, and we prefer the speed of a chatbot to waiting in a helpdesk queue.
IBM Watson with Apple’s Core ML
Until now there have been two options for mobile app artificial intelligence. Cloud based extensive models that require the device to be online, or more limited on-device capability (is there a hotdog in this picture). IBM and Apple have broken this restriction allowing complex Watson models to be built and then run natively on the device in offline mode, with learning updates taking place when reconnected. This has broken one of the final barriers to enterprise AI/AR.
In future articles I will explore some of the exciting and unexpected applications of these new use cases to some key industries and job roles.
",mobile device hardware,Company,greenish blue,bathing cap,headdress,cap,bathing cap
,187446750783_10155840434540784,https://www.facebook.com/ibmwatson/posts/10155840434540784,IBM Watson,SharedVideo,,,8/28/18 9:31, ,4626,4626,0,7508,7508,0,100,85,106,1,1,7125,4391,0,0,87,0,0,0,0,656,691,0,0,0,161513,,23.0,1.0,,23.0,2.0,83,6.0,,,100,6.0,,,,1.0,,,1.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2N4NY6e,187446750783_10155838347520784,https://www.facebook.com/ibmwatson/posts/10155838347520784,"This year, IBM helped send artificial intelligence to space aboard the International Space Station. Meet CIMON, the world's first AI-powered assistant designed to help astronauts on their mission: ",Link,,,8/27/18 9:37, ,11640,11640,0,23705,23705,0,220,143,194,3,3,17926,9025,0,0,149,0,0,0,0,0,0,0,0,0,0,25,93.0,8.0,27,93.0,9.0,74,87.0,,,98,96.0,,,,3.0,,,3.0,,"Die Weltraumforschung hat schon immer zu Pioniertaten inspiriert. Jetzt ist IBM erneut Teil eines Pionierprojekts, das von DLR und Airbus in Auftrag gegeben wurde und dabei half, einen intelligenten, autonomen, mobilen und interaktiven Begleiter zu schaffen. Mit dem Ziel, ihn zu einem von der Crew anerkannten und geschÃ¤tzten Besatzungsmitglied an Bord der ISS zu machen.",https://www.ibm.com/thought-leadership/smart/de-de/ai-in-space/img/cimon_social.jpg,https://www.ibm.com/thought-leadership/smart/de-de/ai-in-space/?social_post=1626044432&linkId=53618899,joy,0.38053,neutral,0,"Meet CIMON, artificial intelligence, International Space Station","Person, Company, Facility",Meet CIMON,Person,anger,0.219092,negative,-0.789689,DLR und Airbus,"Person, Company, Person, Organization, Organization",DLR und Airbus,Person,sadness,0.59525,negative,-0.768815,,"Person, Person, Company, Person, Person, Person, Person, Person, Person","Die Weltraumforschung hat schon immer zu „Firsts“ inspiriert. Im Aufrag des Raumfahrtmanagements des DLR und Airbus haben wir dazu beigetragen, den Crew Interactive Mobile CompaniON (CIMON®)* zu entwickeln.  Unser Ziel: ihn mit Hilfe der künstlichen Intelligenz Watson zum anerkannten und geschätzten Crew-Mitglied der ISS  zu machen.
Am Anfang war er eine Kugel aus Kunststoff. Zu Beginn war nicht viel an ihm dran — nicht einmal ein Name. Also nannten ihn die Ingenieure im Team einfach „Spaceball“.
Bevor er die Weltraumreise des Astronauten-Assistenten auf den Weg brachte, war Matthias Biniok damit beschäftigt, die Watson—Technologie auf dem Erdboden auf Herz und Nieren zu prüfen. 
CIMON® hatte eine kleine Identitätskrise, bevor die Psychologiestudentin Sophie Richter—Mendau hinzukam. 
Nina Fischer, eine begnadete Programmiererin, hatte in ihrer Karriere bereits einige faszinierende technologische Herausforderungen erlebt. 
Diese vier verschiedenen APIs kommen zum Einsatz: Watson Assistant, Visual Recognition, Text to Speech und Speech to Text 
© IBM Corporation 2018
IBM, das IBM Logo, ibm.com und Watson sind Marken der IBM Corporation, die in vielen Ländern weltweit registriert sind. Eine aktuelle Liste der IBM Marken finden Sie im Internet in den „Copyright- und Markeninformationen“ unter www.ibm.com/legal/copytrade.shtml.
*CIMON®, eine in Deutschland eingetragene Marke des Deutschen Zentrums für Luft- und Raumfahrt e. V. (DLR), steht für Crew Interactive MObile CompanioN und ist ein vom DLR-Raumfahrtmanagement gefördertes wissenschaftliches Projekt, finanziert mit Mitteln des Bundesministeriums für Wirtschaft und Energie (BMWi). Andere Produkt- und Servicenamen können Marken der IBM Corporation oder anderer Unternehmen sein.
",,Person,coal black,person,machine,motor,engine
https://ibm.co/2LqEoIF,187446750783_10155836235920784,https://www.facebook.com/ibmwatson/posts/10155836235920784,The demand for skilled data scientists and candidates with AI skills is at an all-time high. Here are five reasons why an increasing number of people are opting for specialized online programs to help them transition to AI careers: ,Link,,,8/26/18 9:42, ,11146,11146,0,22143,22143,0,181,126,153,5,5,17256,9241,0,0,131,0,0,0,0,0,0,0,0,0,0,20,59.0,,22,62.0,,43,87.0,,,56,97.0,,,1,4.0,,1,4.0,,Nanodegrees launched by Udacity cover many technology areas such as AI or data science and are taught by active industry thought leaders.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/08/blog_Nanodegrees_png_socialTile_072618.png,https://www.ibm.com/blogs/watson/2018/08/preparing-for-ai-jobs-why-nanodegrees-are-the-future-of-education/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Preparing+For+AI+Jobs+Nanodegrees+Aug+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.307367,positive,0.830063,"increasing number of people, skilled data scientists, time high, reasons",Person,increasing number of people,Person,joy,0.261953,neutral,0,"data science, Udacity cover, technology areas","Company, Company",data science,Company,joy,0.610259,positive,0.710882,,"Person, Company, Quantity, Quantity","Large enterprises, startups and high-performance businesses across industries are increasingly turning to Artificial Intelligence and advanced analytics to make faster, more effective, data-driven decisions. The volume of unstructured and structured data stored by enterprises is growing at an accelerating rate.
The demand for skilled data scientists and candidates with AI skills is at an all-time high. Yet developing those skills typically requires significant investments of time, energy and money. Businesses are struggling to successfully deploy and manage AI projects due to lack of resources. And employees interested in preparing for these highly-coveted jobs incur significant debt, and delay other strategic business initiatives until they completed a traditional degree after business hours.
While traditional post-secondary programs in this field still have value, many working professionals are turning to online programs for a quicker, less expensive way to get started.
In 2017, IBM predicted that by 2020, demand for these skills would grow by 28% (364,000 jobs) to over 2.7 million job listings. We’ve revised that prediction, as we see growth in this space closer to 45%. A Harvard Business Review article proclaimed there is a growing war being waged for people with skills for the “sexiest job” of the 21st century, the data scientist.
More businesses than ever before are looking to fill a suite of new roles in an AI-driven world:
There are other pressing questions, too. How can existing IT professionals build specific skills for AI platforms, while they stay at their existing jobs? How can AI neophytes build the necessary skills and understanding to enter this lucrative profession, without putting their career on hold while they retrain? Nanodegrees seem to be the perfect solution.
Here are five reasons why an increasing number of people are opting for these specialized online programs to help them transition to AI careers:
1. Nanodegrees offer hands-on experience with real-world value
Traditional classroom training is theory-based, delivered seminar-style by a career professor, from presentation slides and textbooks. By contrast, a nanodegree program uses real data science projects and machine learning models, such as:
Working through the full-lifecycle of AI projects, from planning and design to execution and results, analysis helps fledgling data scientists and researchers to hone their skills, and gain a better understanding of the strategic role AI and analytics can play in solving business challenges.
Working with real tools on realistic projects helps provide aspiring data scientists and AI developers to obtain deeper understanding into how AI platforms like Watson process data and extract insights from it. Many well-known have contributed expertise and datasets to these nanodegree programs, making the curriculum much more engaging than it would be with “dummy” data.
2. Learn from top minds in AI and data science
Nanodegrees launched by Udacity cover many technology areas such as AI or data science and are taught by active industry thought leaders. The opportunity to be coached by an accomplished data scientist like IBM’s Adam Massachi, Airbnb’s Belinda Bennett or Slack’s Stephen Morton is rare, powerful and highly sought-after. These “experts in residence in data science” answer live questions, and provide not only technical advice but also career coaching and mentorship.
Nanodegrees offered in a MOOC (Massive Open Online Course) services model empower students with the opportunity to learn from industry thought leaders, at a fraction of the cost of full degree programs. Those with a foundation of technical understanding can augment their skills at their own pace.
3. Open up new opportunities and level-up existing roles
Career paths in the digital era aren’t nearly as linear as they were even a few decades ago. A university degree would often all but guarantee a student a sustainable career for many years. Today, graduates still find it difficult to get their first job, or end up freelancing or working part-time until they get established in their field.
Those who earn nanodegrees for in-demand areas of new technology like AI, data science, advanced data analytics or related fields can augment their post-secondary education. For developers, IT architects, and data management professionals already with years of experience, these courses can build skills, which help them qualify for higher salaries with their existing employer or within their chosen industries including:
4. The age of digital transformation 
Many businesses have changed or streamlined many of their business processes by adopting forms of AI, such as virtual customer service chatbots in contact centers, and improving their marketing campaigns, and manage risk through AI.
As customers evolve to be more comfortable with bots and get help from virtual shopping assistants, the demand for skills to design, build and test these systems is increasing exponentially. Many companies that are digitally enhancing their processes are investing in nanodegrees for employees whose careers are impacted by AI. Others like Bertelsmann are providing scholarships to students to build AI skills that will support their digital transformation journey.
5. Convenient, self-paced education at the pace of innovation 
Many courses that are designed to help people who are in transitionary periods in their career may start out as practical and current, yet by the time a student graduates a few years later, the curriculum is behind the times. Nanodegrees typically last between six months and a year, and since they are delivered electronically with live experts, the curricula can be updated as new industry innovations occur.
For students that work full-time and have other responsibilities, nanodegree programs are focused, and designed to enhance the skills which solve real-world challenges companies are experiencing today. Consultants can progress through course segments on their own time and apply their learnings immediately. Mentors share their expertise in subject matter like natural language understanding, in digestible workshops. Students in post-secondary programs like mathematics, statistics and computer science can augment their existing education with nanodegrees in data science and AI.
Are you looking for ways to improve your understanding of data science, or get guidance in preparing for jobs in the AI economy?
Check out the “Become a Data Scientist” nanodegree program, and discover how you can succeed in an AI-driven world. Learn at your own pace, for a budget-friendly subscription cost, and gain access to “office hours” career mentoring from the best in the business. You can build effective machine learning models, run data pipelines, build recommendation systems, and deploy solutions to the cloud with industry-aligned projects.
",,Person,coal black,neon lamp,lamp,neon lamp,-
https://ibm.co/2uPgx2w,187446750783_10155834270795784,https://www.facebook.com/ibmwatson/posts/10155834270795784,AI is everywhere. Find the places where Watson is being put to work to solve real-world problems: ,Link,,,8/25/18 10:52, ,8351,8351,0,16177,16177,0,151,99,115,5,5,14823,7535,0,0,135,0,0,0,0,0,0,0,0,0,0,12,59.0,,12,59.0,,30,73.0,,,35,80.0,,,2,3.0,,2,3.0,,Stories about how Watson and AI are changing business.,,https://www.ibm.com/watson/ai-stories/index.html,joy,0.361086,negative,-0.760616,"real-world problems, places","Person, Person",real-world problems,Person,joy,0.225965,neutral,0,"Stories, Watson, AI","Person, Person",Stories,Person,joy,0.632922,positive,0.870709,,"Person, Person","               IBM Watson Stories
                                                                                                                                                                                                                                        United States
           
         
                    IBM®
                        Site map
           
                                                        Search                                                                                                                     
                        
         
       
                                        Watson
                                                          About
                 Products
                                    Use Cases                                        AI for customer service
                     AI for financial services
                     AI for enterprise search
                     AI for contract governance
                   
                 
                 Stories
                                    Learn                                         Build a chatbot
                     Natural language processing
                     Explainable AI
                     Developers
                     Dev tools
                     Data privacy 
                   
                 
                 With Watson
                 Get Started Free Get Started Free
               
             
           
                                                                                                                                                                   
                                                                        This is a world
 with Watson
                   
                                      
                 
               
               
                                
               
                                         
                                                                        This is a world
 with Watson
                   
                                      
                 
               
                                                                             Watson AI is changing how business gets done.
                 
               
                                Professionals are working with Watson to make better-informed decisions, augment their teams' creativity, and produce their best work.

 How can Watson help you?
               
                                                                              
                                                Humana, a leading health insurance provider, reduced costly pre-service calls and improved the provider experience with conversational AI.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, ESPN Fantasy Football managers can combine their football savvy with AI-powered insights and player sentiment analysis to beat the competition.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Automotive giant General Motors is unifying its audit, risk, and control activities with IBM OpenPages — providing holistic insight to help make smarter decisions.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, the US Open is creating the future of the fan experience – for today's game.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Creval is transforming banking support with an AI-powered virtual assistant.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Crédit Mutuel is building upon its strength in customer service expertise with AI.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson and Apple's Core ML, technicians can make the right repairs the first time – anywhere.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Brazilian bank Bradesco is giving personal attention to each of its 65 million customers with Watson.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, Lucy and Equals 3 is delivering results to Fortune 1000 companies and the agencies serving them.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, KPMG is driving innovation and empowering its employees.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Thomson Reuters is working with Watson to help clients deepen their expertise on global data privacy laws.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson IoT, KONE is analyzing data in elevators and escalators around the world to keep people moving smoothly, safely, and efficiently.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, Woodside Energy can retain the knowledge of senior experts and pass it to new employees.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Autodesk used Watson to develop a virtual agent that interacts with customers and speeds response times by 99 percent.
                       
                     
                                            Read the case study on IBM.com →
                     
                   
                                                                
                                                Insurance company employees are working with Watson to assess insurance claims 25 percent faster.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, Korean Air is developing an intelligent detection system to improve operational efficiency and on-time performance.
                       
                     
                                            Read full story →
                     
                   
                                       
                
       
                                        
                            Industry Solutions
                                Advertising
                 Customer Engagement
                 Education
                 Financial Services
                 Health
                 IoT
                 Media
                 Talent
                 Work
               
             
                            Developers
                                Documentation
                 Developer tools
                 SDKs
                 Stack Overflow
                 developerWorks
               
             
                            Company
                                With Watson
                 Watson Blog
                 Watson webinars
                 Contact sales
               
             
           
                        
                                                                                                            Industry Solutions
                     
                                                                                                Customer Engagement
                           Education
                           Financial Services
                           Health
                           IoT
                           Media
                           Talent
                           Work
                         
                       
                     
                   
                                                                      Developers
                     
                                                                                                Documentation
                           Developer tools
                           SDKs
                           Stack Overflow
                           developerWorks
                         
                       
                     
                   
                                                                      Company
                     
                                                                                                With Watson
                           Watson Blog
                           Watson webinars
                           Contact sales
                         
                       
                     
                   
                 
               
             
           
                                        
                
     
                        

",,Person, , , , , 
https://ibm.co/2P29dWG,187446750783_10155830531555784,https://www.facebook.com/ibmwatson/posts/10155830531555784,"Stay in the loop about Watson service updates, learn along through tutorials, watch Think recaps and more – subscribe to IBM Watson's YouTube channel: ",Link,,,8/23/18 12:52, ,3108,3108,0,5501,5501,0,38,26,27,4,4,5066,2847,0,0,34,0,0,0,0,0,0,0,0,0,0,2,19.0,,2,20.0,,11,15.0,,,12,15.0,,,1,3.0,,1,3.0,,"Meet IBM Watson, the AI platform for professionals. Subscribe for tutorials for using Watson services, developer kits, educational clips, event recaps and more.",https://yt3.ggpht.com/a/AATXAJyzfGL7kUk9wfS1iX21IgoPsKOIEEqbit_r-w=s900-c-k-c0xffffffff-no-rj-mo,https://www.youtube.com/channel/UCxPJljXUHvUd9idyfEHvXqg?view_as=subscriber,anger,0.083767,neutral,0,Watson service updates,Person,Watson service updates,Person,joy,0.120566,neutral,0,"Meet IBM Watson, developer kits",Company,Meet IBM Watson,Company,anger,0.03828,neutral,0,,"Company, Company","      YouTube
                                                                               

                                                                                                                                                                                                        
    





                                                                                                          
                     
                                     IBM Watson
                                                                                                                                                                                                                                                                                                                                                                                       
                                                        
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
  

",,Company,blue,neon lamp,lamp,neon lamp,-
https://ibm.co/2lKBPqJ,187446750783_10155829165650784,https://www.facebook.com/ibmwatson/posts/10155829165650784,What makes the MIT-IBM Watson AI lab so incredible? Find out: ,Link,,,8/22/18 19:57, ,8111,8111,0,14160,14160,0,268,155,194,3,3,11805,6794,0,0,225,0,0,0,0,0,0,0,0,0,0,25,127.0,3.0,26,129.0,3.0,55,120.0,,,63,131.0,,,1,2.0,,1,2.0,,The MIT-IBM Watson AI Lab is a joint-research effort to drive AI-related breakthroughs beyond the current bounds of deep learning and basic algorithm development.,https://mitibmwatsonaiLab.mit.edu/images/social.jpg,http://mitibmwatsonailab.mit.edu/,joy,0.210419,neutral,0,MIT-IBM Watson,"Organization, Company, Person",MIT-IBM Watson,Organization,anger,0.101561,neutral,0,MIT-IBM Watson,"Organization, Company, Person",MIT-IBM Watson,Organization,joy,0.572028,positive,0.805255,MIT-IBM Watson,"Company, Organization, Person, Company","The MIT-IBM Watson AI Lab focuses research on healthcare, security, and finance using technologies such as the IBM Cloud, AI platform, blockchain and quantum to deliver the research to industries.
Today we announced our new Membership Program and welcomed Boston Scientific, Nexplore, Refinitiv and Samsung as inaugural members. Members will participate in activities with research scientists from MIT and IBM in pursuit of leading-edge AI advances that hold the potential to transform how business is done. 
IBM highlights new approach to infuse knowledge into NLP models
IBM highlights new approach to infuse knowledge into NLP models
David Cox interview on MIT-IBM Watson AI Lab papers at AAAI
An AI outperformed other systems in identifying potentially fatal interactions between two drugs, according to newly published research
AI could help design better drugs that don’t clash with other medication
Technique reveals whether models of patient risk are accurate
Founded in 2017, the MIT-IBM Watson AI Lab is a unique academic / corporate partnership to spur the evolution and universal adoption of AI.
The MIT-IBM Watson AI Lab focuses research on healthcare, security, and finance using technologies such as the IBM Cloud, AI platform, blockchain and quantum to deliver the research to industries.
We are looking for talented researchers who are as passionate as we are about artificial intelligence, advancing science, and inventing the next generation of intelligent machines. 
",MIT-IBM Watson,Company,coal black,coal black color, , , 
https://ibm.co/2Mrlk2n,187446750783_10155826011205784,https://www.facebook.com/ibmwatson/posts/10155826011205784,IBM is putting smart to work to change the game of tennis by revolutionizing how the sport is experienced and produced at the US Open. Learn how the same Watson technology that supports a smarter tennis experience is simultaneously at work across business and society: ,Link,,,8/21/18 9:30, ,12158,12158,0,23392,23392,0,174,109,136,4,4,16509,8779,0,0,95,0,0,0,0,0,0,0,0,0,0,23,70.0,2.0,24,72.0,2.0,70,50.0,,,83,53.0,,,2,2.0,,2,2.0,,“AI Highlights from Watson” is a suite of powerful AI solutions on IBM cloud allowing the USTA to release highlights within minutes of a match's conclusion.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/08/1086bc86-a4a1-11e8-83cb-4e6200d3db67.jpg,https://www.ibm.com/blogs/watson/2018/08/watson-powers-us-open-experiences-for-millions-of-tennis-fans/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Watson+Powers+US+Open+Experience+For+Fans+Aug+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.218619,positive,0.81625,"smarter tennis experience, game of tennis, Watson technology","Sport, Company, Person, Location",smarter tennis experience,Sport,joy,0.123151,positive,0.731012,"IBM cloud, Highlights","Person, Person, Organization, Company",IBM cloud,Person,joy,0.566709,positive,0.840444,IBM Watson,"Company, Location, Facility, Person, Company, Person, Company","Around the world, tennis fans are eagerly awaiting the final — and arguably most exciting — major Grand Slam event of 2018, the US Open.
This year, approximately 700,000 lucky fans will gather in person to watch the action live at the Arthur Ashe Stadium. They will be joined by more than 10 million fans from around the globe engaging with their own personalized and enhanced tournament experiences courtesy of the UTSA and their digital platforms powered by IBM Watson and the IBM Cloud.
These fans will have their US Open experience supercharged by real-time access to in-game analysis, critical players stats, enriched video highlights, competitive analysis and much more.
In 2018, guests attending matches at the Arthur Ashe stadium can access the Virtual Concierge. Powered by the Watson Assistant API, fans using the “Guest Info” feature in the US Open’s app can use natural language to have their every question understood and answered in real-time by an interactive chatbot. The goal is to empower fans to find anything what they need as they navigate, personalize and reinvent their entire experience of 130 US Open attractions and 900 matches.
New in 2018, the interactive chatbot is now available via Facebook Messenger and across all US Open digital platforms. US Open fans can access the “Virtual Concierge” – available within the Guest Info feature of the Official Apps for iOS, Android, and MobileWeb.
Just like last year, fans in the stadium will now be able to use the mobile app to access news and venue information in real-time, so they can discover who is playing on what court and when, or whether their favorite player is winning. That includes finding the best place to get a hotdog, inquiring about the dining options or transportation. All supported by an interactive map of the venue.
A tournament favorite, IBM SlamTracker is available again this year giving fans exclusive access to live dashboards of all matches in progress. Evolving the experience far beyond the scores, IBM SlamTracker takes fans inside the game, delivering insights from 12 years of Slam data that includes 6,350 matches, 946,759 points, and real-time match data.
IBM SlamTracker is better than ever in 2018, with the fan experience revamped to focus on real-time stats for all live matches. There’s also a momentum feature, where fans will be able to see which player has the advantage and how the momentum shifts between the players as the game progresses.
Keys to the Match – IBM SlamTracker’s most exciting feature – adds context to every moment of match play. Fans can understand each player’s strengths and track their progress against performance keys. Fans can even see how two competitors will match up before the game with inbuilt predictive analytics identifying key strategies for each player based on the analysis of prior match ups, accounting for situational variables like ball position, pace of play and more.
Watson’s technology is empowering the USTA digital teams to deliver the most exciting tournament moments faster than ever. The all-new “AI Highlights from Watson” – a suite of powerful AI solutions on the IBM cloud – is reinventing the highlights production process allowing the USTA to release highlights within minutes of a match’s conclusion.
Watson now watches all the Men’s and Women’s single matches on the 7 show courts within minutes – a task impossible for humans. By absorbing unimaginable amounts of video footage and information in each frame, Watson analyzes match data using visual and auditory queues such as player gestures and crowd reactions. Using this information, “AI Highlights from Watson” curates the tournament’s most exciting moments so the US Open digital team can add or remove shots in near real-time to compile a highlight reel. This reel can quickly be exported to video editing platforms for faster and more powerful storytelling.
These highlights will be shared with millions of fans across all USTA digital platforms, Twitter and YouTube. Fans that ‘favorite’ players in US Open apps will also immediately receive post-match push notifications of highlights, so they can re-watch the excitement immediately.
The US Open generates new data every second – on-the-court, off the court, through Twitter, Facebook, on-camera, live feeds on their website, television etc. Through its powerful partnership with IBM, USTA employees from video editors to the C-suite will be able to derive insights from all this data using IBM technologies, helping to enhance the spectator experience.
Throughout the tournament, Watson-powered technologies will analyze and distribute huge volumes of data. Building on 12 years of Slam data, Watson will incorporate millions of data points in real-time from the Chair Umpire, courtside statisticians, the official line calling system, video feeds and speed serve.
All this information will be collected, analyzed, packaged and the distributed across US Open digital platforms powered by IBM. Fans will get exclusive access to unparalleled levels of insight from real-time scoring to player interviews and in-game match changing moments. The can dive into stats across backhand/forehand winners, faults, aces, ball and player positions as well as radar speed readings for serve and return.
IBM has been the “Official Information AI and Cloud Provider” to the US Open since 1990.
IBM Cloud provides the platform for the US Open’s digital platform, allowing the UTSA to scale up and meet a significant spike in demand during the tournament. In addition, Watson for Cyber Security supports the security analysts protecting the US Open’s digital platforms. All of this ensures fans never miss a moment of the tournament.
AI highlights from Watson is also being used to support the USTA with player development. The project will analyze a large number of American player matches from the challenger series, US Open and other events, to create highlight reels. This accelerates the workflow to allow coaches and the USTA player development team to develop stronger US players.
IBM designs, develops and delivers digital experiences for many global sporting events, including The Masters, Wimbledon and the US Open.
With Watson and IBM Cloud, USTA employees turn more channels, more devices and more video content into individualized experiences for over 10 million fans. Learn more about how IBM is working with US Open.
",IBM Watson,Company,ultramarine,person,people,crowd,-
,187446750783_10155824388210784,https://www.facebook.com/ibmwatson/posts/10155824388210784,IBM Watson,SharedVideo,,,8/20/18 12:09, ,5133,5133,0,9039,9039,0,111,84,102,1,1,8599,4674,0,0,99,0,0,0,0,795,834,0,0,0,60478,,34.0,,,34.0,,83,4.0,,,98,4.0,,,,1.0,,,1.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2OOqZfJ,187446750783_10155822645235784,https://www.facebook.com/ibmwatson/posts/10155822645235784,"Curious to learn what AI has accomplished, big or small? Check out the IBM Tumblr page to read all about Watson stories: ",Link,,,8/19/18 14:06, ,6832,6832,0,12950,12950,0,115,69,97,4,4,11832,6193,0,0,98,0,0,0,0,0,0,0,0,0,0,10,52.0,3.0,12,53.0,5.0,29,43.0,,,52,45.0,,,2,2.0,,2,2.0,,,https://static.tumblr.com/i1pqv8t/gOcohhn58/ibmblr_200x200.jpg,https://ibmblr.tumblr.com/tagged/watson#_=_,joy,0.165657,positive,0.559387,IBM Tumblr page,"Person, Company, Company",IBM Tumblr page,Person, , , , , , , , ,joy,0.584883,positive,0.658311,IBM Watson’s natural language processing,"Company, Person, Person, Organization, Person","Fighting Cyberbullying with AI
Cyberbullying has many people rallying in opposition, but it’s notoriously difficult to fight. One company, Identity Guard, is helping to combat this critical issue. To monitor for and promote adult intervention on cyberbullying across social platforms like Tumblr, Identity Guard leverages IBM Watson’s natural language processing and natural language classification to help extract, filter, understand and categorize the content of their user’s social media feeds. If potential threatening material is identified, parents are sent resources on how to intervene and alleviate the situation. As one component of a multi-pronged cyberbullying detection service, IBM Watson is helping companies like Identity Guard protect kids while giving them space to explore and express themselves online.
See how IBM Watson is a secret weapon against cyberbullying -> 
“Growth and Comfort Never Co-exist”
Growing up with a single mother and three siblings, Ginni Rometty, Chairman, President and CEO of IBM, learned the importance of a good work ethic at an early age. Ginni took these lessons to heart, from school to the workplace. “We learned you never let someone define who you are,” Ginni says. “Only you define who you are.” She earned a degree in engineering from Northwestern University (where she was also the valedictorian of her graduating class) and, in 2011, became the first female CEO of IBM. Today, Ginni defines what it means to be a strong, positive role model for women everywhere. 
Watch Ginni discuss the moments and beliefs that helped guide her life and career (video by @makerswomen) -> 
Identity Protection with the Power of AI
Last year, 16.7 million Americans were victims of identity theft. Intersections, an identity theft protection company, has collaborated with IBM Watson to help keep your identity protected. Their service, Identity Guard, uses AI to monitor huge volumes of structured and unstructured data to find information related to potential identity threats such as data breaches, point-of-sale malware and software vulnerabilities. If a customer is at risk, it issues alerts for potential identity theft within seconds – instead of 1-3 days, which is how long it used to take the company to react to the same kind of threats. 
Learn more about Intersections -> 
World Rhino Day 2018
Each year, World Rhino Day celebrates rhinos and the people and organizations that help protect and support them. IBM believes deeply in protecting the endangered species, and is proud to collaborate with Welgevonden Game Reserve, using the IBM Cloud, IoT and predictive analytics to help protect rhinos from poachers. From all of us at IBM, here’s to wishing rhinos everywhere a happy World Rhino Day!
Learn more about how IBM is helping protect rhinos -> 
Serving Up Smarter Ways to Use Data  
It’s a data-powered world out there—especially at the US Open. For over 25 years, IBM has collaborated with the U.S. Tennis Association to leverage data in rewarding ways for fans, coaches and players alike. This year, we’re demonstrating how these rewards extend far beyond the court. Our onsite experience at the Open shows not only how IBM technologies are being used to change the way fans experience tennis, but also how this same tech is applied to solve real world problems. Did you know Watson Visual Recognition can help identify players’ gestures during matches, as well as defects on a factory floor. Another Watson API, Sound Analysis, can derive insights from the intensity of crowd noise, and also detect wear-and-tear in elevators and train tracks. From the world of tennis to the world at large, IBM understands that well-wielded data can help unlock better experiences for all.
Learn more about IBM and the US Open -> 
Giving AI a lesson in humanity
AI is functional, but can it be friendly? Soul Machines believes so. They’re a company working to enhance the way we interact with systems like virtual tutors and digital assistants that are powered by AI. Soul Machines taps the talents of AI researchers, neuroscientists, psychologists, artists, and other innovative thinkers to help create personable “digital humans” that run on the backbone of IBM Watson—specifically, Watson Assistant, which powers the AI’s dialog interface. By creating approachable AI-powered helpers, Soul Machines is helping ensure you’ll walk away from machine interactions with a smile on your face.
Learn how Watson helps power approachable AI -> 
Watson does Wimbledon
In honor of All-England Lawn Tennis Club (AELTC) 150th anniversary, IBM Watson created the 2018 Official Championship Poster (above). To make it, Watson was taught to recognize all the various photographic elements such as grass, crowds, court, etc. Then, Watson sifted through 150 years of archived Wimbledon photography – over 300,000 photos – and stitched the images together in the appropriate areas, based on color and content. The final photo mosaic is comprised of over 8,000 images, and, thanks to its pointillist quality, looks simultaneously modern and timeless. Beyond art-making, Watson’s visual recognition skills can help businesses in a broader sense, too, helping to classify wide categories of visual content.
Learn more about Wimbledon and Watson -> 
The Highlight Machine
FOX Sports has collaborated with IBM to create the Highlight Machine, a powerful platform that uses AI to archive and curate over 98,000 hours of video clips, game highlights and historical footage from soccer’s biggest tournament. Built with IBM Watson Media’s AI video technology and IBM iX’s user experience expertise, the platform is designed so that soccer fans don’t miss a single play, penalty kick, or goal. Fans can browse the massive archive and build their own personalized highlight reels, sorting and saving clips by year, team, player, match, and play type. And thanks to the processing power of Watson, the clips are available just seconds after the action ends in the match. It’s another way for fans all over the world to enjoy the Beautiful Game.
Learn more about the Highlight Machine -> 
AI-Companion In Space
It’s always good to have some help – especially when you’re going into space. Today, CIMON, a mobile astronaut assistance system, is going to be launched into space to accompany German astronaut Alexander Gerst on his second 6-month mission to the International Space Station. Developed by Airbus and IBM for the German Aerospace Center, CIMON (which stands for Crew Interactive Mobile Companion) is enabled by Watson. Using IBM’s Watson technology, CIMON will help Gerst perform certain tasks and experiments. CIMON can also potentially serve as an early warning system for any technical issues on board. The duo is one more example of what man + machine can do.
Find out more about Watson and CIMON’s journey into space -> 
The sweet sounds of AI-powered collaboration  
While working with R&B musician H.E.R. on a new track, music producer Alex Da Kid wanted to add another voice. With the help of IBM Watson and Spotify, he discovered the perfect collaborator who brought the texture he was searching for: Rapsody. Check out their recently-released song, “Go.”
Listen to “Go” on Spotify->   
TJBot, your friendly neighborhood weather-bot
What can TJBot do? That’s a long list, but we’ll start with the weather. TJWeather is a recipe you can implement that leverages Watson’s Speech to Text and Text to Speech APIs as well as the IBM Weather Insights API, enabling TJBot to tell you the forecast when you ask for it. Another recipe, Weatherbot, gives TJBot the power to forecast rain and tell you the temperature using his arm and head-light—one quick glance at TJBot before you’re out the door will let you know if you need to grab a jacket or an umbrella. Give these recipes a try before you get caught out in the cold without your coat!
Get to know TJBot->   
Putting Smart to Work in Agriculture
Before most of us get out of bed, farmers are using satellite imagery, weather data and Watson to help monitor soil moisture levels. Applying data to help increase crop yields—that’s putting smart to work.
Explore how to put smart to work -> 
",IBM Watson’s natural language processing,Company,ultramarine,videocassette,medium,tabloid,-
http://ibm.co/2nndb0Q via TechRepublic,187446750783_10155820031145784,https://www.facebook.com/ibmwatson/posts/10155820031145784,10 practical scenarios in which IBM is using AI to enhance human capabilities: ,Link,,,8/18/18 10:52, ,23445,23445,0,42659,42659,0,1117,809,947,14,14,30821,17183,0,0,896,0,0,0,0,0,0,0,0,0,0,72,420.0,3.0,76,424.0,3.0,220,638.0,,,277,670.0,,,8,6.0,,8,6.0,,For more than a century IBM has been dedicated to every client's success and to creating innovations that matter for the world,,https://www.ibm.com/us-en/?ar=1,joy,0.065234,neutral,0,practical scenarios,Company,practical scenarios,Company,joy,0.856488,positive,0.979896,"century IBM, client's success",Company,century IBM,Company,joy,0.844333,positive,0.835611,IBM POWER9,"Company, Quantity, Person","Celebrate Women’s History Month with IBMers who are changing the world and inspiring the next generation
From chatbots to drug discovery, these IBMers push the frontiers of AI
 									Meet the women inspiring a new generation of researchers → 								
World’s most powerful supercomputer identifies 77 promising drug compounds
 									Learn how IBM POWER9 is accelerating the search for a cure → 								
A big network outage welcomed her to IBM. She helped it run at 100% since.
 									Find out about this VP, transformation agent and soccer mom → 								
IBM has laid the foundation for a new era of technology and business
 									Read about a year  of growth — and plans for the future → 								
Accelerate your journey to AI with a cloud‑native data platform
Build AI solutions to find relevant answers in complex data
Try IBM Z mainframe software capabilities with no installation required
Create, move and deploy your Java applications on the cloud in minutes
How would you use technology to take on climate change?
How would you use technology to take on climate change?
Get help today for the IBM services and software you own →
Explore technical topics, find trial software and join the community →
",IBM POWER9,Company, , , , , 
https://ibm.co/2KQijYY,187446750783_10155818852505784,https://www.facebook.com/ibmwatson/posts/10155818852505784,"Because AI is becoming increasingly powerful, existing computer hardware is slow to keep up. That's why IBM researchers were driven to develop a fast, efficient chip designed to train AI. Read more via VentureBeat: ",Link,,,8/17/18 19:46, ,11108,11108,0,19637,19637,0,218,119,135,4,4,17347,9773,0,0,184,0,0,0,0,0,0,0,0,0,0,16,110.0,1.0,17,114.0,2.0,53,72.0,,,62,73.0,,,2,2.0,,2,2.0,,IBM researchers have developed a chip that can train certain kinds of neural networks more efficiently than traditional hardware.,,https://venturebeat.com/2018/06/29/ibm-researchers-design-a-fast-power-efficient-chip-for-ai-training/,joy,0.172484,positive,0.676187,IBM researchers,"Person, Company",IBM researchers,Person,joy,0.139534,positive,0.598685,IBM researchers,Company,IBM researchers,Company,joy,0.563096,positive,0.571738,neural network,"Person, Company, Person, Person, Company, PrintMedia","Thanks to powerful graphics chips and advances in distributed computing, optimizing the algorithms at the core of artificial intelligence is easier than ever before. But it’s not particularly efficient on current-day hardware — even powerful GPUs can take days or weeks to train a neural network.
That catalyzed researchers at IBM to develop a new chip tailor-made for AI training. In a paper published in the journal Nature titled “Equivalent-accuracy accelerated neural-network training using analog memory,” they describe a system of transistors and capacitors that can train neural networks quickly, precisely, and highly energy-efficiently.
Neural networks consist of interconnected units called neurons or nodes (a collection of nodes is called a layer), which receive numerical inputs. In a basic network, individual neurons multiply those inputs by a value — a weight — and pass them along to an activation function, which defines the output of the node. Through a strategy known as backpropagation, the weights are adjusted over time, improving the accuracy of the outputs.
GPUs are well-suited for these because unlike traditional processor, which crunch through numbers sequentially, they’re able to perform lots of computations in parallel. But because the processor and memory in graphics chips sit a considerable distance apart from one another on the motherboard, delays are introduced as data shuttles back and forth between them.
“Conventional computers [consume] consume an enormous amount of energy,” Stefano Ambrogio, a postdoctoral researcher at IBM who led the project, told VentureBeat in an interview, “and there’s a lot of waiting involved.”
The scientists’ solution consists of analog memory and traditional electronic components. Individual cells made up of a pair of phase change memory (PCM) units and a combination of a capacitor and three transistors correspond to individual neurons in the network. The PCMs store weight data in memory, which is represented in the transistors and capacitors as an electrical charge.
As the network trains, the capacitor updates the weights, transferring them to the PCM after thousands of cycles.
The capacitor can’t retain values for more than a few milliseconds, but it can be programmed quickly. And the PCM, which is a form of non-volatile memory, doesn’t need an external power source to retain data.
The researches used a mix of hardware PCMs and software-simulated components to benchmark the design, and the results are promising. The chip performed 100 times more calculations per square millimeter than a GPU while using 280 times less power. Even more impressive, it matched the speed and accuracy of Google’s TensorFlow machine learning framework on a variety of computer vision tasks.
“We can do [the calculations] in a very accurate way, at the same accuracy as software,” Ambrogio said.
The researchers’ chip design isn’t without a significant caveat: It’s not optimized for neural networks that aren’t fully connected, such as the long short term memory (LSTM) networks used in cutting-edge speech recognition apps. But the researchers plan to tackle that next.
Ambrogio is confident they’ll be able to build physical chips at scale in the future. He sees them being used for training neural networks in smartphones and other devices that currently lack the necessary computing resources.
“It would be nice to be able to directly process AI where it’s needed,” Ambrogio said. “When you’re able to train a model, you don’t need to send the information [to the cloud] or have [the device] communicate with something else, and it can react instantly to something.”
",neural network,Person, , , , , 
https://ibm.co/2jor9NN,187446750783_10155816637935784,https://www.facebook.com/ibmwatson/posts/10155816637935784,"What are some key phrases that only people in your company would understand? Every industry has its own colloquial terms and expressions. By teaching Watson's Speech-to-Text service your businesses' language, you open the doors to uncovering out-of-the-box solutions: ",Link,,,8/16/18 18:54, ,8386,8386,0,14240,14240,0,89,66,79,7,7,13079,7617,0,0,77,0,0,0,0,0,0,0,0,0,0,8,36.0,1.0,8,39.0,1.0,34,35.0,,,42,37.0,,,4,3.0,,4,3.0,,IBM Watson's Speech-to-Text API service helps provide the tooling and functionality to train Watson to learn your business.,https://www.ibm.com/blogs/watson/wp-content/uploads/2017/12/GettyImages-9397220821.jpg,https://www.ibm.com/blogs/watson/2017/12/ibm-watson-speech-to-text-api/,anger,0.400191,positive,0.889299,"Watson's Speech, key phrases, Text service",Person,Watson's Speech,Person,joy,0.080448,positive,0.820473,"IBM Watson's Speech, Text API service",Company,IBM Watson's Speech,Company,joy,0.571298,positive,0.752911,"New language model customization, language of your business, IBM Watson’s Speech","Person, Company","Key points:
 – IBM Watson’s Speech-to-Text service helps you go deeper than out-of-the-box solutions allow by providing the tooling and functionality to train Watson to learn the language of your business
 – New language model customization, customization weighting and acoustic model customization features provide the flexibility you need to create effective solutions for your unique domain needs
Your business is unique. It has its own language and modes of operation that require customizable solutions to help your people leverage their industry expertise and deliver value. When it comes to speech-to-text solutions, an out-of-the-box service isn’t enough. Your business needs the freedom and flexibility to create solutions that account for your unique industry and domain needs. Consider the following examples:
Each of these scenarios requires the expression of words, phrases, terms, product names and domain-specific jargon that an out-of-the-box service might not fully understand. The discrete environments of each scenario also vary greatly, thereby affecting transcription unless environment variations are properly accounted for.
Beyond the everyday vernacular a baseline speech recognition service provides, as well as the assumption that your audio files will be crisply recorded without interference, IBM Watson’s Speech-to-Text service helps provide the tooling and functionality to train Watson to learn your business.What makes Watson your best choice?
The ability to tailor our base language models to suit your specific domain terminology is enormously powerful, because no one knows the language of your business better than you.This is one of your differentiating factors in the market, and therefore having a language model customization interface at your fingertips allows you to train the Watson Speech-to-Text service more precisely to suit your business language and style with great accuracy.
You can get even more precise in customizing your language model with our Watson Speech-to-Text service by weighting specific words that may be spoken frequently(such as product names or specific terminology used in your business),as opposed to words already in the service’s base vocabulary.You can account for this during machine training, and you can do so for each speech recognition request as needed.This setting is optional, but depending on your speech recognition needs, having this level of language tuning could greatly benefit your application accuracy.
As a complement to our language model customization interface, we now also offer a custom model interface that attends to the acoustical side of your business, thereby helping you go even further in tailoring the service to your business.Think of it as fine-tuning ‘the ear’ of our service, by training Watson to adapt to your specific acoustic environment (like the ambient noise in your call center) and speaker styles (like voice pitch, volume and pace). You can even create and train an acoustic model by providing just the audio files, without the need for corresponding transcription.
In addition to these customization capabilities, read more about all of our speech-to-text tooling features below:
",New language model customization,Person,reddish orange,signorina (woman),person,female,woman
https://ibm.co/2qz1WpQ,187446750783_10155814637135784,https://www.facebook.com/ibmwatson/posts/10155814637135784,"By 2025, there will be 1 trillion gigabytes of global data, and most of it is in the form of text, documents, call logs, social media posts, research papers, feedback comments and more.

The best way to seek real insight in all this information? Using AI. Learn how. ",Link,,,8/15/18 18:12, ,4487,4487,0,8837,8837,0,114,74,101,0,0,5840,2988,0,0,51,0,0,0,0,0,0,0,0,0,0,12,39.0,7.0,12,41.0,9.0,58,20.0,,,81,20.0,,,,,,,,,"Most of the world's data is unstructured. IDC forecasts that by 2025 the global datasphere will grow to 163 zettabytes. That's a trillion gigabytes, and most...",https://i.ytimg.com/vi/LFl_1uKiADk/maxresdefault.jpg,https://www.youtube.com/watch?v=LFl_1uKiADk&t=3s,joy,0.216379,positive,0.594551,"gigabytes of global data, research papers, form of text",Quantity,gigabytes of global data,Quantity,joy,0.642031,positive,0.384185,"global datasphere, world's data, IDC","Company, Quantity",global datasphere,Company,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                                              
            

",YouTube,Company,coal black,call center,building,call center,-
https://ibm.co/2zKT955,187446750783_10155811621140784,https://www.facebook.com/ibmwatson/posts/10155811621140784,"Over the next decade, analyst firm Tractica predicts that annual Global AI enterprise software revenue will grow from $644 million in 2016 to nearly $39 billion by 2025. What is the future of #AI revenue? Our latest blog highlights the top 10 use cases for AI in the next decade: ",Link,,,8/14/18 9:28, ,8505,8505,0,15192,15192,0,111,68,78,6,6,13369,7549,0,0,92,0,0,0,0,0,0,0,0,0,0,16,43.0,,17,45.0,,25,47.0,,,28,50.0,,,3,3.0,,3,3.0,,AI already impacts many aspects of our daily lives at work and at home. Here are the top 10 ways that AI will impact business over the next decade.,https://www.ibm.com/blogs/watson/wp-content/uploads/2017/11/blog_Top10_png_socialTile_081117.png,https://www.ibm.com/blogs/watson/2017/11/top-10-ways-ai-will-impact-business-in-the-next-decade/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Top+10+Ways+AI+Will+Impact+Business+In+Next+Decade&cm_mmca1=000000OF&cm_mmca2=10000408,sadness,0.502085,negative,-0.269107,"latest blog, next decade","Company, Quantity, Quantity, Hashtag",latest blog,Company,joy,0.49316,negative,-0.52988,aspects of our daily lives,Person,aspects of our daily lives,Person,fear,0.519226,positive,0.461173,,"Person, Quantity, Quantity, Company, Quantity, Company","Key Points:
 – AI already impacts many aspects of our daily lives at work and at home
 – Over the next decade, AI enterprise software revenue will grow from $644 million to nearly $39 billion
 – Here are the ways that we predict AI will impact business over the next decade including vehicular object detection, predictive maintenance and intelligent recruitment.
Artificial intelligence already impacts many aspects of our daily lives at work, at home and as we move about. Over the next decade, analyst firm Tractica predicts that annual Global AI enterprise software revenue will grow from $644 million in 2016 to nearly $39 billion by 2025. Services-related revenue should reach almost $150 billion. They report that there are 6 artificial intelligence segments which will account for a significant percentage of these revenues:
1. Machine learning
 2. Natural Language Processing and Understanding
 3. Computer vision
 4. Machine reasoning
 5. Strong AI
 6. Deep learning
These functional areas are applicable to many use cases, industries, and generate benefits to both businesses and individuals. Here are the top use cases which will reap financial rewards for AI technology product and service companies, and a broad spectrum of benefits for everyone else.
Machine and vehicular object detection, identification and avoidance
Self-driving cars and other autonomous vehicles are consistently called the “next revolution” in transportation, technology and, some say, in civilization in general. Some predict that, along with the growth of the electric vehicle segment, it could bring an end (or the beginning of the end) to car ownership as we know it as soon as 2030.
Just as with cloud and computing as a service, it will be interesting to see how consumers and businesses can get the transportation value of a vehicle without the maintenance, storage, upgrades and depreciation costs of vehicle ownership. Would they would be willing to either rent out their vehicle on a site like Turo, or rent someone else’s car for a daily rate? Sharing economy leaders Lyft, Uber and new entrants can easily leverage autonomous cars to facilitate getting a vehicle from one car rental customer to another.
Autonomous forklifts, drones and other robot warehouse workers are already retrieving boxes for shipment for thriving e-commerce companies.  Vehicles are now equipped with sensors to calculate distance and routes to their destination and spatial room between vehicles, and to identify potential hazards like pedestrians, poor road conditions and other vehicles. AI-enabled machines and vehicles don’t cause accidents while texting, they don’t fall asleep at the wheel, and they don’t need lunch breaks. A vehicle which can prioritize driving into the ditch or a tree instead of a person can save lives and reduce insurance costs.
Advances in IoT, geospatial applications and artificial intelligence have aligned to make autonomous vehicles a reality. Autonomous vehicles like Olli aren’t science fiction, they’re reality.
Visual recognition, classification and tagging
In industries like law enforcement, media and entertainment, AI provides organizations with the ability to process large volumes of photographs and NSO images, and prepare them for discovery and reuse.
Financial services data is fast-moving, is highly regulated and Exchange Traded Fund (ETF) data requires a high level of security. Unlike human traders that rely on intuition, AI-driven algorithms like Watson’s Equbot can analyze a 10-year history of stocks and real estate holdings in fractions of seconds, as opposed to hours or days.
Watson can help investors make data-driven decisions on when to buy, hold and sell equities. It can also help regulators identify rogue traders who are making fraudulent securities transactions. Watson Financial Services reduces the risk of misconduct, while addressing the multitude of regulatory requirements trading firms must adhere to on an ongoing basis.
It goes without saying that self-driving cars need up-to-the minute details on the roads and road conditions that it is driving on. It also needs to maintain Simultaneous Localization and Mapping so the autonomous vehicle doesn’t “SLAM” into other cars and trucks on the roadway. AI helps to guide vehicles to their intended destination, relative to other vehicles, buildings and obstructions.
For autonomous vehicles, robots, drones and cargo-carrying transportation governed by AI, geospatial applications can play a role in tracking trends in location-related business data. It could track the locations of customers that buy a certain manufacturer’s product, or identifying regions with an ideal demographic for propensity to buy high-end electronics, for example. Companies can use this data to improve their marketing, customer service and product value.
For manufacturers with high-value machinery, airlines with large fleets of planes or car rental chains with many vehicles, protecting the value of their assets is critical. AI can help these companies (and others) to keep track of when wearable parts were last replaced when servicing needs to be completed next, and how long equipment or vehicles are in service.
Predictive maintenance reduces the frequency of equipment failures, as preventative action can be taken to refurbish or tune assets on a scheduled basis. Maintenance can take place relative to manufacturing or service requirements. For example, if certain equipment is required for a specific product run, it can be serviced outside of those parameters. Or, when a ship is scheduled to be in port for a specific time period, it can be serviced such that it won’t impact service level agreements.
AI can determine the possible outcome if maintenance doesn’t occur, and make accurate determination when equipment or vehicles should be taken out of a service rotation based on failure patterns or age. Sensors can monitor asset performance and transmit the data back to a cognitive analytics hub through IoT.
Government organizations, commercial enterprises and freelance white hat security experts try valiantly to keep ahead of the latest spyware, botnets, DDoS attack patterns, and other threats in cyberspace. Yet hackers are constantly seeking new vulnerabilities to exploit and encryption defenses to topple.
Cognitive Security systems scour the vast amounts of threat intelligence available on the internet, and help companies and public sector organizations to re-mediate their network and service perimeters before hackers can prey upon them. Human security analysts do their best to keep pace with the latest threats, but in many cases they are overwhelmed by Zero Day viruses and other emerging threats. Cognitive security is a way for companies to gain leverage through deep learning and strong AI.
Cognitive capture leverages AI and Machine Learning to expedite the process of “training” their systems to recognize key metadata (like employee numbers, invoice numbers, or loan numbers) and digitize records more effectively. It also liberates companies from scanning application and service vendor lock-ins.
Cognitive capture leverages innovative cloud, machine learning, and open source architecture to convert unstructured data into powerful insights through analytics. It also helps companies meet regulatory requirements without the burden of storing paper records, and increases the speed and accuracy of information discovery. Instead of just extracting the text, images and signatures from documents, cognitive capture learns the context of documents. It can then trigger workflows accordingly, to either file documents away in a repository, or send it to a case management system, accounts receivable or other application for immediate attention.
Traditional applicant tracking systems can be great at filtering out unqualified online job applications, yet they can sometimes eliminate qualified candidates in the process, should a resume not be optimized based on the right keyword phrases. AI makes finding the right candidate a more intelligent, data-driven process. By going beyond the basic words on a resume to determine job fit, it adds context based on reasoning and human inputs.
AI also enhances traditional HR information systems by recommending career paths for certain employees and the best way to coach, motivate and engage employees based on their personality, mindset and other characteristics. Making better hires is a good start: however, retaining employees and ensuring they are mentored and challenged to do their best is part science, part art-form and part algorithm.
These are some of the leading market sectors which are generating revenue for developers of AI software, and service providers in this space. There are other segments like public safety, customer service and more which are growing, and other use cases will continue to emerge.
If you are looking for ways to create efficiencies, disrupt your industry and innovate by leveraging the power of cognitive computing and AI, discover the Watson products and services that best meet your business needs.
",,Person,greenish blue,spin dryer,appliance,dryer,spin dryer
https://ibm.co/2sWNMjE,187446750783_10155809408545784,https://www.facebook.com/ibmwatson/posts/10155809408545784,Is there a code of ethics brands should follow when using a chatbot for their business? It comes down to following 5 simple rules. ,Link,,,8/13/18 9:34, ,8270,8270,0,15191,15191,0,87,51,58,1,1,13830,7515,0,0,76,0,0,0,0,0,0,0,0,0,0,11,34.0,1.0,11,37.0,2.0,21,32.0,,,24,34.0,,,,1.0,,,1.0,,"Businesses often overlook important issues related to morals and ethics of chatbots and AI. Customers need to know when they are communicating with a machine, and that brands will protect their privacy and data in today’s interconnected world.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/06/AI-and-chatbots-ibm-contact-center-1200x628-c2-4.jpg,https://www.ibm.com/blogs/watson/2017/10/the-code-of-ethics-for-ai-and-chatbots-that-every-brand-should-follow/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Conversation-_-WW_WW-_-Code+of+Ethics+Every+Chatbot+Should+Follow+Blog+Oct+27&cm_mmca1=0000,joy,0.388597,neutral,0,"code of ethics brands, simple rules",,code of ethics brands,,joy,0.265401,positive,0.71056,"important issues, Customers",Person,important issues,Person,joy,0.507241,positive,0.452234,,"Person, Person","Key Points:
 – Businesses often overlook important issues related to morals and ethics of chatbots and AI
 – Customers need to know when they are communicating with a machine and not an actual human
 – Ownership of information shared with a bot is another key ethical consideration and can create intellectual property issues
 – The privacy and protection of user data is paramount in today’s interconnected world
(Read the full article “Ethics And Artificial Intelligence With IBM Watson’s Rob High” on Forbes.com. You can also listen to The Modern Customer Podcast with Rob High here.)
See how AI is shaping customer service
Businesses are rapidly waking up to the need for chatbots and other self-service technology. From automating basic communications and customer service, to reducing call center costs and providing a platform for conversational commerce, chatots offer many new opportunities to delight and better serve consumers.
Chatbots can offer 24/7 customer service, rapidly engaging users, answering their queries as whenever they arrive. Millennials in particular are impatient when engaging with brands and expect real-time responses. More than 22% of millennials expect a response within 10 minutes of reaching out to a brand via social media, according to a recent Desk.com study. And 52% of them will abandon online purchases if they can’t find a quick answer.
The need for speed in customer service has never been higher. Leading brands like Staples are increasingly turning to chatbots to provide a solution for this need for speed.
The topic of chatbot ethics is complex and spans a wide area including privacy, data ownership, abuse and transparency.
Rob High, CTO of IBM Watson was recently featured in an article on Forbes.com titled “Ethics And Artificial Intelligence With IBM Watson’s Rob High.” In the article, Rob talks about how in order to keep AI ethical, it needs to be transparent. Rob advises that when customers interact with a brand’s chatbot, for example, they need to know they are communicating with a machine and not an actual human.
“AI, like most other technology tools, is most effective when it is used to extend the natural capabilities of humans instead of replacing them. That means that AI and humans are best when they work together and can trust each other.”
 — Rob High, CTO IBM Watson
Ethics form the foundation of how a bot is built, and more importantly, they dictate how a bot interacts with users. How a bot behaves has the potential to influence how an organization can be perceived and unethical behavior can lead to consumer mistrust and litigation issues. Ethical bots can promote brand loyalty and help boost profit margins.
1. Who should a chatbot serve?
When building a chatbot, an organization must decide who it primarily serves: the needs of the business or the needs of a customer. Amir Shevat, Director of Developer Relations at Slack discusses this topic in his blog post “Hard questions about bot ethics.”
Here, you must determine the exact purpose and business value of the chatbot. One built mainly to provide recommendations to customers can only be ethical if it meets the needs of the customer. Whereas a bot built for internal business improvement should be made to suit the company’s need.
In general, where or not a bot is customer-facing, an ethical organization should always put the needs of the customer before the needs of the business. This means providing the product best suited to those customers, rather than the one with the best profit margin or the speediest implementation. An option for users to provide feedback on the service will help detect issues, improve customer satisfaction and maintain ethical behavior. Bots utilizing machine learning and algorithms to display product offerings or recommendations should also have regular health checks built in for this exact purpose.
2. Am I talking to a chatbot or a human?
Building trust between humans and machines is just like building trust between humans. Brands can build trust by being transparent, aligning expectations to reality, learning from mistakes and continually correcting them, and listening to customer feedback.
When building a chatbot, transparency is a critical consideration. This boils down to the question – is it clear whether the user is talking to a bot or a human? Customers are savvy enough to be able to tell the difference and expect brands to be honest with them. Customers don’t expect chatbots to be perfect, but they want to know what they can and cannot do, and that they are reliable — within reason. Transparency about both failure and success can build trust faster than virtually any other approach.
To work on transparency and reliability, start by asking yourself some basic questions like:
Where sensitive information (like bank details) and life-altering interactions (health and finance) is being communicated, you need to build additional checks for transparency and security. This means providing the user with clarity. Be upfront and build into the introduction that the user is talking to a bot and what personal information is being accessed, analyzed, saved or shared and with whom. Also always provide an option where the user can be immediately be connected to a human if they have concerns that a bot cannot address..
3. Who owns the data shared with a chatbot?
Ownership of information shared with a bot is another key ethical consideration and can create intellectual property issues if not handled correctly.
Does the bot service-provider or the user own their favorite custom pizza creation? If a bot builds a playlist based on the users preferences – who owns it? These are the kind of ethical questions that need to be considered and the answer can fluctuate based on the intent of a bot. A personal-assistant bot would lean towards user ownership, while a representative-bot leans towards service-provider ownership.
Whatever the type of bot, this is another question of transparency. Businesses building bots should provide clarity about who owns what and should include language asking users to agree with their terms of service first.
4. Preventing chatbot abuse
When building a chatbot, it is important to consider how a bot handles abuse. This includes both the giving and receiving of abuse. Here, the ethical stance is to follow Isaac Asimov’s Three Laws of Robotics: “a robot may not injure a human being or, through inaction, allow a human being to come to harm”.
A chatbot should be built with profanity recognition. Upon receiving abuse, the developer has two options. The first is to ignore the abuse by building in a non-response situation where the user abuses the bot. Or, add a default neutral response such as “I’m sorry, I don’t understand your request.” Depending on the severity of abuse — for example death threats or racism — it is important to build in a report function, sending the transcript to a relevant party.
It is of critical importance that chatbots do not abuse humans even if it’s learned behavior that’s a result of what the human has been feeding the bot. Requests from users to end communication should have a built in protocol to end the chat, preventing the bot from harassing or spamming a user. Language filters should be applied for any bots utilizing machine learning algorithms. There have been a few instances over the last year where some bots went rogue after being subverted by online trolls and began tweeting racist propaganda.
5. How should chatbots handle privacy?
The privacy and protection of user data is paramount in today’s interconnected world. The launch of the General Data Protection Regulation protecting citizens of the European Union is a reflection of this.
When building a chatbot, developers should consider the ethics of user privacy. This will help answer questions like:
In this situation, businesses can take direction from existing online interactions. Transparency is the best course of action and a publicly-available privacy policy is a must have for any organization. Developers should also build in mechanisms to ensure the privacy of user information in any interaction — an unspoken user-bot confidentiality agreement. This means encryption of all communications and, depending on the sensitivity of the data, transcription deletion after completion of the interaction.
Ethics should be a core consideration of any action taken by a business. With chatbots still in a stage of relative infancy, the discovery of new ethical issues is likely to continue. Businesses should continue to learn from these emerging cases and build their guiding principles and ethical standards. If in doubt, side with the customer, and always provide transparency.
(Read the full article “Ethics And Artificial Intelligence With IBM Watson’s Rob High” on Forbes.com. You can also listen to The Modern Customer Podcast with Rob High here.)
",,Person,light brown,LED display (computer/TV),machine,computer,digital computer
https://ibm.co/2vY54hs,187446750783_10155807190185784,https://www.facebook.com/ibmwatson/posts/10155807190185784,Did you know? The IBM Watson Unity SDK is the first of its kind to bring scalable artificial intelligence services to Unity. That means taking gaming to a whole other level – like virtual and augmented reality in your games. Learn more: ,Link,,,8/12/18 9:51, ,8994,8994,0,15771,15771,0,103,55,67,3,3,12849,7056,0,0,75,0,0,0,0,0,0,0,0,0,0,12,53.0,,15,54.0,,32,26.0,,,40,27.0,,,1,2.0,,1,2.0,,"IBM and Unity are launching the IBM Watson SDK for Unity on the Unity Asset Store, enabling developers to easily integrate Watson cloud services into their...",https://blogs.unity3d.com/wp-content/uploads/2018/02/image2-1.png,https://blogs.unity3d.com/2018/02/20/bringing-the-power-of-ai-to-developers-with-the-ibm-watson-unity-sdk/?_ga=2.89714651.1383049552.1519136253-1097373577.1519136253,anger,0.129141,positive,0.819462,"IBM Watson Unity SDK, scalable artificial intelligence services",Company,IBM Watson Unity SDK,Company,joy,0.056467,neutral,0,"IBM Watson SDK, Unity, IBM, Unity Asset Store",Company,IBM Watson SDK,Company,joy,0.537902,positive,0.856387,IBM Watson SDK,"Company, Person, Person","IBM and Unity are launching the IBM Watson SDK for Unity on the Unity Asset Store, enabling developers to easily integrate Watson cloud services into their Unity applications such as visual recognition, speech to text, and language classification. The SDK makes it easy for developers to take advantage of modern AI techniques through a set of cloud-based services.
Today we are thrilled to announce a partnership with IBM to launch the IBM Watson SDK for Unity on the Unity Asset Store. This SDK is the first asset of its kind to bring scalable AI services to Unity, enabling developers to easily integrate Watson services into their Unity applications. Millions of Unity developers globally will now have access to the powerful cloud-based AI services of Watson directly within the Unity environment.
Although AR and VR are continuously being applied to the gaming industry to immerse players in virtual environments like galaxies or with geolocation environments where the activity happens on real surroundings, we are now experiencing the advancement of applying these concepts into business use cases. With VR, companies can implement employee training programs that teach workers how to perform a job in a virtual environment without any safety risks, and with AR, field workers can hold up their phone or glasses to a pipe to see if it needs to be fixed, when, and where.
As AR and VR technologies mature, there is increasing interest coming from the enterprise market for innovative applications in marketing, design, engineering, manufacturing and analysis. Unity is the market leader in AR and VR for consumer use cases, as well as rapidly emerging as the market leader for enterprise AR and VR.
With its deep AI expertise and industry knowledge, IBM also has been actively exploring the application of AR and VR with clients such as the Immersive Insights demo, which hints at the enormous potential of AR and VR in enterprise applications. Together, Unity and IBM plan to help drive the development of this market by enabling applications that bring contextual expertise and AI capabilities directly into the employee and/or end consumer’s personal and professional sphere of experience.
This partnership exemplifies IBM and Unity’s commitment to accelerating the enterprise developer journey and equipping them with the tools and resources they need to build powerful new AR and VR apps. As an official platinum sponsor for INDEX Conference, the open developer community event, we’re excited to collaborate with IBM to empower the Unity community with powerful AI-driven cloud services to help expand a new frontier of interactivity. The first step of this journey begins with the IBM Watson SDK for Unity.
With the SDK now available on the Asset Store, Unity developers can now configure games and projects to understand speech, talk with users, and understand the intent of a user in natural language.
One of the key features of the SDK is its powerful speech recognition capabilities. With speech services, developers have access to real-time speech recognition providing highly accurate speech recognition directly in your Unity project. Player speech can be recognized and used to trigger in-game events.IBM Watson SDK for Unity also has powerful language translation and language classification capabilities. In conjunction, both language classification and speech recognition can work together seamlessly to provide voice-driven interactivity in your Unity game.
Watch an example of how IBM teamed up with Ubisoft to give players of Star Trek Bridge Crew the ability to issue commands to NPC’s with just their voice using theIBM Watson SDK for Unity.
For developers interested in the power of AI-driven visual recognition, Watson’s Vision API provides the ability for developers to integrate real-time visual recognition within their Unity projects.Take a look at how a team of developers took advantage of theIBM Watson SDK for Unity during an IBM-sponsored Hackathon to create Watson and Waffles, a VR adventure game which requires the player to sketch game objects using the Vive controller. Using the Vision API, Watson identifies user drawings and generates corresponding 3D objects for the player to use.
For more details about the Watson capabilities available within the IBM Watson SDK for Unity you can leverage to get started, please visit: https://www.ibm.com/watson/products-services/
The SDK is simple to set up and can open up your project to new levels of interactivity. Imagine a game with NPC’s powered with visual recognition technology that recognize in-game objects or even a virtual reality experience with interactions driven completely with voice commands.
Receiving access to the IBM Watson SDK for Unity is easy – simply head over to the Asset Store and download the SDK here.
You also can familiarize yourself with this short video series from IBM, which provides an overview of all of the core features of the IBM Watson SDK for Unity..
Visit the Asset Store and download the IBM Watson SDK for Unity today!
We’ve rounded up some key resources to help you get started with the IBM Watson Unity SDK:
",IBM Watson SDK,Company,black,asterism (cluster of stars),nature,asterism (cluster of stars),-
https://ibm.co/2uOn7D4,187446750783_10155805076485784,https://www.facebook.com/ibmwatson/posts/10155805076485784,"Much like an impressionable child, new technologies like AI are prone to influence by the nature of the information and data sets with which they are presented. Perhaps the training data isn’t representative. Or, AI models could be unknowingly fed biased data that affects their output.

A recent Forrester report “The Ethics Of AI: How To Avoid Harmful Bias and Discrimination” describes the ideal machine learning data models as being 'FAIR': ",Status,,,8/11/18 11:30, ,9475,9475,0,17321,17321,0,127,90,112,7,7,13705,7687,0,0,67,0,0,0,0,0,0,0,0,0,0,6,43.0,,7,44.0,,80,13.0,,,99,13.0,,,4,3.0,,4,3.0,,Forrester report “The Ethics Of AI: How To Avoid Harmful Bias and Discrimination” describes the ideal machine learning data models and how to build trust.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/07/801_Ethics-and-AI-–-How-orgs-can-avoid-harmful-bias-in-models_625ai-02-1024x536.jpg,https://www.ibm.com/blogs/watson/2018/07/trust-in-the-age-of-ai-build-fairness-into-machine-learning-models/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Trust+in+the+Age+of+AI+Building+Fairness+Into+Machine+Learning+Models+July+2018&cm_mmca1=000000OF&cm_mmca2=10000408,sadness,0.290087,negative,-0.44166,recent Forrester report,"Person, Company",recent Forrester report,Person,sadness,0.257617,positive,0.487351,"Forrester report, Harmful Bias",Company,Forrester report,Company,joy,0.513013,negative,-0.285549,,"Person, Company, Person","Enterprise-wide deployments of AI are constrained by the requirements of scaling any new system or technology: transparency, security, and the application’s ability to work across many systems. But solving for these challenges is not enough. Every organization that develops or uses AI, or hosts or processes data, must do so in ways that allow them to rationalize the decisions or recommendations in a way that is easily consumable.
Much like an impressionable child, new technologies like AI are prone to influence by the nature of the information and data sets with which they are presented. Perhaps the training data isn’t representative. Or, AI models could be unknowingly fed biased data that affects their output.
A recent Forrester report “The Ethics Of AI: How To Avoid Harmful Bias and Discrimination” describes the ideal machine learning data models as being FAIR, or:
Businesses should strive to create models that are “FAIR” to protect against harmful bias. Let’s examine Forrester’s recommendations how organizations can leverage AI for the good of humankind, while avoiding the ethical pitfalls associated with perceived discrimination.
The threat of opaque or unfair machine learning models is real, and safety-critical and highly-regulated domains are most likely to feel the impact. Organizations must be able to address unfair models, or suffer reputational, regulatory, and revenue consequences. The obvious reputational risks aside, if for example, your AI mortgage application is rejecting applicants who shouldn’t be rejected, or your AI marketing application isn’t targeting certain potential customers who may buy your product, it’s ultimately just bad business.
How do businesses build models that people trust over time? Lack of transparency into “black boxes” — limited visibility into data sets, computations, assumptions and processing — makes it difficult to pinpoint reasons for model and processing degradation over time. This increases the risks associated with using and supporting the models, and compromises developing trust in the models.
When you’re training an AI model, you also need to be aware of any underlying unfairness in the data. Machine learning, much like human learning, is inherently the “product” of the information provided, relative to the parameters of its programming. It’s important for any company that augments their business processes with machine learning to consider the strengths, weaknesses, opportunities and threats of AI they can’t trust, to ensure their best-laid plans don’t go awry.
The flip-side of bias: Targeted machine learning used for good
There are many scenarios where targeted data actually enhances AI algorithms. When correctly configured, it helps accelerate the time it takes to discover a potential solution and increase the accuracy of search results.
For example, companies looking to optimize their marketing campaigns will create an ideal “persona” of their target audience, and then locate as many prospects as possible which fit that persona profile. AI algorithms can identify prospects that fit these personas from multiple data sources, including CRM applications and social media channels.
Other examples where it’s fundamentally sound to use targeted data in machine learning include:
While these examples of non-representative data used to train models are fundamentally sound, it’s important for companies to ensure their AI models are fair and don’t discriminate so individuals and communities can trust these systems.
When bias leads to discrimination, and discrimination to weakness
Training an AI engine with insufficient data which doesn’t represent every possible permutation will cause the AI bot to ignore anything which it can’t understand.
Consider what happens when a business programs an algorithm to search out prospects based on a narrow demographic profile from limited market research. They may miss out on market segments they never thought of as viable prospects, and create ethical dilemmas.
Data scientists and developers must prevent algorithmic or human bias creeping into their models while still using the helpful bias these models identify to differentiate between customers. Companies should assess the full scope of their market opportunity, so their appearance of prejudice doesn’t damage their reputation.
European GDPR rules are forcing companies to change the way they manage personal information, and how they document their compliance. Businesses need to strike a balance between gathering and storing enough data to understand their audience, while complying with security and privacy regulations.
Many feel that if these concerns are left unchecked there will be a growing possibility of AI reinforcing systemic biases and exacerbating inequality in our business and personal lives.
There are many real-life scenarios where a customer is loyal to a particular retailer, such as a grocery store, which carries specialty foods from their country of origin. Or that tailor their marketing campaigns to specific genders. For example, women with families respond favorably to grocery coupons with significant discounts.
For these retailers, by being sensitive to the unique needs of a critical segment of their market, and eliminating discrimination, companies stand to preserve or grow their customer base by tailoring their product inventory and advertising campaigns based on inclusivity.
AI platforms can also help companies to listen to their audience across more channels, such as social media, online forums and contact center applications. If there is chatter about a company’s insensitivity to particular genders, races, age group or ethnicity, it’s best to identify the issue quickly and address it immediately.
IBM’s vision for ethics and transparency in AI
At IBM we believe we have an inherent obligation to monitor for, and correct, unethical or objectionable bias in the algorithms themselves, as well as any bias caused by the human-influenced data sets their systems interact with. Watson is transparent about who trains our AI systems, what data was used to train those systems, and most importantly what drives our customers’ algorithmic recommendations.
For example, IBM announced plans to release more than 1 million facial images to help better train the AI used for facial recognition. The risk of bias being built into facial recognition AI systems is a concern for any organization developing facial analysis algorithms. For example, does the AI accurately recognize different skin colors and other attributes in a non-discriminatory way. Since AI is only as good as the data that trains it, IBM thinks making a diverse dataset like this available will help root out bias.
At the recent VivaTech 2018 event in Paris. IBM CEO Ginni Rometty talked about her vision of the need for ethics and transparency in AI and data management. Rometty invited business leaders to follow IBM’s Principles for Trust and Transparency:
The Watson team embraces these principles, and they act as our “guiding light” in developing the Watson platform, and customer AI applications on top of it. We are driven by opportunities in industries like banking, retail and manufacturing to help companies to augment their employees’ skills and experiences. You can view Rometty’s entire keynote address here.
Are you looking for further information about how to implement enough AI bias to get better insights from data. Are you concerned with your AI models discriminating against a segment of the population, such as by age, gender, race or sexual orientation? Forrester has some guidelines that can help your business. Download the Forrester report, “The Ethics Of AI: How To Avoid Harmful Bias And Discrimination“.
",,Person,blue,sphere,figure,circle,sphere
https://ibm.co/2FafMBI,187446750783_10155802682395784,https://www.facebook.com/ibmwatson/posts/10155802682395784,".As with any new technology, it's really important that we be thinking now about how we use AI ethically and responsibly. For us, that comes down to three basic principles: trust, respect, and privacy.&quot;

Read more on what IBM Watson CTO Rob High says about these 3 ethical principles via TechRepublic: ",Link,,,8/10/18 9:30, ,9539,9539,0,17229,17229,0,167,93,110,7,7,15127,8483,0,0,140,0,0,0,0,0,0,0,0,0,0,14,84.0,2.0,14,85.0,2.0,48,50.0,,,58,52.0,,,5,2.0,,5,2.0,,"TechRepublic spoke to IBM's Rob High about the ethical, privacy, and security obstacles that artificial intelligence has to overcome.",https://tr1.cbsistatic.com/hub/i/r/2018/03/01/005c45e1-7e9b-43df-9012-57f7ee9fa3bc/thumbnail/770x578/ea8d0af3f9eb1dfda64080cabc7cdc79/big-booths-mwc-2016-12.jpg,https://www.techrepublic.com/article/ibm-watson-cto-the-3-ethical-principles-ai-needs-to-embrace/,joy,0.548898,positive,0.926056,"IBM Watson CTO Rob High, basic principles, new technology, ethical principles","Person, Person, Company",IBM Watson CTO Rob High,Person,fear,0.228087,negative,-0.589837,"IBM's Rob High, artificial intelligence","Person, Company",IBM's Rob High,Person,joy,0.60699,positive,0.646511,,"Person, Person, Company, Organization","IBM Watson CTO Rob High has done a lot of thinking about the privacy, security, and ethical implications of artificial intelligence. He presented some of those ideas at Mobile World Congress 2018, and we talked to him about some of his key findings.
You can watch the interview above or read the transcript below.  
High said, ""One of the things we have to realize about AI--it's relatively new to all of us. There's a lot about it that we don't all fully understand. Even as a technologist, we know where we're trying to bring the technology, but on the other side there's lots of people for which this technology is new. The experiences around that are going to be different. As with any new technology, it's really important that we be thinking now about how we do that ethically and responsibly. For us, that comes down to three basic principles. Trust, respect, and privacy.
""What that basically means is that when you're using an AI technology, you have to trust that it's going to be doing the right thing. Or you focus on things like, can we create transparency in the AI algorithms? Can we get the algorithms to actually identify your level of confidence (in them), for example.""
SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
""Transparency comes down to can we identify what sources of information are being used? Have we established the right properties, the right principles in place when we train these systems to use data that is representative of who we are, and the information that we're using?"" said High.
""Of course, privacy comes down to recognizing that your data is our data. It should be your choice as to what data you're going to provide in order to gain the benefits these AIs offer. That goes from everything from the privacy of enterprise data, and the data that enterprises bring to the table when they use AIs, maintain separation between each of the enterprises all the way through, to how those enterprises protect the privacy of the data of their clients.""
High added, ""The journey for adopting AI and delivering that for value to clients begins with one very basic proposition, which is, is the AI going to augment and amplify the intelligence of the people using it? Because if it's not doing that, it's probably not going to be very useful. You're going to lose this utility very quickly. First of all, identify what that is. How do you help people do what they do better?
SEE: How to implement AI and machine learning (ZDNet special feature) | Download the report as a PDF (TechRepublic)
""If you get that out of the way then you can begin to look at how to apply the technology, but all through that we really encourage our clients to think about two things. One is, how they're going to protect and preserve the privacy of their institutions, of their clients. But also how do they convey the responsibility of their clients to be aware of what data they're getting across and to challenge those cases where, perhaps they don't want to give up the data they're offering. Or at least to make sure the value they're getting from that data is also very supportive of this idea that's augmented their intelligence.""
",,Person,purplish blue,air terminal, , , 
https://ibm.co/2FBkKXT,187446750783_10155800711650784,https://www.facebook.com/ibmwatson/posts/10155800711650784:0,"If you've ever picked up a phone to call customer service, or communicated a problem through a brand's website, you've already interacted with AI. Learn the differences between the 3 most popular types of chatbots that businesses are using today: ",Photo,,,8/9/18 11:06, ,11337,11337,0,20859,20859,0,208,161,189,7,7,15902,8869,0,0,104,0,0,0,0,0,0,0,0,0,0,16,58.0,2.0,16,59.0,2.0,101,22.0,43.0,,116,23.0,50.0,,1,6.0,,1,6.0,,"As chatbots continue to gain popularity, our latest blog highlights the three types of business chatbots you can build to better reach and target customers.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/12/Conversation_service_Social1200x628-1.png,https://www.ibm.com/blogs/watson/2017/12/3-types-of-business-chatbots-you-can-build/,anger,0.162405,positive,0.497646,"customer service, popular types of chatbots",Person,customer service,Person,joy,0.425058,positive,0.725044,"types of business chatbots, latest blog",,types of business chatbots,,sadness,0.539365,positive,0.560402,single-turn type bots,"Person, Company","Key Points:
 From a business perspective, here are the 3 most common chatbots that are being built:
 – Support chatbots that are built to master a single domain
 – Skills chatbots that are single-turn type bots that do not require a lot of contextual awareness
 – Assistant chatbots that are the middle ground between a support and skills chatbot, knowing a little bit about a variety of topics
A few years ago when chatbots were just gaining popularity, there was a lot of talk around what a chatbot actually was. With the advent of natural language processing and various machine learning techniques, some of the more advanced conversational applications wanted to separate themselves from their competition. Many began calling themselves “virtual assistants.” This implied that they were somehow bigger or more powerful than existing chatbots, or perhaps were more conversational or could cover a wider range of topics.
However, we quickly discovered that the market did not care how powerful the bot was or about the underlying technology, so long as it solved the right problems. So in a way, many of these different terms for bots became more or less synonymous with each other. It didn’t matter what you called it – you were getting something you could hold a conversation with. We’re now at a point where we know that regardless of what you call the bot, there are usage patterns and differentiation that make chatbots distinct.
When you’ve done your research and are at the point of beginning to build your bot, think carefully about what problems you’re trying to solve and what functionalities you will want to incorporate. Knowing what you want your application to solve for and assist with will decide the type of chatbot, virtual assistant or agent you ought to build. This will impact both your development plan and, as importantly, your end-user experience. The following are the three main types of chatbots I have come across, with background on their particular uses and variations.
Support chatbots are built to master a single domain, like knowledge about a company. Support chatbots need to have personality, multi-turn capability, and context awareness. They should be able to walk a user through any major business processes, and answer a wide range of FAQ-type questions. You will want to have a short-tail and long-tail combo solution when building this type of chatbot. At IBM Watson, we would use the Watson Conversation service for the short-tail, common questions and processes, and Watson Discovery service for the long-tail, but there are many potential solutions for this. Speech is an optional feature, and not a necessity, since users typically have sat down at a desktop and are ready to figure out their solution. The chatbot developer will want to spend the most time making sure it is as easy as possible to navigate the bot, and ensuring it can execute the actions that your users actually care about (for example, just because you want to sell more credit cards doesn’t mean your customers want to open more credit card accounts).
Skills chatbots are typically more single-turn-type bots that do not require a lot of contextual awareness. They have set commands that are intended to make life easier: “Turn on my living room lights,” for example. Speech functionality is recommended for this type of chatbot so the user does not need to turn on a device or click any buttons. They should be able to follow commands quickly, so that your users can multitask while engaging with the bot. These chatbots do not need to worry too much about contextual awareness, unless you want to design a particularly advanced one, as people will quickly learn what to say, and say it appropriately. It’s a nice bonus if you can give a command, and your bot knows – to return to our example – that you are in the kitchen and acts to turn on the correct lights.
However, this is not a necessary function, as users will quickly learn to give the appropriately specific command. When building a skills bot, it is important to focus on integration, especially when controlling a home or personalized objects. Keep integration simple so your users can interact with the bot without worrying about how to use .
Assistant chatbots are more or less a middle ground between the two bots above. They work best when they know a little bit about a variety of topics. Many people envision these bots will someday become navigators of all other bots that are out there now. Want to pay a bill? Ask your assistant bot to talk to the support bot for your bank. Assistant chatbots need to be conversational and respond to just about anything, while being as entertaining as possible. Siri is a good, current example – while she only does so much, people continually ask her for things simply because even when she cannot perform the command, the response she gives tends to be amusing. When building an assistant chatbot, it is important to make it as obvious as possible how the bot is trained. The range of questions a user might ask is large, so making sure you have adequate coverage is going to be the most difficult factor. In many cases, when people do not know what they should ask, they will not ask anything at all. And if you miss the few topics they initially are willing to try, they will not come back for more.
Even though these are the most common types, many bots in production fall somewhere in between two. Some are even a combination of all three. No matter what type of bot you decide to build, it is important to give your bot some life and personality, make it useful, and make sure it’s easy to use. People interact with bots because they want to get something done in a more natural way than was previously possible. Whether it’s something simple like turning on a light, or something complex like applying for a mortgage, every pattern has specific features that make it stand out, so be sure your bot shines brightly in what it’s designed to do. The possibilities are endless.
",single-turn type bots,Person,blue,razor,tool,cutlery,razor
https://ibm.co/2ukQzjR,187446750783_10155798379015784,https://www.facebook.com/ibmwatson/posts/10155798379015784,"Meet Project Debater, the AI IBM designed to challenge and create arguments for humans on complex issues. ",Link,,,8/8/18 9:25, ,12506,12506,0,22310,22310,0,300,197,238,9,9,19417,10658,0,0,247,0,0,0,0,0,0,0,0,0,0,24,116.0,4.0,27,117.0,4.0,80,132.0,,,101,137.0,,,4,5.0,,4,5.0,,IBM’s Project Debater research project is able to make real-time arguments about complicated debates like subsidizing space exploration.,https://cdn.vox-cdn.com/thumbor/xKUljgsTYgFZGcHHW6yWq56yXuk=/0x146:2040x1214/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/11561677/Project_Debater_with_human_professional.jpg,https://www.theverge.com/2018/6/18/17477686/ibm-project-debater-ai,joy,0.439962,positive,0.5349,"Meet Project Debater, complex issues, AI IBM",Company,Meet Project Debater,Company,anger,0.473393,positive,0.739052,"IBM’s Project Debater research project, space exploration",Company,IBM’s Project Debater research project,Company,joy,0.606543,positive,0.352065,Project Debater,"Quantity, Person, Company, Person, Person, Quantity","At a small event in San Francisco last night, IBM hosted two debate club-style discussions between two humans and an AI called “Project Debater.” The goal was for the AI to engage in a series of reasoned arguments according to some pretty standard rules of debate: no awareness of the debate topic ahead of time, no pre-canned responses. Each side gave a four-minute introductory speech, a four-minute rebuttal to the other’s arguments, and a two-minute closing statement.
Project Debater held its own.
It looks like a huge leap beyond that other splashy demonstration we all remember from IBM when Watson mopped the floor with its competition at Jeopardy. IBM’s AI demonstration today was built on that foundation. It had many corpora of data it could draw from, just like Watson did back in the day. And like Watson, it was able to analyze the contents of all that data to come up with the relevant answer. But this time, the “answer” was cogent points related to subsidizing space and telemedicine laid out in a four-minute speech defending each.
Project Debater cited sources, pandered to the audience’s affinity for children and veterans, and did a passable job of cracking a relevant joke or two in the process. 
That’s pretty impressive. It essentially created a freshman-level term paper kind of argument in just a couple of minutes when presented with a debating topic it had no specific preparation for. The system has “several hundred million articles” that it assumes are accurate in its data banks, which are about 100 areas of knowledge. When it gets a debate topic, it takes a couple of minutes to spelunk through them, decides what would make the best arguments in favor of the topic, and then creates a little speech describing those points. 
Some of the points it made were pretty facile; some quoted sources, and some were pretty clearly cribbed from articles. Still, it was able to move from the “present information” mode we usually think of when we hear AI to a “make an argument” mode. But what impressed me more was that it attempted to directly argue with points that its human opponents made, in nearly real time. (The system needed a couple minutes to analyze the human’s four-minute speech before it could respond.)
It frankly made me feel a little unsettled, but not because of the usual worries like “robots are going to become self-aware and take over” or “AI is coming for our jobs.” It was something subtler and harder to put my finger on. For maybe the first time, I felt like an AI was trying to dissemble. I didn’t see it lie, nor do I think it tried to trick us, but it did engage in a debating tactic that, if you saw a human try it, would make you trust that human a little bit less. 
Here was the scene: a human debater was arguing against the notion that the government should subsidize space exploration. She set up a framework for understanding the world, which is a pretty common debating tactic. Subsidies, she argued, should fit one of two specific criteria: fulfilling basic human needs and creating things that only could be done by the government. Space exploration didn’t fit the bill. Fair enough.
Project Debater, whose job was to respond directly to those points, didn’t quite rebut them directly. It certainly talked in the same zone. It claimed that “subsidizing space exploration usually returns the investment” in the form of economic boosts from scientific discovery, and it said that for a nation like the United States, “having a space exploration program is a critical part of being a great power.” 
What Project Debater didn’t do was directly engage the criteria set forth by its human opponent. And here’s the thing: if I were in that debate, I wouldn’t have done so either. It’s a strong debating tactic to set the framework of debate, and accepting that framework is often a recipe for losing. 
So the question is: did Project Debater simply not understand the criteria, or did it understand and choose not to engage on those terms? Watching the debate, I figured the answer was that it didn’t quite get it, but I wasn’t positive. I couldn’t tell the difference between an AI not being as smart as it could be and an AI being way smarter than I’ve seen an AI be before. It was a pretty cognitively dissonant moment. Like I said, unsettling.
Jeff Welser, the VP and lab director for IBM research at Almaden, put my mind at ease. Project Debater didn’t get it. But it didn’t get it in a really interesting and important way. “There’s been no effort to actually have it play tricky or dissembling games,” he tells me (phew). “But it does actually do … exactly what a human does, but it does it within its limitations.”
Essentially, Project Debater assigns a confidence score to every piece of information it understands. How confident is the system that it actually understands the content of what’s being discussed? “If it’s confident that it got that point right, if it really believes it understands what that opponent was saying, it’s going to try to make a very strong argument against that point specifically,” Welser explains. 
“If it’s less confident,” he says, “it’ll do its best to make an argument that’ll be convincing as an argument even if it doesn’t exactly answer that point — which is exactly what a human does, too, sometimes.”
So, the human says that government should have specific criteria surrounding basic human needs to justify subsidization. Project Debater responds that space is awesome and good for the economy. A human might choose that tactic as a sneaky way to avoid debating on the wrong terms. Project Debater had different motivations in its algorithms, but not that different.
The point of this experiment wasn’t to make me think that I couldn’t trust that a computer is arguing in good faith — though it very much did that. The point is that IBM was showing off that it can train AI in new areas of research that could eventually be useful in real, practical contexts.
The first is parsing a lot of information in a decision-making context. The same technology that can read a corpus of data and come up with a bunch of pros and cons for a debate could be (and has been) used to decide whether or not a stock might be worth investing in. IBM’s system didn’t make the value judgment, but it did provide a bunch of information to the bank showing both sides of a debate about the stock.
As for the debating part, Welser says that it “helps us understand how language is used,” by teaching a system to work in a rhetorical context that’s more nuanced than the usual “Hey Google, give me this piece of information and turn off my lights.” Perhaps it might someday help a lawyer structure their arguments, “not that Project Debater would make a very good lawyer,” Welser joked. Another IBM researcher suggested that this technology could help judge fake news. 
How close is this to being something IBM turns into a product? “This is still a research-level project,” Welser says, though “the technologies underneath it right now” are already beginning to be used in IBM projects.
In the second debate, about telemedicine, Project Debater once again had a difficult time parsing the exact nuance its human opponent was making about how important the human touch is in diagnosis. Rather than discuss that, it fell back to a broader argument, suggesting that maybe the human was just afraid of new innovations. 
”I am a true believer in the power of technology,” quipped the AI, “as I should be.”
",Project Debater,Quantity,blue,speaker,person,speaker,-
https://ibm.co/2n48NDc,187446750783_10155796268170784,https://www.facebook.com/ibmwatson/posts/10155796268170784,"By infusing Watson technology into their Star Trek; Bridge Crew game, Ubisoft lets players seamlessly complete missions online, with both AI characters and human partners while staying fully engaged. ",Link,,,8/7/18 9:47, ,7902,7902,0,14338,14338,0,135,94,106,2,2,12149,6778,0,0,114,0,0,0,0,0,0,0,0,0,0,7,49.0,,11,50.0,,24,75.0,,,27,79.0,,,,2.0,,,2.0,,"That’s where Ubisoft’s VR game, Star Trek: Bridge Crew, is headed with the help of IBM Watson.",https://cdn.vox-cdn.com/thumbor/fIXUmNYcXN7tehfzAS6Sy0bXUXc=/0x0:3063x1604/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/9722689/IBM_150_Extra_Engineers_1951.jpg,https://www.recode.net/ad/16681044/speech-recognition-technology-ibm-watson-star-trek,joy,0.568922,neutral,0,"Star Trek, Watson technology, Bridge Crew game","Person, Company, Person",Star Trek,Person,joy,0.211236,neutral,0,"Star Trek, Ubisoft’s VR game",Company,Star Trek,Company,sadness,0.566006,positive,0.847809,thrill of an immersive game,"Quantity, Person, Person","For the last 60 years, researchers have continued their mission to create a computer that understands naturally spoken language. Because the thrill of an immersive game is the immersion itself, having to break away and revert to manual navigation takes away from the experience.
But thanks to voice control, the experience is seamless. That’s what Watson Speech to Text and Conversation services bring to the table. By infusing AI technology into the game, players can seamlessly complete missions online, with both AI characters and human partners while staying fully engaged. You can also experiment with voice-controlled objects and begin to develop your own game, as well as test out the same software the game uses in the IBM VR Speech Sandbox. Here is how Ubisoft’s VR game, Star Trek: Bridge Crew, is enhanced with Watson tool. 
",thrill of an immersive game,Quantity,reddish brown,ensemble of people,dress,outfit,ensemble of people
https://ibm.co/2Hwv6sY,187446750783_10155794953425784,https://www.facebook.com/ibmwatson/posts/10155794953425784,"&quot;Artificial intelligence is not designed to replace the human mind, but to augment our intelligence and amplify our reach.&quot; Read about one IBMer's journey to learning effective AI on the Watson blog: ",Link,,,8/6/18 18:44, ,8704,8704,0,13650,13650,0,147,86,104,3,4,12022,7650,0,0,125,0,0,0,0,0,0,0,0,0,0,15,72.0,1.0,15,72.0,1.0,37,57.0,,,47,57.0,,,1,3.0,,1,2.0,,"IBM has been on the AI journey for a long time, but the path has not always been smooth. My experience in the consulting business has taught me that successful practitioners need to be flexible and quick to make course corrections. We at IBM have learned along our AI journey, and here are three lessons that come to mind from my own interaction with clients and business colleagues. 1. You fail quickly, and learn fast with AI Remember the adage: garbage in, garbage out. We’ve acknowledged that the results of data analysis are sometimes misleading or even inaccurate. It could result from human error, or personal or institutional biases. Or maybe we’re not asking the right questions. Today we’re building tools that quickly recognize anomalies in the data and even apply a bias rating to outcomes that allow us to make course corrections. Exploration geologists know all about course corrections. They analyze data from drill logs, geological…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/06/AI-jobs_1200x628.png,https://www.ibm.com/blogs/watson/2018/06/journey-ai-three-lessons-learned-effective-implementation/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-3+Lessons+on+Journey+to+AI+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.634047,positive,0.700443,"Artificial intelligence, human mind, quot",Person,Artificial intelligence,Person,joy,0.538828,positive,0.308951,"results of data analysis, consulting business","Company, Person",results of data analysis,Company,joy,0.538571,positive,0.485623,results of data analysis,"Company, Person, Person, HealthCondition, Company, Organization, Person, Person, Company, Quantity","Share this post:
IBM has been on the AI journey for a long time, but the path has not always been smooth. My experience in the consulting business has taught me that successful practitioners need to be flexible and quick to make course corrections. We at IBM have learned along our AI journey, and here are three lessons that come to mind from my own interaction with clients and business colleagues.
1. You fail quickly, and learn fast with AI
Remember the adage: garbage in, garbage out. We’ve acknowledged that the results of data analysis are sometimes misleading or even inaccurate. It could result from human error, or personal or institutional biases. Or maybe we’re not asking the right questions. Today we’re building tools that quickly recognize anomalies in the data and even apply a bias rating to outcomes that allow us to make course corrections.
Exploration geologists know all about course corrections. They analyze data from drill logs, geological shapes, connected devices and maps to plan their next exploration drill. At Goldcorp they are using AI to analyze all this data, and try to identify human error and bias quickly. Their AI platform identifies anomalies and allows geologists to focus on good data as they search for new ore deposits.
2. AI does not replace us; it makes us better
The second lesson is that artificial intelligence is not designed to replace the human mind, but to augment our intelligence and amplify our reach. In the early stages, AI systems were not that smart. Training was a slow, arduous process that required a lot of human intervention. Thankfully, that has led to systems that are now much more robust.
Today, AI platforms are being used in all industries to makes us smarter. A great example is found in healthcare.
Ten million people around the world are living with Parkinson’s disease. The drug treatment hasn’t changed significantly in 50 years. One of our employees living with Parkinson’s thought there must be a better way to advance research. Our AI platform was put to work digesting 28 million medical reports and analyzing 3,800 possible drugs. Sixteen potential drug treatments emerged and the Ontario Brain Institute has funded the initial study with the goal to have more diverse and better treatments for people with Parkinson’s.
AI is not replacing doctors and researchers, but making them smarter.
3. Beware of data ownership in the world of AI
Data ownership has been a hot news item lately. Some large companies have been under fire for misusing data that has been entrusted to them. We believe that you should not be required to relinquish rights to your data in order to have the benefits of an AI platform. In fact, IBM neither owns nor stores any of the data touched by Watson solutions and services. We believe the data and resulting insights belong to your organization and its clients.
A recent IBM survey revealed that 78 percent of respondents say a company’s ability to keep their data private is “extremely important” to them, but only 20 percent “completely trust” organizations they interact with to maintain the privacy of their data.
Your data matters to you — whether it’s your own personal medical records, or the findings from your company’s drug trials or geological surveys.
At the enterprise level, your data is your competitive advantage. If your technology partner is sharing your data with others you may be hurting your business and your clients. You should always retain ownership of your data, and know how it is being used. That is a principle everyone in our industry must adopt.
We’re still in the early stages of our AI journey, and have much to learn as the technology matures. The potential in AI to improve our lives and our businesses is potentially limitless, but as with any new technology, we must approach it responsibly and with a willingness to learn and adapt.
",results of data analysis,Company,green,slope,nature,slope,-
https://ibm.co/2EvwDhZ,187446750783_10155792071910784,https://www.facebook.com/ibmwatson/posts/10155792071910784,"&quot;There are a lot of chatbots out there today that operate on what we call a single-turn exchange... but when somebody asks &quot;what's my account balance?&quot; they may need to know what their account balance is, but that's really not their problem. 

Their problem is that they're getting ready to buy something, or they're trying to figure out how to save up for their kid's education or they're trying to figure out how to pay their bills – there's something behind the question.&quot; – IBM Watson CTO Rob High. ",Status,,,8/5/18 10:15, ,8454,8454,0,12192,12192,0,199,175,227,5,5,9770,6832,0,0,88,0,0,0,0,0,0,0,0,0,0,4,32.0,5.0,4,33.0,7.0,168,16.0,,,211,16.0,,,3,2.0,,3,2.0,,Find out the key differences between chatbots vs. virtual assistants vs. conversational agents from IBM Watson VP and CTO Rob High.,https://cdn.ttgtmedia.com/visuals/German/article/chatbot-2-fotolia.jpg,https://searchcio.techtarget.com/feature/Comparing-chatbots-vs-virtual-assistants-vs-conversational-agents,fear,0.364259,negative,-0.864164,"account balance, kid's education","Company, Person",account balance,Company,joy,0.040039,neutral,0,key differences,"Company, Person",key differences,Company,joy,0.524255,positive,0.613699,conversational agent,"Person, Company, Company","interchangeably, but do those terms really describe the same thing? Not according to Rob High, vice president and CTO at IBM Watson and an IBM Fellow.
In this Q&A, High explains the subtle but distinct differences between those three conversation-based technology terms and the intent behind them. One rule of thumb: The extent to which these technologies engage the user is key to understanding their differences.
What are the differences between terms like chatbot, conversational agent, virtual assistant, etc.?
Rob High: All those terms are used kind of loosely. There are lots of examples in which the terms have been used interchangeably. At IBM, we tend to think of these things somewhat distinctively, and it largely has to do with the degree to which they engage the end user in solving the problem.
   Rob High  
A simple example of this is that there are a lot of chatbots out there today that operate on what we call a single-turn exchange. Somebody says something like 'Alexa, turn on the lights' or 'OK, Google, what's the tallest mountain in the world?' Those are independent, single-turn exchanges. The end user expresses an utterance, the utterance is interpreted or recognized for its intent, and then that intent is mapped onto a specific task.
That's all good, but when somebody asks 'what's my account balance?' they may need to know what their account balance is, but that's really not their problem. Their problem is that they're getting ready to buy something or they're trying to figure out how to save up for their kids' education or they're trying to figure out how to pay their bills -- there's something behind the question.
In my mind, a conversational agent is one that engages the end user into really understanding the nature of the problem behind the question. Part of that includes determining when it's appropriate to dig in deeper but also recognizing that, often, there is a bigger problem there. The conversational agent must be prepared to go to the next level and solicit end users to better understand the problem. Sometimes [conversational agents] have to help [end users] figure out for themselves what the problem is because, sometimes, we'll just go in with a question and we don't really know what it is that we're after.
This is especially important when you're dealing with customer support or servicing a product because if you're having a problem with something that you bought, the first thing that you need to do is describe the problem, but that might just be describing the symptoms and not necessarily the real issue.
It's going to take more than that to figure out what is really going on with the product and what is the issue and whether it's a problem with the product or a problem with the way it's being used or whether it's some transient situation. There are lots of different things that could be behind all that. A conversational agent has to be able to get to that.
You use the term conversational agent, but a lot of people use the term virtual or personal assistant. Which of those terms should we be using, or are they distinct?
High: They're kind of two different sides of the same coin, in some sense. A conversational agent is more focused on what it takes in order to maintain a conversation. With virtual agents or personal assistants, those terms tend to be more relevant in cases where you're trying to create this sense that the conversational agent you're dealing with has its own personality and is somehow uniquely associated with you.
At least for me, the term virtual assistant sort of metaphorically conjures the idea of your own personal butler -- someone who is there with you all the time, knows you deeply, but is dedicated to just you and serving your needs. When a conversational agent is coupled with that kind of personalized knowledge and acts and behaves in a way that gives you the feeling that it's there only for you, I think there becomes an intersection between the two ideas.
For it to serve you on a personal level, any kind of good personal assistant or virtual assistant needs to retain a great deal of context about you, but then use that context as a way of interacting with you -- to use the conversational agent technique for not just anticipating your need but responding to your need and getting to know you better to be able to respond to that need better in the future.
So personal assistants are good at natural language processing and can use machine learning to keep getting better. Do you see chatbots and the various kinds of conversational agents evolving side by side or do you see one overtaking the other?
High: I think both are useful for their own purposes and, to some extent, there's a continuum. But there's certainly a demarcation when it comes to the philosophy of what you're trying to do [and] the tools that you need to be able to do it with and the underlying technologies that are necessary to enable it.
I could imagine a world where chatbots are just chatbots and they do what they've done and they do it well but they don't do much more than that. There may be a use for that, but [I could imagine] other places where there's a lot of utility in going beyond just simply the chatbot to help people with their problems. A lot of that is driven by what kind of utility is called for.
We believe at IBM that the real purpose of AI is to augment human intelligence, not to replace human intelligence. When you think about that, you begin to realize that augmenting human cognition requires getting into a deeper level of understanding of a human and being able to recognize what problems they're trying to get to in a conversation space. [AI] must recognize that humans express themselves in sometimes very subtle ways, and that the intention behind that expression is something that requires a certain degree of reasoning.
The systems have to be trained [using machine learning]; you can't just program them to be able to do all these things. They have to learn. Ultimately, they have to interact with us like we're humans. They have to know something about the fact that, as humans, we have emotions, and our emotions can vary throughout the course of a conversation. [Conversational agents] have to know how to interact with somebody in order to amplify their thinking. There's more to it than just what you typically see today as a chatbot.
So I think both will continue to exist, but a demarcation will occur between those simple things that people can do quickly and easily without a whole lot of additional exploration, versus those situations in which there's a lot of economic value in amplifying human cognition.
How can technologies like chatbots and virtual assistants drive business value? Beyond handling conversational tasks, what's their potential in the enterprise?
High: I think chatbots may be an entry point for almost any enterprise. It's hard to operate an enterprise without having some kind of interface to your clients -- even the simplest of interfaces like those that might occur when you're carrying your smartphone around with you. Almost every institution out there is trying to engage their clients at a deeper level.
Part of that is about getting to know your clients better so that you can serve them better and part of it is about trying to create a higher degree of trust and loyalty. Some of it is about trying to deal with the burgeoning growth in call center expenses as more and more of these relationships drive more hand-holding or deep touch.
I think all of that is conspiring to suggest that going into the digital age, enterprises can only be successful if they're thinking about employing these conversational agents as a way of augmenting their own staff, but, even more so, augmenting the intelligence of their staff and their relationship with their clients and augmenting the intelligence of the clients to create a stronger relationship with the institution.
",conversational agent,Person,jade green,spectrum of colors, , , 
https://ibm.co/2zBV7TA,187446750783_10155789743410784,https://www.facebook.com/ibmwatson/posts/10155789743410784,"“How do I turn on my rear defroster?” Questions that once required consulting a car manual no more – introducing Ask Mercedes, the new virtual assistant powered by Watson. ",Link,,,8/4/18 10:00, ,7727,7727,0,10713,10713,0,114,75,90,4,4,9639,6987,0,0,95,0,0,0,0,0,0,0,0,0,0,8,47.0,,8,48.0,,27,56.0,,,33,57.0,,,2,2.0,,2,2.0,,"“How do I turn on my rear defroster?” and “What type of fuel does this car need?” are the kinds of questions that can send new car owners diving into glovebox for the car manual. Or, they simply start pressing random buttons, hoping for the best. Those days, however, may be over. Daimler AG and IBM have jointly developed the virtual assistant, “Ask Mercedes,” based on IBM Watson conversational technology and the IBM Cloud. The chatbot helps drivers get immediate responses to questions about their cars. From December on available in South Africa and Malaysia (India and Hongkong following in 2018) in the E- and S-Class, the intelligent chatbot Ask Mercedes leaves (almost) no questions about the functionalities of these vehicles unanswered. Ask Mercedes is designed to help not only Mercedes owners – who are getting behind the wheel of increasingly feature-rich vehicles – but also users of car sharing or rental services who may be particularly unfamiliar with newer updates. Ask Mercedes can either…",https://www.ibm.com/blogs/think/wp-content/uploads/2017/11/ibm-mercedes-app-800.jpg,https://www.ibm.com/blogs/think/2017/11/end-of-the-car-manual/,fear,0.10553,neutral,0,"Questions, Ask Mercedes",Person,Questions,Person,joy,0.528373,positive,0.626421,"intelligent chatbot Ask, South Africa, S-Class","Company, Company",intelligent chatbot Ask,Company,joy,0.508104,positive,0.807184,intelligent chatbot Ask,"Company, Company, Company, Person, Company, Company, Location, Location","Share this post:
“How do I turn on my rear defroster?” and “What type of fuel does this car need?” are the kinds of questions that can send new car owners diving into glovebox for the car manual. Or, they simply start pressing random buttons, hoping for the best. Those days, however, may be over.
Daimler AG and IBM have jointly developed the virtual assistant, “Ask Mercedes,” based on IBM Watson conversational technology and the IBM Cloud. The chatbot helps drivers get immediate responses to questions about their cars. From December on available in South Africa and Malaysia (India and Hongkong following in 2018) in the E- and S-Class, the intelligent chatbot Ask Mercedes leaves (almost) no questions about the functionalities of these vehicles unanswered.
Ask Mercedes is designed to help not only Mercedes owners – who are getting behind the wheel of increasingly feature-rich vehicles – but also users of car sharing or rental services who may be particularly unfamiliar with newer updates. Ask Mercedes can either be downloaded as an app or accessed via Facebook and other messenger services, with future plans to embed this AI assistant in the vehicle itself.
Car manuals are usually consulted only as a last resort, and sometimes not at all – which can compound what might start out as a relatively minor issue. Mercedes’ goal is to ensure that all drivers are able to quickly and easily access accurate information about their vehicles.
Recognizing that many users are more willing to query an app, rather than flip through a manual or phone a call center, Mercedes has brought AI from IBM Watson to the experience – introducing an application that knows the car and its functionalities by heart. Users can pose questions specifically about their vehicle, as they would to a knowledgeable Mercedes expert, and can also ask general question about Mercedes features, such as the new EQ design for Mercedes electric vehicles.
By making Ask Mercedes available on multiple channels – including via Facebook Messenger – Mercedes is helping to provide drivers with a consistently high level of support, whether they’re asking a quick question or investigating a more complex issue. Either way, the carmaker wants to ensure that drivers can get back on the road quickly and safely.
To make sure drivers are getting the most precise information, Ask Mercedes can also pose follow up questions to better understand what the driver is asking. It can also answer questions with the aid of multi-media content, such as graphics or drawings.
But the chatbot also knows its limits: If it realizes that it cannot answer a question, it refers the user to additional information or the call center.  As the vehicles become ever more sophisticated, technology can also play a role in enhancing the driver’s comfort with these changes. Above all, technology like Watson is a tool to assist humans – to help them make better-informed decisions, to help answer their of-the-moment questions and sometimes, to help with a smoother ride.
",intelligent chatbot Ask,Company,blue,telephone,telecommunication,telephone,-
https://ibm.co/2piRDl0,187446750783_10155787548720784,https://www.facebook.com/ibmwatson/posts/10155787548720784,"Meet &quot;Olli,&quot; a self-driving bus that uses #AI technology to assist people with disabilities. ",Link,,,8/3/18 9:34, ,9320,9320,0,12830,12830,0,182,92,112,9,9,11159,8344,0,0,141,0,0,0,0,0,0,0,0,0,0,14,95.0,6.0,14,100.0,9.0,46,51.0,,,60,52.0,,,1,8.0,,1,8.0,,Local Motors and IBM are equipping an autonomous electric shuttle bus with technology that assists people with a range of disabilities.,https://cdn.technologyreview.com/i/images/copy-of-olli-at-phoenix-lm-2.jpg?cx=0&cy=458&cw=3000&ch=1687&sw1200,https://www.technologyreview.com/s/604116/a-self-driving-bus-that-can-speak-sign-language/,joy,0.438289,neutral,0,quot,Hashtag,quot,Hashtag,sadness,0.092443,negative,-0.625597,"Local Motors, autonomous electric shuttle bus",Company,Local Motors,Company,sadness,0.461357,negative,-0.297226,city buses,"Person, Person, Company, Company, Company, HealthCondition, Person","It’s been 15 years since a degenerative eye disease forced Erich Manser to stop driving. Today, he commutes to his job as an accessibility consultant via commuter trains and city buses, but he has trouble locating empty seats sometimes and must ask strangers for guidance. 
A step toward solving Manser’s predicament could arrive as soon as next year. Manser’s employer, IBM, and an independent carmaker called Local Motors are developing a self-driving, electric shuttle bus that combines artificial intelligence, augmented reality, and smartphone apps to serve people with vision, hearing, physical, and cognitive disabilities. The buses, dubbed “Olli,” are designed to transport people around neighborhoods at speeds below 35 miles per hour and will be sold to cities, counties, airports, companies, and universities. If the buses enter production in summer 2018, as planned, they could be among the earliest self-driving vehicles on U.S. roads. 
Since Olli is fully autonomous and does not have a human driver, it uses IBM’s AI-powered Watson technology to converse with passengers (via voice and text displayed on an iPad). Olli navigates using radar, lidar, and optical cameras from a company called Meridian Autonomous. Before deploying in a neighborhood, Meridian Autonomous constructs 3-D maps of the area that Local Motors says are accurate to the half-inch. A human fleet manager then determines the bus route. When Olli detects an emergency via its various sensors, it will stop, notify a (human) remote supervisor, and independently run through a checklist of possible problems. “If a passenger has a medical problem or [there’s a safety issue], Olli will call the authorities or drive itself to a hospital or police station,” says Gina O’Connell, a Local Motors general manager who is leading the project. 
Local Motors and IBM started collaborating on Olli in early 2016 and produced a first iteration of the bus in June 2016. That vehicle is currently in trials in Germany and Switzerland. It is the next—second—generation of Olli that will include assistive technologies. That version, which the companies call “Accessible Olli,” will be manufactured starting in 2018, and will retain Watson as a tool for communicating with passengers and add additional Watson features. 
Local Motors and IBM are still testing technologies, but have already identified some capabilities they are likely to add. Future Ollis, for example, might direct visually impaired passengers to empty seats using machine vision to identify open spots, and audio cues and a mobile app to direct the passenger. Olli could also guide passengers via a special type of haptic feedback that uses ultrasound to project sensations through the air. An array of haptic sensors could be designed into every seat, and when people walk down the aisle they would feel a vibration on their hand or arm to alert them that they were at an empty seat, explains Drew LaHart, the program director for IBM’s accessibility division.  
For deaf people, the buses could employ machine vision and augmented reality to read and speak sign language via onboard screens or passengers’ smartphones. LaHart says that Olli could be trained to recognize sign language using machine learning and Watson’s image recognition capabilities. If the bus were equipped with AR technology, it might be able to respond via a hologram of a person signing. 
Machine vision could also enable Olli to recognize passengers waiting at bus stops who have walkers and wheelchairs. The bus would then activate an automated ramp to help them board and then deploy equipment that would secure their assistive devices, locking a wheelchair into place, for example. 
Another potential Olli technology combines machine vision and sensors to detect when passengers leave items under their seats and issues alerts so the possessions can be retrieved, a feature meant to benefit people with age-related dementia and other cognitive disabilities. 
This would all be a significant improvement over the typical bus accommodations of today, which are limited to wheelchair ramps and lifts and audible and visual bus route updates. Local Motors, IBM, and the CTA Foundation, the charitable arm of the Consumer Technology Association, a trade group for the consumer electronics industry, and a partner in Accessible Olli, have spent the past three months soliciting ideas from disability rights organizations and retirement communities, among others. Manser, who works for IBM Accessibility, has organized a workshop with blindness organizations and public transit agencies and attended an MIT assistive technologies hackathon in March to explain the challenges he encounters on public transportation. 
Local Motors plans to keep soliciting public input for several more months. In July, it will devise an engineering plan for the new version of Olli, select suppliers, and calculate the cost of fabricating the bus. It aims to sell the vehicle for about $250,000 and will also offer a leasing-subscription service that would cost $10,000 to $12,000 a month and include hardware upgrades. Because Olli is mostly manufactured on-demand, through 3-D printing, its design can be tweaked quickly in response to user feedback, says O’Connell. 
The company expects public transportation operators will be its main customers and hopes that cities will buy the buses to fill in gaps in their regular transit systems and not just as paratransit vehicles for disabled people. 
For those with disabilities, though, Olli could be a big improvement over the current options.  Door-to-door paratransit service tends to be slow, has to be scheduled ahead of time, and is only available to people who qualify for it, says Henry Claypool, who is the policy director of the Community Living Policy Center at the University of California, San Francisco, and a wheelchair user. “It’s much more reliable to be able to get on and off a bus at the same place and have a predictable schedule, especially if the bus has this type of assistive technology,” he says. 
Olli offers a way to address important limitations of public bus and train systems as well, says Susan Henderson, the executive director of the Disability Rights Education and Defense Fund. The Americans with Disabilities Act mandates only that “key” train and subway stations be accessible, which means that people with wheelchairs, walkers, and scooters often have to travel several stops out of their way to get home or to a destination, says Henderson. “If I still had 10 blocks to go after getting off at my local station, having an Olli rolling around my neighborhood would make a big difference,” she says. 
",city buses,Person,steel blue,shuttle bus, , , 
https://ibm.co/2vvRI8J,187446750783_10155785798520784,https://www.facebook.com/ibmwatson/posts/10155785798520784,How IBM Watson is partnering with Scholastic and Edmodo to enhance education with machine learning: ,Photo,,,8/2/18 12:36, ,9868,9868,0,13700,13700,0,146,94,118,7,7,12168,8801,0,0,115,0,0,0,0,0,0,0,0,0,0,14,68.0,2.0,15,73.0,2.0,37,20.0,46.0,,49,21.0,48.0,,2,5.0,,2,5.0,,IBM announced a strategic partnership with Scholastic and Edmodo that’ll see the two company’s technologies integrated with IBM’s Watson Education platform,https://venturebeat.com/wp-content/uploads/2017/06/ibm_watson_avatar_pos-e1560280426131.jpg?w=1200&strip=all,https://venturebeat.com/2018/06/26/ibms-watson-education-partners-with-scholastic-and-edmodo-for-classroom-content-recommendations/,joy,0.066597,neutral,0,"IBM Watson, machine learning","Company, Company",IBM Watson,Company,joy,0.062809,neutral,0,"strategic partnership, company’s technologies, IBM, IBM’s Watson Education platform","Company, Company",strategic partnership,Company,joy,0.526964,positive,0.858103,"IBM today, IBM’s Watson Education platform","Company, Company, Company, Person","IBM today announced a strategic partnership with Scholastic and Edmodo that will integrate the two companies’ technologies with IBM’s Watson Education platform.
Scholastic said that it’ll make available media, articles, and nonfiction content from its Scholastic Go and ScienceFlix libraries in IBM’s Watson Education, which will use machine learning to cater recommendations to individual students’ abilities and curricular needs.
Edmodo, for its part, will contribute to the development of a tool that’ll use its AskMo search engine and IBM Watson Classroom’s Cognitive Library — a collection of textbooks, test questions, and lesson plans hosted in the cloud — to recommend educational content and resources aligned with students’ grade levels, ages, and interests.
“It [will] help teachers to know where students are in their learning progression,” Chalapathy Neti, vice president of IBM Watson Education, told VentureBeat, “and recommend a piece of learning content that is suited to different learning styles … and preferences. It answers the question, ‘How do I optimize a piece of learning content that teaches a learning objective?'”
IBM says it’ll leverage the Cognitive Library to improve content tagging. And in the coming weeks, teachers who use Edmodo will be able to tap Watson Tutor — a system that uses natural language processing to guide students through review sessions — to assign topic-specific quiz questions.
“Our goal is to create augmented intelligence that’s of value to teachers,” Neti said. “[That’s] why we’re going to places where partners had an existing footprint to make it simpler for teachers to adopt.”
Watson Education comprises two products: IBM Watson Element and IBM Watson Enlight. The former consolidates academic, social, demographic, and behavior data about students in one place and provides insights to teachers about how to best support individual students in the classroom. The latter, Watson Enlight, shows students’ academic strengths and weaknesses, lets teachers plan lessons with activities that align with classes’ needs, and offers learning progressions created by the National Academy of Sciences, Student Achievement Partners, and others.
IBM’s Watson Education reaches more than 200,000 students in states including Texas, California, Florida, Connecticut, and Ohio. IBM says that in an A/B experiment involving more than 800 community college students, Watson Tutor improved academic performance by as much as 40 percent.
Scholastic and Edmodo are only the latest additions to Watson Education’s stable of partners. In June 2017, through a collaboration with Sesame Workshop, IBM built a vocabulary app and a platform — the Sesame Workshop Intelligent Play and Learning Platform — to create a series of cognitive apps, games, and toys. And in 2016, IBM signed a deal with Pearson and Blackboard to bring IBM’s education ecosystem to colleges and universities.
",IBM today,Company,emerald,rubber band, , , 
https://ibm.co/2pRDP1T,187446750783_10155784216530784,https://www.facebook.com/ibmwatson/posts/10155784216530784,"&quot;One of Watson’s greatest values is being able to train it on specific industries and their corresponding data. It’s highly attuned to what our clients need. What’s exciting about my role is I get to sit at this critical intersection — my role is one that helps connect our IBM Cloud technology with Watson. &quot; Get to know Kelly Abuelsaad from the IBM Watson and Cloud platform team, who has more than 35 patents in her name. ",Link,,,8/1/18 19:06, ,8858,8858,0,12419,12419,0,170,136,173,11,11,9692,7197,0,0,89,0,0,0,0,0,0,0,0,0,0,5,50.0,4.0,7,53.0,5.0,109,34.0,1.0,,135,37.0,1.0,,5,6.0,,5,6.0,,"With over 35 patents, Kelly Abuelsaad is a member of the IBM Watson and Cloud Platform team, where she helps bring AI to clients.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/03/blog_kellyWatson_png_socialTile_032818.png,https://www.ibm.com/blogs/watson/2018/03/how-watson-ushers-creativity-through-collaboration/,joy,0.188572,positive,0.883383,"Watson’s greatest values, critical intersection","Person, Person, Company",Watson’s greatest values,Person,joy,0.081766,neutral,0,"Kelly Abuelsaad, member of the IBM Watson, patents","Person, Company",Kelly Abuelsaad,Person,joy,0.652825,positive,0.742267,,"Company, Person, Person, Person, Person","Share this post:
With over 35 patents, Kelly Abuelsaad has always had a passion for creating, whether she’s been playing guitar or finding a new way to apply technology to everyday tasks.
Kelly is a member of the IBM Watson and Cloud Platform team, where she helps bring AI to clients via the cloud. From tinkering on projects in her studio to working within a large group to find answers and patent new technologies, Kelly never stops thinking about what’s possible with AI.
Kelly expands on her career path in AI, the value of teamwork during the creative process, how she strives to improve efficiency through inventing — and the role her team has played in helping IBM achieve 25 years of patent leadership.
 How did you become a Master Inventor at IBM? What’s the process of inventing something?
Technology has always fascinated me. It holds such opportunity and great promise that I couldn’t help but tinker in computers and science at a very early age. I took BASIC in high school and was hooked. I ended up majoring in information technology because in IT, you work with an entire system. You build and orchestrate a whole data center and you get to understand how things intertwine and operate from the ground up. At IBM, my first job was as a systems administrator on a developer team. I was struck by how great the technology was, but it needed to be simpler. It needed to be easy for customers to understand and use.
That’s how I eventually came to be a Master Inventor at IBM. A Master Inventor is frequently involved in a number of areas – including inventing new products and services, mentoring others and evaluating ideas. One thing I’ve learned is that solving technical issues is only one part of what it means to be a successful innovator. Inventing involves brainstorming with colleagues and working to develop applications that could become patents or core services for our clients. It’s about being collaborative, sharing ideas – and knowing how to work with people. I’ve always been what I consider to be a “tech person.” I enjoy tinkering on my own, and still do that quite frequently – but I’ve grown to understand the value of creativity and the perspective of others. I honestly have found the whole brainstorming process fun and addictive.
An invention is a solution to a problem, and there are always multiple solutions to any given problem. I start by asking, “Is the solution I’m developing unique?” Then I next ask, “Is the solution I’m coming up with better than other solutions?” For example, if you need a better way to tie your shoes and you develop an invention to help this problem but it takes five minutes longer, it’s technically unique, but not very useful. If what I’m creating makes a process faster and more adaptable, that’s when I think there might be something there. I also factor in if it’s useful for IBM, in terms of it positively impacting our business.
How are you helping to change the way businesses work? 
One of Watson’s greatest values is being able to train it on specific industries and their corresponding data. It’s highly attuned to what our clients need.
What’s exciting about my role is I get to sit at this critical intersection — my role is one that helps connect our IBM Cloud technology with Watson. The amount of data that’s in the world is exploding. Tools like Watson help us make sense of all that information and knowledge, while advanced cloud platforms can process and securely manage that data. Without both those pieces, neither is as valuable. I’m responsible for continuing to connect these dots, making the process more seamless and intuitive by creatively applying these technologies.
A tangible output of that, which gets me out of bed in the morning? AI is evolving, scaling and becoming more accessible, every day. The progress this industry has made in just a few years is incredible. We are constantly improving Watson so it can learn better, make more sense of data and easily train models according to each industry.
My job is to create common components so our brilliant IBMers who are creating the internal intelligence of Watson can continue focusing on those algorithms without being hindered. The result is that the capabilities of Watson are improving at a faster rate and we have better response times for training and serving models.
You play guitar. You’re a new mom. How do you think these important roles and skills outside of technology have improved your technological creativity? 
If you’re playing an instrument, you can read the music notes off a sheet and play a song. In the same vein, if you’re a software developer, you can get design plans and write the code to create a program. You do both by following the requirements; you’re following someone else’s instructions.
You can create wonderfully beautiful things this way and have lots of fun doing it. However, I’ve found a whole new level of enjoyment and empowerment in coming up with my own ideas – writing that song myself, kickstarting a new invention myself. This can be very hard because putting your own ideas out there for others to listen to makes you vulnerable. But if having a son has taught me one thing, it’s to not take myself too seriously. I’ve learned that parenting often involves coming up with creative solutions. Some ideas end up being great, and some end up being less than stellar. But in the process, I’ve learned how creative I can be by just allowing myself to take a chance.
I encourage everyone I work with to be creative in many different ways. The more experience you have, the more things you’ll learn and the better perspective you’ll have. I’ve learned, quite by accident as I never thought of myself as a creative person, that creativity is a skill that is earned through experience. Get out, try new things — and most importantly, enjoy what you do.
For more information about IBM Watson, visit ibm.com/watson. You can also follow Kelly on Twitter at @kellyabls.
",,Company,coal black,woman,person,female,woman
,187446750783_10155781314280784,https://www.facebook.com/ibmwatson/posts/10155781314280784,"&quot;Yesterday, we pioneered for today; today, we are pioneering for tomorrow.&quot; – Thomas J. Watson, Sr.",Photo,,,7/31/18 10:48, ,6836,6836,0,9447,9447,0,106,57,72,3,4,8673,6323,0,0,92,0,0,0,0,0,0,0,0,0,0,7,60.0,2.0,9,61.0,2.0,33,1.0,26.0,,43,1.0,28.0,,,4.0,,,3.0,,,,,joy,0.402068,neutral,0,"today, quot",Person,today,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2tzBWti,187446750783_10155779223780784,https://www.facebook.com/ibmwatson/posts/10155779223780784,"As the adoption of AI increases, the issue of preventing bias from entering into AI systems is rising to the forefront. We believe no technology — no matter how accurate — can or should replace human judgement, intuition and expertise. It is therefore critical that any organization using AI train the teams working with it to understand bias, including implicit and unconscious bias, monitor for it, and know how to address it: ",Link,,,7/30/18 10:39, ,10374,10374,0,13703,13703,0,192,100,123,6,6,11329,8563,0,0,133,0,0,0,0,0,0,0,0,0,0,26,94.0,2.0,26,97.0,2.0,67,39.0,,,80,43.0,,,3,3.0,,3,3.0,,"IBM Research is committed to AI technologies developed without bias, including facial recognition technology that's built and trained responsibly.",https://www.ibm.com/blogs/research/wp-content/uploads/2018/06/bias.png,https://www.ibm.com/blogs/research/2018/06/ai-facial-analytics/,anger,0.20593,positive,0.440024,,Person,,Person,fear,0.101333,positive,0.617439,IBM Research,Company,IBM Research,Company,joy,0.453823,positive,0.728211,,"Company, Person, Organization, Company, Company, Organization","Society is paying more attention than ever to the question of bias in artificial intelligence systems, and particularly those used to recognize and analyze images of faces. At IBM, we are taking the following actions to ensure facial recognition technology is built and trained responsibly:
1) One of the biggest issues causing bias in the area of facial analysis is the lack of diverse data to train systems on. So, this fall, we intend to make publicly available the following dataset as a tool for the technology industry and research community:
A dataset of annotations for over 1 million images to improve the understanding of bias in facial analysis being built by IBM Research scientists. Images will be annotated with attributes, leveraging geo-tags from Flickr images to balance data from multiple countries and active learning tools to reduce sample selection bias. Currently, the largest facial attribute dataset available is 200,000 images so this new dataset with a million images will be a monumental improvement.
2) Earlier this year, we substantially increased the accuracy of our Watson Visual Recognition service for facial analysis, which demonstrated a nearly ten-fold decrease in error-rate for facial analysis. And, we are continuing to drive continual improvements. A technical workshop is being held (by IBM Research in collaboration with University of Maryland) to identify and reduce bias in facial analysis on Sept 14, 2018 in conjunction with ECCV 2018. The results of the competition using the IBM facial image dataset will be announced at the workshop. Furthermore, our researchers continue to work with a broad range of stakeholders, users and experts to understand other biases and vulnerabilities that can affect AI decision-making, so that we can continue to make our systems better.
AI holds significant power to improve the way we live and work, but only if AI systems are developed and trained responsibly, and produce outcomes we trust. Making sure that the system is trained on balanced data, and rid of biases is critical to achieving such trust.
As the adoption of AI increases, the issue of preventing bias from entering into AI systems is rising to the forefront. We believe no technology — no matter how accurate — can or should replace human judgement, intuition and expertise. The power of advanced innovations, like AI, lies in their ability to augment, not replace, human decision-making. It is therefore critical that any organization using AI — including visual recognition or video analysis capabilities — train the teams working with it to understand bias, including implicit and unconscious bias, monitor for it, and know how to address it.
As a company that leads in driving diversity and inclusion in the corporate world, discrimination of any kind is against IBM’s values. We are deeply committed to ensuring AI technologies are developed without bias.
For more than a century, IBM has responsibly ushered revolutionary technologies into the world. We are dedicated to delivering AI services that are built responsibly, are unbiased and explainable. Our business has been guided by a set of Trust and Transparency Principles, which includes our firm belief that companies advancing AI have a responsibility to address the issue of bias head-on. And we are continually working to evaluate and update our services, advancing them in a way that is trustworthy and inclusive.
",,Company,alizarine red,bazaar,building,retail store,marketplace
https://ibm.co/2J5NTwv,187446750783_10155776984100784,https://www.facebook.com/ibmwatson/posts/10155776984100784,"With over 5,200 branches, Bradesco is one of Brazil’s largest banks. So how are they able to pay attention to each one of their 65 million customers? Learn how they trained Watson to answer questions with accuracy: ",Link,,,7/29/18 9:15, ,11518,11518,0,15689,15689,0,226,147,193,2,2,13780,10219,0,0,162,0,0,0,0,0,0,0,0,0,0,17,106.0,3.0,17,111.0,8.0,80,73.0,,,116,77.0,,,1,1.0,,1,1.0,,How a Brazilian bank pays personal attention to each of their 65 million customers,,https://www.ibm.com/watson/stories/bradesco/,sadness,0.11589,neutral,0,Brazil’s largest banks,"Company, Location",Brazil’s largest banks,Company,sadness,0.452632,neutral,0,"Brazilian bank, personal attention",,Brazilian bank,,joy,0.487799,positive,0.683831,,"Person, Company, Company, Person, Person","Watson is AI from IBM that seamlessly embeds into your workflows while integrating with the leading platforms and tools enterprises already use. Putting AI at your employees' fingertips when they need it - and where they need it - means empowering your teams to focus on what they do best.
There’s even one inside a boat on the Amazon. When branch employees had questions about products or services, they called a central office, but there was often a long wait for answers. This meant the client was also left waiting, and as one manager put it, “No one likes to wait.”
In a business as competitive as banking, if your customers don’t have a great experience, they may not be your customers for long. So Bradesco started looking for a way to increase the speed of service and also improve the level of personalization for each client. That’s when they turned to IBM and Watson.
Their first task was to teach Watson Portuguese, but initially there were some doubts. “It’s more than just learning the language,” said IBM Managing Director Katia Vaskys. “You also need to understand Brazil’s culture, and the regional accents, and the way each region asks a question.”
But after mastering the nuances of Portuguese, Watson was ready to be trained on the business of banking. To do this, Bradesco and IBM worked together to develop a team that taught Watson about the bank’s products and services by asking and answering questions for Watson in natural language—the same way a customer would. 
“Yes, Watson can learn,” said one IBMer, “but it needs people to teach people who are committed and patient.” Because of this team effort, Watson could understand 100% of written questions and 83% of spoken ones after just 5 months of training. And after 10 months, the system was answering 96% of all questions correctly.
Now Watson is trained on 62 products and answers 283,000 questions a month with a 95% accuracy rate, with just 5% requiring calls for further assistance. In some cases, response times have been reduced from 10 minutes to just seconds. “It’s a real wow factor,” exclaimed one manager.
This helps employees have more enriching interactions with clients, because they have time to dedicate to providing the best possible customer experience. “This is when growth happens,” said the Bradesco AI Lead, Marcelo Camara. “Our current clients notice the improved service, which in turn attracts new clients, and this is what helps the bank scale.”
",,Person, , , , , 
https://ibm.co/2KQijYY,187446750783_10155775903205784,https://www.facebook.com/ibmwatson/posts/10155775903205784,"Because AI is becoming increasingly powerful, existing computer hardware is slow to keep up. That's why IBM researchers were driven to develop a fast, efficient chip designed to train AI. Read more via VentureBeat: ",Link,,,7/28/18 20:55, ,15181,15181,0,20519,20519,0,469,280,340,6,6,16061,11926,0,0,353,0,0,0,0,0,0,0,0,0,0,42,233.0,5.0,43,234.0,5.0,127,180.0,,,156,184.0,,,3,3.0,,3,3.0,,IBM researchers have developed a chip that can train certain kinds of neural networks more efficiently than traditional hardware.,,https://venturebeat.com/2018/06/29/ibm-researchers-design-a-fast-power-efficient-chip-for-ai-training/,joy,0.172484,positive,0.676187,IBM researchers,"Person, Company",IBM researchers,Person,joy,0.139534,positive,0.598685,IBM researchers,Company,IBM researchers,Company,joy,0.563096,positive,0.571738,neural network,"Person, Company, Person, Person, Company, PrintMedia","Thanks to powerful graphics chips and advances in distributed computing, optimizing the algorithms at the core of artificial intelligence is easier than ever before. But it’s not particularly efficient on current-day hardware — even powerful GPUs can take days or weeks to train a neural network.
That catalyzed researchers at IBM to develop a new chip tailor-made for AI training. In a paper published in the journal Nature titled “Equivalent-accuracy accelerated neural-network training using analog memory,” they describe a system of transistors and capacitors that can train neural networks quickly, precisely, and highly energy-efficiently.
Neural networks consist of interconnected units called neurons or nodes (a collection of nodes is called a layer), which receive numerical inputs. In a basic network, individual neurons multiply those inputs by a value — a weight — and pass them along to an activation function, which defines the output of the node. Through a strategy known as backpropagation, the weights are adjusted over time, improving the accuracy of the outputs.
GPUs are well-suited for these because unlike traditional processor, which crunch through numbers sequentially, they’re able to perform lots of computations in parallel. But because the processor and memory in graphics chips sit a considerable distance apart from one another on the motherboard, delays are introduced as data shuttles back and forth between them.
“Conventional computers [consume] consume an enormous amount of energy,” Stefano Ambrogio, a postdoctoral researcher at IBM who led the project, told VentureBeat in an interview, “and there’s a lot of waiting involved.”
The scientists’ solution consists of analog memory and traditional electronic components. Individual cells made up of a pair of phase change memory (PCM) units and a combination of a capacitor and three transistors correspond to individual neurons in the network. The PCMs store weight data in memory, which is represented in the transistors and capacitors as an electrical charge.
As the network trains, the capacitor updates the weights, transferring them to the PCM after thousands of cycles.
The capacitor can’t retain values for more than a few milliseconds, but it can be programmed quickly. And the PCM, which is a form of non-volatile memory, doesn’t need an external power source to retain data.
The researches used a mix of hardware PCMs and software-simulated components to benchmark the design, and the results are promising. The chip performed 100 times more calculations per square millimeter than a GPU while using 280 times less power. Even more impressive, it matched the speed and accuracy of Google’s TensorFlow machine learning framework on a variety of computer vision tasks.
“We can do [the calculations] in a very accurate way, at the same accuracy as software,” Ambrogio said.
The researchers’ chip design isn’t without a significant caveat: It’s not optimized for neural networks that aren’t fully connected, such as the long short term memory (LSTM) networks used in cutting-edge speech recognition apps. But the researchers plan to tackle that next.
Ambrogio is confident they’ll be able to build physical chips at scale in the future. He sees them being used for training neural networks in smartphones and other devices that currently lack the necessary computing resources.
“It would be nice to be able to directly process AI where it’s needed,” Ambrogio said. “When you’re able to train a model, you don’t need to send the information [to the cloud] or have [the device] communicate with something else, and it can react instantly to something.”
",neural network,Person, , , , , 
https://ibm.co/2FafMBI,187446750783_10155772674330784,https://www.facebook.com/ibmwatson/posts/10155772674330784,"&quot;The journey for adopting AI and delivering that for value to clients begins with one very basic proposition, which is, is the AI going to augment and amplify the intelligence of the people using it? Because if it's not doing that, it's probably not going to be very useful. You're going to lose this utility very quickly.&quot; – Watson VP, CTO Rob High in an interview with TechCrunch: ",Status,,,7/27/18 10:13, ,7046,7046,0,9705,9705,0,55,34,42,2,2,9024,6558,0,0,43,0,0,0,0,0,0,0,0,0,0,5,27.0,,5,28.0,,31,3.0,,,38,4.0,,,1,1.0,,1,1.0,,"TechRepublic spoke to IBM's Rob High about the ethical, privacy, and security obstacles that artificial intelligence has to overcome.",https://tr1.cbsistatic.com/hub/i/r/2018/03/01/005c45e1-7e9b-43df-9012-57f7ee9fa3bc/thumbnail/770x578/ea8d0af3f9eb1dfda64080cabc7cdc79/big-booths-mwc-2016-12.jpg,https://www.techrepublic.com/article/ibm-watson-cto-the-3-ethical-principles-ai-needs-to-embrace/,fear,0.137485,negative,-0.477543,basic proposition,"Person, Person",basic proposition,Person,fear,0.228087,negative,-0.589837,"IBM's Rob High, artificial intelligence","Person, Company",IBM's Rob High,Person,joy,0.60699,positive,0.646511,,"Person, Person, Company, Organization","IBM Watson CTO Rob High has done a lot of thinking about the privacy, security, and ethical implications of artificial intelligence. He presented some of those ideas at Mobile World Congress 2018, and we talked to him about some of his key findings.
You can watch the interview above or read the transcript below.  
High said, ""One of the things we have to realize about AI--it's relatively new to all of us. There's a lot about it that we don't all fully understand. Even as a technologist, we know where we're trying to bring the technology, but on the other side there's lots of people for which this technology is new. The experiences around that are going to be different. As with any new technology, it's really important that we be thinking now about how we do that ethically and responsibly. For us, that comes down to three basic principles. Trust, respect, and privacy.
""What that basically means is that when you're using an AI technology, you have to trust that it's going to be doing the right thing. Or you focus on things like, can we create transparency in the AI algorithms? Can we get the algorithms to actually identify your level of confidence (in them), for example.""
SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
""Transparency comes down to can we identify what sources of information are being used? Have we established the right properties, the right principles in place when we train these systems to use data that is representative of who we are, and the information that we're using?"" said High.
""Of course, privacy comes down to recognizing that your data is our data. It should be your choice as to what data you're going to provide in order to gain the benefits these AIs offer. That goes from everything from the privacy of enterprise data, and the data that enterprises bring to the table when they use AIs, maintain separation between each of the enterprises all the way through, to how those enterprises protect the privacy of the data of their clients.""
High added, ""The journey for adopting AI and delivering that for value to clients begins with one very basic proposition, which is, is the AI going to augment and amplify the intelligence of the people using it? Because if it's not doing that, it's probably not going to be very useful. You're going to lose this utility very quickly. First of all, identify what that is. How do you help people do what they do better?
SEE: How to implement AI and machine learning (ZDNet special feature) | Download the report as a PDF (TechRepublic)
""If you get that out of the way then you can begin to look at how to apply the technology, but all through that we really encourage our clients to think about two things. One is, how they're going to protect and preserve the privacy of their institutions, of their clients. But also how do they convey the responsibility of their clients to be aware of what data they're getting across and to challenge those cases where, perhaps they don't want to give up the data they're offering. Or at least to make sure the value they're getting from that data is also very supportive of this idea that's augmented their intelligence.""
",,Person,purplish blue,air terminal, , , 
https://ibm.co/2KJ6yCv,187446750783_10155771384870784,https://www.facebook.com/ibmwatson/posts/10155771384870784,"Nearly four decades ago, IBM released its first PC. Since then, the growth of technology has expanded enormously. Dive into history with IBM Watson CTO Rob High to learn how the computer age unfolded as well as our progression into future of #AI: ",Link,,,7/26/18 18:30, ,5792,5792,0,7850,7850,0,80,48,69,3,3,7290,5434,0,0,70,0,0,0,0,0,0,0,0,0,0,8,44.0,,8,47.0,,30,19.0,,,47,22.0,,,1,2.0,,1,2.0,,,,https://voicesinai.com/episode/episode-55-a-conversation-with-rob-high/,sadness,0.201394,positive,0.788292,"IBM Watson CTO Rob High, Dive","Company, Quantity, Person",IBM Watson CTO Rob High,Company, , , , , , , , ,joy,0.622378,positive,0.482208,,"Company, Person, Person, Person, Person, Company, Quantity","Rob High is an IBM fellow, VP and Chief Technical Officer at IBM Watson.
Byron Reese: This is Voices in AI, brought to you by GigaOm. I’m Byron Reese. August 12th, 1981. That was the day IBM released the IBM PC and who could have imagined what that would lead to? Who would’ve ever thought, from that vantage point, of our world today? Who could’ve imagined that eventually you would have one on every desktop and then they would all be connected? Who would have guessed that through those connections, trillions of dollars of wealth would be created? All the companies, you know, that you see in the news every day from eBay to Amazon to Google to Baidu to Alibaba, all of them have, in one way or the other, as the seed of their genesis, that moment on August 12th, 1981. 
Now the interesting thing about that date, August of ‘81, that’s kind of getting ready to begin the school year, the end of the summer. And it so happens that our guest, Rob High graduated from UC Santa Cruz in 1981, so he graduated about the same time, just a few months before this PC device was released. And he went and joined up with IBM. And for the last 36/37 years, he has been involved in that organization affecting what they’re doing, watching it all happen, and if you think about it, what a journey that must be. If you ever pay your respects to Elvis Presley and see his tombstone, you’ll see it says, “He became a living legend in his own time.” Now, I’ll be the first to say that’s a little redundant, right? He was either a living legend or a legend in his own time. That being said, if there’s anybody who can be said to be a living legend in his own time, it’s our guest today. It’s Rob High. He is an IBM fellow, he is a VP at IBM, he is the Chief Technical Officer at IBM Watson and he is with us today. Welcome to the show, Rob!
Rob High: Yeah, thank you very much. I appreciate the references but somehow I think my kids would consider those accolades to be a little, probably, you know, not accurate.
Well, but from a factual standpoint, you joined IBM in 1981 when the PC was brand new.
Yeah - I’ve really been honored with having the opportunity to work on some really interesting problems over the years. And with that honor has come the responsibility to bring value to those problems, to the solutions we have for those problems. And for that, I’ve always been well-recognized. So I do appreciate you bringing that up. In fact, it really is more than just any one person in this world that makes changes meaningful.
Well, so walk me back to that. Don’t worry, this isn’t going to be a stroll down memory lane, but I’m curious. In 1981, IBM was of course immense, as immense as it is now and the PC had to be a kind of tiny part of that at that moment in time. It was new. When did your personal trajectory intercept with that or did it ever? Had you always been on the bigger system side of IBM?
No, actually. It was almost immediate. Probably was, I don’t know the exact number, but probably I was pretty close to the first one hundred or two hundred people that ordered a PC when it got announced. In fact, the first thing I did at IBM was to take the PC into work and show my colleagues what the potential was. I was just doing simple, silly things at the time, but I wanted to make an impression that this really was going to change the way that we were thinking about our roles at work and what technology was going to do to help change our trajectory there. So, no, I actually had the privilege of being there at the very beginning. I won’t say that I had the foresight to recognize its utility but I certainly appreciated it and I think that to some extent, my own career followed the trajectory of change that has occurred similar to what PCs did to us back then. In other areas as well: including web computing, and service orientation, now cloud computing, and of course cognitive computing.
And so, walk me through that and then let’s jump into Watson. So, walk me through the path you went through as this whole drama of the computer age unfolded around you. Where did you go from point to point to point through that and end up where you are now?
Not long after I began work for IBM, I had an opportunity to take a role in the development of our ATMs, so automated teller machines in our banking industry, development organization. I was, I landed actually working on how to do service and maintenance on these ATMs, writing software for doing dumps on them. But actually, it wasn’t long after that, that I had the chance to influence the thinking around the use of personal computers as the underlying engine for building these ATMs. Up until then, the hardware, the underlying hardware was all proprietary to the problem of creating an automated machine, a machine that people could interact with that could provide teller functions. We saw a potential for other applications and so, we sort of shifted our thinking from being dedicated to ATMs to being more generally applicable to a variety of different self-service terminals and we built that on PCs. We had a X86s at the time, actually 86s and 8186s, later 8286s and that progressed forward.
I was on a team that tried to create a multi-threaded version of DOS, so that we could manage the various IO functions that were being performed in a machine concurrently, whether that was reading your mag stripe or handling display updates or dispensing cash. There’s a lot of parallel processing that was needed for that. Later, that led to work with the OS 2 team, the kernel team to create a headless version of the multi-threaded operating system, which was later superseded by Windows. And then, from there, moved into other forms of banking services including what I consider to be one of the first examples of an underlying middleware that, at the time, we called Application Foundation, that later led to my involvement in distributed object programming, distributed systems and object programming within those kind of distributor systems. Which later then led to I think we called the Soft Object Server, which later graduated into a thing that we now call WebSphere.
I was involved with the creation of the very first component model distributed, component model that later served as the foundation for J2EE Java 2 Enterprise Edition, EJB as in Enterprise Java Beans. The EJB specification was modeled after work that I did early on around server component model and then from there, led the WebSphere team, graduated from that to leading our SOA Foundation for IBM. Realized that one of the key things to anything that we do in the area of technology is creating an association to value, business value, of course is one of the key things we tend to measure, but wouldn’t be of any value of any sort, if it’s not valuable to people, then doing the technology is really not worthwhile. From that, I developed a premise that rather than technologists attempting to figure out how to adapt the technology to the value of the business, how about if the business actually figured out how to adapt their needs to an expression of requirement on technology. That’s not necessarily a novel idea, but I wanted to make that very practical… So we started a project that I called BPSO, the Business Partner Support Organization, which I was in the middle of when they came to me to ask me to take over as CTO for Watson.
Wow, what a walk. So, from PC DOS to OS 2 to Java to Web servers to Watson. ATMs are really an interesting use case because it was predicted they would destroy jobs and yet, what we have today are more tellers than we had when the ATM came out. The ATM lowered the cost of opening a bank branch, which meant banks opened more branches and need more tellers. Did you, do you think that’s a dynamic we’re going to see over and over again as artificial intelligence and automation goes into different areas? Is it actually going to create demand in new and surprising ways? 
That’s actually the trend, I believe, that has occurred with virtually every new technology since the advent of creating technologies. Creating tools. I make the point often that some of the earliest tools, hammers, axes, later shovels, and what became hydraulics, and so on and so forth, all of those have sort of had the same fundamental characteristics, which is they tend to extend and amplify our human strengths. And that process of amplifying, finding ourselves, amplifying the things that we do, while it will change the nature of the work that we do, I mean we’re no longer scratching holes in the ground with our fingers, but we’re able to then do so much more with that that it opens up all kinds of possibilities. Things at the time that when we created tools we probably weren’t thinking about. You mentioned earlier about the advent of the PC and how that’s changed our industry. Think back, only just 10 years ago, and the advent of smartphones and what that has done to change the nature of how we operate on a daily basis, as individuals, as human beings. And I do think the same effect is starting to grow here with AI. And while we can already see some of those benefits in terms of offloading some of the mundane and tedious tasks that people perform, so they can open their time to doing more creative things, I don’t think that we know yet the extent to which we’re going to find new uses, new utility, new value for this technology as we go forward.
I’m in total agreement with you on that. That one side of the equation, “Oh my gosh, that job’s been eliminated” is really obvious in the front, and that, “Oh my gosh, these 10 jobs are created down the line because of that” that’s all kind of… not obvious. So, you just see the obvious half of the equation. I’m completely on board with you there. That being said, we do have cases where technology has had a dramatic effect on overall employment, negatively. The number one case touted about “oh my gosh, automation’s awesome” is, for 10,000 years, it took 90% of us to grow our food. Now it’s 2%. There’s no question there’s fewer people in the food industry than there were 100 years ago, 1,000 years ago, 10,000 years ago. So that happens. So, in your head, how do you paint the offset to that? How do you say, “Yeah, that happens, but we maintain full employment the whole time?” What do you think is going on there for the dynamic that offsets even areas where automation does unequivocally eliminate sectors?
Yeah, one thing we should keep in mind here when we talk about this, is that while what you said is true, that is a fraction of a percent of the number of - the percentage of the total number of people working in the food industry as a percentage of the population is smaller, the population itself has also grown at the same time. So I don’t know where that lands in terms of the actual physical number of people but that said, I mean, we need to be mindful of that. We also have to be open to it. Nothing is really ever as extreme as we tend to paint things. I’m not going to discount the fact that there are some people who won’t be doing what they were doing before. And that does happen and when it happens, it can be very disruptive for those individuals. More often than not, what I’m seeing right now, in the case of AI, this won’t replace entire individuals. It doesn’t sort of take and eliminate what that person does for a company or anything else that they do. It does eliminate some of the tasks that they perform and so, an example of that would be in a call center. We see a call center agent that today, they are up until now, have had to answer a wide range of questions that people ask when they get on the phone or get in through a contact channel. Everything from “What are your hours of operation?” all the way through to, “Hey, I’ve got this product I just bought and it’s not working. I need help fixing it.” And if you look at that range of problems that people present, there’s a fairly large percentage of those problems that are really pretty tedious and mundane and don’t bring a whole lot of satisfaction to anybody.
Knowing what your hours of operation are? I don’t know if I need another person there manning the telephone to tell me what time they’re open. I can look up that on the web. I can look that up through an IVR. I can get it through a conversational agent, not only does that help me as needing an answer to that question, get to that answer quicker, but for the person at the other end, that’s kind of tedious and mundane question to have to deal with all day long if that’s the only thing you’re dealing with. If instead  having something else answer these questions for you, frees you up to now go and work on really interesting problems. If I as a client have a problem, I begin with a fairly simple question that can be answered by a conversational agent; eventually I might get to the more important, salient, and challenging question. If at that time, I turn it over and talk to a human, that call center agent not only is going to be able to address that issue in ways that today most AI systems aren’t even capable of, but for them, they get to go home at the end of the day feeling like they did something really interesting, really useful. They helped someone in a really meaningful way.
For the consumer, that means they got their problem solved that much faster. So there’s kind of a win-win all the way around in a lot of these situations that isn’t really about people losing their jobs, it’s about freeing them up and giving them the time and energy to go concentrate on more creative problems, creative issues, exercise their own creativity in ways they simply couldn’t before, because of the amount of time they spent doing the tedious stuff.
Fair enough. So to change the topic just a little bit, let’s talk about transferred learning. So humans have this great ability that we can be trained on a sample size of one thing. I can show you an object you’ve never seen before, some weirdly-shaped object, and I can say, “Find this object in all these photos” and the object could be partially obscured, it could be underwater, it could be covered with molasses, it could be chewed on by a dog, it could be any number of these things and we’re like, “There it is! There it is! There it is! There it is!” But machines, they have it, and they seem much more rigid and brittle, but what are we doing there? What are we good at that we haven’t figured out how to teach machines to be good at yet?
Well there’s a degree of sophistication in our human mind, in the structure of a human mind, the pathways of analysis that we execute. There’s just a degree of complexity and sophistication, beautiful complexity, if you will, that we hardly understand for ourselves, let alone have figured out how to replicate in computing systems. We talk a lot about neural nets in computing systems today, as sort of the underlying technology for AI systems. But those neural networks that we’re emulating in software or  sometimes now even in hardware, are really, by comparison, very simplistic, very primitive. And so, a lot of this comes down to not having nearly enough complexity in the computing system, let alone then trying to understand what kinds of complexities are important and valuable. And value is of course another big part of this. Where is the motivation that drives us to want to increase complexity when in doing so, we also have to deal with the consequences of that complexity? So I think that a lot of this is where we are in time; some of it is around our basic level of understanding. And then a great deal of that will be determined over time by the economics of our field.
If you hold a general intelligence out, an AGI’s this thing that we kind of intuitively know what it would be like interacting with. We have a conversation with it, and it can do a range of things, a lot like you can. So I often ask my guests, “do you feel like our existing techniques that we have that’ve given us narrow AI, that’ve given us Watson, that’ve given us these amazing things, are we on the way to that? Or is that thing, that AGI, a completely different thing? And it only really shares the words artificial intelligence; that’s kind of just a linguistic quirk. It has nothing to do really with the kind of stuff we’re building today?” What would you say?
Well first of all, there’s been a historical debate about what people mean by AI. I think in the early days, in our naivety and hubris, we tended to gravitate more towards this, as you said, intuitive notion that AI ought to be about replicating the richness and breadth of the human mind. The way that Von Neumann put it, there ought to be as many… computers ought to be able to answer as many questions as there are people to ask them, is what it’s saying. So I think that there was this perception that computers ought to and AI ought to lead us to sort of the same kinds of intelligence that we see in human beings. I think since then, we’ve come to understand two things: One is that it’s really no longer about replicating the human mind for the sake of replicating the human mind. It’s really about doing things in computers that benefit human beings, so I prefer the term augmented intelligence over artificial intelligence because I think that it comes closer to representing what’s useful and meaningful.
The other thing is, I think we have the challenge in defining what intelligence is. This again is another debate that I think that has been going on for decades. What is intelligence? Let’s just assume that our own human intelligence could be clearly defined and quantified. First of all, that what we have established as human intelligence is really the product of eons of evolutionary selection that required us to create a certain way of thinking as a way of surviving, as a matter of survival. I don’t know that that’s the kind of intelligence we would demand of a system or computer that is intended to help us with practically anything. What we want its intelligence to be is the kind of intelligence that we don’t possess; the kind of intelligence that is in that space beyond where humans tend to focus our attention, the things that we’re really good at. And what’s really neat is the form of intelligence that augments that, that amplifies that, that does the things we’re not good at, like assimilating the relationships and the connections and information at massive scale. We’re just not good at that.
Even our ability to recognize, which is the dominant form of AI today, is around recognition tasks. A machine can see things at a level of resolution that our own human eyes cannot, that our own human brain cannot fully resolve. So there’s places where we need help and we can benefit from that help, where a machine can do certain things that not only are we not capable of doing, but we don't’ really have much interest in doing. It’s not about a jobs problem. It’s about how do we do our jobs better because we now have this tool available to us to help us do things we couldn’t do before.
Yeah, it’s true. We don’t have a consensus definition of intelligence. We don’t have one of what we mean by artificial. We don’t have a consensus definition of the word life or the word death. The words… seeing, recognizing, understanding. We don’t have a consensus definition of creativity. I mean there are a lot of these things that only exist in nebulous concepts. That being said, it’s interesting to me that science fiction doesn’t just kind of predict the future. In a way, it makes it. There was an X Prize to make a tricorder like Dr. McCoy used. And Uhura, she used the Bluetooth device. Any way you look at it, that was a Bluetooth device in her ear. And you see these things up on the screen… When I have people on the show, they often tell me, specifically with Star Trek, they’re inspired by it. And more than once, people tell me “I want to build the Enterprise computer.” You can just ask it anything and it will answer it. And that is, the enterprise computer didn’t, Majel Barrett voiced it. It didn’t really have any personality or anything. Then you go one step beyond that and they want to build Commander Data. And the enterprise computer, but it also had “personality.” It’s a hard word since it’s got the word person in it. So, let me ask it a different way. Can we build the Enterprise computer, which is a Von Neumann Machine that can answer any question? And can we build Commander Data today? Could we? Will we? We seem to be wanting to because we build all these devices, that, if I say any of their names, they’re all sitting next to me and they’ll perk up, but we have all these devices that we’re building that seem to want to do that. So, are we going to build that? 
So, first of all, let me say that I think that the task of being able to infer answers to questions based on conducting a survey of literature, is very real. I mean, that’s certainly approximately what Watson was doing on a game of Jeopardy… reading hundreds of millions of pages of literature and finding in that literature recorded evidence of answers that were applicable, that could be evaluated and measured against their applicability to the question being asked. So the answer to that clearly is yes. And whether that’s done against literature, done against more structured sources; that seems to have a lot of utility. If nothing else, it becomes the next generation of what we used to think of as search. Instead of putting in keywords, you get answers or potential sources of answers. We’re now getting to a point where we basically ask a question and get those answers, those questions answered from facts from literature. The next phase of progress is I think going to be about deductive reasoning, which is deriving answers, inferring answers, where the answer was not previously recorded, [but] rather it has to be kind of made up, if you will. Constructed.
Now, I expect the vast majority of that will be centered around forms of deduction that rely on axioms that are relevant to a particular domain. So if I wanted to ask questions about the probability of somebody getting in an accident in their car and having to claim damage, that’s something that we’ve done typically from actuarial tables and other forms of predictive analytics using quantitative data. If we add to that some qualitative aspects of life, whether that’s knowledge about how people’s emotions react to different weather circumstances and stuff like that, then we might be able to do even a better job applying those axioms, building answers to questions like “Is this person going to get in an accident today?” I think that where it becomes much more problematic to predict where this technology will go is when you start thinking about what we call adductive reasoning, which is the process of reasoning that generates those axioms. What happened eons ago that caused someone to realize that when adding two numbers together you get a product, you get a sum, that could be reliably produced over and over again, given two different pieces of information.
What were those axioms, how did that person come up with that axiom? What was the process of generating the axiom of mathematics? And of course, I can give you a simple example but think about all the more complex bases. How does the doctor come to understand that when they see a patient with a certain combination of symptoms that they ought to be considering this test or that test or this diagnosis or another one? There was a creative process involved there that I think still eludes us when we think about this from an AI standpoint. Now you also asked, “Should we expect that, will we do that?” I think then we’ve got to start thinking about economics and what is valuable to people to have the AI systems participate in? Because at the end of the day, people are not going to invest in creating these technologies beyond an academic consideration unless there is some way of creating value from the creation of the technology.
And if people aren’t going to pay for it, they probably won’t do it or they won’t do it for very long. If you do pay for it, then they will or if it has some sort of other economic [value], I say economic here very loosely because it doesn’t have necessarily have to be for financial gain. It can be for the gains or benefits that we get when we’re able to form better and tighter relationships with each other or when we’re able to increase our leisure or enhance our entertainment. Whatever. I mean there needs to be some sort of incentive that motivates the creation and the sustaining of these technologies. We’ve seen history littered with lots of failed technology advances that didn’t make sense. Go back to Star Trek. Certainly with the flip phone, you could say it was a good approximation of the Star Trek communicator device. You flipped it up and I’ve seen stories of the early inventors of the flip phone attempting to emulate that science fiction.
But that’s funny, you don’t see flip phones much anymore. We’ve moved beyond that technology that was inspired by our imagination [and] turned out to not have as much utility as being able to touch a screen and manipulate icons on that screen.
Some of the use cases though for an artificial intelligence that can interact with people, and you gave the simplest one, include a call center to handle the simplest most straight forward questions that would drive a human crazy to do. But you go to the other extreme of that and… caregivers for the elderly is often cited, daycare workers, and greeters… all sorts of places where you would expect in a human to find some amount of emotional engagement. Do you have any worries or qualms or concerns about giving these systems human voices, human names, and getting them to simulate human emotion? Let’s say about how Weizenbaum ended up feeling about ELIZA… that there’s something inherently dishonest and misleading about doing that? Or is that not even something you think about?
No, I actually do think about this and I am worried about that. I do believe that it is important that we be honest and transparent in both the delivery of these technologies as well as in our demands of how we use them. We formed with a number of other companies around this, the Partnership for AI, in which we sort of debate some of these ethical issues. And certainly as a group, we’ve come to the conclusion that AIs should not represent themselves. They should not attempt to pretend or masquerade to the end user as being another human being. And that’s not saying they won’t take on some anthropomorphic properties, because there is a benefit that comes from trying to communicate with human beings to be able to do so in a way that people recognize as having meaning.
For example, when you and I are talking as human beings, it’s not just our words that we’re exchanging. We’re amplifying and punctuating those words with inflection and intonation and cadence in our vocalization of those words. If you were in person, we might also be feeding off each other’s body language or eye contact or facial expression, hand movements, all those things that help human beings understand the meaning and the intent behind the words. So there may be some anthropomorphisms that get engaged, but the net result should not be to suggest that any of these digital assistants, these conversational agents, are in fact human and no one should ever be misled into believing that what they’re interacting with is a human being, when in fact what they’re dealing with is a digital agent.
The thing about Weizenbaum though is, everyone knew ELIZA was a robot. He wasn’t concerned about full disclosure. Not a robot, a bot. He wasn’t concerned about full disclosure. He said even fully knowing it, that you project all this onto them, like it has a name… It’s like you might treat an intelligent agent one way if its personified in a human and you might treat it a completely different way if it were a personified as a giant walking banana. As a human, you give it all of this cred, you assume that it feels and it cares and you just project all this stuff onto it.
That’s right.
And so you can, 12 ways to Sunday, tell everybody “I’m a robot.”  It could be wearing a shirt that says I’m a robot but if it looks human enough and sounds human enough, people will still… I guess what I’m saying is, I noticed that when I interact with even the very rudimentary devices I have now, and one of them is going off and telling me way more than I want to know and I say, “Stop!” the way I would never talk to a person. I wonder if that has a numbing effect on human empathy and the way we interact with humans.
Yeah, I’ll give you another example of why this is important. And that is, that there is a group of people in our society today that I think oftentimes we associate them with being millennials, but I don’t think it’s as limited as that. There are certain people who almost to some extent prefer to deal with a digital end point, as opposed to a human because of the anonymity that it represents and so, not only do they want the assurance that what they’re dealing with is not a human being, because it gives them some comfort in the anonymity, but also, if there were that reassurance, they we wouldn’t want to be fooled into thinking otherwise. In other words, we certainly wouldn’t want for a human being to jump on the line and continue the conversation without that end user knowing that they’re now switching from a non-human endpoint to now a human.
So it goes both ways. It’s something that we’ve got to be conscious of and something that, again as us, as providers of technology, IBM I’m speaking of here, as people who integrate these technologies into their solutions, which oftentimes are other people. As well as of course the end users. We as end users of these technologies, as consumers of these technologies, all of us play a role. We ought to sustain our responsibility in ensuring that this technology is being used appropriately, that it’s transparent about what it is, that we’re demanding it be used and provided to us in a way that it reinforces that. If 12 ways to Sunday is not enough to make that clear, add another - 13, 14, I don’t know how many different ways you have to say it, but keep on reinforcing it. What you’re dealing with here is a conversational agent at this point in time, or later, from the conversation you switch over to human, [announce]- “What you’re dealing with now is a human.” And just make it very clear to people, both so they don’t get unnerved, but more importantly, they don’t get fooled into believing something they shouldn’t.
What was your involvement, if any, in Kasparov and Deep Blue?
I didn’t have any involvement. I had the opportunity to meet Garry the other day.
I saw that on your LinkedIn and that’s why I was asking.
Yeah, I was at a speaker session where Francesca Rossi, Dr. Rossi from our team, who actually leads all our ethical discussions [spoke]. She and Garry Kasparov had a chance to speak together.
You’re undoubtedly of course quite familiar with this, so I just want to ask you two brief questions about it. So one, Kasparov said at the time, “at least Deep Blue didn’t enjoy beating him.” Do you think that someday a computer will enjoy beating a human? 
I don’t. No, I don’t really want to predict that because frankly, I don’t even know what that means. And again, I would fall back on my earlier comment, I mean, why would we? Why would we ever create a system that was even simulating that sense of awareness? What kind of economic value does that really deliver? Frankly, I can’t find one.
Well, I guess there are two answers to that. We don’t necessarily have to exhaust all that. One is that it’s an emergent property that would just happen on its own. That’s what emotions are and second, somebody’s going to do it for no economic value. Somebody’s just going to do it for the intellectual challenge of it all. 
Yeah, that very well may be. That’s right. I mean there’s lots of academic activity, they’re exploring areas in this space, but first of all, I’ll reinforce that they’re a long way away from getting there and none of what I’ve seen so far at all suggests that it’s going to be achieved (that is, emergent capability). But even if it does get done academically, I’m not… I don’t think that’s going to have any utility in our world.
And my second Kasparov question is: In the end, Kasparov concluded that a human… So you said you prefer augmented intelligence, over artificial. And Kasparov said, “in the end, the best chess player is a computer that makes a suggested move and a human who kind of evaluates it and chooses to take the move or not, but it’s this kind of human in partnership with an AI.” Do you think that’s really true or is that just a fictional détente that we tell ourselves to get through this transition period without having to deal with the fact now that a machine is just better at playing chess than any human who’s ever lived? 
No, I believe it is. It is really the practical way of thinking about how this world evolves, how this world of technology and AI evolve… Nobody built a shovel for the sake of pleasing other shovels. And so I don’t see how or why we would expect that that would be any different with this technology. These things will take shape, they will be influenced, they will, in some sense, their evolution, their technological evolution will be driven by where we get value from them. And if we’re not, we as humans are not getting value from it, why put any sustaining investment in it? And if we do get value from it, then we will invest in it, they will invest in creating this thing, they will be sustained, but that ultimately will be shaped by a balance between the utility we get and the implication that that utility has on other aspects of life… even now, with some of the discourses occurring in the use of smartphones. We’re recognizing that all of the advantages and benefits and utility that we get from smartphones, come at a cost, which is: neck strain, a lot of broken relationships, lack of good conversation at dinner tables, and stuff like that. So I think there will be a bit of a reconciliation of that, and we’ll see that be tempered into some sort of equilibrium.
So presumably though, you were involved in the Jeopardy match?
No, not directly. I actually was engaged in the team after that, after the Jeopardy match had actually been performed, but in doing so, I had the opportunity to spend a lot of time with that team and learned a lot from them and…
Well, let me ask you two questions about that if you don’t mind. One of them is, Ken Jennings, I don’t know if you’ve seen his TED Talk on the topic, but he basically says that there was this graph they used to email him every week, and it showed a dot where he was and it showed Watson, dot dot dot coming towards him week by week by week. He said, “That’s what the future looks like. It isn’t Terminator hunting you down, it’s a machine that’s getting a little better, a little better, a little better, doing that thing that is that thing you do best.” Do you think, on that team, there was ever any doubt that eventually the machine would win or was it an open question at one point?
There certainly were open questions along the way. I know that historically, if nothing else, you can read that in some of the books [that] have been written about [it]. For example, Steven Baker wrote a book that chronicled some of the development work and you can see where the team had self-doubt along the way. I’ll tell you, even on the day of the match, there was no certainty that Watson was going to win that game. If you recall the first day, the match on the first day, Watson did ok, kind of held its own. The second day actually, it did look like it was going to lose. It actually got behind significantly. Of course on the third day, it came back and some of that is just simply due to the varying ability of the human experience. How good were the players, the contestants on that day, what were the topics that were coming up in subject, and how well were they in line with what they knew?  And even though Watson had ingested 200 million pages of literature, that didn’t mean that it knew everything. Even Watson has some limitations. I think even then there was some doubt. It achieved about 83-85% accuracy, which put it right there in what we call the Winner’s Cloud. Which gave it a really good fighting chance and I think if we were to build the technology again using modern technique, it might’ve even been a little bit better.
I remember what it was really good at was trying to find information in the literature and associate that with the question being asked and that’s a fairly narrow task. While we like to think it was better than Ken and Brad at that task, that doesn’t mean that it was better than Ken and Brad. Ken and Brad as humans are better in many other ways. It was just around that one specific slice of their life.
This is probably not an answerable question, but you know that answer that’s always quoted in the articles about it is, “What is a meringue-harangue?” Watson’s answer. Do you think that’s a creative answer? Would you project creativity onto Watson or is that no different than what’s 2+2 and Watson says 4? Is there nothing about that answer that’s particularly different than 2+2?
Well, I mean, even a blind monkey gets a peanut every once in a while. Some of this is purely random things that occur, which by the way, I should point out, I think a lot of human ideas tend to be kind of random as well. So there is some utility in being able to come up with novel representations of information. But, no, I think it was inapt to the case. It was a little bit closer to executing, exercising the axioms, because it was simply deriving that from what was available in the literature.
So, one more question about this. I would love to get an update on Watson and where you see it heading. So, I don’t know how long ago it was, but Danny Hillis made a computer that never lost a game of Tic Tac Toe, but he made it entirely out of yarn and tinker toys and then, computers mastered checkers. Then they mastered Chess with Kasparov. And then, you know Jeopardy. And then Go, Alpha Go. And then poker. They’re beating top ranked poker players. Games are an interesting spot because they have confined rules and winners and losers and points and all these other things. Is there another game for computers to kind of beat humans at that is next? Or is Go the ultimate? Or is it merely the penultimate, sort of like difficult human game? Or have we kind of passed, “Yeah, they can kind of beat us at anything.”
I think there’s strong indications that when the problem being solved is really tightly defined, where the rules of the problem have no ambiguity to it or the outcomes have no ambiguity, where it’s clear whether somebody did or did not win or lose, anything like that, there’s a strong indication that technology’s gotten to the point where sooner or later, we’ll be able to contest and win at any of those kinds of situations. And that’s useful from again an academic standpoint. It helps us test out new technologies. I will also point out that rarely in life are our everyday experiences so well defined, say even more strongly, almost…. Nothing that I do on a daily basis, nothing that most of us do [is] that well-defined. Even when we think the roles are well-defined, we find that even the rules themselves have interpretations. There’s judgments being applied to that and even then, those judgments can change over time depending on who you’re dealing with, or the circumstances. That’s why we have a court system,  a Supreme Court system -- their responsibility basically is to interpret the meaning behind the rules, the laws of the Constitution. So it just goes to show that those kinds of games, while certainly, I think it’s every indication that computing systems will be able to exceed at those kinds of games, we should recognize them for what they are. They’re just games.
So, give us an update as it were on Watson. How is it knocking it out of the park? What’s being done? What are the new challenges? What are the new milestones? Just tell us that whole Watson story please. 
Yeah, well, so first of all, we continue to make tremendous advances in the accuracy of our recognition services, whether that’s visual recognition, or speech recognition, or in term recognition in language. So that has been a really nice thing to look at, look upon, look back on. Where I think there’s going to be more progress and some advances that will be interesting and meaningful, is in the depth of the kinds of conversations that people can create with these conversational agents, these conversational services. Specifically, where there’s a lot of interest and a lot of focus right now is how, in a conversational agent, we can move beyond simply answering the question asked or performing the task that was expressed, to beginning to get behind the problem. To get to the thing that led to that question.
An example of this is if I come to a conversational agent and I ask, “What is my account balance?” That may be something I need to know, but that’s really not my problem. My problem is getting ready to buy something or trying to figure out how to save for my kids’ education. There’s something behind that and I think a conversational agent that is able to recognize that there’s something more and has the ability to engage in a deeper conversation that gets behind that, will bring more utility to those people who use conversational agents. It’ll enable the conversational agents to help people in ways that today most chat bots are kind of constrained by. So I think we’re seeing a whole new range of utility starting to open up surrounding these conversational agents. And then of course, the other big area of advancement is around knowledge, knowledge representation, knowledge exploration and discovery, and how that then is opening up what I think of as the long tail of the types of questions people want to ask and get answered.
And so, put some meat on those bones. We would hear stories about, “Oh, Watson has matched the prognosis, the treatment plan for cancer patients, and in 30% of cases, it had something additional to add...” Give us some real world examples of how the technology is being applied in the real world and is working?
I think where we’re going to see the greatest benefit in the use cases, that will benefit the most from the improving degree of knowledge evaluation will be in any role where your responsibility is essentially to do research, right? That could be in the form of medical research, in financial product research, in product evaluation, anywhere when what we’re trying to do is get below the surface of the knowledge as stated in whatever literature we’re depending upon. Where the associations between knowledge that are either explicitly stated or implied now become relevant to our understanding. So, let’s take this into financial advisory services for example.
Today, most financial advisors rely on research that makes judgments about the usefulness of one financial product or another based predominantly, in many cases exclusively, on quantitative analysis, quantitative data. Looking at past performance, looking at the number of shareholders in that investment, looking at its basic risk profile in different economic conditions. All these things are quantitative and are evaluated today using quantitative analytics. What oftentimes is missing is any evaluation of the qualitative space. So how did that, how will that, that investment be affected by events that are only just now being discussed in the news, for example? Or in some county, or city council meeting. Those kinds of knowledge sources which we as humans rely on heavily, we won’t hesitate to go look up in the newspaper and use an article that we found there to quickly judge whether somebody is going to be affected by that. Or if there’s a discussion at city council about some new water treatment plant being created, then we know that it’s going to have some kind of economic impact on the businesses and the residents in the area immediately surrounding that water treatment plant. Now, using these cognitive systems, using natural language understanding and being able to evaluate the relationships between different entities, we’re beginning to focus that, factor that in to some of these investment decisions.
And so, if there’s an enterprise, a CEO of an enterprise out there listening right now and he or she has a company that’s got a 1,000 people and they make stuff, they make a product and they ship it, and they have customers, they have all these things - would it be a fair bet, in your mind, that they have business problems like that -- like you just described -- that Watson can inform on, buried somewhere in the data in their organization, or not? 
There is a vast quantity of information that organizations today collect or have access to that is going untapped. Most organizations for that kind of information rely on the humans in the organization to go out and read all that material and keep up with it and make sense of it all. And in some organizations, they either employ a lot of people to do that or, in many cases, most cases, they simply don’t have the staff to keep up with it, so as a result, all that information is just flowing by them unused. Unvalued. And that’s a place where Watson and AIs can begin to bring some advantage.
And you feel it’s time for, if there’s someone listening and they aren’t necessarily a “high-tech company,” but still we’re now at that point in Watson and AIs’ life cycle that they should already be thinking about these things now? Or…
Yeah, first of all, the tools have gotten to the point where you don’t need to be a data scientist to make use of them. These things are a journey. You’re not going to suddenly turn on AI and it immediately affects the outcomes of your business. But, if you don’t begin that journey, then you don’t get to that point where you get an inflection in that kind of return, that kind of result. So, getting the journey started, leveraging what’s there, even if that’s in a minor way, for the minor value that it brings, gets you on a path where, over time, as you grow that, you grow your understanding, you grow your use of it, [it] will then eventually start to pop up as very measurable difference in how your business performs. So, now’s the time to get started. It’s feasible, it’s viable, it works, the tools are good, and the skills are out there now to tap into. There's lots of help if you need it. The sooner you get started, the sooner you get down that journey. And by the way, chances are, if you’re not doing it, your competition is. If they get started not only are they getting advantage of it, but they’re also going to get ahead of the curve on you because they’ve got that journey started.
Well that is a great place to leave it: a call to action with the great potential and a little ominous overtone as well. So, I want to thank you so much Rob for a fascinating hour. I have my list of questions I wanted to talk to you about. I didn’t even make it through half of them. It’s fascinating, you’re a fascinating guy, and anytime you want to come back, we’d love to have you on the show. 
Thank you, Byron. I appreciate that.
Byron explores issues around artificial intelligence and conscious computers in his new book The Fourth Age: Smart Robots, Conscious Computers, and the Future of Humanity.
",,Company, , , , , 
https://ibm.co/2JqmN6W,187446750783_10155769157795784,https://www.facebook.com/ibmwatson/posts/10155769157795784,"Australian startup Lingmo uses IBM Watson to take 30-second blocks of conversation in English, Japanese, French, Chinese, Italian, Spanish, German, Portuguese and Arabic and return it to the One2One earpiece coherently in any of those languages via Business Insider: ",Link,,,7/25/18 18:30, ,8961,8961,0,11967,11967,0,114,81,115,2,2,9834,7441,0,0,86,0,0,0,0,0,0,0,0,0,0,6,43.0,2.0,8,46.0,2.0,53,33.0,,,76,39.0,,,1,1.0,,1,1.0,,  The Australian startup which launched an earpiece that can instantly translate nine languages now has a smartwatch and a messaging service.,https://edge.alluremedia.com.au/uploads/businessinsider/2018/03/two-watches.jpg,https://www.businessinsider.com.au/lingmo-smartwatch-translates-languages-2018-3,joy,0.275751,neutral,0,"Australian startup Lingmo, 30-second blocks of conversation, IBM Watson","Quantity, Company",Australian startup Lingmo,Quantity,joy,0.490414,positive,0.586758,Australian startup,,Australian startup,,joy,0.586879,positive,0.590356,Lingmo International,"Company, Person, Person, Quantity, Company, Person, Quantity, Quantity, Quantity, Organization, Location, Person, Company, Quantity, Quantity, Location, Quantity","The Australian startup which launched an earpiece that can instantly translate nine languages now has a smartwatch and a messaging service.
In less than a year since he launched the TranslateOne2One device at a United Nations event in Switzerland, former plumber Danny May has become an unlikely, but extremely busy, advocate for IBM’s AI technology, Watson.
Watson takes 30-second blocks of conversation in English, Japanese, French, Chinese, Italian, Spanish, German, Portuguese and Arabic and returns it to the One2One earpiece coherently in any of those languages.
May began working on the technology five years ago when he struggled to communicate effectively while on a business trip to China.
His startup, Lingmo International, released the $279 earpiece in October last year, even beating Google’s Pixel Bud translation service to the market, with the major advantage over its competitors of using a SIM card to operate independently of a phone.
But by December, feedback proved to May that an earpiece isn’t a good fit for everybody. So here’s another way to chat with someone in nine different languages:
It’s called the Time2Translate and you can buy it tomorrow, with delivery expected in April, anywhere in the world.
“People loved the One2One tech and loved what it was doing, but some people found it hard to use on the ears,” May says. “The tech was never in question, it was always just a matter of how we could put it into a better user experience.”
The smartwatch also knocks out some extra features that people weren’t really using on the earpiece.
“There was too much going on, people just wanted a translation device,” May says.
Lingmo kept Google Maps — it is essentially a travel accessory — and Bluetooth capability if people don’t want to connect to Lingmo’s prepaid SIM network. Google Play is available for downloads, but other app stores have been axed.
In return, the Time2Translate gets a four-hour constant use battery life (14 hours standby) and extra memory.
And most importantly, it’s on your wrist.
As if speaking into a watch like you have in all your spy film dreams isn’t impressive enough, Lingmo is also launching new software along with the Time2Translate which enables real-time messaging in nine languages.
So you can send a voice message in English on your watch and the recipient will receive it in Chinese. But what is truly extrordinary is the watch will enable up to 1,000 users to converse in a group chat across all nine languages.
Those languages represent 90% of the world’s spoken words.
May said Lingmo burned through five protoypes to find speakers for the side of the watch that met the standard required for speaking English into, and hearing Arabic out of up to two metres away. 
And because Lingmo is working with Watson every second to improve its service, the translation is far beyond the typical clunky word-for-word systems you might be used to online.
But for a premium service, expect to pay a premium price – the watch starts from $US699 for the Lifestyle model. Here’s the complete spec rundown: 
“We just wanted to turn those (earpiece) negatives into positives,” May says about developing the smartwatch. “Interest has been really positive around the world, and we’re now dealing with some proof of concepts with major airlines and US multinationals. 
“We’re slowly getting there; it’s just about doing it right and being a startup it’s just about focusing on the little things and getting them right first.”
 Yes, it has speakers. Loud ones. Picture: Supplied
Since the October rollout of One2One, Lingmo International has moved into new office on the NSW central coast and grown its staff from three to more than 20. It also now has offices in the Middle East and China, and a virtual office in Silicon Valley which it is looking to make permanent.
May says it’s been a challenging time in his life, but he doesn’t miss sticking his hand down the toilet.
“It’s what you start a company for. You have your hard times but you just have to keep pushing on and that’s what it’s all about with the watch.
“You just have to keep innovating.”
His ultimate goal is to see Lingmo’s product line include the “holy grail”, where anyone can pick up a phone and make a call which instantly translates to the other end and back again.
“We’re making slow inroads,” he says. “The software on the watch is a significant step towards that.”
Follow Business Insider Australia on Facebook, Twitter, LinkedIn, and Instagram.
",Lingmo International,Company,charcoal,addiction,person,person,addiction
https://ibm.co/2ILrGaa,187446750783_10155766785705784,https://www.facebook.com/ibmwatson/posts/10155766785705784,How is IBM using AI and cloud to accelerate growth in an increasingly cloud-centric world? Hear Watson and Cloud SVP David Kenny on where we stand in CNBC: ,Link,,,7/24/18 18:19, ,12210,12210,0,16452,16452,0,354,248,296,7,7,13180,9877,0,0,253,0,0,0,0,0,0,0,0,0,0,15,138.0,3.0,16,140.0,3.0,105,158.0,,,133,163.0,,,4,3.0,,4,3.0,,"David Kenny, IBM Watson and Cloud Platform senior vice president, speaks with CNBC’s “Squawk Alley” on the tech giant’s push to close in on the competition in the cloud sector. 
",https://image.cnbcfm.com/api/v1/image/105202613-184684816.jpg?v=1529478225,https://www.cnbc.com/video/2018/05/11/ibm-watson-cloud.html?linkId=51617025,joy,0.085318,positive,0.541349,"Cloud SVP David Kenny, cloud-centric world, IBM","Company, Person, Person",Cloud SVP David Kenny,Company,sadness,0.126884,neutral,0,"senior vice president, David Kenny","Person, Person, Company, Company",senior vice president,Person,sadness,0.461302,negative,-0.696181,"Global Business, Financial News, real-time snapshot, Data",Quantity,"Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.
",Global Business,Quantity,gray,intersection,junction,intersection,-
https://ibm.co/2lrav0s,187446750783_10155763903120784,https://www.facebook.com/ibmwatson/posts/10155763903120784,"With the advent of machine learning and deep learning, AI has changed from a sci-fi fantasy to an inherent part of everyday life, from reading news to fighting cancer and detecting fraud and more. 

However, developing artificial intelligence and machine learning applications remains elusive to most organizations. Here's how one IBMer is working to make AI productive: ",Link,,,7/23/18 9:20, ,8170,8170,0,11184,11184,0,139,103,134,9,11,9877,7230,0,0,133,0,0,0,0,0,0,0,0,0,0,10,52.0,1.0,11,54.0,1.0,65,46.0,,,84,50.0,,,4,7.0,,4,5.0,,"AI will transform our world and the businesses leading the future, but only if it is easily accessible to everyone",https://i2.wp.com/bdtechtalks.com/wp-content/uploads/2018/04/Armand-Ruiz-1-1926873092-1523178431937.png?fit=1048%2C853&ssl=1,https://bdtechtalks.com/2018/04/09/ibm-watson-democratizing-ai-deep-learning/,joy,0.446035,positive,0.726933,"advent of machine learning, deep learning, artificial intelligence, sci-fi fantasy","Person, HealthCondition",advent of machine learning,Person,joy,0.66247,positive,0.931904,"world, businesses",Person,world,Person,joy,0.589151,positive,0.68033,,"Person, Person","Years ago, when I was taking my first steps in computer programming, coding was for geeks and computer programs had limited use. Development tools were very crude, writing code was hard (remember Assembly, C, Pascal?), compiling and linking was a nightmare (MAKE files anyone?), and debugging was even worse. Long story short, programming was not for the faint of heart. You needed nerves of steel and had to patiently fail over and over before you got the hang of writing good code.
But as software gradually rose in prominence, the entry barrier to programming lowered. Presently computer software has found an important role in almost everything we do, from shopping to applying for university course and communicating with friends and family and whatnot. Accordingly, the tools to create software, the programming languages and Integrated Development Environments (IDEs) have become more intuitive and easy to learn. If in my days, it took an average of two jam-packed years to become a decent developer, today the same can be achieved in a fraction of the time.
We’re seeing the same trend happen in artificial intelligence. With the advent of machine learning and deep learning, AI has changed from a sci-fi fantasy to an inherent part of everyday life, from reading news to fighting cancer and detecting fraud and more.
However, like in the early days of software, developing artificial intelligence and machine learning applications remains elusive to most organizations and people, and only large tech companies can make productive use of it.
A number of experts and companies are leading efforts to address this issue. Among them is Armand Ruiz, Product Manager at IBM Watson, whose team is working on tools that not only make data scientists more productive, but also make data science, AI and deep learning more accessible to the enterprise. In an interview with TechTalks, Ruiz shared insights and experience on the challenges of the AI industry and solutions to democratize it.
The challenges of developing AI applications
A recent Gartner survey of CIOs ranked artificial intelligence as one of the hardest technologies to implement. “While the level of difficulty varies with the type of AI technology being implemented and the process it is being deployed into, there are several key barriers to adoption: skills, standardization, complexity and a lack of collaboration,” says Ruiz, adding that many challenges are specific to deep learning, which is a relatively recent innovation that increases the amount and type of data that can be tapped by an AI system.
When creating deep learning applications, developers build and train “neural networks,” a software structure that is roughly inspired by the human brain. These neural networks can accomplish a variety of tasks, such as identifying the content of images, performing face recognition or analyzing the meaning and intent of human language.
But developing deep learning models is a very painstaking and expensive process. “First, deep learning is a computationally intensive and highly specialized field,” Ruiz says. “It requires a highly tuned system with the right combination of software, drivers, compute, memory, network, and storage resources,” the combinations of which can reach thousands or millions of dollars in costs.
In fact, deep learning as a concept has been around for a long while, but only became a reality with the explosion of availability of storage and compute resources, mostly held by big cloud providers. While many of these companies make their AI tools available to developers and companies, they remain the exclusive gatekeepers to those platforms.
Ruiz also points to the lack of skilled engineers to develop AI applications. “While formalized education in deep learning is growing, the talent pool is still limited,” he says.
The acquisition of scarce AI talent become an arms race between large tech companies, which sometimes pay their engineers salaries that reach millions of dollars per year. This makes it very difficult for smaller companies and organizations to gain access to talent and innovation and compete in the space.
“There is also a lack of standardization across deep learning teams, with different data scientists preferring different open source frameworks to build their models,” Ruiz says. This can make it increasingly challenging for data scientists to share and re-use models within their own teams.
Another fact worth considering is that neural network design is just one stage of a much larger workflow, Ruiz notes, which also encompasses the training, evaluation, deployment, monitoring and enhancement of deep learning models. “Data scientists must understand many functional areas beyond design. This includes being familiar with, and able to work on, various infrastructures and architectures that differ widely in their use and application,” Ruiz says.
Finally, Ruiz points to the disconnect in many organizations between IT (those with the technical expertise to analyze the data) and domain experts (those able to glean insights from it) as a barrier to the adoption of AI across organizations. “These teams often work in siloes, with differing tools and little visibility into each other’s work. The result is AI that falls short in its promise to augment people’s expertise,” Ruiz says. “This is an issue I’ve seen personally in my experience in data science and is a challenge I am passionate about working with my team to overcome.”
There’s an analogy worth reminding here. In its earlier days, plain-old programming was a deeply technical endeavor that only highly skilled engineers and developers could engage in. A large part of their time would have to go into understanding the problem space they were developing for and bridging the gap between domain experts and computer code. But as programming tools became easier to use and Application Programming Interfaces (APIs) became more capable, software development became democratized and more and more people from diverse backgrounds became able to transform their domain expertise into software. AI needs to go through a similar process.
These elements can make it challenging for organizations to deploy deep learning on an enterprise-wide basis, hindering them from maximizing the business value they get from their data, Ruiz says.
How do you democratize AI and deep learning?
“To realize the full potential of AI, we need tools that make it easier for today’s data science teams to develop AI systems that can help glean insights from data,” Ruiz says.
For this to happen, deep learning solutions and frameworks must enable data professionals to more quickly and precisely design new neural networks, optimize their training models, understand, re-use and enhance the networks that their peers have already created, and collaborate across the organization. “At IBM, we are already doing this by offering tools that make deep learning accessible to individuals of varying skill levels,” Ruiz says.
Ruiz is working with a team of product managers who formerly worked as data scientists. So they understand the challenges that various users face when working with data and AI, and they’re focused on building tools that make data science and other complex technologies accessible to everyone, from scientists to the average enterprise user.
One of their notable efforts is Watson Studio’s Deep Learning as a Service solution, which recently made its debut. Deep Learning as a Service draws from advances made at IBM Research to enable organizations to overcome the common barriers to deep learning deployment, including skills, standardization, and complexity. Among the features of Deep Learning as a Service is a Neural Network Modeler, an intuitive drag-and-drop interface that enables non-programmers to build models by visually selecting, configuring, designing and auto-coding their neural network using popular deep learning frameworks such as TensorFlow, Caffe and PyTorch.
“Our goal is to make it much easier for enterprises, along with data scientists and developers, to cost-effectively build, optimize, and train neural networks at scale, using well-known frameworks with minimal code,” Ruiz says.
The future of AI depends on democratizing it
As data scientist Doug Rose pointed out in this column not long ago, AI needs greater representation of the humanities in order to overcome its hurdles and challenges. And as acclaimed historian rightly pointed out in the annual World Economic Forum Davos, the future of humanity might depend on how distributed AI and big data become. So the efforts of Ruiz and his colleagues to democratize AI might be more significant than they seem.
“AI holds enormous power to transform our world and the businesses leading the future, including how we consume information, how we shape communication, and how we engage with technology,” Ruiz notes. “However, AI can only have this impact if it is easily accessible and can be applied with purpose. The democratization of AI technology, combined with improved widespread understanding of its usage and growing consumer trust, will help to break down current barriers that make it difficult to integrate AI into enterprise workflows. Organizations deploying AI technologies at scale will see significant increases in productivity and efficiency, allowing employees to focus on more complex, creative, and higher-impact tasks.”
",,Person,light brown,person,plant,weed,tumbleweed
https://ibm.co/2DXShi2,187446750783_10155761731700784,https://www.facebook.com/ibmwatson/posts/10155761731700784,"&quot;IBM and the AFT worked together for more than 2 years to develop a solution to the problem of inadequate support for teachers. The result is Teacher Advisor, a free online tool that uses Watson to help teachers find the best-quality content—vetted by a range of education experts and nonprofits—to assist them with their work in the classroom.&quot; ",Link,,,7/22/18 9:30, ,10653,10653,0,14474,14474,0,148,98,132,9,13,12090,8905,0,0,118,0,0,0,0,0,0,0,0,0,0,18,60.0,1.0,18,62.0,1.0,68,38.0,,,87,45.0,,,4,9.0,,4,5.0,,Randi Weingarten and Stanley S. Litow explore how we can move past divisiveness on key education issues.,https://www.edweek.org/media/2018/01/08/17-web-comm-weingarten-470x235-socialmedia-copyright-getty.jpg,https://www.edweek.org/ew/articles/2018/01/09/in-education-perfect-must-not-become-the.html,joy,0.724427,positive,0.632325,"free online tool, best-quality content, Teacher Advisor, range of education experts","Company, Quantity, Person",free online tool,Company,joy,0.326735,negative,-0.799388,Randi Weingarten,"Person, Person",Randi Weingarten,Person,joy,0.610601,positive,0.427193,,"Person, Organization, Organization, Organization, Organization, Person, Organization, Person, Location, Location","America’s future, and the futures of our more than 50 million public school students, are one and the same. Essential to this future are the more than 3 million teachers who—more than anyone else besides parents and the students themselves—are responsible for our children’s success. But our dedicated teachers are hamstrung by inadequate funding and a lack of other types of support that are critical to providing our children with high-quality education. That is why all of us must work together to make teacher success our top priority.
Public-private partnerships that allow us to get past divisiveness on key education issues can be critically important to education reform. As the former deputy chancellor of schools in New York City (Stanley Litow) and the former head of the city’s United Federation of Teachers (Randi Weingarten), the two of us know the importance of putting differences aside in service of the greater good. We have learned the hard way that perfect can be the enemy of good and that we must set aside our criticisms if we are to build a sustainable future for our children.
None of us has all the solutions, but one critical challenge on which we agree is our national teacher shortage, which could soon hit crisis levels. A 2016 Learning Policy Institute study projects a shortfall of more than 100,000 teachers by this calendar year, and it’s not hard to see why. Inadequate salaries, poor working conditions, the cost of obtaining qualifications, and deficient teaching and learning resources have contributed to rampant dissatisfaction among teachers. In fact, a recent study by the American Federation of Teachers and the educator-advocacy Badass Teachers Association revealed that two-thirds of teachers usually feel stressed out—twice the level of workers in the general population. (The respondents included 4,000 educators in a public survey and a random sample of 850 AFT educators.)
Stress can be particularly acute for early-grade teachers. Under pressure to improve student achievement, many elementary school teachers are suddenly asked to instruct unfamiliar grade levels or master specialized areas like math without adequate support. This lack of support affects our nation’s youths directly. Children in early grades cannot afford to miss the essential building blocks in math and other subjects, which research indicates are directly connected to overall achievement.
The IBM Foundation and the AFT worked together for more than two years—with the backing of the Carnegie, Ford, and Niarchos foundations and in collaboration with more than 1,000 teachers—to develop a solution to the problem of inadequate support. The result, which was launched nationwide at the start of the current school year, is a free online tool that helps teachers find the best-quality content—vetted by a range of education experts and nonprofits—to assist them with their work in the classroom. Teacher Advisor uses IBM’s artificial-intelligence technology to produce tailored advice for teachers in grades K-5. It delivers relevant material based on teacher queries, drawing from a repository of more than 2,000 high-quality math lessons, proven teaching strategies, and videos. Importantly, Teacher Advisor is a support tool, which will improve with continued training and use. It does not evaluate teacher performance.
The idea for Teacher Advisor sprang from conversations with educators and policymakers across the political spectrum. They set aside polemical differences to support our teachers, and early feedback on the tool has been promising. 
Technology cannot be the only answer to any problem—there are no silver bullets in education. Any new approach needs to be part of a genuine collaboration with teachers, who are in the driver’s seat, to produce gains in student achievement. We believe additional collaborations will be essential to improving how we help teachers and students succeed. And we know that working together—not pointing fingers—will be critical to our nation’s future success. Teacher Advisor is not the only way to help alleviate one of the many challenges facing teachers today, and we certainly hope it won’t be the last. But we believe it is an important step toward harnessing the transformative power of collaboration to improve education.
We cannot afford to continue to undervalue public education. If we do, our nation’s children will have the most to lose. Instead, we can, and should, roll up our sleeves and work together to support our teachers’ tireless efforts to improve kids’ chances of success.
 Notice: We recently upgraded our comments. (Learn more here.) If you are logged in as a subscriber or registered user and already have a Display Name on edweek.org, you can post comments. If you do not already have a Display Name, please create one here. 
",,Person,ultramarine,print,fabric,print,-
https://ibm.co/2Hwv6sY,187446750783_10155759743160784,https://www.facebook.com/ibmwatson/posts/10155759743160784,"&quot;Artificial intelligence is not designed to replace the human mind, but to augment our intelligence and amplify our reach.&quot; 

In our latest blog, read about one IBMer's journey to learning effective AI: ",Link,,,7/21/18 11:56, ,11266,11266,0,15170,15170,0,209,145,170,5,5,12826,9360,0,0,173,0,0,0,0,0,0,0,0,0,0,25,84.0,2.0,25,89.0,2.0,57,101.0,,,66,104.0,,,1,4.0,,1,4.0,,"IBM has been on the AI journey for a long time, but the path has not always been smooth. My experience in the consulting business has taught me that successful practitioners need to be flexible and quick to make course corrections. We at IBM have learned along our AI journey, and here are three lessons that come to mind from my own interaction with clients and business colleagues. 1. You fail quickly, and learn fast with AI Remember the adage: garbage in, garbage out. We’ve acknowledged that the results of data analysis are sometimes misleading or even inaccurate. It could result from human error, or personal or institutional biases. Or maybe we’re not asking the right questions. Today we’re building tools that quickly recognize anomalies in the data and even apply a bias rating to outcomes that allow us to make course corrections. Exploration geologists know all about course corrections. They analyze data from drill logs, geological…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/06/AI-jobs_1200x628.png,https://www.ibm.com/blogs/watson/2018/06/journey-ai-three-lessons-learned-effective-implementation/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-3+Lessons+on+Journey+to+AI+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.694862,positive,0.757104,"Artificial intelligence, human mind",Person,Artificial intelligence,Person,joy,0.538828,positive,0.308951,"results of data analysis, consulting business","Company, Person",results of data analysis,Company,joy,0.538571,positive,0.485623,results of data analysis,"Company, Person, Person, HealthCondition, Company, Organization, Person, Person, Company, Quantity","Share this post:
IBM has been on the AI journey for a long time, but the path has not always been smooth. My experience in the consulting business has taught me that successful practitioners need to be flexible and quick to make course corrections. We at IBM have learned along our AI journey, and here are three lessons that come to mind from my own interaction with clients and business colleagues.
1. You fail quickly, and learn fast with AI
Remember the adage: garbage in, garbage out. We’ve acknowledged that the results of data analysis are sometimes misleading or even inaccurate. It could result from human error, or personal or institutional biases. Or maybe we’re not asking the right questions. Today we’re building tools that quickly recognize anomalies in the data and even apply a bias rating to outcomes that allow us to make course corrections.
Exploration geologists know all about course corrections. They analyze data from drill logs, geological shapes, connected devices and maps to plan their next exploration drill. At Goldcorp they are using AI to analyze all this data, and try to identify human error and bias quickly. Their AI platform identifies anomalies and allows geologists to focus on good data as they search for new ore deposits.
2. AI does not replace us; it makes us better
The second lesson is that artificial intelligence is not designed to replace the human mind, but to augment our intelligence and amplify our reach. In the early stages, AI systems were not that smart. Training was a slow, arduous process that required a lot of human intervention. Thankfully, that has led to systems that are now much more robust.
Today, AI platforms are being used in all industries to makes us smarter. A great example is found in healthcare.
Ten million people around the world are living with Parkinson’s disease. The drug treatment hasn’t changed significantly in 50 years. One of our employees living with Parkinson’s thought there must be a better way to advance research. Our AI platform was put to work digesting 28 million medical reports and analyzing 3,800 possible drugs. Sixteen potential drug treatments emerged and the Ontario Brain Institute has funded the initial study with the goal to have more diverse and better treatments for people with Parkinson’s.
AI is not replacing doctors and researchers, but making them smarter.
3. Beware of data ownership in the world of AI
Data ownership has been a hot news item lately. Some large companies have been under fire for misusing data that has been entrusted to them. We believe that you should not be required to relinquish rights to your data in order to have the benefits of an AI platform. In fact, IBM neither owns nor stores any of the data touched by Watson solutions and services. We believe the data and resulting insights belong to your organization and its clients.
A recent IBM survey revealed that 78 percent of respondents say a company’s ability to keep their data private is “extremely important” to them, but only 20 percent “completely trust” organizations they interact with to maintain the privacy of their data.
Your data matters to you — whether it’s your own personal medical records, or the findings from your company’s drug trials or geological surveys.
At the enterprise level, your data is your competitive advantage. If your technology partner is sharing your data with others you may be hurting your business and your clients. You should always retain ownership of your data, and know how it is being used. That is a principle everyone in our industry must adopt.
We’re still in the early stages of our AI journey, and have much to learn as the technology matures. The potential in AI to improve our lives and our businesses is potentially limitless, but as with any new technology, we must approach it responsibly and with a willingness to learn and adapt.
",results of data analysis,Company,green,slope,nature,slope,-
https://ibm.co/2uOn7D4,187446750783_10155755129285784,https://www.facebook.com/ibmwatson/posts/10155755129285784,"Much like an impressionable child, new technologies like AI are prone to influence by the nature of the information and data sets with which they are presented. To avoid bias and build ethical machine learning models, Forrester developed the FAIR business model. Read about it over on the Watson blog: ",Link,,,7/19/18 11:06, ,8438,8438,0,11566,11566,0,134,82,90,5,5,9619,7107,0,0,110,0,0,0,0,0,0,0,0,0,0,20,55.0,1.0,22,57.0,1.0,35,49.0,,,41,49.0,,,3,2.0,,3,2.0,,Forrester report “The Ethics Of AI: How To Avoid Harmful Bias and Discrimination” describes the ideal machine learning data models and how to build trust.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/07/801_Ethics-and-AI-–-How-orgs-can-avoid-harmful-bias-in-models_625ai-02-1024x536.jpg,https://www.ibm.com/blogs/watson/2018/07/trust-in-the-age-of-ai-build-fairness-into-machine-learning-models/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Trust+in+the+Age+of+AI+Building+Fairness+Into+Machine+Learning+Models+July+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.687147,positive,0.781989,"impressionable child, ethical machine learning models","Person, Company",impressionable child,Person,sadness,0.257617,positive,0.487351,"Forrester report, Harmful Bias",Company,Forrester report,Company,joy,0.513013,negative,-0.285549,,"Person, Company, Person","Enterprise-wide deployments of AI are constrained by the requirements of scaling any new system or technology: transparency, security, and the application’s ability to work across many systems. But solving for these challenges is not enough. Every organization that develops or uses AI, or hosts or processes data, must do so in ways that allow them to rationalize the decisions or recommendations in a way that is easily consumable.
Much like an impressionable child, new technologies like AI are prone to influence by the nature of the information and data sets with which they are presented. Perhaps the training data isn’t representative. Or, AI models could be unknowingly fed biased data that affects their output.
A recent Forrester report “The Ethics Of AI: How To Avoid Harmful Bias and Discrimination” describes the ideal machine learning data models as being FAIR, or:
Businesses should strive to create models that are “FAIR” to protect against harmful bias. Let’s examine Forrester’s recommendations how organizations can leverage AI for the good of humankind, while avoiding the ethical pitfalls associated with perceived discrimination.
The threat of opaque or unfair machine learning models is real, and safety-critical and highly-regulated domains are most likely to feel the impact. Organizations must be able to address unfair models, or suffer reputational, regulatory, and revenue consequences. The obvious reputational risks aside, if for example, your AI mortgage application is rejecting applicants who shouldn’t be rejected, or your AI marketing application isn’t targeting certain potential customers who may buy your product, it’s ultimately just bad business.
How do businesses build models that people trust over time? Lack of transparency into “black boxes” — limited visibility into data sets, computations, assumptions and processing — makes it difficult to pinpoint reasons for model and processing degradation over time. This increases the risks associated with using and supporting the models, and compromises developing trust in the models.
When you’re training an AI model, you also need to be aware of any underlying unfairness in the data. Machine learning, much like human learning, is inherently the “product” of the information provided, relative to the parameters of its programming. It’s important for any company that augments their business processes with machine learning to consider the strengths, weaknesses, opportunities and threats of AI they can’t trust, to ensure their best-laid plans don’t go awry.
The flip-side of bias: Targeted machine learning used for good
There are many scenarios where targeted data actually enhances AI algorithms. When correctly configured, it helps accelerate the time it takes to discover a potential solution and increase the accuracy of search results.
For example, companies looking to optimize their marketing campaigns will create an ideal “persona” of their target audience, and then locate as many prospects as possible which fit that persona profile. AI algorithms can identify prospects that fit these personas from multiple data sources, including CRM applications and social media channels.
Other examples where it’s fundamentally sound to use targeted data in machine learning include:
While these examples of non-representative data used to train models are fundamentally sound, it’s important for companies to ensure their AI models are fair and don’t discriminate so individuals and communities can trust these systems.
When bias leads to discrimination, and discrimination to weakness
Training an AI engine with insufficient data which doesn’t represent every possible permutation will cause the AI bot to ignore anything which it can’t understand.
Consider what happens when a business programs an algorithm to search out prospects based on a narrow demographic profile from limited market research. They may miss out on market segments they never thought of as viable prospects, and create ethical dilemmas.
Data scientists and developers must prevent algorithmic or human bias creeping into their models while still using the helpful bias these models identify to differentiate between customers. Companies should assess the full scope of their market opportunity, so their appearance of prejudice doesn’t damage their reputation.
European GDPR rules are forcing companies to change the way they manage personal information, and how they document their compliance. Businesses need to strike a balance between gathering and storing enough data to understand their audience, while complying with security and privacy regulations.
Many feel that if these concerns are left unchecked there will be a growing possibility of AI reinforcing systemic biases and exacerbating inequality in our business and personal lives.
There are many real-life scenarios where a customer is loyal to a particular retailer, such as a grocery store, which carries specialty foods from their country of origin. Or that tailor their marketing campaigns to specific genders. For example, women with families respond favorably to grocery coupons with significant discounts.
For these retailers, by being sensitive to the unique needs of a critical segment of their market, and eliminating discrimination, companies stand to preserve or grow their customer base by tailoring their product inventory and advertising campaigns based on inclusivity.
AI platforms can also help companies to listen to their audience across more channels, such as social media, online forums and contact center applications. If there is chatter about a company’s insensitivity to particular genders, races, age group or ethnicity, it’s best to identify the issue quickly and address it immediately.
IBM’s vision for ethics and transparency in AI
At IBM we believe we have an inherent obligation to monitor for, and correct, unethical or objectionable bias in the algorithms themselves, as well as any bias caused by the human-influenced data sets their systems interact with. Watson is transparent about who trains our AI systems, what data was used to train those systems, and most importantly what drives our customers’ algorithmic recommendations.
For example, IBM announced plans to release more than 1 million facial images to help better train the AI used for facial recognition. The risk of bias being built into facial recognition AI systems is a concern for any organization developing facial analysis algorithms. For example, does the AI accurately recognize different skin colors and other attributes in a non-discriminatory way. Since AI is only as good as the data that trains it, IBM thinks making a diverse dataset like this available will help root out bias.
At the recent VivaTech 2018 event in Paris. IBM CEO Ginni Rometty talked about her vision of the need for ethics and transparency in AI and data management. Rometty invited business leaders to follow IBM’s Principles for Trust and Transparency:
The Watson team embraces these principles, and they act as our “guiding light” in developing the Watson platform, and customer AI applications on top of it. We are driven by opportunities in industries like banking, retail and manufacturing to help companies to augment their employees’ skills and experiences. You can view Rometty’s entire keynote address here.
Are you looking for further information about how to implement enough AI bias to get better insights from data. Are you concerned with your AI models discriminating against a segment of the population, such as by age, gender, race or sexual orientation? Forrester has some guidelines that can help your business. Download the Forrester report, “The Ethics Of AI: How To Avoid Harmful Bias And Discrimination“.
",,Person,blue,sphere,figure,circle,sphere
https://ibm.co/2ISlEWe,187446750783_10155752917850784,https://www.facebook.com/ibmwatson/posts/10155752917850784,Watch IBM CEO Ginni Rometty address questions revolving around AI technology via CNBC: ,Link,,,7/18/18 9:46, ,9003,9003,0,12731,12731,0,463,312,380,4,4,9548,6770,0,0,380,0,0,0,0,0,0,0,0,0,0,31,172.0,5.0,35,173.0,5.0,169,163.0,,,200,180.0,,,3,1.0,,3,1.0,,"Ginni Rometty, IBM chairman and CEO, talks about privacy concerns, social justice and artificial intelligence from the VivaTech Conference in France.",https://image.cnbcfm.com/api/v1/image/105228833-5ED2-SB-052418-IBMceo.jpg?v=1529478307,https://www.cnbc.com/video/2018/05/24/ibm-ceo-we-have-to-have-trust-in-technology.html,joy,0.095594,neutral,0,Watch IBM CEO Ginni Rometty address questions,"Person, Company",Watch IBM CEO Ginni Rometty address questions,Person,sadness,0.131402,neutral,0,"Ginni Rometty, privacy concerns, social justice, artificial intelligence, IBM chairman","Person, Company",Ginni Rometty,Person,sadness,0.461302,negative,-0.696181,"Global Business, Financial News, real-time snapshot, Data",Quantity,"Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.
",Global Business,Quantity,alizarine red,champion,person,contestant,champion
https://ibm.co/2BVNJaF,187446750783_10155750794400784,https://www.facebook.com/ibmwatson/posts/10155750794400784,"To combat cyberbullying, Identity Guard used Watson's Natural Language Processing to build a solution that is able to understand and categorize what individuals are sending and receiving. If a threat is identified, it triggers an alert that is sent parents. Learn more: ",Link,,,7/17/18 9:45, ,5745,5745,0,7813,7813,0,138,71,97,2,2,4917,3566,0,0,93,0,0,0,0,0,0,0,0,0,0,29,74.0,1.0,30,76.0,1.0,46,32.0,,,63,34.0,,,2,,,2,,,Identity Guard’s cyberbullying features monitor the social media feeds to which both parents and children have given it access.,https://www.ibm.com/blogs/client-voices/wp-content/uploads/2018/02/Meier-tile.jpg,https://www.ibm.com/blogs/client-voices/ai-technology-protect-teens-cyberbullying/,fear,0.234939,negative,-0.36124,"Identity Guard, Watson's Natural Language","Organization, Person",Identity Guard,Organization,anger,0.293396,neutral,0,"Identity Guard, social media feeds",,Identity Guard,,joy,0.594566,positive,0.289397,,"Organization, Quantity, Organization, Person, Company, Quantity","An astonishing 87% of youth have witnessed cyberbullying. In 2017 alone, over 13 million American children were bullied or cyberbullied.
For me, the struggle against bullying and cyberbullying is a personal one. In October of 2006, my 13-year-old daughter Megan took her own life as a result of cyberbullying. Committed to helping prevent similar tragedies, I founded the Megan Meier Foundation, a non-profit dedicated to supporting and inspiring actions to end bullying and cyberbullying.
Since its inception in December 2007, our Foundation has reached over 305,000 students, parents, and educators in 270 communities and 38 states. By spreading Megan’s story and educating others on internet safety and the consequences of bullying and cyberbullying, I hope to end these occurrences, helping one child at a time cope with these negative social issues.
In 2016, Identity Guard began consulting with our Foundation and other cyberbullying experts to build an effective solution that protects children and teens without invading their privacy. Using the power of artificial intelligence, Identity Guard’s cyberbullying features monitor the social media feeds to which both parents and children have given it access.
With IBM Watson technologies that enable natural language processing (NLP) and natural language classifiers (NLC), the solution is able to understand and categorize what individuals are sending and receiving. Complex algorithms then identify instances, or potential instances, of cyberbullying or self-harm. If a threat is identified, it triggers an alert that is sent parents.
Within the alert are screenshots that include the dates and times of what caused the warning. If parents agree that this is an instance of cyberbullying or potential self-harm, they are guided to a suite of free resources—including guidance on state laws and school policies—to help them figure out how to respond.
Parents are also directed to my Foundation, where, at no charge, they can talk to an individual to air their concerns, review a checklist of actions, and take a breath before they respond—ensuring that they act from an informed position rather than a state of panic.
Given the proliferation of mobile devices and social media, parents often feel overwhelmed when it comes to their kids engaging online. We’ve worked hard with Identity Guard to create a solution that provides a safe means of engagement. Children and teens can participate in social media with their privacy intact; with parents receiving alerts only if issues are identified.
For the past decade, my Foundation has focused on listening to parents, kids and educators to help them getter a better idea of how to respond, and what actions can be done to help curb bullying and cyberbullying threats.
With this experience and knowledge, we’ve created resources that better equip parents so they can start a dialog with their kids about bullying, cyberbullying and suicide. We focus on helping both parent and child realize that they can address these issues together, as they both learn about what each can do to respond.
Technology isn’t bad; rather it’s how we use it. Social media can be scary for parents as their kids begin to get online, but our Foundation is working with Identity Guard to help parents be knowledgeable and stay informed, while enabling kids to stay safely engaged.
I dream of a world where bullying and cyberbullying no longer exist, for I know firsthand of the possible devastating consequences. I believe that through empowering our society to celebrate individuality and the acceptance of others, we can work together to make a difference and create a safer and kinder world. Identity Guard’s cyberbullying features are a helpful first step in this direction.
",,Organization,coal black,reader,person,scholar,reader
https://ibm.co/2IoGR4V,187446750783_10155748657385784,https://www.facebook.com/ibmwatson/posts/10155748657385784,We’re excited to share that IBM Watson Knowledge Catalog was named a Leader in the first Forrester Wave™: Machine Learning Data Catalogs. Learn more and download the 2018 report: ,Link,,,7/16/18 9:45, ,2491,2491,0,3459,3459,0,47,16,25,1,1,2794,2038,0,0,39,0,0,0,0,0,0,0,0,0,0,5,32.0,,6,33.0,,7,10.0,,,15,10.0,,,1,,,1,,,"IBM Watson Knowledge Catalog was recently recognized by Forrester as a Leader in: “The Forrester Wave™: Machine Learning Data Catalogs, Q2 2018.”",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/06/WKC_Forrester_1200x628.jpg,https://www.ibm.com/blogs/watson/2018/06/forrester-names-ibm-a-leader-in-machine-learning-data-catalogs/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Forrester+Names+IBM+a+Leader+in+Machine+Learning+Data+Catalogs+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.399222,positive,0.735811,IBM Watson Knowledge Catalog,Company,IBM Watson Knowledge Catalog,Company,joy,0.178254,neutral,0,IBM Watson Knowledge Catalog,"Company, Company",IBM Watson Knowledge Catalog,Company,joy,0.499598,positive,0.729065,"IBM Watson, IBM Watson Knowledge Catalog","Company, Person, Person","The promise of AI is that it will deliver digital transformation and improve productivity and efficiency across businesses. For many of our customers, IBM Watson has already helped deliver on this promise – by enriching customer interactions, accelerating research and discovery, empowering employees, and mitigating risk.
The next step for businesses is to make AI ubiquitous by operationalizing their workflows across the full AI lifecycle. IBM is committed to delivering these fundamental, end-to-end AI capabilities and giving enterprises everything they need.
For example, consider the critical step of understanding and preparing data for productive and speedy use in analytical tools, machine learning and deep learning. Your teams first need access to all your data –no matter where it lives. But there are often multiple barriers to fully harnessing the value of your data, including:
IBM has addressed these challenges with IBM Watson Knowledge Catalog, which was recently recognized by Forrester as a Leader in: “The Forrester Wave™: Machine Learning Data Catalogs, Q2 2018.”
Machine learning data catalogs (MLDCs) are the stepping stone for an intelligent business – they help scale out data understanding and speed up data use. IBM’s MLDC offering, Watson Knowledge Catalog, is an intelligent cataloging service that knowledge workers, including data scientists, can use to index all the available data sets in their business, on premises or cloud. This includes open and third-party data, as well as dashboards, data science and ML models, connections, notebooks and more, to activate them for analytics, machine learning and deep learning with IBM Watson Studio.
“The Forrester Wave™: Machine Learning Data Catalogs, Q2 2018,” which evaluated the major machine learning data catalogs, mentions that IBM Watson Knowledge Catalog: “disguises its ML and cataloging power behind a simple role-based workspace. Revisiting its traditional data management and governance approach to enablement, IBM designed its MLDC from the ground up around role intent and behavior, with ML at the core and the ability to tap into Watson APIs.” [1]
Driving business value with Watson Knowledge Catalog: A use case
Think about how this could work with processing insurance claims, which is an expensive, time consuming, and risk-intensive process. The more time it takes to process a claim and make required adjustments, the higher the risk of lawsuits, which are a costly outcome. Challenges around claims processing become especially intense during natural calamities, when insurers need to process a sudden spike in claims, even to the point of transporting adjusters to the impacted location.
With a data-driven approach, the information gathering process can be significantly expedited with immediate access to relevant information at the first notice of loss, and the use of data, analytics and AI to help identify potential claim fraud using deep learning and detailed data analysis.
Using information that’s available in the insurance company’s enterprise Knowledge Catalog, the provider can easily develop a data-driven claims process that:
Watson Knowledge Catalog is a self-service environment built for enterprises scaling their data and AI strategies.  To  accelerate and maximize  value from AI,  organizations  need  a  strategy that gives  users  access to all their data – no matter where it lives.  The ability for users to review and recommend data sets and analytics assets powers collaboration, while dynamic masking anonymizes and restricts sensitive data. 
Watson Knowledge Catalog also provides foundational data workflows, including preparation, that activates data for productive use with IBM Watson Studio,  a single environment that powers the end-to-end AI workflow.
View our tutorial to learn more about the intelligent and collaborative capabilities of Watson Knowledge Catalog that empower the insurance industry’s business analysts, data scientists and data professionals. You can also find more inspiration and learning on the IBM Watson blog.
To learn more about Watson Knowledge Catalog and Watson Studio, visit ibm.co/wkc.
",IBM Watson,Company,blue,desktop,electronic device,video display,desktop
,187446750783_10155746503425784,https://www.facebook.com/ibmwatson/posts/10155746503425784,Sundays are for science: explore the science behind the AI revolution and the tremendous opportunity being unleashed for businesses and society with IBM's Dr. John Kelly and David Kenny and special guests. Watch the Think keynote replay now.,Link,,,7/15/18 9:28, ,3854,3854,0,5515,5515,0,64,38,47,2,2,4807,3355,0,0,59,0,0,0,0,0,0,0,0,0,0,7,33.0,,8,35.0,,16,24.0,,,22,25.0,,,1,1.0,,1,1.0,,,,,joy,0.758571,positive,0.859722,"tremendous opportunity, IBM's Dr. John Kelly, science","Person, Person, Company",tremendous opportunity,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2Hwv6sY,187446750783_10155744341435784,https://www.facebook.com/ibmwatson/posts/10155744341435784,"&quot;Artificial intelligence is not designed to replace the human mind, but to augment our intelligence and amplify our reach.&quot;

In our latest blog, read about one IBMer's journey to learning effective AI: ",Link,,,7/14/18 10:30, ,4913,4913,0,7278,7278,0,140,77,100,3,3,6006,4135,0,0,106,0,0,0,0,0,0,0,0,0,0,20,65.0,5.0,23,67.0,5.0,31,52.0,,,43,57.0,,,1,2.0,,1,2.0,,"IBM has been on the AI journey for a long time, but the path has not always been smooth. My experience in the consulting business has taught me that successful practitioners need to be flexible and quick to make course corrections. We at IBM have learned along our AI journey, and here are three lessons that come to mind from my own interaction with clients and business colleagues. 1. You fail quickly, and learn fast with AI Remember the adage: garbage in, garbage out. We’ve acknowledged that the results of data analysis are sometimes misleading or even inaccurate. It could result from human error, or personal or institutional biases. Or maybe we’re not asking the right questions. Today we’re building tools that quickly recognize anomalies in the data and even apply a bias rating to outcomes that allow us to make course corrections. Exploration geologists know all about course corrections. They analyze data from drill logs, geological…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/06/AI-jobs_1200x628.png,https://www.ibm.com/blogs/watson/2018/06/journey-ai-three-lessons-learned-effective-implementation/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-3+Lessons+on+Journey+to+AI+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.694862,positive,0.757104,"Artificial intelligence, human mind",Person,Artificial intelligence,Person,joy,0.538828,positive,0.308951,"results of data analysis, consulting business","Company, Person",results of data analysis,Company,joy,0.538571,positive,0.485623,results of data analysis,"Company, Person, Person, HealthCondition, Company, Organization, Person, Person, Company, Quantity","Share this post:
IBM has been on the AI journey for a long time, but the path has not always been smooth. My experience in the consulting business has taught me that successful practitioners need to be flexible and quick to make course corrections. We at IBM have learned along our AI journey, and here are three lessons that come to mind from my own interaction with clients and business colleagues.
1. You fail quickly, and learn fast with AI
Remember the adage: garbage in, garbage out. We’ve acknowledged that the results of data analysis are sometimes misleading or even inaccurate. It could result from human error, or personal or institutional biases. Or maybe we’re not asking the right questions. Today we’re building tools that quickly recognize anomalies in the data and even apply a bias rating to outcomes that allow us to make course corrections.
Exploration geologists know all about course corrections. They analyze data from drill logs, geological shapes, connected devices and maps to plan their next exploration drill. At Goldcorp they are using AI to analyze all this data, and try to identify human error and bias quickly. Their AI platform identifies anomalies and allows geologists to focus on good data as they search for new ore deposits.
2. AI does not replace us; it makes us better
The second lesson is that artificial intelligence is not designed to replace the human mind, but to augment our intelligence and amplify our reach. In the early stages, AI systems were not that smart. Training was a slow, arduous process that required a lot of human intervention. Thankfully, that has led to systems that are now much more robust.
Today, AI platforms are being used in all industries to makes us smarter. A great example is found in healthcare.
Ten million people around the world are living with Parkinson’s disease. The drug treatment hasn’t changed significantly in 50 years. One of our employees living with Parkinson’s thought there must be a better way to advance research. Our AI platform was put to work digesting 28 million medical reports and analyzing 3,800 possible drugs. Sixteen potential drug treatments emerged and the Ontario Brain Institute has funded the initial study with the goal to have more diverse and better treatments for people with Parkinson’s.
AI is not replacing doctors and researchers, but making them smarter.
3. Beware of data ownership in the world of AI
Data ownership has been a hot news item lately. Some large companies have been under fire for misusing data that has been entrusted to them. We believe that you should not be required to relinquish rights to your data in order to have the benefits of an AI platform. In fact, IBM neither owns nor stores any of the data touched by Watson solutions and services. We believe the data and resulting insights belong to your organization and its clients.
A recent IBM survey revealed that 78 percent of respondents say a company’s ability to keep their data private is “extremely important” to them, but only 20 percent “completely trust” organizations they interact with to maintain the privacy of their data.
Your data matters to you — whether it’s your own personal medical records, or the findings from your company’s drug trials or geological surveys.
At the enterprise level, your data is your competitive advantage. If your technology partner is sharing your data with others you may be hurting your business and your clients. You should always retain ownership of your data, and know how it is being used. That is a principle everyone in our industry must adopt.
We’re still in the early stages of our AI journey, and have much to learn as the technology matures. The potential in AI to improve our lives and our businesses is potentially limitless, but as with any new technology, we must approach it responsibly and with a willingness to learn and adapt.
",results of data analysis,Company,green,slope,nature,slope,-
,187446750783_10155742280045784,https://www.facebook.com/ibmwatson/posts/10155742280045784,"To create Wimbledon's poster, Watson Visual Recognition was used to to review over 300,000 separate images from the entire historical archive of The All England Lawn Tennis Club before nearly 9,000 images were selected to make up the final design. Working IBM Watson, the industry leading artificial intelligence capability, AI became the artist. ",Link,,,7/13/18 10:58, ,4496,4496,0,6501,6501,0,158,124,157,3,3,3248,2313,0,0,88,0,0,0,0,0,0,0,0,0,0,14,46.0,1.0,18,50.0,1.0,75,61.0,,,91,66.0,,,1,2.0,,1,2.0,,,,,joy,0.182608,neutral,0,"Watson Visual Recognition, Wimbledon's poster, separate images","Facility, Person, Company, Sport",Watson Visual Recognition,Facility, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2NNRWjQ,187446750783_10155740075810784,https://www.facebook.com/ibmwatson/posts/10155740075810784,We're asking developers worldwide to step up to the plate and save lives during natural disasters using their coding skills. Sign up for Call for Code: ,SharedVideo,,,7/12/18 9:34, ,2298,2298,0,2661,2661,0,265,251,309,4,4,2472,2144,0,0,247,0,0,0,0,371,376,0,0,0,95678,,33.0,,,33.0,,241,13.0,,,295,14.0,,,3,1.0,,3,1.0,,Answer the Call for Code by building global solutions for disaster preparedness.,https://developer.ibm.com/callforcode/img/2020_cfc-logo.png,https://developer.ibm.com/callforcode/,sadness,0.343331,neutral,0,natural disasters,,natural disasters,,joy,0.263089,negative,-0.435401,"disaster preparedness, global solutions",,disaster preparedness,,joy,0.628946,positive,0.658924,"Winners of the Grand Prize, recent global IBM survey","Company, Quantity, Quantity, Quantity, Organization, Quantity, NaturalEvent","Join the movement where over 210,000 participants have stepped up in the past 2 years to build over 8,000 applications for urgent societal issues. Your ideas to help halt and reverse the impact of climate change could earn you $200K and actually be deployed.
Winners of the Grand Prize receive $200,000 USD cash and open source deployment support through Code and Response™ with The Linux Foundation.
In a recent global IBM survey of more than 3,000 developers, first responders, and social activists, 77% agree that climate change is the single most pressing issue of our time. In the same survey, 79% of respondents agree that climate change is something that can be reduced or combatted with technology.
Innovate with the latest technology to address energy sustainability, water sustainability, or disaster resiliency. Winning solutions are deployed in communities that need the most help.
Create an application that makes an immediate and lasting impact in communities around the world by using AI, IoT, data science, and the latest IBM Cloud™ open source development platforms. 
 Learn about the competition, see what you can win, and start coding with a free IBM Cloud account. 
Learn about the impact of climate change and use resources like code patterns, expert videos, and tutorials to build your idea.
Whether you need to find teammates, meet experts, ask questions, or share ideas - there’s a community for you. 
Tell us what you’ve built and how. Submit your idea and your code for a chance to win $200k USD. Submissions open on March 22, 2020 and will close on July 31, 2020.
The Grand Prize winners of the inaugural 2018 Call for Code Global Challenge designed solar-powered mesh network devices that build connectivity where there is none. The team brought their devices in a field test to parts of Puerto Rico hit hardest by Hurricane Maria.
The Grand Prize winners of the 2019 Call for Code Global Challenge beat out nearly 180,000 participants with their solution. The Barcelona-based team, which includes first responders, developed a Watson-based AI solution designed to monitor health and safety in firefighters, both long term and in real-time.
""The climate crisis is caused by us - and the solutions must come from us. We have the tools: technology is on our side""
The 2020 Call for Code Global Challenge is aligned with the United Nations and the launch for its 75th anniversary of a global conversation on urgent issues such as climate crisis. Call for Code is a multi-year initiative created in 2018 by the David Clark Cause with founding partner IBM.
IBM today announced the 2019 Call for Code grand prize was awarded to Prometeo for developing a health monitoring platform for firefighters. The [team] will receive $200,000 and assistance from IBM and its partners to bring the project to life.
[IBM's] Call for Code and Code and Response programs leverage IBM’s technology to address some of the world’s most pressing problems.
By providing foundational technologies and investing financial resources in these initiatives, IBM and its partners are aiming to inspire new approaches and new solutions to growing, evolving global problems. Call for Code and Code and Response are clearly on the right path.
Have questions about the challenge? Visit the Call for Code program page to view  frequently asked questions.
Now in its third year, the Call for Code Initiative is the largest technical challenge of its kind. The 2020 Call for Code Global Challenge asks the world's developers to build solutions for climate change. The world is facing unprecedented, interconnected environmental challenges and we believe technology can help.
Commit to the cause. Push for change. Answer the call. 
callforcode.org
",Winners of the Grand Prize,Company,ultramarine,ultramarine color,blue color,ultramarine color,-
https://ibm.co/2KCSsmk,187446750783_10155738143335784,https://www.facebook.com/ibmwatson/posts/10155738143335784,"Get a head start on planning summer travel with Best Western Hotels &amp; Resorts's new AI-powered ads, designed to answer all your travel questions via Adweek: ",Link,,,7/11/18 11:10, ,3834,3834,0,5335,5335,0,66,36,45,0,0,4559,3324,0,0,55,0,0,0,0,0,0,0,0,0,0,5,32.0,2.0,5,34.0,5.0,23,15.0,,,30,15.0,,,,,,,,,The hotel chain is also debuting a chatbot.,https://www.adweek.com/wp-content/uploads/2018/06/WatsonAd_BestWestern-CONTENT-2018-600x315.jpg,https://www.adweek.com/brand-marketing/best-western-is-turning-to-ibm-watsons-ai-to-help-travelers-plan-summer-vacations/,joy,0.782794,positive,0.901607,"head start, Best Western Hotels, summer travel",,head start,,joy,0.265406,neutral,0,hotel chain,,hotel chain,,joy,0.497631,positive,0.83297,plenty of Best Western,"Person, Company, Person, Person, Company","The campaign, which begins today, will run across IBM’s Weather Channel app and weather.com and use Watson’s AI capabilities to have a text-based conversation with users. When a user clicks on an ad, they will be prompted to share what their plans are for the trip before getting specific ideas. There are also plenty of Best Western-based messages along the way such as prompts for how to make a reservation or what’s included in a hotel.
Using Watson, IBM ingested a variety of data from both Best Western and other sources to better understand the travel category; data like travel itineraries, parking information for various destinations, and tips on how to stay hydrated. The AI’s ability to process natural language then allows it to communicate back and forth with a user in a more human-like way.
The target market for Best Western’s campaign includes both business and leisure travelers along with urban millennials, the companies said. The campaign will also provide the brand with a trove of new data about consumers such as which questions they ask, what they’re interested in, where they’re going. The campaign also comes just two weeks before Best Western will debut a new chatbot aimed at helping rewards customers.
“We have very strong understandings of our rewards customers,” said Best Western Chief Marketing Officer Dorothy Dowling. “We have more than 35 million customers that are part of our Best Western rewards program, so we have a lot of knowledge in terms of what their behavior looks like in terms of booking as well as qualifying and understanding what they want to do in market.”
While Best Western is the first hospitality brand to use IBM Watson’s advertising suite, it’s just the latest campaign created by Watson Advertising, which debuted a suite of new products last fall.
Other brands that have used Watson include an undisclosed entertainment brand, which used Watson ads to recommend shows for people to watch based on their current mood and interests. Watson-powered campaigns usually take between four and 12 weeks depending on their complexity, according to IBM.
Ad campaigns powered by Watson for other brands have had average engagement times of between two and three minutes—far higher than a standard banner ad, according to IBM Watson Chief Revenue Officer Carrie Seifer,
“The last two years, we’ve had these Watson ad units available to advertisers where it really uses AI inside of the ad units to have a much more sophisticated conversation between customer and advertiser,” Seifer said.
",plenty of Best Western,Person,blue,water heater,machine,vending machine,-
https://ibm.co/2KQijYY,187446750783_10155736009095784,https://www.facebook.com/ibmwatson/posts/10155736009095784,"Because AI is becoming increasingly powerful, existing computer hardware is slow to keep up. That's why IBM researchers were driven to develop a fast, efficient chip designed to train AI. Read more via VentureBeat: ",Link,,,7/10/18 11:54, ,11423,11423,0,15541,15541,0,273,187,230,5,5,11946,8895,0,0,198,0,0,0,0,0,0,0,0,0,0,26,107.0,1.0,28,107.0,1.0,104,97.0,,,127,103.0,,,4,1.0,,4,1.0,,IBM researchers have developed a chip that can train certain kinds of neural networks more efficiently than traditional hardware.,,https://venturebeat.com/2018/06/29/ibm-researchers-design-a-fast-power-efficient-chip-for-ai-training/,joy,0.172484,positive,0.676187,IBM researchers,"Person, Company",IBM researchers,Person,joy,0.139534,positive,0.598685,IBM researchers,Company,IBM researchers,Company,joy,0.563096,positive,0.571738,neural network,"Person, Company, Person, Person, Company, PrintMedia","Thanks to powerful graphics chips and advances in distributed computing, optimizing the algorithms at the core of artificial intelligence is easier than ever before. But it’s not particularly efficient on current-day hardware — even powerful GPUs can take days or weeks to train a neural network.
That catalyzed researchers at IBM to develop a new chip tailor-made for AI training. In a paper published in the journal Nature titled “Equivalent-accuracy accelerated neural-network training using analog memory,” they describe a system of transistors and capacitors that can train neural networks quickly, precisely, and highly energy-efficiently.
Neural networks consist of interconnected units called neurons or nodes (a collection of nodes is called a layer), which receive numerical inputs. In a basic network, individual neurons multiply those inputs by a value — a weight — and pass them along to an activation function, which defines the output of the node. Through a strategy known as backpropagation, the weights are adjusted over time, improving the accuracy of the outputs.
GPUs are well-suited for these because unlike traditional processor, which crunch through numbers sequentially, they’re able to perform lots of computations in parallel. But because the processor and memory in graphics chips sit a considerable distance apart from one another on the motherboard, delays are introduced as data shuttles back and forth between them.
“Conventional computers [consume] consume an enormous amount of energy,” Stefano Ambrogio, a postdoctoral researcher at IBM who led the project, told VentureBeat in an interview, “and there’s a lot of waiting involved.”
The scientists’ solution consists of analog memory and traditional electronic components. Individual cells made up of a pair of phase change memory (PCM) units and a combination of a capacitor and three transistors correspond to individual neurons in the network. The PCMs store weight data in memory, which is represented in the transistors and capacitors as an electrical charge.
As the network trains, the capacitor updates the weights, transferring them to the PCM after thousands of cycles.
The capacitor can’t retain values for more than a few milliseconds, but it can be programmed quickly. And the PCM, which is a form of non-volatile memory, doesn’t need an external power source to retain data.
The researches used a mix of hardware PCMs and software-simulated components to benchmark the design, and the results are promising. The chip performed 100 times more calculations per square millimeter than a GPU while using 280 times less power. Even more impressive, it matched the speed and accuracy of Google’s TensorFlow machine learning framework on a variety of computer vision tasks.
“We can do [the calculations] in a very accurate way, at the same accuracy as software,” Ambrogio said.
The researchers’ chip design isn’t without a significant caveat: It’s not optimized for neural networks that aren’t fully connected, such as the long short term memory (LSTM) networks used in cutting-edge speech recognition apps. But the researchers plan to tackle that next.
Ambrogio is confident they’ll be able to build physical chips at scale in the future. He sees them being used for training neural networks in smartphones and other devices that currently lack the necessary computing resources.
“It would be nice to be able to directly process AI where it’s needed,” Ambrogio said. “When you’re able to train a model, you don’t need to send the information [to the cloud] or have [the device] communicate with something else, and it can react instantly to something.”
",neural network,Person, , , , , 
,187446750783_10155733548670784,https://www.facebook.com/ibmwatson/posts/10155733548670784,IBM Watson,SharedVideo,,,7/9/18 7:28, ,2855,2855,0,3291,3291,0,120,94,125,0,0,3062,2738,0,0,111,0,0,0,0,1518,1544,0,0,0,61907,,40.0,,,41.0,,93,4.0,,,121,4.0,,,,,,,,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2DNYtFb,187446750783_10155730285105784,https://www.facebook.com/ibmwatson/posts/10155730285105784,"Available now, Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI. ",Link,,,7/7/18 18:04, ,14425,14425,0,20281,20281,0,419,272,348,8,8,15550,11429,0,0,344,0,0,0,0,0,0,0,0,0,0,35,194.0,5.0,37,195.0,6.0,151,138.0,,,198,150.0,,,3,5.0,,3,5.0,,"Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity. Consider three distinct examples – 1. Fixing issues with Visual Diagnosis User: A person in the field equipped with an iPhone trying to visually diagnose a problem. Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage. 2. Recommendations based on Visual analysis User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations. Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/03/GettyImages-1086731554.jpg,https://www.ibm.com/blogs/watson/2018/03/ai-everywhere-ibm-watson-apple-core-ml/,anger,0.075048,neutral,0,Watson Visual Recognition Service,"Person, Company, Company",Watson Visual Recognition Service,Person,sadness,0.551904,negative,-0.449804,Visual Diagnosis User,Person,Visual Diagnosis User,Person,joy,0.548225,positive,0.631349,number of users,"Person, HealthCondition, Company, Person, Company","Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity.
Consider three distinct examples –
1. Fixing issues with Visual Diagnosis
User: A person in the field equipped with an iPhone trying to visually diagnose a problem.
Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage.
2. Recommendations based on Visual analysis
User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations.
Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying unknown or complex machine parts to classifying plants or food.
3. Visual triggers for a business process
User: An end user and a trigger for a downstream business process
Usage: Business processes range from creating a work order for repair to updating a shopping cart for purchase; from intervening in quality control to safety procedure in manufacturing; from initiating an insurance claim to a collaborative analysis for experts in medicine.
These are a diverse set of scenarios with a common thread running through them: the need for a low-latency and rich insight for a human or a downstream process.
Imagine a scenario where a user is trying to access results while on-the-go (changing network speeds), or in hard-to-reach places (manufacturing plants, buildings, store interiors, remote areas, etc.). This impacts the user’s ability to do the job, which can have a domino effect on business processes and the bottom line for companies.
The most compelling way to empower that user combines relevant AI insights, at the time of need, without the user having to worry about network connectivity issues.
To set this in motion, you need:
1. A technique to handle tradeoffs between immediate insights, irrespective of connectivity, with richer insights from the cloud, allowing the user to focus on the task at hand.
2. Collaborative methods and tools for users, developers and/or data scientists to build solutions in a way that allows them to focus on the higher end of the solution spectrum.
3. An approach with associated technology that enables a process of rapid iteration to keep up with constantly changing data and other surrounding factors.
Components of this solution are being successfully used by enterprises and consumers across industries and geographies.
Watson services on the IBM Cloud provide rich and relevant insights from a variety of public and enterprise data sources to applications. IBM’s approach to data and privacy with Watson ensures that client data and insights are not shared with IBM or third parties, and that client data does not contribute to training a centralized knowledge graph.
Apple Core ML is a foundational machine learning (ML) framework that lets you integrate ML models into your app. Core ML delivers optimized performance for Apple products with minimal memory footprint and battery consumption impact. User privacy is protected as data is stored locally and encrypted by default.
What’s new – Bringing it together with a seamless experience
Available today, Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI.
These are key aspects of what is now available to the ecosystem of users and developers. Read more about the partnership here.
1. Watson SDK low latency, and offline process for custom Visual Recognition models using Core ML with the rich insights from the Watson services on the cloud.
2. Watson Studio provides a low-code, end-to-end collaborative environment that enables developers to quickly and easily catalog, classify, provision, and train their data and models.
3. Developer assets and best practices including Code Patterns for developers to get started, starter kits to quickly build iOS apps that combine these Watson services with other components, and code examples to get started now.
These offerings are the first step towards mitigating challenges for users, developers, and enterprises. Companies have already started building enhancements to applications that leverage Watson Visual Recognition Service for Core ML.
For the developer, this drives a paradigm for building once and deploying at heterogeneous endpoints. For the user, this translates to growth in the expertise spectrum and higher productivity. For the enterprise, this is an inevitable step toward mobile and AI revolutionizing how we work.
Watch the demo to see how this all comes together for part and issue identification on Arduino boards, a representative for any component.
",number of users,Person,blue,X-ray film,photographic equipment,photographic film,X-ray film
https://ibm.co/2HQo7eM,187446750783_10155728523550784,https://www.facebook.com/ibmwatson/posts/10155728523550784,"“Deep-Learning-as-a-Service seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power.” via The Wall Street Journal: ",Link,,,7/6/18 19:59, ,8776,8776,0,11999,11999,0,161,90,105,5,5,10343,7624,0,0,138,0,0,0,0,0,0,0,0,0,0,16,82.0,1.0,17,82.0,1.0,42,53.0,,,51,54.0,,,2,3.0,,2,3.0,,"Deep-Learning-as-a-Service, unveiled Tuesday in Las Vegas, aims at easing the complex process of creating deep-learning algorithms for business data, the company said.",//si.wsj.net/public/resources/images/BN-XY012_0320_c_P_20180320173444.jpg,https://blogs.wsj.com/cio/2018/03/20/ibm-tool-seeks-to-bridge-ai-skills-gap/,joy,0.312581,negative,-0.609749,"Deep-Learning, a-Service, deep-learning tools",PrintMedia,Deep-Learning,PrintMedia,joy,0.525414,positive,0.928478,"Deep-Learning, complex process, Las Vegas, a-Service",Location,Deep-Learning,Location,joy,0.473438,positive,0.702652,,"Company, Company, Person, Person, Person, Location","Deep-Learning-as-a-Service, unveiled at IBM’s annual IT industry conference in Las Vegas, seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power, the company said.
The new service allows companies to upload data in Watson Studio, IBM’s cloud-native platform for data scientists, developers and business analysts. There, they can create deep-learning algorithms for datasets – known in AI parlance as a “neural network” – using a drag-and-drop interface to select, configure, design and code the network.
IBM also has automated the repetitive process of fine-tuning deep-learning algorithms, with successive training runs started, monitored and stopped automatically.
For many firms, the complexity of creating smart algorithms from scratch has kept them from leveraging AI to parse massive stores of data for business value, the company said.
Ginni Rometty, IBM’s chairman and chief executive, called data the “basis for competitive advantage,” in her opening remarks at Tuesday’s event.
In today’s cloud-powered markets, she said, businesses need to leverage multiple digital platforms, while embedding smart tools into every process they run. “You’ve got to keep making AI easier to use,” she added.
In a recent Gartner survey, chief information officers ranked AI, along with digital security and the Internet of Things, as the hardest technologies to implement, citing hard-to-find skills required to make them work. The survey included more than 3,000 CIOs across all major industries.
Werner Goertz, a Gartner research director, said skills, expertise and staff around AI “remain in incredibly short supply, and whatever talent is out there is quickly absorbed by the big players.”
“There is an enormous gap” between the available capabilities and the skills required to make them work, Ben Fried, CIO of Google Inc. said earlier this month at WSJ CIO Network’s annual meeting in San Francisco.
Google in January launched Cloud AutoML, a similar AI tool designed to help developers automatically build and train deep-learning models. Google Cloud also offers pre-trained models.
Microsoft Corp., Salesforce.com Inc., Oracle Corp. and other cloud providers have added AI and machine learning capabilities into many of their cloud-based enterprise tools and services.
For IBM, and other tech giants, cloud computing and related services, such as AI, have been a boon. In January, the company reported a 3.6% increase in fourth-quarter revenue to $22.54 billion -- its first quarterly revenue gain since 2012 -- driven in part by a 30% increase in cloud-computing revenue to $5.5 billion, the company said.
",,Company, , , , , 
,187446750783_10155725613480784,https://www.facebook.com/ibmwatson/posts/10155725613480784,IBM Watson,SharedVideo,,,7/5/18 10:51, ,3136,3136,0,3468,3468,0,173,142,174,5,6,3249,2954,0,0,161,0,0,0,0,2036,2152,0,0,0,68414,,46.0,,,46.0,,141,7.0,,,167,7.0,,,1,5.0,,1,4.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2Mcl2J8,187446750783_10155722066990784,https://www.facebook.com/ibmwatson/posts/10155722066990784,"&quot;To adopt IBM Watson into your world – whether that’s putting it to work in a complex process like supply chain or something geared toward a consumer interaction, like a chatbot – you have to see and believe in its impact. I do that by showing what Watson is capable of, what it has already empowered people to accomplish, and what the possibilities of our future hold.&quot; – IBMer Rachel Liddell. Read her story on our blog: ",Link,,,7/3/18 18:04, ,7053,7053,0,9581,9581,0,108,71,88,6,7,8830,6610,0,0,96,0,0,0,0,0,0,0,0,0,0,5,39.0,2.0,5,40.0,2.0,41,37.0,,,50,38.0,,,4,3.0,,4,2.0,,"To Rachel Liddell, telling stories is far more than entertainment. It’s one of the most powerful tools we have to spur change and inspire action in the world. Rachel majored in literary studies at Middlebury College, exploring literature across cultures, geographies, and time. She learned how creative storytelling can shape our understanding of the world, deepen the role we take within it, and impact our behavior in ways that can drive amazing change. Now, in a storytelling plot twist, Rachel works for one of the largest technology companies in the world – IBM – applying her passion for literature, and expertise with words, to help articulate the story of our AI future. Based at IBM’s Watson Experience Center in New York City’s Astor Place, Rachel helps business leaders and influencers understand how Watson will change their organizations, their communities – and their lives – by telling stories about the real impact and exciting possibilities of AI. We…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/05/blog_watsonWomen_png_socialTile_052218.png,https://www.ibm.com/blogs/watson/2018/05/showing-telling-ibm-engagement-leader-helps-people-see-future-watson/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-How+IBM+leader+helps+people+see+future+with+Watson+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.683194,positive,0.781597,"IBM Watson, possibilities of our future hold, complex process, supply chain","Company, Person",IBM Watson,Company,joy,0.683438,positive,0.891323,"creative storytelling, Rachel Liddell, New York City’s Astor Place, IBM’s Watson Experience Center, storytelling plot twist","Person, Person, Organization, Facility, Company",creative storytelling,Person,joy,0.623288,positive,0.749295,,"Person, Company, Person, Person, Person, Facility","To Rachel Liddell, telling stories is far more than entertainment. It’s one of the most powerful tools we have to spur change and inspire action in the world. Rachel majored in literary studies at Middlebury College, exploring literature across cultures, geographies, and time. She learned how creative storytelling can shape our understanding of the world, deepen the role we take within it, and impact our behavior in ways that can drive amazing change.
Now, in a storytelling plot twist, Rachel works for one of the largest technology companies in the world – IBM – applying her passion for literature, and expertise with words, to help articulate the story of our AI future. Based at IBM’s Watson Experience Center in New York City’s Astor Place, Rachel helps business leaders and influencers understand how Watson will change their organizations, their communities – and their lives – by telling stories about the real impact and exciting possibilities of AI.
We talk with Rachel about how she helps people see – and prepare for – the future with AI.
Did you ever see yourself working for a technology company?  
Technology was one of the few subjects not on my radar while at Middlebury. I was buried in literature, studying topics like political science, sociology and physics – but technology? It wasn’t even an area of interest, or one I thought my skillset was aligned to. Looking back, I see how literature and technology have so much in common. They both require a considerable amount of creativity, collaboration and communication. Technology is both a vehicle for language, but also a language itself – and it is rapidly redefining the world as we know it today. How, when, where and what we communicate is influenced heavily by the growing repertoire of technology at our disposal.
How I wound up at IBM is a classic story itself. Throughout college I loved exploring new topics and meeting people, which is part of what drove me to take on a role in admissions where I would build relationships with prospective students and give tours to inform them about the college. Through that role, I met my now mentor. He worked for IBM and opened my eyes to the possibilities of starting my career in technology. AI has the potential to improve nearly everything we do – from how we process information, engage with one another, and how we apply creativity. That includes communication and storytelling. Looking back, I don’t see my academic experience in literature and my career choice in tech as disconnected, but instead closely aligned. I’ll always be a literary nerd at heart, so the opportunity to be on the front lines of a technology that will influence so much about our future – including how and what we tell stories about – is hugely exciting and rewarding. 
How do you help people understand AI, especially when they’re critical about the technology? 
To adopt IBM Watson into your world – whether that’s putting it to work in a complex process like supply chain or something geared toward a consumer interaction, like a chat bot – you have to see and believe in its impact. I do that by showing what Watson is capable of, what it has already empowered people to accomplish, and what the possibilities of our future hold.  
It can be difficult to articulate how a technology as complicated and all-encompassing as AI will have an impact on one person. This is why storytelling is so important. It’s my job to understand what matters to everyone I meet with – what makes them, as a character, tick – and then show them how Watson can help them be the hero in their own story, achieving great things together. That can be presenting the ways in which Watson makes sharing knowledge across an organization better and smarter, or showing how Watson analyzes tone to inform more intelligent marketing campaigns. But regardless of what the story is about, it must connect on a personal level. That’s when I see the “aha” moment. The moment people realize how AI will make them better at their job, make their information more actionable – that’s when skeptics turn into optimists. 
It’s important to note that I don’t shy away from the tough questions. One of the most exciting parts about working in the field of AI today is just how many unknowns there are. It’s still early days for this technology. IBM is developing it responsibly and carefully, but there is much we all still must learn and discover. When I meet with someone who is skeptical, or worse, afraid, I remind them that this is an exciting frontier that they not only have an opportunity – but a responsibility – to help shape.
When did Watson – and the opportunity for AI – first inspire you? 
One of the first times I truly understood the power of AI was, once again, when it became personal. Both of my parents are doctors. They’ve dedicated their careers to health and medicine, working long hours during the day and continuing to work at home in the evening – working to provide the best possible care for their patients. So, when my mother told me she struggled with her dictation software, I had my own “aha” moment –better access to information can have an enormous impact. With AI, patient insights aren’t just easier to find – they jump right off the page. Watson can analyze thousands of medical articles and studies, while nearly simultaneously comparing that data to a patient’s historic records. Things that physicians, even my parents, despite their brilliance, can’t do effectively at scale – but AI can do it for them, freeing them to deliver better care to more patients. 
That’s why I’m so excited about Watson and humbled to be part of the team building the future of AI at IBM. For me, it’s not so much about what the technology is – but what is does. IBM is transforming the world by helping people be better at what they do. Whether that’s as simple as turning my mother’s notes into immediate, actionable insight or redefining how doctors access data to inform better, potentially life-saving treatments, the opportunity AI presents is to make us better at everything we do.  
Looking ahead, five to ten years, where do you see AI having the greatest impact? 
Very soon, AI will become omnipresent throughout our personal and professional lives. It will help people, like my mother, become even better at their jobs by turning the data that surrounds us into insights we can leverage to do amazing things. At home, it will help us experience life, understand the world – and yes, tell stories – across cultures, geographies and barriers in a way we’re just starting to see a glimpse of now.
This future will be powered by businesses that empower their employees.  Which is why today we should all be looking forward – five, ten, even twenty years from now – and thinking about what our role can be in that future. I never thought my artistic and literary background would be applicable at a company like IBM. But what I realize now, and what I encourage everyone to consider, is how important creativity and communication will be to our future. Connecting the dots with this life-changing technology requires humans to work together, think outside of the box and be consistently curious. Ask questions, ponder the impossible – and always be learning. 
",,Person,blue,anchorperson,person,anchorperson,-
https://ibm.co/2N4NY6e,187446750783_10155719147365784,https://www.facebook.com/ibmwatson/posts/10155719147365784,"Over the weekend, IBM helped send artificial intelligence to space aboard the International Space Station. 

Meet CIMON, the world's first AI-powered assistant designed to help astronauts on their mission: ",Link,,,7/2/18 9:32, ,12434,12434,0,17100,17100,0,302,177,233,7,7,12842,9593,0,0,216,0,0,0,0,0,0,0,0,0,0,30,154.0,5.0,37,161.0,6.0,108,86.0,,,137,96.0,,,1,6.0,,1,6.0,,"Die Weltraumforschung hat schon immer zu Pioniertaten inspiriert. Jetzt ist IBM erneut Teil eines Pionierprojekts, das von DLR und Airbus in Auftrag gegeben wurde und dabei half, einen intelligenten, autonomen, mobilen und interaktiven Begleiter zu schaffen. Mit dem Ziel, ihn zu einem von der Crew anerkannten und geschÃ¤tzten Besatzungsmitglied an Bord der ISS zu machen.",https://www.ibm.com/thought-leadership/smart/de-de/ai-in-space/img/cimon_social.jpg,https://www.ibm.com/thought-leadership/smart/de-de/ai-in-space/?social_post=1626044432&linkId=53618899,joy,0.386955,neutral,0,"Meet CIMON, artificial intelligence, International Space Station","Person, Company, Facility",Meet CIMON,Person,anger,0.219092,negative,-0.789689,DLR und Airbus,"Person, Company, Person, Organization, Organization",DLR und Airbus,Person,sadness,0.59525,negative,-0.768815,,"Person, Person, Company, Person, Person, Person, Person, Person, Person","Die Weltraumforschung hat schon immer zu „Firsts“ inspiriert. Im Aufrag des Raumfahrtmanagements des DLR und Airbus haben wir dazu beigetragen, den Crew Interactive Mobile CompaniON (CIMON®)* zu entwickeln.  Unser Ziel: ihn mit Hilfe der künstlichen Intelligenz Watson zum anerkannten und geschätzten Crew-Mitglied der ISS  zu machen.
Am Anfang war er eine Kugel aus Kunststoff. Zu Beginn war nicht viel an ihm dran — nicht einmal ein Name. Also nannten ihn die Ingenieure im Team einfach „Spaceball“.
Bevor er die Weltraumreise des Astronauten-Assistenten auf den Weg brachte, war Matthias Biniok damit beschäftigt, die Watson—Technologie auf dem Erdboden auf Herz und Nieren zu prüfen. 
CIMON® hatte eine kleine Identitätskrise, bevor die Psychologiestudentin Sophie Richter—Mendau hinzukam. 
Nina Fischer, eine begnadete Programmiererin, hatte in ihrer Karriere bereits einige faszinierende technologische Herausforderungen erlebt. 
Diese vier verschiedenen APIs kommen zum Einsatz: Watson Assistant, Visual Recognition, Text to Speech und Speech to Text 
© IBM Corporation 2018
IBM, das IBM Logo, ibm.com und Watson sind Marken der IBM Corporation, die in vielen Ländern weltweit registriert sind. Eine aktuelle Liste der IBM Marken finden Sie im Internet in den „Copyright- und Markeninformationen“ unter www.ibm.com/legal/copytrade.shtml.
*CIMON®, eine in Deutschland eingetragene Marke des Deutschen Zentrums für Luft- und Raumfahrt e. V. (DLR), steht für Crew Interactive MObile CompanioN und ist ein vom DLR-Raumfahrtmanagement gefördertes wissenschaftliches Projekt, finanziert mit Mitteln des Bundesministeriums für Wirtschaft und Energie (BMWi). Andere Produkt- und Servicenamen können Marken der IBM Corporation oder anderer Unternehmen sein.
",,Person,coal black,person,machine,motor,engine
https://ibm.co/2J2E99U,187446750783_10155717585580784,https://www.facebook.com/ibmwatson/posts/10155717585580784,"IBM is working to create 1,800 new jobs to build a stronger AI presence in France: ",Link,,,7/1/18 16:12, ,9782,9782,0,13332,13332,0,169,94,108,5,5,11744,8480,0,0,151,0,0,0,0,0,0,0,0,0,0,20,77.0,1.0,22,81.0,1.0,44,54.0,,,51,57.0,,,3,2.0,,3,2.0,,"IBM is also adding new training programs for its 'new collar' skills in AI, blockchain, cloud, and IoT.",https://tr3.cbsistatic.com/hub/i/r/2018/05/23/787708ef-be2b-4db6-a249-cbed2a7f830a/thumbnail/770x578/a7912c33feeeb174b1b7e801fbccb295/aijobs.jpg,https://www.techrepublic.com/article/ibm-to-add-1800-jobs-in-france-to-meet-growing-demand-for-ai/,joy,0.552262,positive,0.839672,"new jobs, IBM","Company, Person",new jobs,Company,joy,0.290664,neutral,0,"new training programs, new collar' skills, IBM",Company,new training programs,Company,joy,0.466737,positive,0.677622,IBM's initiative,"Company, Location, Person, Person, Person, Person"," 	IBM is working to bring 1,800 jobs to France over the next two years in effort to bolster talent in artificial intelligence, IoT, cloud, and blockchain, CEO Ginni Rometty said at the Tech for Good Summit in Paris Wednesday.
 	Also at the summit, the firm announced an expansion of its program for "" 	new collar"" skills training, IBM's initiative to train tech workers with specific high-level skills outside of a traditional four-year degree. The summit was hosted by French President Emmanuel Macron, a press release noted.
 	""President Macron is making a big bet, and a smart one, that AI is going to transform every job, every profession and every industry,"" Rometty said in the release. ""At IBM, we share this belief and see evidence of it every day with Watson driving exponential impact here in France and around the world. That is why we are bringing 1,800 new jobs to France to meet growing demand for AI from our clients.""
 	 	SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
 	Of the 1,800 jobs, IBM will hire business consultants, IT architects, developers, and technical experts the release said. Some 400 of the jobs will be certain AI roles that IBM announced back in March.
 	Utilizing local public and private partners, IBM will also use the hiring initiative to help create ""local competitiveness hubs"" to strengthen its presence in France. These are already underway in Lille and Strasbourg, the release said.
 	""IBM will continue to work with the government to make sure France has the skilled workforce necessary to take advantage of this unique era,"" Nicolas Sekkaki, general manager of IBM France, said in the release.
 	As part of the new collar training expansion, IBM will be creating roles in security, data science, AI, and more. These roles won't require a four-year degree, as noted, but employees will be prepared ""through vocational or on-the-job training,"" the release said.
 	According to the release, IBM is also working with the French government to support its P-TECH (Pathways to Technology Early College High School) education model, providing next-gen skills and job training for disadvantaged youth. More than 400 companies are now involved with P-TECH, the release said.
 	The launch of IBM France Academy was also announced at the summit in an effort to ""train IBM France employees, clients and partners to build modern skills for the AI-era,"" the release said.
 	The real impact of AI on jobs is yet to be seen. While the technology will undoubtedly eliminate some roles, some have predicted that it could  	create more jobs in place of those. Additionally, a 2018 Workplace Institute report noted that 82% of employees believe AI will improve their jobs in some way.
",IBM's initiative,Company,black,dance,person,dance,-
https://ibm.co/2IAF8uy,187446750783_10155714682750784,https://www.facebook.com/ibmwatson/posts/10155714682750784,"&quot;IBM's now one of the big dogs in the new high-stakes world of modern enterprise IT centered on how cloud, AI, blockchain, machine learning, and advanced cybersecurity can help businesses get, manage and exploit data to make better decisions, dazzle customers and trounce competitors.&quot; ",Link,,,6/30/18 12:06, ,16808,16808,0,23459,23459,0,857,621,701,8,8,18529,13692,0,0,675,0,0,0,0,0,0,0,0,0,0,43,293.0,4.0,45,298.0,4.0,145,504.0,,,181,520.0,,,5,3.0,,5,3.0,,A resurgent IBM becomes one of the world's top 3 enterprise-cloud providers under the courageous leadership of CEO Ginni Rometty as cloud revenue topped $17 billion for 2017 and hit $5.5 billion--up 30%--in Q4. IBM's achievement proves why conventional wisdom is useless in our unconventional world.,https://thumbor.forbes.com/thumbor/fit-in/1200x0/filters%3Aformat%28jpg%29/https%3A%2F%2Fspecials-images.forbesimg.com%2Fdam%2Fimageserve%2F503702202%2F0x0.jpg%3Ffit%3Dscale,https://www.forbes.com/sites/bobevans1/2018/01/19/ibm-joins-microsoft-amazon-atop-cloud-world-booming-cloud-business-ends-long-revenue-decline/#46fa6c9e49c4,joy,0.566134,positive,0.937289,machine learning,Company,machine learning,Company,joy,0.47765,negative,-0.381805,"resurgent IBM, conventional wisdom","Person, Company, Quantity, Quantity, Quantity",resurgent IBM,Person,sadness,0.591304,positive,0.657601,"IBM's cloud revenue, CLOUD WARS","Company, Person, Company, Quantity, Quantity","(Note: After an award-winning career in the media business covering the tech industry, Bob Evans was VP of Strategic Communications at SAP in 2011, and Chief Communications Officer at Oracle from 2012 to 2016. He now runs his own firm, Evans Strategic Communications LLC.)
CLOUD WARS -- Accelerating its remarkable turnaround and establishing itself among the top 3 enterprise-cloud players, IBM's cloud revenue for the year rose 24% to $17 billion and jumped $30% in the fourth quarter to $5.5 billion.
With cloud revenue now making up 21% of IBM's total revenue of $79.1 billion, IBM's reinvigorated technology and market focus have allowed the company to snap an agonizing streak of 20+ quarters of declining revenue as CEO Ginni Rometty's heroic transformation of the iconic 106-year-old company has come full circle.
With its multifaceted cloud business leading the way, IBM's ""strategic imperatives""—cloud, security, analytics and mobile—grew 14% in the fourth quarter and now account for close to 50% of the company's revenue.
This type of resurgence in the dynamic and rapidly evolving tech sector is supposed to be impossible—for several years now, the prophets of doom have been saying IBM had lost its way, couldn't afford to invest in advanced technology, was overinvested in services, didn't get the cloud, and was hopelessly trapped in a death spiral.
But proving yet again that conventional wisdom in today's unconventional enterprise-IT world is utterly worthless, IBM reported growth across the board and projected continued growth throughout 2018.
And Rometty solidified her reputation as not only a courageous CEO willing to take on the near-impossible task of turning around a slumping giant, but also as a visionary strategist who several years ago set a bold new vision for the company centered on powerful new technologies, defied critics who said IBM should be sold off in pieces, and forcefully recreated IBM as one of the world's pre-eminent sources of innovation and business value.
""During 2017, we strengthened our position as the leading enterprise cloud provider and established IBM as the blockchain leader for business,"" Rometty said in a press release announcing its financial results, adding that IBM is ""uniquely positioned to help clients use data and AI to build smarter businesses.""
""Strengthened,"" indeed. In the red-hot enterprise-cloud sector, here are some highlights of what IBM achieved in the fourth quarter and for all of 2017 as it defied the doomsayers and joined Microsoft and Amazon among the three biggest and most-influential cloud vendors.
And in an internal move that will create huge new scaling capabilities for the IBM Cloud, senior vice-president Martin Schroeter said on the earnings call that IBM would be moving its massive services business—the current backlog is $120 billion—onto the IBM Cloud platform.
""So not only are we building and moving new SaaS properties into the cloud—which have great margins—and not only are we building our Platform as a Service and building ecosystems around that, but we also have north of $120 billion backlog in our services business that we're in the process of moving to the cloud,"" Schroeter told the analysts per the earnings-call transcript on SeekingAlpha.com.
""So when we talk scale, we're moving our whole services platform on to the IBM Cloud, and that's going to give us the scale we need, not just for that infrastructure layer but it's going to give us the scale we need to manage applications, it's going to give us to scale we need to deliver SaaS as effectively as possible and efficiently as possible. So we've got a lot of scale coming our way.""
So IBM is not just ""back""—IBM's now one of the big dogs in the new high-stakes world of modern enterprise IT centered on how cloud, AI, blockchain, machine learning, and advanced cybersecurity can help businesses get, manage and exploit data to make better decisions, dazzle customers and trounce competitors.
And IBM fully deserves to be regarded as one of the Big Three in the Cloud Wars along with Microsoft and Amazon.
I've analyzed and written about the enterprise-tech business for more than 20 years from the media side as an editor-in-chief and chief content officer, and more recently as Chief Communications Officer at Oracle from 2012-2016. I've written thousands of articles and columns about business innovation, competitive advantage, strategy, leadership, disruptive technology, customer case-studies, CEO profiles, digital transformation and cloud computing. Late last year, I resigned from Oracle to launch my own company, Evans Strategic Communications, which helps businesses grow via thought leadership and innovative storytelling.
",IBM's cloud revenue,Company,blue,celebrity,person,adult,celebrity
,187446750783_10155709928290784,https://www.facebook.com/ibmwatson/posts/10155709928290784,IBM Watson,SharedVideo,,,6/28/18 6:48, ,3001,3001,0,3260,3260,0,182,161,196,3,3,3043,2843,0,0,172,0,0,0,0,1398,1411,0,0,0,69779,,38.0,1.0,,41.0,1.0,160,1.0,,,195,1.0,,,,3.0,,,3.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2KkTCPH,187446750783_10155708336465784,https://www.facebook.com/ibmwatson/posts/10155708336465784,"AI has the potential to help close the learning gap and to equalize opportunity regardless of student-teacher ratio, school budget or lack of resources. IBM Watson is partnering with Scholastic and Edmodo to do just that. Learn more about how the partnership will impact classrooms: ",Link,,,6/27/18 10:46, ,8009,8009,0,11188,11188,0,126,67,86,8,10,9103,6613,0,0,100,0,0,0,0,0,0,0,0,0,0,19,64.0,3.0,21,66.0,3.0,40,29.0,,,57,29.0,,,7,3.0,,7,1.0,,"In classrooms with children of all ages and in schools around the world, teachers are met with the challenge of addressing each student’s individual needs and the rate at which he or she learns. At IBM our Watson Education team is focused on leveraging AI to improve learning outcomes and implement solutions that will help all students succeed. The IBM Watson Education platform relies on digital trends and AI to give teachers the tools they need to be most effective and help learners perform at the top of their abilities. By using AI as an added assistant in the classroom, our goal is to encourage lifelong learning where each person is met with the individualized tools they need to succeed in school and beyond. To help achieve this goal, we are excited to announce two new collaborations with Scholastic and Edmodo. Expanding our reach through these new partnerships way will give educators the resources they need to ensure that there…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/06/Wason_Education_1.jpg,https://www.ibm.com/blogs/watson/2018/06/using-ai-to-close-learning-gap/,joy,0.221376,negative,-0.826161,"student-teacher ratio, IBM Watson, learning gap, school budget","Person, Company, Company",student-teacher ratio,Person,joy,0.651404,positive,0.814433,"Watson Education team, IBM Watson Education platform, added assistant","Organization, Company, Person",Watson Education team,Organization,joy,0.647999,positive,0.836997,Watson Education team,"Company, Company","In classrooms with children of all ages and in schools around the world, teachers are met with the challenge of addressing each student’s individual needs and the rate at which he or she learns. At IBM our Watson Education team is focused on leveraging AI to improve learning outcomes and implement solutions that will help all students succeed. The IBM Watson Education platform relies on digital trends and AI to give teachers the tools they need to be most effective and help learners perform at the top of their abilities.
By using AI as an added assistant in the classroom, our goal is to encourage lifelong learning where each person is met with the individualized tools they need to succeed in school and beyond. To help achieve this goal, we are excited to announce two new collaborations with Scholastic and Edmodo.
Expanding our reach through these new partnerships way will give educators the resources they need to ensure that there is no gap between what a student is expected to learn and what he or she has actually learned. IBM AI paired with Scholastic and Edmodo’s existing educational infrastructures streamline this process by highlighting student-specific needs within the context of curricular standards. Scholastic and Edmodo are both leaders in the field of education and we are excited to use AI to bring our shared vision to life.
We are collaborating with Scholastic, the global children’s publishing, education and media company, to bring IBM’s Watson Education Platform users a vast variety of nonfiction content that aligns with curriculum standards and has multiple, leveled articles and media for students at every skill and interest level.
Combining the content from Scholastic GO!® and ScienceFlix™ with IBM’s AI capabilities will allow teachers to understand the learning progression and mastery of each student, while creating recommendations catered to individual needs and abilities.
IBM will leverage its Watson Education Cognitive Library to improve content tagging, which will have an immediate improvement on teachers’ ability to provide customized recommendations to students based on performance. This will incorporate content from Scholastic GO!® and ScienceFlix.™
IBM and Edmodo — the world’s largest learning network for K–12 students, teachers, administrators and parents — are collaborating to develop a personalized content recommendation engine that can be integrated within Edmodo’s existing social education platform. Teachers and students on Edmodo will receive personalized recommendations for learning resources by combining Watson Classroom’s Cognitive Library service and the millions of resources that have been shared by educators on Edmodo. Classes that have integrated Edmodo will be able to see recommended multimedia content that aligns to the grade level, age and subject matter interests of students. In addition the team will be leveraging IBM Watson Tutor technology to create a new service that grants teachers on Edmodo the ability to select a package of topic-specific questions to assign to a student as either a learning activity or a natural language conversational assessment.
AI has the potential to help close the learning gap and to equalize opportunity regardless of student-teacher ratio, school budget or lack of resources. All students benefit from an education that is tailored to their strengths and learning patterns. With Watson Education and our new collaborations with Scholastic and Edmodo, we are making strides toward creating a more personalized learning experience that is catered to each individual student. Together with our growing ecosystem of education partners, we look forward to cultivating an environment for life-long learners to grow, succeed and overcome challenges of all shapes and sizes.
Watson Education is bringing education into the cognitive era through personalization. With Watson Education, educators and students together can transform the individualized learning throughout their lifelong learning journey. Our cognitive solutions that understand, reason and learn help educators gain insights into the learning styles, preferences, and the aptitude of every student.
",Watson Education team,Company,greenish blue,person,hosiery,stocking,-
,187446750783_10155706106020784,https://www.facebook.com/ibmwatson/posts/10155706106020784,IBM Watson,SharedVideo,,,6/26/18 8:22, ,1650,1650,0,1969,1969,0,123,110,126,1,1,1777,1472,0,0,114,0,0,0,0,252,255,0,0,0,65662,,27.0,,,31.0,,107,6.0,,,120,6.0,,,,1.0,,,1.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2IoGR4V,187446750783_10155705211625784,https://www.facebook.com/ibmwatson/posts/10155705211625784,We’re excited to share that IBM Watson Knowledge Catalog was named a Leader in the first Forrester Wave™: Machine Learning Data Catalogs. Learn more and download the 2018 report: ,Link,,,6/25/18 19:05, ,7190,7190,0,9801,9801,0,85,50,62,1,1,8707,6425,0,0,72,0,0,0,0,0,0,0,0,0,0,9,37.0,2.0,9,38.0,3.0,28,24.0,,,38,24.0,,,1,,,1,,,"IBM Watson Knowledge Catalog was recently recognized by Forrester as a Leader in: “The Forrester Wave™: Machine Learning Data Catalogs, Q2 2018.”",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/06/WKC_Forrester_1200x628.jpg,https://www.ibm.com/blogs/watson/2018/06/forrester-names-ibm-a-leader-in-machine-learning-data-catalogs/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Forrester+Names+IBM+a+Leader+in+Machine+Learning+Data+Catalogs+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.399222,positive,0.735811,IBM Watson Knowledge Catalog,Company,IBM Watson Knowledge Catalog,Company,joy,0.178254,neutral,0,IBM Watson Knowledge Catalog,"Company, Company",IBM Watson Knowledge Catalog,Company,joy,0.499598,positive,0.729065,"IBM Watson, IBM Watson Knowledge Catalog","Company, Person, Person","The promise of AI is that it will deliver digital transformation and improve productivity and efficiency across businesses. For many of our customers, IBM Watson has already helped deliver on this promise – by enriching customer interactions, accelerating research and discovery, empowering employees, and mitigating risk.
The next step for businesses is to make AI ubiquitous by operationalizing their workflows across the full AI lifecycle. IBM is committed to delivering these fundamental, end-to-end AI capabilities and giving enterprises everything they need.
For example, consider the critical step of understanding and preparing data for productive and speedy use in analytical tools, machine learning and deep learning. Your teams first need access to all your data –no matter where it lives. But there are often multiple barriers to fully harnessing the value of your data, including:
IBM has addressed these challenges with IBM Watson Knowledge Catalog, which was recently recognized by Forrester as a Leader in: “The Forrester Wave™: Machine Learning Data Catalogs, Q2 2018.”
Machine learning data catalogs (MLDCs) are the stepping stone for an intelligent business – they help scale out data understanding and speed up data use. IBM’s MLDC offering, Watson Knowledge Catalog, is an intelligent cataloging service that knowledge workers, including data scientists, can use to index all the available data sets in their business, on premises or cloud. This includes open and third-party data, as well as dashboards, data science and ML models, connections, notebooks and more, to activate them for analytics, machine learning and deep learning with IBM Watson Studio.
“The Forrester Wave™: Machine Learning Data Catalogs, Q2 2018,” which evaluated the major machine learning data catalogs, mentions that IBM Watson Knowledge Catalog: “disguises its ML and cataloging power behind a simple role-based workspace. Revisiting its traditional data management and governance approach to enablement, IBM designed its MLDC from the ground up around role intent and behavior, with ML at the core and the ability to tap into Watson APIs.” [1]
Driving business value with Watson Knowledge Catalog: A use case
Think about how this could work with processing insurance claims, which is an expensive, time consuming, and risk-intensive process. The more time it takes to process a claim and make required adjustments, the higher the risk of lawsuits, which are a costly outcome. Challenges around claims processing become especially intense during natural calamities, when insurers need to process a sudden spike in claims, even to the point of transporting adjusters to the impacted location.
With a data-driven approach, the information gathering process can be significantly expedited with immediate access to relevant information at the first notice of loss, and the use of data, analytics and AI to help identify potential claim fraud using deep learning and detailed data analysis.
Using information that’s available in the insurance company’s enterprise Knowledge Catalog, the provider can easily develop a data-driven claims process that:
Watson Knowledge Catalog is a self-service environment built for enterprises scaling their data and AI strategies.  To  accelerate and maximize  value from AI,  organizations  need  a  strategy that gives  users  access to all their data – no matter where it lives.  The ability for users to review and recommend data sets and analytics assets powers collaboration, while dynamic masking anonymizes and restricts sensitive data. 
Watson Knowledge Catalog also provides foundational data workflows, including preparation, that activates data for productive use with IBM Watson Studio,  a single environment that powers the end-to-end AI workflow.
View our tutorial to learn more about the intelligent and collaborative capabilities of Watson Knowledge Catalog that empower the insurance industry’s business analysts, data scientists and data professionals. You can also find more inspiration and learning on the IBM Watson blog.
To learn more about Watson Knowledge Catalog and Watson Studio, visit ibm.co/wkc.
",IBM Watson,Company,blue,desktop,electronic device,video display,desktop
https://ibm.co/2I8Y2eS3,187446750783_10155702254520784,https://www.facebook.com/ibmwatson/posts/10155702254520784,"Just how are businesses these days using AI-powered chatbots to enhance customer experience? This list takes a look at the industries that are already utilizing them, including Australia's UBank's use of Watson Assistant to develop RoboBrain: ",Link,,,6/24/18 9:44, ,8172,8172,0,11271,11271,0,129,83,106,8,9,9695,7129,0,0,112,0,0,0,0,0,0,0,0,0,0,10,59.0,3.0,12,59.0,4.0,42,47.0,,,57,49.0,,,4,4.0,1.0,4,4.0,1.0,For more than a century IBM has been dedicated to every client's success and to creating innovations that matter for the world,,https://www.ibm.com/us-en/?ar=1,joy,0.076053,positive,0.633652,"use of Watson Assistant, Australia's UBank, list","Person, Location, Person",use of Watson Assistant,Person,joy,0.856488,positive,0.979896,"century IBM, client's success",Company,century IBM,Company,joy,0.844333,positive,0.835611,IBM POWER9,"Company, Quantity, Person","Celebrate Women’s History Month with IBMers who are changing the world and inspiring the next generation
From chatbots to drug discovery, these IBMers push the frontiers of AI
 									Meet the women inspiring a new generation of researchers → 								
World’s most powerful supercomputer identifies 77 promising drug compounds
 									Learn how IBM POWER9 is accelerating the search for a cure → 								
A big network outage welcomed her to IBM. She helped it run at 100% since.
 									Find out about this VP, transformation agent and soccer mom → 								
IBM has laid the foundation for a new era of technology and business
 									Read about a year  of growth — and plans for the future → 								
Accelerate your journey to AI with a cloud‑native data platform
Build AI solutions to find relevant answers in complex data
Try IBM Z mainframe software capabilities with no installation required
Create, move and deploy your Java applications on the cloud in minutes
How would you use technology to take on climate change?
How would you use technology to take on climate change?
Get help today for the IBM services and software you own →
Explore technical topics, find trial software and join the community →
",IBM POWER9,Company, , , , , 
,187446750783_10155700015730784,https://www.facebook.com/ibmwatson/posts/10155700015730784,Explore the science behind the AI revolution and the tremendous opportunity being unleashed for businesses and society with IBM's Dr. John Kelly and David Kenny and special guests. Watch the Think keynote replay now.,Link,,,6/23/18 9:30, ,8311,8311,0,11371,11371,0,122,60,65,1,1,10253,7596,0,0,105,0,0,0,0,0,0,0,0,0,0,14,63.0,1.0,15,66.0,1.0,21,41.0,,,23,42.0,,,1,,,1,,,,,,joy,0.677622,positive,0.841328,"tremendous opportunity, IBM's Dr. John Kelly","Person, Person, Company",tremendous opportunity,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2KnH22N,187446750783_10155697882525784,https://www.facebook.com/ibmwatson/posts/10155697882525784,"&quot;AI is changing the world by transforming how we work. AI systems have the power to learn at incredibly fast rates —continuously sharpening their skills. They are good at what they do: processing information at a blazingly fast rate. But they don’t reason like we do. We’re creative and capable of real thought. They are there to help us to do what we do best.&quot; 

Read more about Anamita Guha's experience working on the IBM Watson team and her ambitious side hustle project launching the Bot Asset Exchange community. ",Link,,,6/22/18 8:30, ,7120,7120,0,9637,9637,0,127,86,90,3,3,8957,6695,0,0,118,0,0,0,0,0,0,0,0,0,0,7,51.0,,7,52.0,,57,31.0,,,58,32.0,,,2,1.0,,2,1.0,,"Anamita Guhagrew launched Bot Asset Exchange, a community driven hub for enterprise bot developers to share and build bots powered by IBM Watson Assistant.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/04/blog_execWatson_socialTile_042418.jpg,https://www.ibm.com/blogs/watson/2018/04/decoding-the-brain-aiding-developers-with-watson/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Watson+Women+Blog&cm_mmca1=000000OF&cm_mmca2=10000409,joy,0.6366,positive,0.614441,"Anamita Guha's experience, IBM Watson team, ambitious side hustle project","Person, Person",Anamita Guha's experience,Person,sadness,0.169159,neutral,0,"Anamita Guhagrew, Bot Asset Exchange",Company,Anamita Guhagrew,Company,joy,0.624695,positive,0.77211,,"Person, Person, Person, Company, Company, Person","Anamita Guha grew up surrounded by coders and IPOs in the way other kids’ childhoods were filled with trips to the mall or little league. Growing up in San Francisco, where both her parents helped build the Valley we know today, Anamita developed, almost intrinsically, an understanding of the power technology has to connect people and change the world.
And by an early age –we’re talking four years old –Anamita was up and running on her own computer. At nine, she started designing websites as a side-hustle. Out of this early digital relationship and the exposure she received to a diversity of people and ideas in Silicon Valley, Anamita became increasingly intrigued by people –and how they process information, become motivated by their beliefs and ultimately make decisions.
Now at IBM Watson, Anamita has combined her aptitude for technology —along with her passion for understanding the human mind —to create the tools developers rely on to change the world with Watson. We chat with her about her unique background, path in the Valley and how she sees AI changing the world, one decision at a time.
How did you become interested in the human mind, and ultimately AI?
Technology has always fascinated me, but not for what it does –instead, for what it inspires us to do. Growing up in Silicon Valley, I learned at a pretty early age that just by giving people better access to information, it significantly opens our perspective and decision-making capabilities. This process of information to output was so fascinating to me that I actually chose a cognitive science major. I wanted to know: how does the brain work? How do we think about things? And, as interesting as those classes were, I quickly found that what I was really after was a better understanding of human cognition. So, in college, I started shifting my focus to classes in AI, machine learning and computational models of the mind.
What I learned was that these technologies, which were new and growing rapidly at the time, had the potential to extend the possibilities of what humans are capable of –in a way like we’ve never seen before. To me, AI was the next revolution of information. Much like the dot-com era expanded our access to information, and each other –AI will amplify this even further and extend human possibilities in revolutionary new ways. I just kept thinking how exciting it would to be to layer the human brain’s ability to process information, instinct and insight with the capabilities of an AI system. Combined, it’s the ultimate decision-making machine–doctors, lawyers, my barista even –will have better access to more complete and broader information, giving us the ability to make decisions with more confidence, and even greater outcomes.
What’s one example of when you saw the potential AI has to redefine human cognition?
In June 2017, I spearheaded a really exciting a side project at IBM. We launched something called the Bot Asset Exchange, which is a community driven hub for enterprise bot developers to share and build bots powered by IBM Watson Assistant. Since this was a side project, we needed to recruit various people within IBM –it became almost like a scavenger hunt in terms of putting all of the pieces together, but the outcome was hugely impactful.
The platform launched with more than 120 conversational interfaces in various categories and was easy to learn. This tool now provides more ways for developers to communicate directly with one another, so they can discuss bots they are working on and ones that might be added soon. The Bot Asset Exchange also makes it possible for these developers to quickly deploy the backend logic necessary to create conversational interfaces for multiple enterprise and consumer –like chatbots for popular messaging apps or voice apps – to more critical dialogs, like legal and government bots.
What do you think AI’s largest impact on the world will be?
AI is changing the world by transforming how we work. AI systems have the power to learn at incredibly fast rates —continuously sharpening their skills. They are good at what they do: processing information at a blazingly fast rate. But they don’t reason like we do. We’re creative and capable of real thought. They are there to help us to do what we do best.
As businesses transform, I think AI will trend toward personalization. By that, I mean users will perceive the AI systems they are interacting with as being made just for them. We’re already seeing this happen. For example, IBM Watson is helping leading European bank Crédit Mutuel’s 20,000 customer advisors maximize their time. Watson can help them handle the routine queries, giving each customer a personalized approach while giving them more time to meet the needs of customers with more complex needs. I think this kind of personalization means improved service —each customer comes away feeling valued, and like the world has almost personalized just for them.
Click here for more information on Bot Asset Exchange and be sure to follow Anamita on Twitter.
",,Person,coal black,person,person,female,woman
https://ibm.co/2K9noah,187446750783_10155696103555784,https://www.facebook.com/ibmwatson/posts/10155696103555784,Combining the power of IBM Watson and Box means  businesses in every industry can accelerate their digital transformation journeys. ,Link,,,6/21/18 11:36, ,9122,9122,0,11991,11989,0,176,97,113,4,4,10022,7497,0,0,154,0,0,0,0,0,0,0,0,0,0,17,94.0,1.0,19,95.0,1.0,37,64.0,,,46,67.0,,,1,3.0,,1,3.0,,IBM and Box are excited to announce the availability of a new service offering to help organizations build custom Box Skills that apply Watson AI.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/06/IBM-Box_1200x628.jpg,https://www.ibm.com/blogs/watson/2018/06/box-and-ibm-watson-unveil-new-skills-to-power-intelligent-enterprise-cloud-content-management/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-With+Watson+Box+Cloud+Management+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.103119,neutral,0,power of IBM Watson,Company,power of IBM Watson,Company,joy,0.201975,positive,0.919553,"availability of a new service, custom Box Skills",Company,availability of a new service,Company,joy,0.571928,positive,0.795469,custom Box Skills,"Company, Person, Person, Quantity, Company","IBM and Box are excited to announce the availability of a new service offering to help organizations build custom Box Skills that apply Watson AI technologies to the Box Skills framework. These new, customizable solutions, built using the Box Skills kit, will enable businesses to apply IBM’s enterprise-strength Watson AI to enterprise content managed in Box. By bringing intelligence to enterprise content and leveraging Watson to enrich that content stored in Box, businesses in every industry can accelerate their digital transformation journeys.
Why is this important? Content is at the heart of nearly every business process, across multiple industries. Whether it’s a sales contract or proposal, an HR onboarding form or something as simple as a resume. Traditional documents aside, in today’s world, content is just as likely to mean large collections of images or hours of audio or video recordings.In all of these cases, AI technology today has an incredible opportunity to turn that raw unstructured data into actionable information and metadata that can be used to inject more intelligence into the business. This new service is especially important since Box is the cloud content management platform for more than 69 percent of the Fortune 500 companies. We are only at the beginning of what’s possible for AI in the enterprise.
IBM is introducing two new services for building custom Box Skills:
Custom image insights with Watson Visual Recognition: This custom solution analyzes image data, enriching it with classifiers to make it easy to search and consume, and training custom visual models that best address business needs. For example, an environmental organization could leverage a custom skill that can analyze satellite images of coastal erosion in Box, quickly detecting areas of most impact, speeding up the time to taking action and reducing the costs of monitoring.
In addition to applying Watson technologies to Box Skills, the IBM team will also build custom solutions that apply Watson AI to Box via the Box Platform APIs for other use cases. For example, IBM has built a service that processes documents uploaded to Box to translate the documents into other languages. This automated process significantly reduces the time it takes a person to create translated versions of documents and enables multinational organizations to more quickly share and collaborate across not just multiple time zones, but multiple languages.
",custom Box Skills,Company,ultramarine,ultramarine color,blue color,ultramarine color,-
,187446750783_10155693607985784,https://www.facebook.com/ibmwatson/posts/10155693607985784,IBM Watson,SharedVideo,,,6/20/18 7:14, ,3642,3642,0,4112,4127,0,258,205,248,2,2,3857,3391,0,0,241,0,0,0,0,1828,1882,0,0,0,30553,,70.0,1.0,,74.0,1.0,205,,,,248,,,,1,1.0,,1,1.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
,187446750783_10155691538660784,https://www.facebook.com/ibmwatson/posts/10155691538660784,IBM Watson,SharedVideo,,,6/19/18 7:21, ,2273,2273,0,2624,2624,0,280,247,320,5,5,2415,2132,0,0,267,0,0,0,0,1518,1566,0,0,0,97406,,60.0,,,61.0,,245,11.0,,,309,11.0,,,1,4.0,,1,4.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2ISlEWe,187446750783_10155689791105784,https://www.facebook.com/ibmwatson/posts/10155689791105784,Watch IBM CEO Ginni Rometty address questions revolving around AI technology via CNBC: ,Link,,,6/18/18 9:11, ,7630,7630,0,10535,10535,0,365,236,284,5,5,8152,6050,0,0,309,0,0,0,0,0,0,0,0,0,0,21,143.0,2.0,24,147.0,2.0,112,154.0,,,127,157.0,,,3,2.0,,3,2.0,,"Ginni Rometty, IBM chairman and CEO, talks about privacy concerns, social justice and artificial intelligence from the VivaTech Conference in France.",https://image.cnbcfm.com/api/v1/image/105228833-5ED2-SB-052418-IBMceo.jpg?v=1529478307,https://www.cnbc.com/video/2018/05/24/ibm-ceo-we-have-to-have-trust-in-technology.html,joy,0.095594,neutral,0,Watch IBM CEO Ginni Rometty address questions,"Person, Company",Watch IBM CEO Ginni Rometty address questions,Person,sadness,0.131402,neutral,0,"Ginni Rometty, privacy concerns, social justice, artificial intelligence, IBM chairman","Person, Company",Ginni Rometty,Person,sadness,0.461302,negative,-0.696181,"Global Business, Financial News, real-time snapshot, Data",Quantity,"Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.
",Global Business,Quantity,alizarine red,champion,person,contestant,champion
https://ibm.co/2DNYtFb,187446750783_10155687615895784,https://www.facebook.com/ibmwatson/posts/10155687615895784,"Available now, Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI.
",Link,,,6/17/18 9:30, ,12201,12201,0,17099,17099,0,441,242,291,11,12,12373,8769,0,0,355,0,0,0,0,0,0,0,0,0,0,61,226.0,2.0,61,229.0,2.0,110,145.0,,,134,157.0,,,6,6.0,,6,5.0,,"Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity. Consider three distinct examples – 1. Fixing issues with Visual Diagnosis User: A person in the field equipped with an iPhone trying to visually diagnose a problem. Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage. 2. Recommendations based on Visual analysis User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations. Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/03/GettyImages-1086731554.jpg,https://www.ibm.com/blogs/watson/2018/03/ai-everywhere-ibm-watson-apple-core-ml/,anger,0.075048,neutral,0,Watson Visual Recognition Service,"Person, Company, Company",Watson Visual Recognition Service,Person,sadness,0.551904,negative,-0.449804,Visual Diagnosis User,Person,Visual Diagnosis User,Person,joy,0.548225,positive,0.631349,number of users,"Person, HealthCondition, Company, Person, Company","Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity.
Consider three distinct examples –
1. Fixing issues with Visual Diagnosis
User: A person in the field equipped with an iPhone trying to visually diagnose a problem.
Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage.
2. Recommendations based on Visual analysis
User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations.
Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying unknown or complex machine parts to classifying plants or food.
3. Visual triggers for a business process
User: An end user and a trigger for a downstream business process
Usage: Business processes range from creating a work order for repair to updating a shopping cart for purchase; from intervening in quality control to safety procedure in manufacturing; from initiating an insurance claim to a collaborative analysis for experts in medicine.
These are a diverse set of scenarios with a common thread running through them: the need for a low-latency and rich insight for a human or a downstream process.
Imagine a scenario where a user is trying to access results while on-the-go (changing network speeds), or in hard-to-reach places (manufacturing plants, buildings, store interiors, remote areas, etc.). This impacts the user’s ability to do the job, which can have a domino effect on business processes and the bottom line for companies.
The most compelling way to empower that user combines relevant AI insights, at the time of need, without the user having to worry about network connectivity issues.
To set this in motion, you need:
1. A technique to handle tradeoffs between immediate insights, irrespective of connectivity, with richer insights from the cloud, allowing the user to focus on the task at hand.
2. Collaborative methods and tools for users, developers and/or data scientists to build solutions in a way that allows them to focus on the higher end of the solution spectrum.
3. An approach with associated technology that enables a process of rapid iteration to keep up with constantly changing data and other surrounding factors.
Components of this solution are being successfully used by enterprises and consumers across industries and geographies.
Watson services on the IBM Cloud provide rich and relevant insights from a variety of public and enterprise data sources to applications. IBM’s approach to data and privacy with Watson ensures that client data and insights are not shared with IBM or third parties, and that client data does not contribute to training a centralized knowledge graph.
Apple Core ML is a foundational machine learning (ML) framework that lets you integrate ML models into your app. Core ML delivers optimized performance for Apple products with minimal memory footprint and battery consumption impact. User privacy is protected as data is stored locally and encrypted by default.
What’s new – Bringing it together with a seamless experience
Available today, Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI.
These are key aspects of what is now available to the ecosystem of users and developers. Read more about the partnership here.
1. Watson SDK low latency, and offline process for custom Visual Recognition models using Core ML with the rich insights from the Watson services on the cloud.
2. Watson Studio provides a low-code, end-to-end collaborative environment that enables developers to quickly and easily catalog, classify, provision, and train their data and models.
3. Developer assets and best practices including Code Patterns for developers to get started, starter kits to quickly build iOS apps that combine these Watson services with other components, and code examples to get started now.
These offerings are the first step towards mitigating challenges for users, developers, and enterprises. Companies have already started building enhancements to applications that leverage Watson Visual Recognition Service for Core ML.
For the developer, this drives a paradigm for building once and deploying at heterogeneous endpoints. For the user, this translates to growth in the expertise spectrum and higher productivity. For the enterprise, this is an inevitable step toward mobile and AI revolutionizing how we work.
Watch the demo to see how this all comes together for part and issue identification on Arduino boards, a representative for any component.
",number of users,Person,blue,X-ray film,photographic equipment,photographic film,X-ray film
https://ibm.co/2JD1gbo,187446750783_10155685878340784,https://www.facebook.com/ibmwatson/posts/10155685878340784,"IBM is calling on developers worldwide in the &quot;Call for Code,&quot; a contest designed to create the best technology solution for natural disaster relief. Read more via Business Insider: ",Link,,,6/16/18 15:19, ,19756,19756,0,28240,28240,0,873,619,765,5,5,17857,12460,0,0,572,0,0,0,0,0,0,0,0,0,0,90,296.0,18.0,96,299.0,26.0,322,344.0,,,396,369.0,,,3,2.0,,3,2.0,,"The winners of the contest, which is part of the Call For Code initiative, and will also get support from IBM to make the prototype a reality and introduction to venture capitalists.",https://i.insider.com/5b071cae1ae66238008b4760?width=1200&format=jpeg,https://www.businessinsider.com/ibm-call-for-code-natural-disaster-relief-2018-5,joy,0.75815,positive,0.69261,best technology solution,Company,best technology solution,Company,joy,0.27033,neutral,0,"winners of the contest, part of the Call, Code initiative",Company,winners of the contest,Company,joy,0.170146,positive,0.650865,,"Company, Quantity, Quantity, Organization, Company","IBM is asking developers to build a solution to disaster relief — and the company is providing an incentive to do it.
The company on Thursday at the VivaTech Conference in Paris announced Call for Code, a global initiative that calls on developers to create technology that can be used for natural disaster preparedness and relief. 
The main component of the initiative is a contest, where the creators of a prototype — like an app that predicts when and where the disaster will be most severe — will win $200,000, support from IBM to make the prototype a reality, and introduction to venture capitalists.  
IBM, which is working with the United Nations Human Rights Office and the American Red Cross, is pledging $30 million over five years to the program. The money will go toward developer tools, technologies, free code and training with experts. Developers can already access IBM resources about data and AI, blockchain, cloud and IoT technologies. 
""At IBM, we harness the power of technologies like AI, blockchain, IoT and cloud to address some of the biggest opportunities and challenges in business,"" Bob Lord, IBM chief digital officer, said in a statement. ""Now, with Call for Code, we are calling on all developers to join us and use these same leading edge technologies to help people, their communities and society."" 
IBM is an acknowledged leader in the use of blockchain for financial and enterprise reasons, and its Watson AI services are popular in certain areas like health care. So making these technologies available, along with the $30 million pledge, encourages coders to gain experience with IBM's tech, while also serving a cause.
",,Company,Tyrian purple,newsreader,person,newsreader,-
,187446750783_10155680747290784,https://www.facebook.com/ibmwatson/posts/10155680747290784,IBM Watson,SharedVideo,,,6/14/18 8:31, ,3094,3094,0,3506,3506,0,372,310,406,4,4,3268,2884,0,0,349,0,0,0,0,3045,3114,0,0,0,31326,,106.0,3.0,,106.0,6.0,310,1.0,,,405,1.0,,,1,3.0,,1,3.0,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2Mcl2J8,187446750783_10155678849350784,https://www.facebook.com/ibmwatson/posts/10155678849350784,"&quot;To adopt IBM Watson into your world – whether that’s putting it to work in a complex process like supply chain or something geared toward a consumer interaction, like a chat bot – you have to see and believe in its impact. I do that by showing what Watson is capable of, what it has already empowered people to accomplish, and what the possibilities of our future hold.&quot; – IBMer Rachel Liddell. ",Link,,,6/13/18 9:30, ,5432,5432,0,7491,7491,0,99,60,69,1,1,6519,4724,0,0,87,0,0,0,0,0,0,0,0,0,0,10,43.0,2.0,10,44.0,4.0,41,20.0,,,48,21.0,,,1,,,1,,,"To Rachel Liddell, telling stories is far more than entertainment. It’s one of the most powerful tools we have to spur change and inspire action in the world. Rachel majored in literary studies at Middlebury College, exploring literature across cultures, geographies, and time. She learned how creative storytelling can shape our understanding of the world, deepen the role we take within it, and impact our behavior in ways that can drive amazing change. Now, in a storytelling plot twist, Rachel works for one of the largest technology companies in the world – IBM – applying her passion for literature, and expertise with words, to help articulate the story of our AI future. Based at IBM’s Watson Experience Center in New York City’s Astor Place, Rachel helps business leaders and influencers understand how Watson will change their organizations, their communities – and their lives – by telling stories about the real impact and exciting possibilities of AI. We…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/05/blog_watsonWomen_png_socialTile_052218.png,https://www.ibm.com/blogs/watson/2018/05/showing-telling-ibm-engagement-leader-helps-people-see-future-watson/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-How+IBM+leader+helps+people+see+future+with+Watson+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.490429,positive,0.78473,"IBM Watson, complex process, possibilities of our future hold, supply chain","Company, Person",IBM Watson,Company,joy,0.683438,positive,0.891323,"creative storytelling, Rachel Liddell, New York City’s Astor Place, IBM’s Watson Experience Center, storytelling plot twist","Person, Person, Organization, Facility, Company",creative storytelling,Person,joy,0.623288,positive,0.749295,,"Person, Company, Person, Person, Person, Facility","To Rachel Liddell, telling stories is far more than entertainment. It’s one of the most powerful tools we have to spur change and inspire action in the world. Rachel majored in literary studies at Middlebury College, exploring literature across cultures, geographies, and time. She learned how creative storytelling can shape our understanding of the world, deepen the role we take within it, and impact our behavior in ways that can drive amazing change.
Now, in a storytelling plot twist, Rachel works for one of the largest technology companies in the world – IBM – applying her passion for literature, and expertise with words, to help articulate the story of our AI future. Based at IBM’s Watson Experience Center in New York City’s Astor Place, Rachel helps business leaders and influencers understand how Watson will change their organizations, their communities – and their lives – by telling stories about the real impact and exciting possibilities of AI.
We talk with Rachel about how she helps people see – and prepare for – the future with AI.
Did you ever see yourself working for a technology company?  
Technology was one of the few subjects not on my radar while at Middlebury. I was buried in literature, studying topics like political science, sociology and physics – but technology? It wasn’t even an area of interest, or one I thought my skillset was aligned to. Looking back, I see how literature and technology have so much in common. They both require a considerable amount of creativity, collaboration and communication. Technology is both a vehicle for language, but also a language itself – and it is rapidly redefining the world as we know it today. How, when, where and what we communicate is influenced heavily by the growing repertoire of technology at our disposal.
How I wound up at IBM is a classic story itself. Throughout college I loved exploring new topics and meeting people, which is part of what drove me to take on a role in admissions where I would build relationships with prospective students and give tours to inform them about the college. Through that role, I met my now mentor. He worked for IBM and opened my eyes to the possibilities of starting my career in technology. AI has the potential to improve nearly everything we do – from how we process information, engage with one another, and how we apply creativity. That includes communication and storytelling. Looking back, I don’t see my academic experience in literature and my career choice in tech as disconnected, but instead closely aligned. I’ll always be a literary nerd at heart, so the opportunity to be on the front lines of a technology that will influence so much about our future – including how and what we tell stories about – is hugely exciting and rewarding. 
How do you help people understand AI, especially when they’re critical about the technology? 
To adopt IBM Watson into your world – whether that’s putting it to work in a complex process like supply chain or something geared toward a consumer interaction, like a chat bot – you have to see and believe in its impact. I do that by showing what Watson is capable of, what it has already empowered people to accomplish, and what the possibilities of our future hold.  
It can be difficult to articulate how a technology as complicated and all-encompassing as AI will have an impact on one person. This is why storytelling is so important. It’s my job to understand what matters to everyone I meet with – what makes them, as a character, tick – and then show them how Watson can help them be the hero in their own story, achieving great things together. That can be presenting the ways in which Watson makes sharing knowledge across an organization better and smarter, or showing how Watson analyzes tone to inform more intelligent marketing campaigns. But regardless of what the story is about, it must connect on a personal level. That’s when I see the “aha” moment. The moment people realize how AI will make them better at their job, make their information more actionable – that’s when skeptics turn into optimists. 
It’s important to note that I don’t shy away from the tough questions. One of the most exciting parts about working in the field of AI today is just how many unknowns there are. It’s still early days for this technology. IBM is developing it responsibly and carefully, but there is much we all still must learn and discover. When I meet with someone who is skeptical, or worse, afraid, I remind them that this is an exciting frontier that they not only have an opportunity – but a responsibility – to help shape.
When did Watson – and the opportunity for AI – first inspire you? 
One of the first times I truly understood the power of AI was, once again, when it became personal. Both of my parents are doctors. They’ve dedicated their careers to health and medicine, working long hours during the day and continuing to work at home in the evening – working to provide the best possible care for their patients. So, when my mother told me she struggled with her dictation software, I had my own “aha” moment –better access to information can have an enormous impact. With AI, patient insights aren’t just easier to find – they jump right off the page. Watson can analyze thousands of medical articles and studies, while nearly simultaneously comparing that data to a patient’s historic records. Things that physicians, even my parents, despite their brilliance, can’t do effectively at scale – but AI can do it for them, freeing them to deliver better care to more patients. 
That’s why I’m so excited about Watson and humbled to be part of the team building the future of AI at IBM. For me, it’s not so much about what the technology is – but what is does. IBM is transforming the world by helping people be better at what they do. Whether that’s as simple as turning my mother’s notes into immediate, actionable insight or redefining how doctors access data to inform better, potentially life-saving treatments, the opportunity AI presents is to make us better at everything we do.  
Looking ahead, five to ten years, where do you see AI having the greatest impact? 
Very soon, AI will become omnipresent throughout our personal and professional lives. It will help people, like my mother, become even better at their jobs by turning the data that surrounds us into insights we can leverage to do amazing things. At home, it will help us experience life, understand the world – and yes, tell stories – across cultures, geographies and barriers in a way we’re just starting to see a glimpse of now.
This future will be powered by businesses that empower their employees.  Which is why today we should all be looking forward – five, ten, even twenty years from now – and thinking about what our role can be in that future. I never thought my artistic and literary background would be applicable at a company like IBM. But what I realize now, and what I encourage everyone to consider, is how important creativity and communication will be to our future. Connecting the dots with this life-changing technology requires humans to work together, think outside of the box and be consistently curious. Ask questions, ponder the impossible – and always be learning. 
",,Person,blue,anchorperson,person,anchorperson,-
https://ibm.co/2J2E99U,187446750783_10155676976415784,https://www.facebook.com/ibmwatson/posts/10155676976415784,"&quot;At IBM, we share this belief and see evidence of it every day with Watson driving exponential impact here in France and around the world. That is why we are bringing 1,800 new jobs to France to meet growing demand for AI from our clients.&quot; – IBM CEO Ginni Rometty via TechRepublic: ",Link,,,6/12/18 9:40, ,7486,7486,0,10241,10241,0,146,83,114,6,6,8363,6259,0,0,115,0,0,0,0,0,0,0,0,0,0,17,64.0,5.0,20,68.0,5.0,58,29.0,,,83,31.0,,,1,5.0,,1,5.0,,"IBM is also adding new training programs for its 'new collar' skills in AI, blockchain, cloud, and IoT.",https://tr3.cbsistatic.com/hub/i/r/2018/05/23/787708ef-be2b-4db6-a249-cbed2a7f830a/thumbnail/770x578/a7912c33feeeb174b1b7e801fbccb295/aijobs.jpg,https://www.techrepublic.com/article/ibm-to-add-1800-jobs-in-france-to-meet-growing-demand-for-ai/,joy,0.704931,positive,0.519683,new jobs,"Company, Location, Person",new jobs,Company,joy,0.290664,neutral,0,"new training programs, new collar' skills, IBM",Company,new training programs,Company,joy,0.466737,positive,0.677622,IBM's initiative,"Company, Location, Person, Person, Person, Person"," 	IBM is working to bring 1,800 jobs to France over the next two years in effort to bolster talent in artificial intelligence, IoT, cloud, and blockchain, CEO Ginni Rometty said at the Tech for Good Summit in Paris Wednesday.
 	Also at the summit, the firm announced an expansion of its program for "" 	new collar"" skills training, IBM's initiative to train tech workers with specific high-level skills outside of a traditional four-year degree. The summit was hosted by French President Emmanuel Macron, a press release noted.
 	""President Macron is making a big bet, and a smart one, that AI is going to transform every job, every profession and every industry,"" Rometty said in the release. ""At IBM, we share this belief and see evidence of it every day with Watson driving exponential impact here in France and around the world. That is why we are bringing 1,800 new jobs to France to meet growing demand for AI from our clients.""
 	 	SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
 	Of the 1,800 jobs, IBM will hire business consultants, IT architects, developers, and technical experts the release said. Some 400 of the jobs will be certain AI roles that IBM announced back in March.
 	Utilizing local public and private partners, IBM will also use the hiring initiative to help create ""local competitiveness hubs"" to strengthen its presence in France. These are already underway in Lille and Strasbourg, the release said.
 	""IBM will continue to work with the government to make sure France has the skilled workforce necessary to take advantage of this unique era,"" Nicolas Sekkaki, general manager of IBM France, said in the release.
 	As part of the new collar training expansion, IBM will be creating roles in security, data science, AI, and more. These roles won't require a four-year degree, as noted, but employees will be prepared ""through vocational or on-the-job training,"" the release said.
 	According to the release, IBM is also working with the French government to support its P-TECH (Pathways to Technology Early College High School) education model, providing next-gen skills and job training for disadvantaged youth. More than 400 companies are now involved with P-TECH, the release said.
 	The launch of IBM France Academy was also announced at the summit in an effort to ""train IBM France employees, clients and partners to build modern skills for the AI-era,"" the release said.
 	The real impact of AI on jobs is yet to be seen. While the technology will undoubtedly eliminate some roles, some have predicted that it could  	create more jobs in place of those. Additionally, a 2018 Workplace Institute report noted that 82% of employees believe AI will improve their jobs in some way.
",IBM's initiative,Company,black,dance,person,dance,-
https://ibm.co/2HQo7eM,187446750783_10155674893845784,https://www.facebook.com/ibmwatson/posts/10155674893845784,"&quot;Deep-Learning-as-a-Service, unveiled at IBM’s annual IT industry conference in Las Vegas, seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power,&quot; via The Wall Street Journal: ",Link,,,6/11/18 8:32, ,7317,7317,0,10001,10001,0,134,67,84,6,6,8791,6356,0,0,117,0,0,0,0,0,0,0,0,0,0,15,72.0,2.0,15,72.0,2.0,37,34.0,,,44,40.0,,,2,4.0,,2,4.0,,"Deep-Learning-as-a-Service, unveiled Tuesday in Las Vegas, aims at easing the complex process of creating deep-learning algorithms for business data, the company said.",//si.wsj.net/public/resources/images/BN-XY012_0320_c_P_20180320173444.jpg,https://blogs.wsj.com/cio/2018/03/20/ibm-tool-seeks-to-bridge-ai-skills-gap/,joy,0.313567,positive,0.521166,"Deep-Learning, IBM’s annual IT industry conference, large amounts","Company, Location",Deep-Learning,Company,joy,0.525414,positive,0.928478,"Deep-Learning, complex process, Las Vegas, a-Service",Location,Deep-Learning,Location,joy,0.473438,positive,0.702652,,"Company, Company, Person, Person, Person, Location","Deep-Learning-as-a-Service, unveiled at IBM’s annual IT industry conference in Las Vegas, seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power, the company said.
The new service allows companies to upload data in Watson Studio, IBM’s cloud-native platform for data scientists, developers and business analysts. There, they can create deep-learning algorithms for datasets – known in AI parlance as a “neural network” – using a drag-and-drop interface to select, configure, design and code the network.
IBM also has automated the repetitive process of fine-tuning deep-learning algorithms, with successive training runs started, monitored and stopped automatically.
For many firms, the complexity of creating smart algorithms from scratch has kept them from leveraging AI to parse massive stores of data for business value, the company said.
Ginni Rometty, IBM’s chairman and chief executive, called data the “basis for competitive advantage,” in her opening remarks at Tuesday’s event.
In today’s cloud-powered markets, she said, businesses need to leverage multiple digital platforms, while embedding smart tools into every process they run. “You’ve got to keep making AI easier to use,” she added.
In a recent Gartner survey, chief information officers ranked AI, along with digital security and the Internet of Things, as the hardest technologies to implement, citing hard-to-find skills required to make them work. The survey included more than 3,000 CIOs across all major industries.
Werner Goertz, a Gartner research director, said skills, expertise and staff around AI “remain in incredibly short supply, and whatever talent is out there is quickly absorbed by the big players.”
“There is an enormous gap” between the available capabilities and the skills required to make them work, Ben Fried, CIO of Google Inc. said earlier this month at WSJ CIO Network’s annual meeting in San Francisco.
Google in January launched Cloud AutoML, a similar AI tool designed to help developers automatically build and train deep-learning models. Google Cloud also offers pre-trained models.
Microsoft Corp., Salesforce.com Inc., Oracle Corp. and other cloud providers have added AI and machine learning capabilities into many of their cloud-based enterprise tools and services.
For IBM, and other tech giants, cloud computing and related services, such as AI, have been a boon. In January, the company reported a 3.6% increase in fourth-quarter revenue to $22.54 billion -- its first quarterly revenue gain since 2012 -- driven in part by a 30% increase in cloud-computing revenue to $5.5 billion, the company said.
",,Company, , , , , 
https://ibm.co/2JD1gbo,187446750783_10155672961885784,https://www.facebook.com/ibmwatson/posts/10155672961885784,Have you heard about the Call for Code? IBM is calling on developers worldwide in a contest to create the best technology solution for natural disaster relief. Read more via Business Insider: ,Link,,,6/10/18 9:34, ,29561,29561,0,42761,42761,0,1601,1164,1367,12,12,22449,15744,0,0,903,0,0,0,0,0,0,0,0,0,0,157,527.0,19.0,158,528.0,22.0,509,704.0,,,623,744.0,,,7,5.0,,7,5.0,,"The winners of the contest, which is part of the Call For Code initiative, and will also get support from IBM to make the prototype a reality and introduction to venture capitalists.",https://i.insider.com/5b071cae1ae66238008b4760?width=1200&format=jpeg,https://www.businessinsider.com/ibm-call-for-code-natural-disaster-relief-2018-5,joy,0.422356,neutral,0,"best technology solution, Business Insider",Company,best technology solution,Company,joy,0.27033,neutral,0,"winners of the contest, part of the Call, Code initiative",Company,winners of the contest,Company,joy,0.170146,positive,0.650865,,"Company, Quantity, Quantity, Organization, Company","IBM is asking developers to build a solution to disaster relief — and the company is providing an incentive to do it.
The company on Thursday at the VivaTech Conference in Paris announced Call for Code, a global initiative that calls on developers to create technology that can be used for natural disaster preparedness and relief. 
The main component of the initiative is a contest, where the creators of a prototype — like an app that predicts when and where the disaster will be most severe — will win $200,000, support from IBM to make the prototype a reality, and introduction to venture capitalists.  
IBM, which is working with the United Nations Human Rights Office and the American Red Cross, is pledging $30 million over five years to the program. The money will go toward developer tools, technologies, free code and training with experts. Developers can already access IBM resources about data and AI, blockchain, cloud and IoT technologies. 
""At IBM, we harness the power of technologies like AI, blockchain, IoT and cloud to address some of the biggest opportunities and challenges in business,"" Bob Lord, IBM chief digital officer, said in a statement. ""Now, with Call for Code, we are calling on all developers to join us and use these same leading edge technologies to help people, their communities and society."" 
IBM is an acknowledged leader in the use of blockchain for financial and enterprise reasons, and its Watson AI services are popular in certain areas like health care. So making these technologies available, along with the $30 million pledge, encourages coders to gain experience with IBM's tech, while also serving a cause.
",,Company,Tyrian purple,newsreader,person,newsreader,-
https://ibm.co/2Hwv6sY,187446750783_10155671029245784,https://www.facebook.com/ibmwatson/posts/10155671029245784,"&quot;Artificial intelligence is not designed to replace the human mind, but to augment our intelligence and amplify our reach.&quot; 

In our latest blog, read about one IBMer's journey to learning effective AI: ",Link,,,6/9/18 10:02, ,9372,9372,0,13215,13215,0,229,141,181,2,3,10762,7572,0,0,192,0,0,0,0,0,0,0,0,0,0,26,101.0,2.0,29,103.0,3.0,64,87.0,,,88,93.0,,,1,2.0,,1,1.0,,"IBM has been on the AI journey for a long time, but the path has not always been smooth. My experience in the consulting business has taught me that successful practitioners need to be flexible and quick to make course corrections. We at IBM have learned along our AI journey, and here are three lessons that come to mind from my own interaction with clients and business colleagues. 1. You fail quickly, and learn fast with AI Remember the adage: garbage in, garbage out. We’ve acknowledged that the results of data analysis are sometimes misleading or even inaccurate. It could result from human error, or personal or institutional biases. Or maybe we’re not asking the right questions. Today we’re building tools that quickly recognize anomalies in the data and even apply a bias rating to outcomes that allow us to make course corrections. Exploration geologists know all about course corrections. They analyze data from drill logs, geological…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/06/AI-jobs_1200x628.png,https://www.ibm.com/blogs/watson/2018/06/journey-ai-three-lessons-learned-effective-implementation/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-3+Lessons+on+Journey+to+AI+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408,joy,0.694862,positive,0.757104,"Artificial intelligence, human mind",Person,Artificial intelligence,Person,joy,0.538828,positive,0.308951,"results of data analysis, consulting business","Company, Person",results of data analysis,Company,joy,0.538571,positive,0.485623,results of data analysis,"Company, Person, Person, HealthCondition, Company, Organization, Person, Person, Company, Quantity","Share this post:
IBM has been on the AI journey for a long time, but the path has not always been smooth. My experience in the consulting business has taught me that successful practitioners need to be flexible and quick to make course corrections. We at IBM have learned along our AI journey, and here are three lessons that come to mind from my own interaction with clients and business colleagues.
1. You fail quickly, and learn fast with AI
Remember the adage: garbage in, garbage out. We’ve acknowledged that the results of data analysis are sometimes misleading or even inaccurate. It could result from human error, or personal or institutional biases. Or maybe we’re not asking the right questions. Today we’re building tools that quickly recognize anomalies in the data and even apply a bias rating to outcomes that allow us to make course corrections.
Exploration geologists know all about course corrections. They analyze data from drill logs, geological shapes, connected devices and maps to plan their next exploration drill. At Goldcorp they are using AI to analyze all this data, and try to identify human error and bias quickly. Their AI platform identifies anomalies and allows geologists to focus on good data as they search for new ore deposits.
2. AI does not replace us; it makes us better
The second lesson is that artificial intelligence is not designed to replace the human mind, but to augment our intelligence and amplify our reach. In the early stages, AI systems were not that smart. Training was a slow, arduous process that required a lot of human intervention. Thankfully, that has led to systems that are now much more robust.
Today, AI platforms are being used in all industries to makes us smarter. A great example is found in healthcare.
Ten million people around the world are living with Parkinson’s disease. The drug treatment hasn’t changed significantly in 50 years. One of our employees living with Parkinson’s thought there must be a better way to advance research. Our AI platform was put to work digesting 28 million medical reports and analyzing 3,800 possible drugs. Sixteen potential drug treatments emerged and the Ontario Brain Institute has funded the initial study with the goal to have more diverse and better treatments for people with Parkinson’s.
AI is not replacing doctors and researchers, but making them smarter.
3. Beware of data ownership in the world of AI
Data ownership has been a hot news item lately. Some large companies have been under fire for misusing data that has been entrusted to them. We believe that you should not be required to relinquish rights to your data in order to have the benefits of an AI platform. In fact, IBM neither owns nor stores any of the data touched by Watson solutions and services. We believe the data and resulting insights belong to your organization and its clients.
A recent IBM survey revealed that 78 percent of respondents say a company’s ability to keep their data private is “extremely important” to them, but only 20 percent “completely trust” organizations they interact with to maintain the privacy of their data.
Your data matters to you — whether it’s your own personal medical records, or the findings from your company’s drug trials or geological surveys.
At the enterprise level, your data is your competitive advantage. If your technology partner is sharing your data with others you may be hurting your business and your clients. You should always retain ownership of your data, and know how it is being used. That is a principle everyone in our industry must adopt.
We’re still in the early stages of our AI journey, and have much to learn as the technology matures. The potential in AI to improve our lives and our businesses is potentially limitless, but as with any new technology, we must approach it responsibly and with a willingness to learn and adapt.
",results of data analysis,Company,green,slope,nature,slope,-
https://ibm.co/2ouW1yG,187446750783_10155669795975784,https://www.facebook.com/ibmwatson/posts/10155669795975784,"Machine learning models need to be trained on large amounts of data to ensure that they are accurate, but for many problems, that large data set simply doesn’t exist. IBM Watson CTO Rob High believes this is a solvable problem – learn why via TechCrunch: ",Link,,,6/8/18 18:14, ,9632,9632,0,13091,13091,0,273,155,182,7,7,10844,7722,0,0,232,0,0,0,0,0,0,0,0,0,0,19,155.0,1.0,20,155.0,1.0,55,111.0,,,69,113.0,,,3,4.0,,3,4.0,,"For IBM Watson CTO Rob High, the biggest technological challenge in machine learning right now is figuring out how to train models with less data. ""It's a challenge, it's a goal and there's certainly reason to believe that it's possible,"" High told me during an interview at the annual Mobile World Congress in Barcelona.",https://techcrunch.com/wp-content/uploads/2018/02/img_20180227_171316.jpg?w=533,https://techcrunch.com/2018/02/27/ibm-watson-cto-rob-high-on-bias-and-other-challenges-in-machine-learning/,sadness,0.177177,positive,0.318055,"IBM Watson CTO Rob High, large amounts of data","Person, Company",IBM Watson CTO Rob High,Person,joy,0.506627,positive,0.633511,"IBM Watson CTO Rob High, biggest technological challenge","Person, Company, Organization",IBM Watson CTO Rob High,Person,joy,0.54021,positive,0.485841,IBM  Watson CTO Rob High,"Person, Person, Company, Person, Person, Person, Location, Organization, Person, Company","For IBM  Watson CTO Rob High, the biggest technological challenge in machine learning right now is figuring out how to train models with less data. “It’s a challenge, it’s a goal and there’s certainly reason to believe that it’s possible,” High told me during an interview at the annual Mobile World Congress in Barcelona.
With this, he echoes similar statements all across the industry. Google’s AI chief John Giannandrea, for example, also recently listed this as one of the main challenges the search giant’s machine learning groups are trying to tackle. Typically, machine learning models need to be trained on large amounts of data to ensure that they are accurate, but for many problems, that large data set simply doesn’t exist.
High, however, believes this is a solvable problem. Why? “Because humans do it. We have a data point,” he said. One thing to keep in mind is that even when we see that evidenced in what humans are doing, you have to recognize it’s not just that session, it’s not just that moment that is informing how humans learn. We bring all of this context to the table.” For High, it’s this context that’ll make possible training models with less data, as well as recent advances in transfer learning, that is, the ability to take one trained model and then use this data to kickstart the training of another model where less data may exist.
The challenges for AI — and especially conversational AI — go beyond that, though. “On the other end is really trying to understand how better to interact with humans in ways that they would find natural and that are influential to their thinking,” says High. “Humans are influenced by not just the words that they exchange but also by how we encase those words in vocalizations, inflection, intonation, cadence, temper, facial expression, arm and hand gestures.” High doesn’t think an AI necessarily needs to mimic these in some kind of anthropomorphic form, but maybe in some other form like visual cues on a device.
At the same time, most AI systems also still need to get better at understanding the intent of a question and how that relates to individuals’ previous questions about something, as well as their current state of mind and personality.
That brings up another question, though. Many of these machine learning models that are in use right now are inherently biased because of the data with which they were trained. That often means that a given model will work great for you if you’re a white male but then fails black women, for example. “First of all, I think that there’s two sides to that equation. One is, there may be aggregate bias to this data and we have to be sensitive to that and force ourselves to consider data that broadens the cultural and demographic aspects of the people it represents,” said High. “The flip side of that, though, is that you actually want aggregate bias in these kind of systems over personal bias.”
As an example, High cited work IBM did with the Sloan Kettering Cancer Center. IBM and the hospital trained a model based on the work of some of the best cancer surgeons. “But Sloan Kettering has a particular philosophy about how to do medicine. So that philosophy is embodied in their biases. It’s their institutional biases, it’s their brand. […] And any system that is going to be used outside of Sloan Kettering needs to carry that same philosophy forward.”
“A big part of making sure that these things are biased in the right way is both making sure that you have the right people submitting for and who these people are representative of — of the broader culture.” That’s a discussion that High says now regularly comes up with IBM’s clients, too, which is a positive sign in an industry that still often ignores these kind of topics.
",IBM  Watson CTO Rob High,Person,coal black,stringer (wooden),support,timber,stringer (wooden)
https://ibm.co/2Hnmjtf,187446750783_10155665563595784,https://www.facebook.com/ibmwatson/posts/10155665563595784,"Thanks to its Watson-powered email analyzer and its four virtual assistants, Crédit Mutuel is enriching interactions between client advisors and customers. Watson has made it possible to find the right answers 60% faster and can help deflect and address 50% of the 350,000 daily emails received by the bank’s client advisors. ",Link,,,6/6/18 16:00, ,579,579,0,831,831,0,29,24,40,0,0,305,205,0,0,10,0,0,0,0,0,0,0,0,0,0,3,10.0,5.0,3,10.0,6.0,14,15.0,,,23,17.0,,,,,,,,,"With Watson, CrÃ©dit Mutuel is continuing to build on their leading and awarded customer service capabilities",https://www.ibm.com/watson/assets/duo/img/stories/credit-mutuel-social.jpg,https://www.ibm.com/watson/stories/creditmutuel/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Watson+Credit+Mutuel+Customer+Stories+Facebook+June+2018&cm_mmca1=000000OF&cm_mmca2=10000408&,joy,0.396586,positive,0.925966,"Crédit Mutuel, Thanks, email analyzer, right answers","Company, Person, Quantity, Quantity",Crédit Mutuel,Company,joy,0.147639,neutral,0,"dit Mutuel, Watson",Person,dit Mutuel,Person,joy,0.569466,positive,0.664017,"Crédit Mutuel, quality of client relationships","Company, Person, Quantity, Person","Crédit Mutuel, one of France’s leading banks, has over 5,000 branches that receive more than 350,000 online inquiries a day – and volume is growing 23% a year. Maintaining the quality of client relationships, while dealing with an ever-rising stream of customers and client requests, meant reinventing the role of client advisor or losing their competitive edge.
After running a diagnosis of how client advisors were spending their time, Crédit Mutuel found that a significant part of their work involved answering simple and repetitive questions. With this in mind, the bank turned to IBM to find a solution that could speed up everyday processes and allow client advisors time to address more complicated and nuanced problems.
When Watson was introduced at Crédit Mutuel, employees began asking about the possibility of their jobs being replaced by AI. The bank needed to convince employees of Watson’s ability to empower them do their jobs better - not replace them. “The challenge was offering something that would be good enough for customer advisors to change their habits,” said one of Crédit Mutuel’s project managers.
Getting adoption at scale meant regularly reminding customer advisors to go through Watson, rather than rely on older systems they might be more comfortable with. As the system improved and became more user-friendly, its use increased. Watson began transforming how client advisors could get work done.
“Watson is my assistant. He’s a time-saver and lets me know my client better,” said one of Crédit Mutuel’s 20,000’s customer advisors. “Watson is a job facilitator. It allows resources to be refocused on matters of added value,” said Reichert.
Today’s professionals must find the right answers at the right time, so they can provide expert advice in real time. Learn how you can increase productivity with AI.  
The key to handling rapidly shifting business conditions is knowledgeable, enabled employees. Learn how you can empower your workforce with AI.  
Crédit Mutuel has trained Watson to help its client advisors provide customers with quick and comprehensive information on an array of offerings, from car and housing insurance to a range of savings and investment products. “It’s impossible for our customer advisors to know all of our 200 products. So we provide them with tools to have the right information for the right client,” said Mathieu Dehestru, Head of Transformation, Marketing and Big Data at Crédit Mutuel insurance. “Watson gives more time to our client advisors, so they have more time for client relationships,” he said.
Thanks to its Watson-infused email analyzer and four virtual assistants, Crédit Mutuel is able to enrich interactions between client advisors and customers. Watson has made it possible to find the right answers 60% faster, and it can help deflect and address 50% of the 350,000 daily emails received by the bank’s client advisors. 
",Crédit Mutuel,Company,gray,person, , , 
https://ibm.co/2GhZPhy,187446750783_10155663517780784,https://www.facebook.com/ibmwatson/posts/10155663517780784,"Ever wished for a one-stop shop when it comes to getting questions answered by your bank? Australia-based UBank created a solution: an AI-powered bot that improved response time for more than 400,000 Australian customers. Learn more about RoboBrain: ",Link,,,6/5/18 20:17, ,6080,6080,0,8185,8185,0,113,53,63,2,2,6909,4827,0,0,97,0,0,0,0,0,0,0,0,0,0,18,69.0,,19,71.0,,33,23.0,,,39,24.0,,,2,,,2,,,"Customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank",https://d1902livswy8rb.cloudfront.net/dimg/800x800/dimg/dreamstime_s_34490308-2.jpg,https://www.cmo.com.au/article/635526/ubank-ai-vision-expands-rollout-robobrain/,joy,0.529701,positive,0.436218,"one-stop shop, response time","Company, Location",one-stop shop,Company,joy,0.124299,positive,0.566024,"IBM Watson capabilities, one-stop, one-screen solution, solution","Person, Company",IBM Watson capabilities,Person,joy,0.57428,positive,0.701942,launch of RoboBrain,"Person, Company, Person, Person, Company, Person, Company, Location","UBank’s CMO says the launch of RoboBrain, a hyper-personalised cognitive assistant, is dramatically improving customer response times and a massive leap forward in the bank’s AI journey.   
The digital-only banking group took its first steps into AI last year with the launch of RoboChat, a chatbot designed to help customers through the home loan application process. In less than 12 months, RoboChat has been asked more than 22,000 questions, with over 80 per cent answered correctly on the first attempt.   
“After the success of RoboChat, we wanted to find a solution that our people could use and benefit from directly,” UBank CMO, Jo Kelly, told CMO. 
This led to RoboBrain, designed and developed by UBank’s North Sydney-based team in collaboration with IBM. The customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank.   
In the past, the UBank team had to move between a handful of different platforms in order to find the answer to customer questions, Kelly explained. Consolidating a number of the bank’s knowledge bases, RoboBrain provides immediate information for employees in one spot.   
“Now, thanks to RoboBrain, we’ve got a one-stop portal of information where we can search information and find the answer almost instantly,” she said.     
By typing in a question in natural language, the UBank team on the phone or on LiveChat can find answers in approximately two seconds to thousands of questions asked by customers, such as “what was the interest rate in June 2011?” or “how do I set up a regular transfer?”.    
Kelly said RoboBrain improves on the overall customer experience by making interactions as convenient as possible.    
“Customers don’t want to spend their time talking to their bank, so when they get in touch with us over LiveChat, Secure Mail, Facebook or on the phone, we need to meet their expectations and help them as quickly as we can,” she said.   
Since going live, RoboBrain has sped up processes for more than 40 per cent of UBank’s 200 employees, and improved response time for more than 400,000 Australian customers, cutting down search time by 33 per cent.   
For Kelly, AI is a major focus area - and a key to marketing success - at the digital bank.   
“We see AI as a key enabler in disrupting the home loan market and changing the end to end process of buying a home from applying to approval and then settlement. We believe it’s important to embrace technologies to adapt to the ever-increasing expectations of our customers and create a more personalised experience,” she said.   
Asked what’s next in terms of AI, Kelly said UBank flagged more innovation around customer service. RoboBrain has been trained to display and share complex information in real-time, and like any AI-based solution, the more it’s used, the smarter it gets, she noted.   
RoboBrain will learn and improve by adapting to the search terms used, based on the rating applied, and through ongoing training by UBank experts.   
",launch of RoboBrain,Person,blue,liquid metal reactor,apparatus,nuclear reactor,liquid metal reactor
https://ibm.co/2JqmN6W,187446750783_10155661217970784,https://www.facebook.com/ibmwatson/posts/10155661217970784,"Lingmo uses Watson to take 30-second blocks of conversation in English, Japanese, French, Chinese, Italian, Spanish, German, Portuguese and Arabic and return it to the One2One earpiece coherently in any of those languages via Business Insider: ",Link,,,6/4/18 18:26, ,7715,7715,0,10517,10517,0,134,69,87,4,4,8928,6498,0,0,115,0,0,0,0,0,0,0,0,0,0,21,68.0,,23,71.0,,29,42.0,1.0,,43,43.0,1.0,,3,1.0,,3,1.0,,  The Australian startup which launched an earpiece that can instantly translate nine languages now has a smartwatch and a messaging service.,https://edge.alluremedia.com.au/uploads/businessinsider/2018/03/two-watches.jpg,https://www.businessinsider.com.au/lingmo-smartwatch-translates-languages-2018-3,joy,0.293939,neutral,0,30-second blocks of conversation,"Quantity, Person",30-second blocks of conversation,Quantity,joy,0.490414,positive,0.586758,Australian startup,,Australian startup,,joy,0.586879,positive,0.590356,Lingmo International,"Company, Person, Person, Quantity, Company, Person, Quantity, Quantity, Quantity, Organization, Location, Person, Company, Quantity, Quantity, Location, Quantity","The Australian startup which launched an earpiece that can instantly translate nine languages now has a smartwatch and a messaging service.
In less than a year since he launched the TranslateOne2One device at a United Nations event in Switzerland, former plumber Danny May has become an unlikely, but extremely busy, advocate for IBM’s AI technology, Watson.
Watson takes 30-second blocks of conversation in English, Japanese, French, Chinese, Italian, Spanish, German, Portuguese and Arabic and returns it to the One2One earpiece coherently in any of those languages.
May began working on the technology five years ago when he struggled to communicate effectively while on a business trip to China.
His startup, Lingmo International, released the $279 earpiece in October last year, even beating Google’s Pixel Bud translation service to the market, with the major advantage over its competitors of using a SIM card to operate independently of a phone.
But by December, feedback proved to May that an earpiece isn’t a good fit for everybody. So here’s another way to chat with someone in nine different languages:
It’s called the Time2Translate and you can buy it tomorrow, with delivery expected in April, anywhere in the world.
“People loved the One2One tech and loved what it was doing, but some people found it hard to use on the ears,” May says. “The tech was never in question, it was always just a matter of how we could put it into a better user experience.”
The smartwatch also knocks out some extra features that people weren’t really using on the earpiece.
“There was too much going on, people just wanted a translation device,” May says.
Lingmo kept Google Maps — it is essentially a travel accessory — and Bluetooth capability if people don’t want to connect to Lingmo’s prepaid SIM network. Google Play is available for downloads, but other app stores have been axed.
In return, the Time2Translate gets a four-hour constant use battery life (14 hours standby) and extra memory.
And most importantly, it’s on your wrist.
As if speaking into a watch like you have in all your spy film dreams isn’t impressive enough, Lingmo is also launching new software along with the Time2Translate which enables real-time messaging in nine languages.
So you can send a voice message in English on your watch and the recipient will receive it in Chinese. But what is truly extrordinary is the watch will enable up to 1,000 users to converse in a group chat across all nine languages.
Those languages represent 90% of the world’s spoken words.
May said Lingmo burned through five protoypes to find speakers for the side of the watch that met the standard required for speaking English into, and hearing Arabic out of up to two metres away. 
And because Lingmo is working with Watson every second to improve its service, the translation is far beyond the typical clunky word-for-word systems you might be used to online.
But for a premium service, expect to pay a premium price – the watch starts from $US699 for the Lifestyle model. Here’s the complete spec rundown: 
“We just wanted to turn those (earpiece) negatives into positives,” May says about developing the smartwatch. “Interest has been really positive around the world, and we’re now dealing with some proof of concepts with major airlines and US multinationals. 
“We’re slowly getting there; it’s just about doing it right and being a startup it’s just about focusing on the little things and getting them right first.”
 Yes, it has speakers. Loud ones. Picture: Supplied
Since the October rollout of One2One, Lingmo International has moved into new office on the NSW central coast and grown its staff from three to more than 20. It also now has offices in the Middle East and China, and a virtual office in Silicon Valley which it is looking to make permanent.
May says it’s been a challenging time in his life, but he doesn’t miss sticking his hand down the toilet.
“It’s what you start a company for. You have your hard times but you just have to keep pushing on and that’s what it’s all about with the watch.
“You just have to keep innovating.”
His ultimate goal is to see Lingmo’s product line include the “holy grail”, where anyone can pick up a phone and make a call which instantly translates to the other end and back again.
“We’re making slow inroads,” he says. “The software on the watch is a significant step towards that.”
Follow Business Insider Australia on Facebook, Twitter, LinkedIn, and Instagram.
",Lingmo International,Company,charcoal,addiction,person,person,addiction
https://ibm.co/2stwJCX,187446750783_10155658177355784,https://www.facebook.com/ibmwatson/posts/10155658177355784,"AI and automation will impact nearly every facet of the workforce in some way in the future. However, certain industries—particularly human resources and finance—are more likely to see big changes in 2018. New AI tools are complementing the skills of human workers in these areas, and changing many established roles that are easy to automate via TechRepublic: ",Link,,,6/3/18 10:12, ,9635,9635,0,13596,13596,0,194,149,178,3,3,11139,8050,0,0,167,0,0,0,0,0,0,0,0,0,0,23,52.0,2.0,23,52.0,2.0,49,112.0,,,60,118.0,,,2,1.0,,2,1.0,,"AI and a tech jobs boom are poised to change the employment landscape in 2018, according to Glassdoor.",https://tr3.cbsistatic.com/hub/i/r/2017/12/19/208acec2-2087-4326-8cc5-e5d798e74cdc/thumbnail/770x578/4b07d8839aea6569758022ab9916227b/istock-655801624.jpg,https://www.techrepublic.com/article/the-5-most-important-tech-job-trends-for-2018/?ftag=COS-05-10aaa0h&utm_campaign=trueAnthem:%20Trending%20Content&utm_content=5a4659a404d3015b0d788955&utm_medium=trueAnthem&utm_source=facebook,sadness,0.233373,positive,0.87553,"human resources, skills of human workers",,human resources,,joy,0.343617,positive,0.58156,tech jobs boom,Person,tech jobs boom,Person,joy,0.501719,positive,0.61787,job market,"Person, Person, Organization, Company, Quantity, Quantity, Person, GeographicFeature","The job market will continue to shift in 2018, as technologies such as artificial intelligence (AI) impact many industries, and mobile changes the way people find and apply for jobs, according to a new report from job search site Glassdoor. 
Despite two major hurricanes and political challenges, the US economy experienced a strong year, Andrew Chamberlain, Glassdoor's chief economist, wrote in the report: 1.9 million new jobs were added in 11 months, and stock markets reached an all-time high. Additionally, the nation's unemployment rate dropped to a 17-year low, fueling a talent war in tech, healthcare, e-commerce, and other professional services, he added. 
""This year has been good for many--but not all--workers,"" Chamberlain wrote. ""Job seekers who've mastered key skills in data science, software development, and health professions are seeing rising pay and benefits. At the same time, average wages for many remain stubbornly flat. Despite a healthy job market overall, job growth is sharply divided, with tech skills earning a premium and others being left behind by rising artificial intelligence (AI) and automation."" 
SEE: IT jobs 2018: Hiring priorities, growth areas, and strategies to fill open roles (Tech Pro Research)
Tech jobs continue to spread: In 2017, a growing number of employers in  finance, retail, manufacturing, and other traditional industries began creating more tech roles. And a growing share of tech hiring is happening far from Silicon Valley, in more affordable tech clusters such as Seattle, Austin, Detroit, Dallas, and Raleigh, Glassdoor found. 
Here are five job disruptions to watch for 2018, according to Chamberlain. 
1. AI changing the future of work
AI and automation will impact nearly every facet of the workforce in some way in the future. However, certain industries--particularly human resources and finance--are more likely to see big changes in 2018. New AI tools are complementing the skills of human workers in these areas, and changing many established roles that are easy to automate. 
2. Modernization of mobile job applications
Since most job application systems were created in the past, applying for a job via a mobile device can be a difficult process, Chamberlain said. It's likely that 2018 will see growth in mobile application platforms, though it may take time before they are commonly used.
3. Job growth in tech, healthcare, and labor-intensive roles
Innovations in tech will drive job creation in 2018, in both tech and traditionally non-tech industries, Chamberlain said. Significant demographic shifts, such as the aging population, will also lead to massive workforce changes. Many traditional jobs, such as waiters and truck drivers, that cannot be automated easily in the near terms will continue to grow in number, he predicted.
4. Increased transparency in the application and interview process
The online job application process remains opaque for many employees, Chamberlain said. In 2018, it's likely that job seekers will gain more visibility into both the application process and the status of job applications in real time.
5. Encouraging employee passions through role experimentation
Companies are increasingly finding ways for employees to experiment with different roles within the company, to tap the changing skills and passions of their workforce, reduce turnover, and better match talent to positions, Chamberlain said. It's likely this will continue and expand in the new year. 
",job market,Person,gray,checkout counter,furniture,table,checkout counter
https://ibm.co/2FBkKXT,187446750783_10155655763685784,https://www.facebook.com/ibmwatson/posts/10155655763685784,"If you've ever picked up a phone to call customer service, or communicated a problem through a brand's website, you've already interacted with AI. Learn the differences between the 3 most popular types of chatbots that businesses are using today: ",Photo,,,6/2/18 9:00, ,6889,6889,0,9320,9320,0,112,91,141,1,1,8438,6285,0,0,80,0,0,0,0,0,0,0,0,0,0,7,27.0,2.0,7,28.0,2.0,34,21.0,43.0,,43,23.0,75.0,,1,,,1,,,"As chatbots continue to gain popularity, our latest blog highlights the three types of business chatbots you can build to better reach and target customers.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/12/Conversation_service_Social1200x628-1.png,https://www.ibm.com/blogs/watson/2017/12/3-types-of-business-chatbots-you-can-build/,anger,0.162405,positive,0.497646,"customer service, popular types of chatbots",Person,customer service,Person,joy,0.425058,positive,0.725044,"types of business chatbots, latest blog",,types of business chatbots,,sadness,0.539365,positive,0.560402,single-turn type bots,"Person, Company","Key Points:
 From a business perspective, here are the 3 most common chatbots that are being built:
 – Support chatbots that are built to master a single domain
 – Skills chatbots that are single-turn type bots that do not require a lot of contextual awareness
 – Assistant chatbots that are the middle ground between a support and skills chatbot, knowing a little bit about a variety of topics
A few years ago when chatbots were just gaining popularity, there was a lot of talk around what a chatbot actually was. With the advent of natural language processing and various machine learning techniques, some of the more advanced conversational applications wanted to separate themselves from their competition. Many began calling themselves “virtual assistants.” This implied that they were somehow bigger or more powerful than existing chatbots, or perhaps were more conversational or could cover a wider range of topics.
However, we quickly discovered that the market did not care how powerful the bot was or about the underlying technology, so long as it solved the right problems. So in a way, many of these different terms for bots became more or less synonymous with each other. It didn’t matter what you called it – you were getting something you could hold a conversation with. We’re now at a point where we know that regardless of what you call the bot, there are usage patterns and differentiation that make chatbots distinct.
When you’ve done your research and are at the point of beginning to build your bot, think carefully about what problems you’re trying to solve and what functionalities you will want to incorporate. Knowing what you want your application to solve for and assist with will decide the type of chatbot, virtual assistant or agent you ought to build. This will impact both your development plan and, as importantly, your end-user experience. The following are the three main types of chatbots I have come across, with background on their particular uses and variations.
Support chatbots are built to master a single domain, like knowledge about a company. Support chatbots need to have personality, multi-turn capability, and context awareness. They should be able to walk a user through any major business processes, and answer a wide range of FAQ-type questions. You will want to have a short-tail and long-tail combo solution when building this type of chatbot. At IBM Watson, we would use the Watson Conversation service for the short-tail, common questions and processes, and Watson Discovery service for the long-tail, but there are many potential solutions for this. Speech is an optional feature, and not a necessity, since users typically have sat down at a desktop and are ready to figure out their solution. The chatbot developer will want to spend the most time making sure it is as easy as possible to navigate the bot, and ensuring it can execute the actions that your users actually care about (for example, just because you want to sell more credit cards doesn’t mean your customers want to open more credit card accounts).
Skills chatbots are typically more single-turn-type bots that do not require a lot of contextual awareness. They have set commands that are intended to make life easier: “Turn on my living room lights,” for example. Speech functionality is recommended for this type of chatbot so the user does not need to turn on a device or click any buttons. They should be able to follow commands quickly, so that your users can multitask while engaging with the bot. These chatbots do not need to worry too much about contextual awareness, unless you want to design a particularly advanced one, as people will quickly learn what to say, and say it appropriately. It’s a nice bonus if you can give a command, and your bot knows – to return to our example – that you are in the kitchen and acts to turn on the correct lights.
However, this is not a necessary function, as users will quickly learn to give the appropriately specific command. When building a skills bot, it is important to focus on integration, especially when controlling a home or personalized objects. Keep integration simple so your users can interact with the bot without worrying about how to use .
Assistant chatbots are more or less a middle ground between the two bots above. They work best when they know a little bit about a variety of topics. Many people envision these bots will someday become navigators of all other bots that are out there now. Want to pay a bill? Ask your assistant bot to talk to the support bot for your bank. Assistant chatbots need to be conversational and respond to just about anything, while being as entertaining as possible. Siri is a good, current example – while she only does so much, people continually ask her for things simply because even when she cannot perform the command, the response she gives tends to be amusing. When building an assistant chatbot, it is important to make it as obvious as possible how the bot is trained. The range of questions a user might ask is large, so making sure you have adequate coverage is going to be the most difficult factor. In many cases, when people do not know what they should ask, they will not ask anything at all. And if you miss the few topics they initially are willing to try, they will not come back for more.
Even though these are the most common types, many bots in production fall somewhere in between two. Some are even a combination of all three. No matter what type of bot you decide to build, it is important to give your bot some life and personality, make it useful, and make sure it’s easy to use. People interact with bots because they want to get something done in a more natural way than was previously possible. Whether it’s something simple like turning on a light, or something complex like applying for a mortgage, every pattern has specific features that make it stand out, so be sure your bot shines brightly in what it’s designed to do. The possibilities are endless.
",single-turn type bots,Person,blue,razor,tool,cutlery,razor
https://ibm.co/2oCky3W,187446750783_10155651426075784,https://www.facebook.com/ibmwatson/posts/10155651426075784,"She started her first company as an eight-year-old, and created the country’s largest AI student group. Allie Miller has always been driven. Now, after receiving an MBA from Wharton and graduating with a degree in Cognitive Science from Dartmouth, Allie is a part of IBM Watson's Visual Recognition team, shaping the future of Watson technologies that help businesses understand the context of their images. ",Link,,,5/31/18 8:56, ,9405,9405,0,12845,12845,0,298,223,266,3,3,10477,7764,0,0,251,0,0,0,0,0,0,0,0,0,0,28,99.0,1.0,34,101.0,1.0,160,69.0,,,195,71.0,,,3,,,3,,,Allie Miller is shaping IBM Watson technologies that help businesses understand Visual Recognition. Learn more about Allie's career and journey into AI.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/02/profileCrop_png_socialTile_022618.png,https://www.ibm.com/blogs/watson/2018/02/redefining-how-we-get-it-done-with-allie-miller-ibm-watson/,joy,0.328354,positive,0.75008,"Cognitive Science, part of IBM Watson","Person, Quantity, Organization, Location, Person",Cognitive Science,Person,joy,0.196497,positive,0.80574,"Allie Miller, IBM Watson technologies, Allie's career","Person, Company",Allie Miller,Person,joy,0.641793,positive,0.797175,,"Person, Person, Person, Company, Person, Company, GeographicFeature, Quantity, Organization","Share this post:
Allie Miller has always been a doer. From starting her first company as an eight-year-old, to creating the country’s largest AI student group, to doing the polar plunge in the Antarctic Ocean – Allie has always found a way to grab life by the horns and get the job done.
Now, after receiving an MBA from Wharton and graduating with a degree in Cognitive Science from Dartmouth, Allie has joined the ultimate get-it-done heavyweight, IBM Watson. As part of the Visual Recognition team, Allie is shaping the future of the Watson technologies that help businesses understand the context of their images, leading to the discovery of actionable insight.
Heading into Think 2018, Allie takes a short break from her aggressive to-do list to talk about how Watson is partnering with professionals to help businesses “get it done” in revolutionary new ways – and what exciting opportunities, but also potential hurdles, are on her radar for 2018.
How did you end up with a career in AI, and what brought you to IBM Watson?
Since I can remember, I’ve been obsessed with the way people process information, and what drives their decision-making. Whether it’s a complicated work challenge or just choosing the route we take to work in the morning, how we as humans reason and problem-solve is fascinating.
Heading to Dartmouth, I knew that’s what I wanted to learn more about. Since the power of AI really lies in augmenting human capabilities, I chose to study Cognitive Science—a blend of Psychology, Philosophy, Linguistics, and Computer Science. This expanded my understanding of the human mind, how it works, and what influences our decision-making. I wanted to take these classes and home in on the technical aspect of cognition, which led me to run a two-and-a-half-year study on natural language. That really laser-focused my career path toward artificial intelligence.
I was offered several AI opportunities, but what drew me to Watson was not only IBM’s early leadership in the space, but also the care and commitment that IBM takes in training and development. I’m constantly learning, growing, being challenged and pushed. I can’t wait to get up every morning and not just read about what’s coming next, but contribute to it every day.
You’re about to take the stage at Think 2018. What’s on your mind to share with the world?
The progress we have made with visual recognition technology in just the past few years, to me, is astounding. Beyond pulling insight out of content, Watson Visual Recognition can really be customized for any use case. And, since Watson can understand industries inside and out, it’s almost like having an instant co-pilot that understands exactly how you live and work, and makes you smarter about what you’re doing. It’s really that simple.
There’s nothing I love more than taking 15 minutes to show someone just how easy it is to adopt Watson into their business – and how it can boost their bottom-line. Once we take away this hesitation and skepticism, the opportunities and possibilities quickly emerge.
But, in addition to running toward these exciting opportunities, I’m constantly mindful of the pitfalls. AI is a powerful technology, and with power comes great responsibility. We need to make sure we innovate at the same rate we create guardrails.
What is the most exciting part of your job?
You mean other than the free Diet Coke? For me, it comes down to the frontier work, the opportunity to affect important change on our world – and collaborating with some of the best, brightest people I’ve ever met.
The beauty of Watson is that it’s for everyone. A large enterprise can integrate AI into their workflows and see immediate, tangible benefits: increased productivity, better insight, and enhanced decision-making. But what’s even more exciting is that today everyone, even smaller businesses and individuals who may have fewer resources or technological know-how, can benefit. We’ve created accessible avenues for small, medium and large companies to access AI. We can deliver big, complex solutions or smaller, scrappier ones. Nothing gets me more excited than when I show someone — a professional, a friend — just how easy it is to instantly implement and benefit from AI.
If you had to sum it up, what will AI do for us this year?
I think AI will make each of us increasingly unstoppable. AI is highly technical, but it’s also immensely humanistic. AI could deepen what it means to be human. By taking everything we produce — the documents we create, photos we share, conversations we have — and extracting insight we never could have seen, we can be better — more creative, more inspired, and more resourceful. The power of having Watson, the ultimate “go-getter”, behind it all is incredible.
Want to hear more from Allie? Register for Think 2018 today and make sure you check out her session. You can read more about Watson services here, and follow Allie on Twitter (@alliekmiller) and LinkedIn.
",,Person,coal black,person,figure,circle,-
https://ibm.co/2INwXuq,187446750783_10155649980785784,https://www.facebook.com/ibmwatson/posts/10155649980785784,"In the &quot;The Forrester New Wave™: Conversational Computing Platforms, Q2 2018,&quot; IBM Watson Assistant is named as a Leader in conversational computing: ",Photo,,,5/30/18 14:29, ,7090,7090,0,9966,9966,0,134,85,117,1,1,8269,6002,0,0,96,0,0,0,0,0,0,0,0,0,0,12,57.0,1.0,15,59.0,1.0,50,18.0,32.0,,61,20.0,36.0,,,1.0,,,1.0,,"Improve customer and employee experiences with market leading AI

, IBM account registration",https://1.www.s81c.com/common/images/ibm-leadspace-1200x627.jpg,https://www.ibm.com/account/reg/us-en/signup?formid=urx-31820&cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Conversation-_-WW_WW-_-Forrester+Wave+Facebook+&cm_mmca1=000027BD&cm_mmca2=10006919&,joy,0.350291,neutral,0,"Conversational Computing Platforms, Forrester New Wave, quot",Company,Conversational Computing Platforms,Company,sadness,0.130895,neutral,0,"IBM account registration, employee experiences, customer","Person, Company",IBM account registration,Person,joy,0.507004,positive,0.943004,"business-critical area, IBM Watson Assistant, related matters","Company, Company, Person","Learn why Forrester named IBM Watson Assistant as a leader in the business-critical area of conversational computing in the The Forrester New Wave™: Conversational Computing Platforms. You’ll discover why it is increasingly important for businesses to build engaging interactions that deliver value to their customers. 
Enter your information now to read the report. 
Or,  r  ead more about conversational AI with Watson.
Learn why Forrester named IBM Watson Assistant as a leader in the business-critical area of conversational computing in the The Forrester New Wave™: Conversational Computing Platforms. You’ll discover why it is increasingly important for businesses to build engaging interactions that deliver value to their customers. 
Enter your information now to read the report. 
Or,  r  ead more about conversational AI with Watson.
We use phone in order to reach you for account related matters or, with your permission, to contact you related to other products and services.   
",business-critical area,Company, , , , , 
https://ibm.co/2vY54hs,187446750783_10155647481290784,https://www.facebook.com/ibmwatson/posts/10155647481290784,Did you know? The IBM Watson Unity SDK is the first of its kind to bring scalable artificial intelligence services to Unity. That means taking gaming to a whole other level – think virtual and augmented reality in your games. Learn more: ,Link,,,5/29/18 8:38, ,8756,8756,0,12151,12151,0,144,73,99,7,7,9528,6799,0,0,107,0,0,0,0,0,0,0,0,0,0,25,82.0,4.0,25,85.0,5.0,39,37.0,,,59,40.0,,,4,3.0,,4,3.0,,"IBM and Unity are launching the IBM Watson SDK for Unity on the Unity Asset Store, enabling developers to easily integrate Watson cloud services into their...",https://blogs.unity3d.com/wp-content/uploads/2018/02/image2-1.png,https://blogs.unity3d.com/2018/02/20/bringing-the-power-of-ai-to-developers-with-the-ibm-watson-unity-sdk/?_ga=2.89714651.1383049552.1519136253-1097373577.1519136253,anger,0.137791,positive,0.819462,"IBM Watson Unity SDK, scalable artificial intelligence services",Company,IBM Watson Unity SDK,Company,joy,0.056467,neutral,0,"IBM Watson SDK, Unity, IBM, Unity Asset Store",Company,IBM Watson SDK,Company,joy,0.537902,positive,0.856387,IBM Watson SDK,"Company, Person, Person","IBM and Unity are launching the IBM Watson SDK for Unity on the Unity Asset Store, enabling developers to easily integrate Watson cloud services into their Unity applications such as visual recognition, speech to text, and language classification. The SDK makes it easy for developers to take advantage of modern AI techniques through a set of cloud-based services.
Today we are thrilled to announce a partnership with IBM to launch the IBM Watson SDK for Unity on the Unity Asset Store. This SDK is the first asset of its kind to bring scalable AI services to Unity, enabling developers to easily integrate Watson services into their Unity applications. Millions of Unity developers globally will now have access to the powerful cloud-based AI services of Watson directly within the Unity environment.
Although AR and VR are continuously being applied to the gaming industry to immerse players in virtual environments like galaxies or with geolocation environments where the activity happens on real surroundings, we are now experiencing the advancement of applying these concepts into business use cases. With VR, companies can implement employee training programs that teach workers how to perform a job in a virtual environment without any safety risks, and with AR, field workers can hold up their phone or glasses to a pipe to see if it needs to be fixed, when, and where.
As AR and VR technologies mature, there is increasing interest coming from the enterprise market for innovative applications in marketing, design, engineering, manufacturing and analysis. Unity is the market leader in AR and VR for consumer use cases, as well as rapidly emerging as the market leader for enterprise AR and VR.
With its deep AI expertise and industry knowledge, IBM also has been actively exploring the application of AR and VR with clients such as the Immersive Insights demo, which hints at the enormous potential of AR and VR in enterprise applications. Together, Unity and IBM plan to help drive the development of this market by enabling applications that bring contextual expertise and AI capabilities directly into the employee and/or end consumer’s personal and professional sphere of experience.
This partnership exemplifies IBM and Unity’s commitment to accelerating the enterprise developer journey and equipping them with the tools and resources they need to build powerful new AR and VR apps. As an official platinum sponsor for INDEX Conference, the open developer community event, we’re excited to collaborate with IBM to empower the Unity community with powerful AI-driven cloud services to help expand a new frontier of interactivity. The first step of this journey begins with the IBM Watson SDK for Unity.
With the SDK now available on the Asset Store, Unity developers can now configure games and projects to understand speech, talk with users, and understand the intent of a user in natural language.
One of the key features of the SDK is its powerful speech recognition capabilities. With speech services, developers have access to real-time speech recognition providing highly accurate speech recognition directly in your Unity project. Player speech can be recognized and used to trigger in-game events.IBM Watson SDK for Unity also has powerful language translation and language classification capabilities. In conjunction, both language classification and speech recognition can work together seamlessly to provide voice-driven interactivity in your Unity game.
Watch an example of how IBM teamed up with Ubisoft to give players of Star Trek Bridge Crew the ability to issue commands to NPC’s with just their voice using theIBM Watson SDK for Unity.
For developers interested in the power of AI-driven visual recognition, Watson’s Vision API provides the ability for developers to integrate real-time visual recognition within their Unity projects.Take a look at how a team of developers took advantage of theIBM Watson SDK for Unity during an IBM-sponsored Hackathon to create Watson and Waffles, a VR adventure game which requires the player to sketch game objects using the Vive controller. Using the Vision API, Watson identifies user drawings and generates corresponding 3D objects for the player to use.
For more details about the Watson capabilities available within the IBM Watson SDK for Unity you can leverage to get started, please visit: https://www.ibm.com/watson/products-services/
The SDK is simple to set up and can open up your project to new levels of interactivity. Imagine a game with NPC’s powered with visual recognition technology that recognize in-game objects or even a virtual reality experience with interactions driven completely with voice commands.
Receiving access to the IBM Watson SDK for Unity is easy – simply head over to the Asset Store and download the SDK here.
You also can familiarize yourself with this short video series from IBM, which provides an overview of all of the core features of the IBM Watson SDK for Unity..
Visit the Asset Store and download the IBM Watson SDK for Unity today!
We’ve rounded up some key resources to help you get started with the IBM Watson Unity SDK:
",IBM Watson SDK,Company,black,asterism (cluster of stars),nature,asterism (cluster of stars),-
https://ibm.co/2HQo7eM,187446750783_10155643676695784,https://www.facebook.com/ibmwatson/posts/10155643676695784,"“Deep-Learning-as-a-Service seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power.” via The Wall Street Journal: ",Link,,,5/27/18 9:28, ,9870,9870,0,13389,13389,0,183,107,118,3,3,11833,8579,0,0,167,0,0,0,0,0,0,0,0,0,0,16,87.0,1.0,19,87.0,1.0,34,74.0,,,42,76.0,,,1,2.0,,1,2.0,,"Deep-Learning-as-a-Service, unveiled Tuesday in Las Vegas, aims at easing the complex process of creating deep-learning algorithms for business data, the company said.",//si.wsj.net/public/resources/images/BN-XY012_0320_c_P_20180320173444.jpg,https://blogs.wsj.com/cio/2018/03/20/ibm-tool-seeks-to-bridge-ai-skills-gap/,joy,0.312581,negative,-0.609749,"Deep-Learning, a-Service, deep-learning tools",PrintMedia,Deep-Learning,PrintMedia,joy,0.525414,positive,0.928478,"Deep-Learning, complex process, Las Vegas, a-Service",Location,Deep-Learning,Location,joy,0.473438,positive,0.702652,,"Company, Company, Person, Person, Person, Location","Deep-Learning-as-a-Service, unveiled at IBM’s annual IT industry conference in Las Vegas, seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power, the company said.
The new service allows companies to upload data in Watson Studio, IBM’s cloud-native platform for data scientists, developers and business analysts. There, they can create deep-learning algorithms for datasets – known in AI parlance as a “neural network” – using a drag-and-drop interface to select, configure, design and code the network.
IBM also has automated the repetitive process of fine-tuning deep-learning algorithms, with successive training runs started, monitored and stopped automatically.
For many firms, the complexity of creating smart algorithms from scratch has kept them from leveraging AI to parse massive stores of data for business value, the company said.
Ginni Rometty, IBM’s chairman and chief executive, called data the “basis for competitive advantage,” in her opening remarks at Tuesday’s event.
In today’s cloud-powered markets, she said, businesses need to leverage multiple digital platforms, while embedding smart tools into every process they run. “You’ve got to keep making AI easier to use,” she added.
In a recent Gartner survey, chief information officers ranked AI, along with digital security and the Internet of Things, as the hardest technologies to implement, citing hard-to-find skills required to make them work. The survey included more than 3,000 CIOs across all major industries.
Werner Goertz, a Gartner research director, said skills, expertise and staff around AI “remain in incredibly short supply, and whatever talent is out there is quickly absorbed by the big players.”
“There is an enormous gap” between the available capabilities and the skills required to make them work, Ben Fried, CIO of Google Inc. said earlier this month at WSJ CIO Network’s annual meeting in San Francisco.
Google in January launched Cloud AutoML, a similar AI tool designed to help developers automatically build and train deep-learning models. Google Cloud also offers pre-trained models.
Microsoft Corp., Salesforce.com Inc., Oracle Corp. and other cloud providers have added AI and machine learning capabilities into many of their cloud-based enterprise tools and services.
For IBM, and other tech giants, cloud computing and related services, such as AI, have been a boon. In January, the company reported a 3.6% increase in fourth-quarter revenue to $22.54 billion -- its first quarterly revenue gain since 2012 -- driven in part by a 30% increase in cloud-computing revenue to $5.5 billion, the company said.
",,Company, , , , , 
https://ibm.co/2J0AFVf,187446750783_10155641900160784,https://www.facebook.com/ibmwatson/posts/10155641900160784,"Got time for a debate on AI between experts in the field? Watch IBM's Chief Architect Ruchir Puri and other panelists participate in a lively discussion at the American Museum of Natural History on how AI is opening doors to limitless possibilities, and if we’re ready for them. ",Link,,,5/26/18 11:12, ,8581,8581,0,12420,12420,0,153,96,118,4,4,11336,7881,0,0,134,0,0,0,0,0,0,0,0,0,0,7,64.0,2.0,9,64.0,2.0,50,56.0,,,59,59.0,,,,4.0,,,4.0,,"Isaac Asimov’s famous Three Laws of Robotics might be seen as early safeguards for our reliance on artificial intelligence, but as Alexa guides our homes and...",https://i.ytimg.com/vi/gb4SshJ5WOY/maxresdefault.jpg,https://www.youtube.com/watch?v=gb4SshJ5WOY,joy,0.3636,positive,0.874643,"American Museum of Natural History, lively discussion","Person, Person, Company, Facility",American Museum of Natural History,Person,joy,0.325221,positive,0.642521,"Isaac Asimov, artificial intelligence, Laws of Robotics",Person,Isaac Asimov,Person,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
            

",YouTube,Company,coal black,aperture  (camera),controller,aperture  (camera),-
https://ibm.co/2J2E99U,187446750783_10155640585385784,https://www.facebook.com/ibmwatson/posts/10155640585385784,"IBM is working to create 1,800 new jobs to build a stronger AI presence in France: ",Link,,,5/25/18 18:15, ,9293,9293,0,13081,13081,0,196,117,134,1,1,10689,7513,0,0,164,0,0,0,0,0,0,0,0,0,0,22,84.0,1.0,22,87.0,1.0,54,66.0,,,64,70.0,,,1,,,1,,,"IBM is also adding new training programs for its 'new collar' skills in AI, blockchain, cloud, and IoT.",https://tr3.cbsistatic.com/hub/i/r/2018/05/23/787708ef-be2b-4db6-a249-cbed2a7f830a/thumbnail/770x578/a7912c33feeeb174b1b7e801fbccb295/aijobs.jpg,https://www.techrepublic.com/article/ibm-to-add-1800-jobs-in-france-to-meet-growing-demand-for-ai/,joy,0.552262,positive,0.839672,"new jobs, IBM","Company, Person",new jobs,Company,joy,0.290664,neutral,0,"new training programs, new collar' skills, IBM",Company,new training programs,Company,joy,0.466737,positive,0.677622,IBM's initiative,"Company, Location, Person, Person, Person, Person"," 	IBM is working to bring 1,800 jobs to France over the next two years in effort to bolster talent in artificial intelligence, IoT, cloud, and blockchain, CEO Ginni Rometty said at the Tech for Good Summit in Paris Wednesday.
 	Also at the summit, the firm announced an expansion of its program for "" 	new collar"" skills training, IBM's initiative to train tech workers with specific high-level skills outside of a traditional four-year degree. The summit was hosted by French President Emmanuel Macron, a press release noted.
 	""President Macron is making a big bet, and a smart one, that AI is going to transform every job, every profession and every industry,"" Rometty said in the release. ""At IBM, we share this belief and see evidence of it every day with Watson driving exponential impact here in France and around the world. That is why we are bringing 1,800 new jobs to France to meet growing demand for AI from our clients.""
 	 	SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
 	Of the 1,800 jobs, IBM will hire business consultants, IT architects, developers, and technical experts the release said. Some 400 of the jobs will be certain AI roles that IBM announced back in March.
 	Utilizing local public and private partners, IBM will also use the hiring initiative to help create ""local competitiveness hubs"" to strengthen its presence in France. These are already underway in Lille and Strasbourg, the release said.
 	""IBM will continue to work with the government to make sure France has the skilled workforce necessary to take advantage of this unique era,"" Nicolas Sekkaki, general manager of IBM France, said in the release.
 	As part of the new collar training expansion, IBM will be creating roles in security, data science, AI, and more. These roles won't require a four-year degree, as noted, but employees will be prepared ""through vocational or on-the-job training,"" the release said.
 	According to the release, IBM is also working with the French government to support its P-TECH (Pathways to Technology Early College High School) education model, providing next-gen skills and job training for disadvantaged youth. More than 400 companies are now involved with P-TECH, the release said.
 	The launch of IBM France Academy was also announced at the summit in an effort to ""train IBM France employees, clients and partners to build modern skills for the AI-era,"" the release said.
 	The real impact of AI on jobs is yet to be seen. While the technology will undoubtedly eliminate some roles, some have predicted that it could  	create more jobs in place of those. Additionally, a 2018 Workplace Institute report noted that 82% of employees believe AI will improve their jobs in some way.
",IBM's initiative,Company,black,dance,person,dance,-
https://ibm.co/2klQaJi,187446750783_10155637857840784,https://www.facebook.com/ibmwatson/posts/10155637857840784,Join the movement with IBM: ,SharedVideo,,,5/24/18 11:17, ,2414,2414,0,2753,2753,0,323,293,370,4,4,2490,2199,0,0,295,0,0,0,0,953,1018,0,0,0,95678,,48.0,5.0,,48.0,6.0,290,10.0,,,359,11.0,,,2,2.0,,2,2.0,,,,https://callforcode.org/,joy,0.263074,neutral,0,"movement, IBM",Company,movement,Company, , , , , , , , ,joy,0.63019,positive,0.679695,,"Person, Organization, Organization, Company, Organization, Quantity, Quantity, Quantity, Quantity","The 2020 Call for Code Global Challenge invites the world’s innovators to help halt and reverse the impact of climate change with open source technology. 
               Created by David Clark Cause, with Founding Partner IBM, in partnership with the United Nations Human Rights and The Linux Foundation, Call for Code is the largest tech-for-good challenge of its kind. Join the challenge for a               chance to win $200K and support to deploy your solution to help make an immediate and lasting impact.
“The climate emergency is a race we are losing, but it is a race we can win.”
On its 75th anniversary, the United Nations has launched the biggest-ever global conversation on how to address urgent issues such as climate change. Heeding the UN’s rallying cry for help, David Clark Cause and IBM are joining forces             with key UN agencies and world leaders to tackle the climate crisis through Call for Code.
Whether you are a developer ready to code, a corporation who wants to become a sponsor, or a global citizen concerned about climate change, you can inspire action. Using technologies like AI, IoT, and cloud computing, today’s developer             can create solutions that foster a more sustainable future.
Now in its third year, Call for Code has the support of enterprises, experts, humanitarian and international organizations, charitable partners, and celebrities. But             it takes a village — join us in the fight.
With a goal of protecting first responders as they battle wildfires, the Barcelona-based team created an AI solution that monitors firefighters health and safety both in real-time and long term. 
Climate change is the defining issue of our time, affecting our world and our livelihood.
The average global temperature has increased by .85 degree C in the past 130 years.
Sea levels have risen 19 CM due to warmer oceans and melting ice.
Global warming contributes to more frequent and intense natural disasters such as wildfires and droughts. 
By focusing on energy sustainability, water sustainability, and disaster resiliency, your solution can make an impact.
In the midst of this new, terrifying paradigm a new kind of hero has emerged: The coder.
While many companies promote social good initiatives, not all programs are strategically sound or measurably impactful. An excellent example … Call for Code.
The contest is different as it looks not only to reward the best ideas with financial backing, but also with technical help to scale those ideas.
",,Person, , , , , 
https://ibm.co/2piRDl0,187446750783_10155636238765784,https://www.facebook.com/ibmwatson/posts/10155636238765784,"Meet &quot;Olli,&quot; a self-driving bus created by Locol Motors and IBM Watson that uses #AI technology to assist people with disabilities. ",Link,,,5/23/18 15:04, ,7735,7735,0,10538,10538,0,172,95,111,7,7,8684,6386,0,0,151,0,0,0,0,0,0,0,0,0,0,22,91.0,3.0,22,95.0,3.0,52,50.0,,,59,52.0,,,3,4.0,,3,4.0,,Local Motors and IBM are equipping an autonomous electric shuttle bus with technology that assists people with a range of disabilities.,https://cdn.technologyreview.com/i/images/copy-of-olli-at-phoenix-lm-2.jpg?cx=0&cy=458&cw=3000&ch=1687&sw1200,https://www.technologyreview.com/s/604116/a-self-driving-bus-that-can-speak-sign-language/,joy,0.096537,neutral,0,"Locol Motors, IBM Watson, quot","Company, Company, Hashtag",Locol Motors,Company,sadness,0.092443,negative,-0.625597,"Local Motors, autonomous electric shuttle bus",Company,Local Motors,Company,sadness,0.461357,negative,-0.297226,city buses,"Person, Person, Company, Company, Company, HealthCondition, Person","It’s been 15 years since a degenerative eye disease forced Erich Manser to stop driving. Today, he commutes to his job as an accessibility consultant via commuter trains and city buses, but he has trouble locating empty seats sometimes and must ask strangers for guidance. 
A step toward solving Manser’s predicament could arrive as soon as next year. Manser’s employer, IBM, and an independent carmaker called Local Motors are developing a self-driving, electric shuttle bus that combines artificial intelligence, augmented reality, and smartphone apps to serve people with vision, hearing, physical, and cognitive disabilities. The buses, dubbed “Olli,” are designed to transport people around neighborhoods at speeds below 35 miles per hour and will be sold to cities, counties, airports, companies, and universities. If the buses enter production in summer 2018, as planned, they could be among the earliest self-driving vehicles on U.S. roads. 
Since Olli is fully autonomous and does not have a human driver, it uses IBM’s AI-powered Watson technology to converse with passengers (via voice and text displayed on an iPad). Olli navigates using radar, lidar, and optical cameras from a company called Meridian Autonomous. Before deploying in a neighborhood, Meridian Autonomous constructs 3-D maps of the area that Local Motors says are accurate to the half-inch. A human fleet manager then determines the bus route. When Olli detects an emergency via its various sensors, it will stop, notify a (human) remote supervisor, and independently run through a checklist of possible problems. “If a passenger has a medical problem or [there’s a safety issue], Olli will call the authorities or drive itself to a hospital or police station,” says Gina O’Connell, a Local Motors general manager who is leading the project. 
Local Motors and IBM started collaborating on Olli in early 2016 and produced a first iteration of the bus in June 2016. That vehicle is currently in trials in Germany and Switzerland. It is the next—second—generation of Olli that will include assistive technologies. That version, which the companies call “Accessible Olli,” will be manufactured starting in 2018, and will retain Watson as a tool for communicating with passengers and add additional Watson features. 
Local Motors and IBM are still testing technologies, but have already identified some capabilities they are likely to add. Future Ollis, for example, might direct visually impaired passengers to empty seats using machine vision to identify open spots, and audio cues and a mobile app to direct the passenger. Olli could also guide passengers via a special type of haptic feedback that uses ultrasound to project sensations through the air. An array of haptic sensors could be designed into every seat, and when people walk down the aisle they would feel a vibration on their hand or arm to alert them that they were at an empty seat, explains Drew LaHart, the program director for IBM’s accessibility division.  
For deaf people, the buses could employ machine vision and augmented reality to read and speak sign language via onboard screens or passengers’ smartphones. LaHart says that Olli could be trained to recognize sign language using machine learning and Watson’s image recognition capabilities. If the bus were equipped with AR technology, it might be able to respond via a hologram of a person signing. 
Machine vision could also enable Olli to recognize passengers waiting at bus stops who have walkers and wheelchairs. The bus would then activate an automated ramp to help them board and then deploy equipment that would secure their assistive devices, locking a wheelchair into place, for example. 
Another potential Olli technology combines machine vision and sensors to detect when passengers leave items under their seats and issues alerts so the possessions can be retrieved, a feature meant to benefit people with age-related dementia and other cognitive disabilities. 
This would all be a significant improvement over the typical bus accommodations of today, which are limited to wheelchair ramps and lifts and audible and visual bus route updates. Local Motors, IBM, and the CTA Foundation, the charitable arm of the Consumer Technology Association, a trade group for the consumer electronics industry, and a partner in Accessible Olli, have spent the past three months soliciting ideas from disability rights organizations and retirement communities, among others. Manser, who works for IBM Accessibility, has organized a workshop with blindness organizations and public transit agencies and attended an MIT assistive technologies hackathon in March to explain the challenges he encounters on public transportation. 
Local Motors plans to keep soliciting public input for several more months. In July, it will devise an engineering plan for the new version of Olli, select suppliers, and calculate the cost of fabricating the bus. It aims to sell the vehicle for about $250,000 and will also offer a leasing-subscription service that would cost $10,000 to $12,000 a month and include hardware upgrades. Because Olli is mostly manufactured on-demand, through 3-D printing, its design can be tweaked quickly in response to user feedback, says O’Connell. 
The company expects public transportation operators will be its main customers and hopes that cities will buy the buses to fill in gaps in their regular transit systems and not just as paratransit vehicles for disabled people. 
For those with disabilities, though, Olli could be a big improvement over the current options.  Door-to-door paratransit service tends to be slow, has to be scheduled ahead of time, and is only available to people who qualify for it, says Henry Claypool, who is the policy director of the Community Living Policy Center at the University of California, San Francisco, and a wheelchair user. “It’s much more reliable to be able to get on and off a bus at the same place and have a predictable schedule, especially if the bus has this type of assistive technology,” he says. 
Olli offers a way to address important limitations of public bus and train systems as well, says Susan Henderson, the executive director of the Disability Rights Education and Defense Fund. The Americans with Disabilities Act mandates only that “key” train and subway stations be accessible, which means that people with wheelchairs, walkers, and scooters often have to travel several stops out of their way to get home or to a destination, says Henderson. “If I still had 10 blocks to go after getting off at my local station, having an Olli rolling around my neighborhood would make a big difference,” she says. 
",city buses,Person,steel blue,shuttle bus, , , 
https://ibm.co/2J1GHVI,187446750783_10155634729120784,https://www.facebook.com/ibmwatson/posts/10155634729120784,"AI has the potential to improve our lives and create value in both, business and personal applications. With Watson is a program brings a community of people, from individuals to enterprises, interested in learning and building with AI together. With Watson provides exclusive access to AI technical experts to help accelerate your AI vision. Learn more about how you can get started With Watson: ",Link,,,5/22/18 19:45, ,6877,6877,0,9714,9714,0,131,75,90,2,2,8259,6000,0,0,108,0,0,0,0,0,0,0,0,0,0,16,63.0,1.0,16,68.0,1.0,43,35.0,,,49,41.0,,,2,,,2,,,With Watson is a customer success program that provides exclusive access to AI marketing to get the most out of Watson and the IBM network.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/05/With-Watson_1200x628.png,https://www.ibm.com/blogs/watson/2018/05/with-watson-ai-community/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-With+Watson+First+Blog&cm_mmca1=000029UC&cm_mmca2=10008400,joy,0.331499,positive,0.945567,community of people,"Person, Person",community of people,Person,joy,0.197638,positive,0.678235,"exclusive access, customer success program, Watson","Person, Company",exclusive access,Person,joy,0.555168,positive,0.793828,customer success program,"Person, Person","AI has the potential to improve our lives and create value in both, business and personal applications. Businesses from start-ups to large enterprises are rethinking their strategies with AI in mind and starting the inevitable journey to becoming more “intelligent” across multiple departments and roles. This process can often seem daunting and overwhelming but we’re here to help.
Watson is the leading AI for business today, and we’ve already helped hundreds of companies along this journey. With Watson is a customer success program that brings a community of people, from individuals to enterprises, interested in learning and/or building with AI together. It provides exclusive access to AI marketing and technical experts to help accelerate your AI vision while getting the most out of Watson and the IBM network.
1. Enhance your solutions
 With the support of Watson technical specialists and access to tools, build products to advance your AI journey. Resources include member-only technical content, starter-code, webinars, office hours and more.
2. Get connected, build your AI network
 Expand the power of your brand With Watson and get connected to a network of AI innovators. Learn and engage with AI specialists, developers, inventors and other With Watson members.
3. Elevate the power of your brand With Watson
 As you advance through the program you will unlock access to the With Watson brand, co-marketing, workshops and more.
Our members span multiple industries and company sizes from H&R Block and Salesforce to Identity Guard and Equals 3. View our Success Stories to learn more about how we’re helping our members propel their businesses forward.
Our program has three levels, each with its own specific set of benefits and support for any stage of your AI journey.Advancing your Watson-based solutions and reaching your success milestones unlocks With Watson program benefits along the way.
1. With Watson Growth
 For early adopters/anyone exploring or starting to use Watson services.
Key Benefits: Gain access to a like-minded community of people starting their AI journey. You also get access to a variety of tech and marketing content.
Brand and marketing benefits:
Growth tier member story:
2. With Watson Premier
 For organizations with applications built with Watson Services that are looking to accelerate their AI transformation.
Brand and marketing benefits:
Premier tier member stories:
3. With Watson Strategic
 For organizations pursuing large-scale projects with IBM Watson that require joint investment and commitment.
Brand and marketing benefits:
",customer success program,Person,ultramarine,ultramarine color,blue color,ultramarine color,-
https://ibm.co/2EWGxJA,187446750783_10155631957425784,https://www.facebook.com/ibmwatson/posts/10155631957425784,"&quot;Artificial intelligence is the opportunity of our time, and skills are the issue of our time. Some jobs will be displaced, but 100% of jobs will be augmented by AI,” according to IBM CEO Ginni Rometty. &quot;Technology companies are inventing these technologies, so we have the responsibility to help people adapt to it — and I don’t mean just giving them tablets or PCs, but lifelong learning systems.” via The New York Times: ",Link,,,5/21/18 11:46, ,8846,8846,0,12186,12186,0,194,120,152,4,4,9619,6941,0,0,158,0,0,0,0,0,0,0,0,0,0,27,77.0,3.0,28,78.0,4.0,83,47.0,,,105,47.0,,,3,1.0,,3,1.0,,Technology is advancing by leaps and bounds.,https://static01.nyt.com/images/2018/01/17/opinion/17friedman2/merlin_132380423_eb6e2d98-1190-43ed-9195-fc76a0a0223a-facebookJumbo.jpg,https://www.nytimes.com/2018/01/16/opinion/while-you-were-sleeping.html?linkId=47053575,joy,0.452167,positive,0.760342,"Technology companies, jobs","Quantity, Person, Person, Company",Technology companies,Quantity,joy,0.349447,positive,0.759353,"Technology, leaps",,Technology,,joy,0.478115,positive,0.462031,,"Company, Organization, Person, Location","Donald Trump poses a huge dilemma for commentators: to ignore his daily outrages is to normalize his behavior, but to constantly write about them is to stop learning. Like others, I struggle to get this balance right, which is why I pause today to point out some incredible technological changes happening while Trump has kept us focused on him — changes that will pose as big an adaptation challenge to American workers as transitioning from farms to factories once did.
Two and half years ago I was researching a book that included a section on IBM’s cognitive computer, “Watson,” which had perfected the use of artificial intelligence enough to defeat the two all-time “Jeopardy!” champions. After my IBM hosts had shown me Watson at its Yorktown Heights, N.Y., lab, they took me through a room where a small group of IBM scientists were experimenting with something futuristic called “quantum computing.” They left me thinking this was Star Wars stuff — a galaxy and many years far away.
Last week I visited the same lab, where my hosts showed me the world’s first quantum computer that can handle 50 quantum bits, or qubits, which it unveiled in November. They still may need a decade to make this computer powerful enough and reliable enough for groundbreaking industrial applications, but clearly quantum computing has gone from science fiction to nonfiction faster than most anyone expected.
Who cares? Well, if you think it’s scary what we can now do with artificial intelligence produced by classical binary digital electronic computers built with transistors — like make cars that can drive themselves and software that can write news stories or produce humanlike speech — remember this: These “old” computers still don’t have enough memory or processing power to solve what IBM calls “historically intractable problems.” Quantum computers, paired with classical computers via the cloud, have the potential to do that in minutes or seconds.
For instance, “while today’s supercomputers can simulate … simple molecules,” notes MIT Technology Review, “they quickly become overwhelmed.” So chemical modelers — who attempt to come up with new compounds for things like better batteries and lifesaving drugs — “are forced to approximate how an unknown molecule might behave, then test it in the real world to see if it works as expected. The promise of quantum computing is to vastly simplify that process by exactly predicting the structure of a new molecule, and how it will interact with other compounds.”
Quantum computers process information, using the capabilities of quantum physics, differently from traditional computers. “Whereas normal computers store information as either a 1 or a 0, quantum computers exploit two phenomena — entanglement and superposition — to process information,” explains MIT Technology Review. The result is computers that may one day “operate 100,000 times faster than they do today,” adds Wired magazine.
Talia Gershon, an IBM researcher, posted a fun video explaining the power of quantum computers to optimize and model problems with an exponential number of variables. She displayed a picture of a table at her wedding set for 10 guests, and posed this question: How many different ways can you seat 10 people? It turns out, she explained, there are “3.6 million ways to arrange 10 people for dinner.”
Classical computers don’t solve “big versions of this problem very well at all,” she said, like trying to crack sophisticated encrypted codes, where you need to try a massive number of variables, or modeling molecules where you need to account for an exponential number of interactions. Quantum computers, with their exponential processing power, will be able to crack most encryption without breaking a sweat.
It’s just another reason China, the N.S.A., IBM, Intel, Microsoft and Google are now all racing — full of sweat — to build usable quantum systems.
“If I try to map a caffeine molecule problem on a normal computer, that computer would have to be one-tenth the volume of this planet in size,” said Arvind Krishna, head of research at IBM. “A quantum computer just three or four times the size of those we’ve built today should be able to solve that problem.”
And then there are all those problems we never even imagined we could model and solve. Universities and companies are already accessing three IBM quantum systems (ranging from 5 to 16 qubits) that are online and open source at ibm.com/IBMQ, and they’ve already run two million quantum programs to prove out, and write papers on, theories that we never had the processing power before to prove.
But, again, look at where we are today thanks to artificial intelligence from digital computers — and the amount of middle-skill and even high-skill work they’re supplanting — and then factor in how all of this could be supercharged in a decade by quantum computing.
As education-to-work expert Heather McGowan (www.futureislearning.com) points out: “In October 2016, Budweiser transported a truckload of beer 120 miles with an empty driver’s seat. … In December 2016, Amazon announced plans for the Amazon Go automated grocery store, in which a combination of computer vision and deep-learning technologies track items and only charges customers when they remove the items from the store. In February 2017, Bank of America began testing three ‘employee-less’ branch locations that offer full-service banking automatically, with access to a human, when necessary, via video teleconference.”
This will be a challenge for developed countries, but even more so for countries like Egypt, Pakistan, Iran, Syria, Saudi Arabia, China and India — where huge numbers of youths are already unemployed because they lack the education for even this middle-skill work THAT’S now being automated.
It’s why IBM’s C.E.O., Ginni Rometty, remarked to me in an interview: “Every job will require some technology, and therefore we’ll need to revamp education. The K-12 curriculum is obvious, but it’s the adult retraining — lifelong learning systems — that will be even more important.”
Artificial intelligence “is the opportunity of our time, and skills are the issue of our time. Some jobs will be displaced, but 100 percent of jobs will be augmented by A.I.,” added Rometty. Technology companies “are inventing these technologies, so we have the responsibility to help people adapt to it — and I don’t mean just giving them tablets or P.C.s, but lifelong learning systems.”
To back that up, said Rometty, IBM designed Pathways in Technology (P-Tech) schools, partnering with close to 100 public high schools and community colleges to create a six-year program that serves large numbers of low-income students. P-Tech schools offer calculus and physics alongside workplace skills — problem solving, writing and job interviewing. These skills are reinforced through mentorships and internships with IBM and more than 300 other companies. Kids graduate in six years or less with both a high school diploma and an associate junior college degree.
“The graduation rates are four times the average, and those getting jobs are at two times the median salary,” said Rometty, “and many are going on to four-year colleges.”
Each time work gets outsourced or tasks get handed off to a machine, “we must reach up and learn a new skill or in some ways expand our capabilities as humans in order to fully realize our collaborative potential,” McGowan said.
Therefore, education needs to shift “from education as a content transfer to learning as a continuous process where the focused outcome is the ability to learn and adapt with agency as opposed to the transactional action of acquiring a set skill,” said McGowan. “Instructors/teachers move from guiding and accessing that transfer process to providing social and emotional support to the individual as they move into the role of driving their own continuous learning.”
Anyway, I didn’t mean to distract from the “Trump Reality Show,” but I just thought I’d mention that Star Wars technology is coming not only to a theater near you, but to a job near you. We need to be discussing and adapting to its implications as much as we do Trump’s tweets.
",,Company,gray,furnace room,indoors,furnace room,-
https://ibm.co/2GhZPhy,187446750783_10155629989330784,https://www.facebook.com/ibmwatson/posts/10155629989330784,How a digital-only bank created a Watson-powered chatbot called RoboBrain that improved response rates for customers by more than 40%: ,Link,,,5/20/18 12:25, ,6777,6777,0,9495,9495,0,146,77,101,3,3,8159,5792,0,0,123,0,0,0,0,0,0,0,0,0,0,22,73.0,2.0,23,79.0,2.0,41,38.0,,,60,41.0,,,1,2.0,,1,2.0,,"Customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank",https://d1902livswy8rb.cloudfront.net/dimg/800x800/dimg/dreamstime_s_34490308-2.jpg,https://www.cmo.com.au/article/635526/ubank-ai-vision-expands-rollout-robobrain/,joy,0.111889,positive,0.692266,response rates,Quantity,response rates,Quantity,joy,0.124299,positive,0.566024,"IBM Watson capabilities, one-stop, one-screen solution, solution","Person, Company",IBM Watson capabilities,Person,joy,0.57428,positive,0.701942,launch of RoboBrain,"Person, Company, Person, Person, Company, Person, Company, Location","UBank’s CMO says the launch of RoboBrain, a hyper-personalised cognitive assistant, is dramatically improving customer response times and a massive leap forward in the bank’s AI journey.   
The digital-only banking group took its first steps into AI last year with the launch of RoboChat, a chatbot designed to help customers through the home loan application process. In less than 12 months, RoboChat has been asked more than 22,000 questions, with over 80 per cent answered correctly on the first attempt.   
“After the success of RoboChat, we wanted to find a solution that our people could use and benefit from directly,” UBank CMO, Jo Kelly, told CMO. 
This led to RoboBrain, designed and developed by UBank’s North Sydney-based team in collaboration with IBM. The customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank.   
In the past, the UBank team had to move between a handful of different platforms in order to find the answer to customer questions, Kelly explained. Consolidating a number of the bank’s knowledge bases, RoboBrain provides immediate information for employees in one spot.   
“Now, thanks to RoboBrain, we’ve got a one-stop portal of information where we can search information and find the answer almost instantly,” she said.     
By typing in a question in natural language, the UBank team on the phone or on LiveChat can find answers in approximately two seconds to thousands of questions asked by customers, such as “what was the interest rate in June 2011?” or “how do I set up a regular transfer?”.    
Kelly said RoboBrain improves on the overall customer experience by making interactions as convenient as possible.    
“Customers don’t want to spend their time talking to their bank, so when they get in touch with us over LiveChat, Secure Mail, Facebook or on the phone, we need to meet their expectations and help them as quickly as we can,” she said.   
Since going live, RoboBrain has sped up processes for more than 40 per cent of UBank’s 200 employees, and improved response time for more than 400,000 Australian customers, cutting down search time by 33 per cent.   
For Kelly, AI is a major focus area - and a key to marketing success - at the digital bank.   
“We see AI as a key enabler in disrupting the home loan market and changing the end to end process of buying a home from applying to approval and then settlement. We believe it’s important to embrace technologies to adapt to the ever-increasing expectations of our customers and create a more personalised experience,” she said.   
Asked what’s next in terms of AI, Kelly said UBank flagged more innovation around customer service. RoboBrain has been trained to display and share complex information in real-time, and like any AI-based solution, the more it’s used, the smarter it gets, she noted.   
RoboBrain will learn and improve by adapting to the search terms used, based on the rating applied, and through ongoing training by UBank experts.   
",launch of RoboBrain,Person,blue,liquid metal reactor,apparatus,nuclear reactor,liquid metal reactor
https://ibm.co/2EvwDhZ,187446750783_10155627597725784,https://www.facebook.com/ibmwatson/posts/10155627597725784,&quot;There are a lot of chatbots out there today that operate on what we call a single-turn exchange... but when somebody asks &quot;what's my account balance?&quot;...their problem is that they're getting ready to buy something or they're trying to figure out how to save up for their kid's education or they're trying to figure out how to pay their bills – there's something behind the question.&quot; – IBM Watson CTO Rob High on the differences between conversational agents. ,Link,,,5/19/18 11:02, ,7477,7477,0,10565,10565,0,150,111,139,2,2,9568,6769,0,0,136,0,0,0,0,0,0,0,0,0,0,14,47.0,1.0,15,48.0,2.0,77,43.0,,,93,46.0,,,,2.0,,,2.0,,Find out the key differences between chatbots vs. virtual assistants vs. conversational agents from IBM Watson VP and CTO Rob High.,https://cdn.ttgtmedia.com/visuals/German/article/chatbot-2-fotolia.jpg,https://searchcio.techtarget.com/feature/Comparing-chatbots-vs-virtual-assistants-vs-conversational-agents,fear,0.370883,negative,-0.821987,"account balance, kid's education","Person, Company",account balance,Person,joy,0.040039,neutral,0,key differences,"Company, Person",key differences,Company,joy,0.524255,positive,0.613699,conversational agent,"Person, Company, Company","interchangeably, but do those terms really describe the same thing? Not according to Rob High, vice president and CTO at IBM Watson and an IBM Fellow.
In this Q&A, High explains the subtle but distinct differences between those three conversation-based technology terms and the intent behind them. One rule of thumb: The extent to which these technologies engage the user is key to understanding their differences.
What are the differences between terms like chatbot, conversational agent, virtual assistant, etc.?
Rob High: All those terms are used kind of loosely. There are lots of examples in which the terms have been used interchangeably. At IBM, we tend to think of these things somewhat distinctively, and it largely has to do with the degree to which they engage the end user in solving the problem.
   Rob High  
A simple example of this is that there are a lot of chatbots out there today that operate on what we call a single-turn exchange. Somebody says something like 'Alexa, turn on the lights' or 'OK, Google, what's the tallest mountain in the world?' Those are independent, single-turn exchanges. The end user expresses an utterance, the utterance is interpreted or recognized for its intent, and then that intent is mapped onto a specific task.
That's all good, but when somebody asks 'what's my account balance?' they may need to know what their account balance is, but that's really not their problem. Their problem is that they're getting ready to buy something or they're trying to figure out how to save up for their kids' education or they're trying to figure out how to pay their bills -- there's something behind the question.
In my mind, a conversational agent is one that engages the end user into really understanding the nature of the problem behind the question. Part of that includes determining when it's appropriate to dig in deeper but also recognizing that, often, there is a bigger problem there. The conversational agent must be prepared to go to the next level and solicit end users to better understand the problem. Sometimes [conversational agents] have to help [end users] figure out for themselves what the problem is because, sometimes, we'll just go in with a question and we don't really know what it is that we're after.
This is especially important when you're dealing with customer support or servicing a product because if you're having a problem with something that you bought, the first thing that you need to do is describe the problem, but that might just be describing the symptoms and not necessarily the real issue.
It's going to take more than that to figure out what is really going on with the product and what is the issue and whether it's a problem with the product or a problem with the way it's being used or whether it's some transient situation. There are lots of different things that could be behind all that. A conversational agent has to be able to get to that.
You use the term conversational agent, but a lot of people use the term virtual or personal assistant. Which of those terms should we be using, or are they distinct?
High: They're kind of two different sides of the same coin, in some sense. A conversational agent is more focused on what it takes in order to maintain a conversation. With virtual agents or personal assistants, those terms tend to be more relevant in cases where you're trying to create this sense that the conversational agent you're dealing with has its own personality and is somehow uniquely associated with you.
At least for me, the term virtual assistant sort of metaphorically conjures the idea of your own personal butler -- someone who is there with you all the time, knows you deeply, but is dedicated to just you and serving your needs. When a conversational agent is coupled with that kind of personalized knowledge and acts and behaves in a way that gives you the feeling that it's there only for you, I think there becomes an intersection between the two ideas.
For it to serve you on a personal level, any kind of good personal assistant or virtual assistant needs to retain a great deal of context about you, but then use that context as a way of interacting with you -- to use the conversational agent technique for not just anticipating your need but responding to your need and getting to know you better to be able to respond to that need better in the future.
So personal assistants are good at natural language processing and can use machine learning to keep getting better. Do you see chatbots and the various kinds of conversational agents evolving side by side or do you see one overtaking the other?
High: I think both are useful for their own purposes and, to some extent, there's a continuum. But there's certainly a demarcation when it comes to the philosophy of what you're trying to do [and] the tools that you need to be able to do it with and the underlying technologies that are necessary to enable it.
I could imagine a world where chatbots are just chatbots and they do what they've done and they do it well but they don't do much more than that. There may be a use for that, but [I could imagine] other places where there's a lot of utility in going beyond just simply the chatbot to help people with their problems. A lot of that is driven by what kind of utility is called for.
We believe at IBM that the real purpose of AI is to augment human intelligence, not to replace human intelligence. When you think about that, you begin to realize that augmenting human cognition requires getting into a deeper level of understanding of a human and being able to recognize what problems they're trying to get to in a conversation space. [AI] must recognize that humans express themselves in sometimes very subtle ways, and that the intention behind that expression is something that requires a certain degree of reasoning.
The systems have to be trained [using machine learning]; you can't just program them to be able to do all these things. They have to learn. Ultimately, they have to interact with us like we're humans. They have to know something about the fact that, as humans, we have emotions, and our emotions can vary throughout the course of a conversation. [Conversational agents] have to know how to interact with somebody in order to amplify their thinking. There's more to it than just what you typically see today as a chatbot.
So I think both will continue to exist, but a demarcation will occur between those simple things that people can do quickly and easily without a whole lot of additional exploration, versus those situations in which there's a lot of economic value in amplifying human cognition.
How can technologies like chatbots and virtual assistants drive business value? Beyond handling conversational tasks, what's their potential in the enterprise?
High: I think chatbots may be an entry point for almost any enterprise. It's hard to operate an enterprise without having some kind of interface to your clients -- even the simplest of interfaces like those that might occur when you're carrying your smartphone around with you. Almost every institution out there is trying to engage their clients at a deeper level.
Part of that is about getting to know your clients better so that you can serve them better and part of it is about trying to create a higher degree of trust and loyalty. Some of it is about trying to deal with the burgeoning growth in call center expenses as more and more of these relationships drive more hand-holding or deep touch.
I think all of that is conspiring to suggest that going into the digital age, enterprises can only be successful if they're thinking about employing these conversational agents as a way of augmenting their own staff, but, even more so, augmenting the intelligence of their staff and their relationship with their clients and augmenting the intelligence of the clients to create a stronger relationship with the institution.
",conversational agent,Person,jade green,spectrum of colors, , , 
https://ibm.co/2pRDP1T,187446750783_10155623157070784,https://www.facebook.com/ibmwatson/posts/10155623157070784,"&quot;One of Watson’s greatest values is being able to train it on specific industries and their corresponding data. It’s highly attuned to what our clients need. What’s exciting about my role is I get to sit at this critical intersection — my role is one that helps connect our IBM Cloud technology with Watson. &quot; Get to know Kelly Abuelsaad from the IBM Watson and Cloud platform team, who has more than 35 patents in her name.  ",Link,,,5/17/18 11:04, ,7919,7919,0,10988,10988,0,148,109,126,10,10,8374,6264,0,0,93,0,0,0,0,0,0,0,0,0,0,12,47.0,,13,49.0,,86,26.0,,,100,26.0,,,2,8.0,,2,8.0,,"With over 35 patents, Kelly Abuelsaad is a member of the IBM Watson and Cloud Platform team, where she helps bring AI to clients.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/03/blog_kellyWatson_png_socialTile_032818.png,https://www.ibm.com/blogs/watson/2018/03/how-watson-ushers-creativity-through-collaboration/,joy,0.188572,positive,0.883383,"Watson’s greatest values, critical intersection","Person, Person, Company",Watson’s greatest values,Person,joy,0.081766,neutral,0,"Kelly Abuelsaad, member of the IBM Watson, patents","Person, Company",Kelly Abuelsaad,Person,joy,0.652825,positive,0.742267,,"Company, Person, Person, Person, Person","Share this post:
With over 35 patents, Kelly Abuelsaad has always had a passion for creating, whether she’s been playing guitar or finding a new way to apply technology to everyday tasks.
Kelly is a member of the IBM Watson and Cloud Platform team, where she helps bring AI to clients via the cloud. From tinkering on projects in her studio to working within a large group to find answers and patent new technologies, Kelly never stops thinking about what’s possible with AI.
Kelly expands on her career path in AI, the value of teamwork during the creative process, how she strives to improve efficiency through inventing — and the role her team has played in helping IBM achieve 25 years of patent leadership.
 How did you become a Master Inventor at IBM? What’s the process of inventing something?
Technology has always fascinated me. It holds such opportunity and great promise that I couldn’t help but tinker in computers and science at a very early age. I took BASIC in high school and was hooked. I ended up majoring in information technology because in IT, you work with an entire system. You build and orchestrate a whole data center and you get to understand how things intertwine and operate from the ground up. At IBM, my first job was as a systems administrator on a developer team. I was struck by how great the technology was, but it needed to be simpler. It needed to be easy for customers to understand and use.
That’s how I eventually came to be a Master Inventor at IBM. A Master Inventor is frequently involved in a number of areas – including inventing new products and services, mentoring others and evaluating ideas. One thing I’ve learned is that solving technical issues is only one part of what it means to be a successful innovator. Inventing involves brainstorming with colleagues and working to develop applications that could become patents or core services for our clients. It’s about being collaborative, sharing ideas – and knowing how to work with people. I’ve always been what I consider to be a “tech person.” I enjoy tinkering on my own, and still do that quite frequently – but I’ve grown to understand the value of creativity and the perspective of others. I honestly have found the whole brainstorming process fun and addictive.
An invention is a solution to a problem, and there are always multiple solutions to any given problem. I start by asking, “Is the solution I’m developing unique?” Then I next ask, “Is the solution I’m coming up with better than other solutions?” For example, if you need a better way to tie your shoes and you develop an invention to help this problem but it takes five minutes longer, it’s technically unique, but not very useful. If what I’m creating makes a process faster and more adaptable, that’s when I think there might be something there. I also factor in if it’s useful for IBM, in terms of it positively impacting our business.
How are you helping to change the way businesses work? 
One of Watson’s greatest values is being able to train it on specific industries and their corresponding data. It’s highly attuned to what our clients need.
What’s exciting about my role is I get to sit at this critical intersection — my role is one that helps connect our IBM Cloud technology with Watson. The amount of data that’s in the world is exploding. Tools like Watson help us make sense of all that information and knowledge, while advanced cloud platforms can process and securely manage that data. Without both those pieces, neither is as valuable. I’m responsible for continuing to connect these dots, making the process more seamless and intuitive by creatively applying these technologies.
A tangible output of that, which gets me out of bed in the morning? AI is evolving, scaling and becoming more accessible, every day. The progress this industry has made in just a few years is incredible. We are constantly improving Watson so it can learn better, make more sense of data and easily train models according to each industry.
My job is to create common components so our brilliant IBMers who are creating the internal intelligence of Watson can continue focusing on those algorithms without being hindered. The result is that the capabilities of Watson are improving at a faster rate and we have better response times for training and serving models.
You play guitar. You’re a new mom. How do you think these important roles and skills outside of technology have improved your technological creativity? 
If you’re playing an instrument, you can read the music notes off a sheet and play a song. In the same vein, if you’re a software developer, you can get design plans and write the code to create a program. You do both by following the requirements; you’re following someone else’s instructions.
You can create wonderfully beautiful things this way and have lots of fun doing it. However, I’ve found a whole new level of enjoyment and empowerment in coming up with my own ideas – writing that song myself, kickstarting a new invention myself. This can be very hard because putting your own ideas out there for others to listen to makes you vulnerable. But if having a son has taught me one thing, it’s to not take myself too seriously. I’ve learned that parenting often involves coming up with creative solutions. Some ideas end up being great, and some end up being less than stellar. But in the process, I’ve learned how creative I can be by just allowing myself to take a chance.
I encourage everyone I work with to be creative in many different ways. The more experience you have, the more things you’ll learn and the better perspective you’ll have. I’ve learned, quite by accident as I never thought of myself as a creative person, that creativity is a skill that is earned through experience. Get out, try new things — and most importantly, enjoy what you do.
For more information about IBM Watson, visit ibm.com/watson. You can also follow Kelly on Twitter at @kellyabls.
",,Company,coal black,woman,person,female,woman
https://ibm.co/2HENx3n,187446750783_10155617300835784,https://www.facebook.com/ibmwatson/posts/10155617300835784,"From the automotive industry to customer service and banking, more businesses are resolving longtime industry challenges with the help of AI – right now. See how Watson is being put to work in the real world: ",Link,,,5/15/18 19:52, ,5992,5992,0,8221,8221,0,88,51,65,1,1,6934,5122,0,0,74,0,0,0,0,0,0,0,0,0,0,15,39.0,1.0,15,40.0,2.0,24,31.0,,,30,35.0,,,1,,,1,,,Explore the latest artificial intelligence examples and applications and learn how companies are using AI to solve their most challenging problems.,,https://www.ibm.com/watson/think-2018/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Watson+Think+Hub+FB+May+2018&cm_mmca1=000000OF&cm_mmca2=10000408&,joy,0.196072,negative,-0.242762,"automotive industry, customer service","Person, Person",automotive industry,Person,joy,0.223135,positive,0.720218,latest artificial intelligence examples,,latest artificial intelligence examples,,joy,0.433225,positive,0.596953,"actionable steps, challenging problems businesses face today, industry leaders","Person, Person","Learn how to get started with Watson, and explore successful use cases from businesses using AI and the results they’re seeing. 
Learn how to get started with Watson, and explore successful use cases from businesses using AI and the results they’re seeing. 
Hear actionable steps you can take to solve some of the most common and challenging problems businesses face today, directly from Watson experts and industry leaders such as Coca-Cola, Thomson Reuters, and Honda. 
",actionable steps,Person, , , , , 
https://ibm.co/2ILrGaa,187446750783_10155619837210784,https://www.facebook.com/ibmwatson/posts/10155619837210784,How is IBM using AI and cloud to accelerate growth in an increasingly cloud-centric world? Hear Watson and Cloud SVP David Kenny on where we stand in CNBC: ,Link,,,5/15/18 18:35, ,9447,9447,0,12960,12960,0,300,180,210,8,8,10202,7480,0,0,230,0,0,0,0,0,0,0,0,0,0,19,140.0,1.0,21,143.0,2.0,62,125.0,,,77,133.0,,,6,2.0,,6,2.0,,"David Kenny, IBM Watson and Cloud Platform senior vice president, speaks with CNBC’s “Squawk Alley” on the tech giant’s push to close in on the competition in the cloud sector. 
",https://image.cnbcfm.com/api/v1/image/105202613-184684816.jpg?v=1529478225,https://www.cnbc.com/video/2018/05/11/ibm-watson-cloud.html?linkId=51617025,joy,0.085318,positive,0.541349,"Cloud SVP David Kenny, cloud-centric world, IBM","Company, Person, Person",Cloud SVP David Kenny,Company,sadness,0.126884,neutral,0,"senior vice president, David Kenny","Person, Person, Company, Company",senior vice president,Person,sadness,0.461302,negative,-0.696181,"Global Business, Financial News, real-time snapshot, Data",Quantity,"Data is a real-time snapshot *Data is delayed at least 15 minutes. Global Business and Financial News, Stock Quotes, and Market Data and Analysis.
",Global Business,Quantity,gray,intersection,junction,intersection,-
http://ibm.co/2I0KcrF,187446750783_10155617160885784,https://www.facebook.com/ibmwatson/posts/10155617160885784,"It can take financial advisors hours or even days to hunt down the right answers hidden in documents, call logs, chat transcripts and more; Watson can help them find answers in seconds. That’s because AI can identify patterns, trends and relationships that humans can’t see in large volumes of data – regardless of where that data resides in the enterprise.

Join our webinar tomorrow at 1pm EDT to learn how a leading Australian bank is using Watson to empower experts – and how your business can too: ",Link,,,5/14/18 18:14, ,5750,5750,0,7917,7917,0,86,50,61,1,1,6813,4734,0,0,78,0,0,0,0,0,0,0,0,0,0,12,39.0,,12,41.0,,32,20.0,,,41,20.0,,,1,,,1,,,,,https://event.on24.com/eventRegistration/EventLobbyServlet?target=reg20.jsp&partnerref=WatsonTwitter&eventid=1657280&sessionid=1&key=B00BF6CB06C9B8D24DD9B98F533DB5A9&regTag=&sourcepage=register,joy,0.433596,positive,0.381251,"financial advisors hours, webinar tomorrow","Person, Person",financial advisors hours,Person, , , , , , , , ,sadness,0.461582,neutral,0,,," 		 		 		Event Registration
 		 		  		 		  		 		 		 		   	 	  		 			 				 			
 			 				 			
 			 				 			
 			             
 		
 		 			 		
 		 			 		
 		 			 		
  		 			 		  		  		 		 	  

",,, , , , , 
https://ibm.co/2IAF8uy,187446750783_10155614798270784,https://www.facebook.com/ibmwatson/posts/10155614798270784,"&quot;IBM's now one of the big dogs in the new high-stakes world of modern enterprise IT centered on how cloud, AI, blockchain, machine learning, and advanced cybersecurity can help businesses get, manage and exploit data to make better decisions, dazzle customers and trounce competitors.&quot; ",Link,,,5/13/18 9:12, ,20534,20534,0,27558,27558,0,831,605,723,13,13,17628,12941,0,0,561,0,0,0,0,0,0,0,0,0,0,52,298.0,5.0,54,308.0,10.0,192,449.0,,,236,487.0,,,10,3.0,,10,3.0,,A resurgent IBM becomes one of the world's top 3 enterprise-cloud providers under the courageous leadership of CEO Ginni Rometty as cloud revenue topped $17 billion for 2017 and hit $5.5 billion--up 30%--in Q4. IBM's achievement proves why conventional wisdom is useless in our unconventional world.,https://thumbor.forbes.com/thumbor/fit-in/1200x0/filters%3Aformat%28jpg%29/https%3A%2F%2Fspecials-images.forbesimg.com%2Fdam%2Fimageserve%2F503702202%2F0x0.jpg%3Ffit%3Dscale,https://www.forbes.com/sites/bobevans1/2018/01/19/ibm-joins-microsoft-amazon-atop-cloud-world-booming-cloud-business-ends-long-revenue-decline/#46fa6c9e49c4,joy,0.566134,positive,0.937289,machine learning,Company,machine learning,Company,joy,0.47765,negative,-0.381805,"resurgent IBM, conventional wisdom","Person, Company, Quantity, Quantity, Quantity",resurgent IBM,Person,sadness,0.591304,positive,0.657601,"IBM's cloud revenue, CLOUD WARS","Company, Person, Company, Quantity, Quantity","(Note: After an award-winning career in the media business covering the tech industry, Bob Evans was VP of Strategic Communications at SAP in 2011, and Chief Communications Officer at Oracle from 2012 to 2016. He now runs his own firm, Evans Strategic Communications LLC.)
CLOUD WARS -- Accelerating its remarkable turnaround and establishing itself among the top 3 enterprise-cloud players, IBM's cloud revenue for the year rose 24% to $17 billion and jumped $30% in the fourth quarter to $5.5 billion.
With cloud revenue now making up 21% of IBM's total revenue of $79.1 billion, IBM's reinvigorated technology and market focus have allowed the company to snap an agonizing streak of 20+ quarters of declining revenue as CEO Ginni Rometty's heroic transformation of the iconic 106-year-old company has come full circle.
With its multifaceted cloud business leading the way, IBM's ""strategic imperatives""—cloud, security, analytics and mobile—grew 14% in the fourth quarter and now account for close to 50% of the company's revenue.
This type of resurgence in the dynamic and rapidly evolving tech sector is supposed to be impossible—for several years now, the prophets of doom have been saying IBM had lost its way, couldn't afford to invest in advanced technology, was overinvested in services, didn't get the cloud, and was hopelessly trapped in a death spiral.
But proving yet again that conventional wisdom in today's unconventional enterprise-IT world is utterly worthless, IBM reported growth across the board and projected continued growth throughout 2018.
And Rometty solidified her reputation as not only a courageous CEO willing to take on the near-impossible task of turning around a slumping giant, but also as a visionary strategist who several years ago set a bold new vision for the company centered on powerful new technologies, defied critics who said IBM should be sold off in pieces, and forcefully recreated IBM as one of the world's pre-eminent sources of innovation and business value.
""During 2017, we strengthened our position as the leading enterprise cloud provider and established IBM as the blockchain leader for business,"" Rometty said in a press release announcing its financial results, adding that IBM is ""uniquely positioned to help clients use data and AI to build smarter businesses.""
""Strengthened,"" indeed. In the red-hot enterprise-cloud sector, here are some highlights of what IBM achieved in the fourth quarter and for all of 2017 as it defied the doomsayers and joined Microsoft and Amazon among the three biggest and most-influential cloud vendors.
And in an internal move that will create huge new scaling capabilities for the IBM Cloud, senior vice-president Martin Schroeter said on the earnings call that IBM would be moving its massive services business—the current backlog is $120 billion—onto the IBM Cloud platform.
""So not only are we building and moving new SaaS properties into the cloud—which have great margins—and not only are we building our Platform as a Service and building ecosystems around that, but we also have north of $120 billion backlog in our services business that we're in the process of moving to the cloud,"" Schroeter told the analysts per the earnings-call transcript on SeekingAlpha.com.
""So when we talk scale, we're moving our whole services platform on to the IBM Cloud, and that's going to give us the scale we need, not just for that infrastructure layer but it's going to give us the scale we need to manage applications, it's going to give us to scale we need to deliver SaaS as effectively as possible and efficiently as possible. So we've got a lot of scale coming our way.""
So IBM is not just ""back""—IBM's now one of the big dogs in the new high-stakes world of modern enterprise IT centered on how cloud, AI, blockchain, machine learning, and advanced cybersecurity can help businesses get, manage and exploit data to make better decisions, dazzle customers and trounce competitors.
And IBM fully deserves to be regarded as one of the Big Three in the Cloud Wars along with Microsoft and Amazon.
I've analyzed and written about the enterprise-tech business for more than 20 years from the media side as an editor-in-chief and chief content officer, and more recently as Chief Communications Officer at Oracle from 2012-2016. I've written thousands of articles and columns about business innovation, competitive advantage, strategy, leadership, disruptive technology, customer case-studies, CEO profiles, digital transformation and cloud computing. Late last year, I resigned from Oracle to launch my own company, Evans Strategic Communications, which helps businesses grow via thought leadership and innovative storytelling.
",IBM's cloud revenue,Company,blue,celebrity,person,adult,celebrity
,187446750783_10155612593965784,https://www.facebook.com/ibmwatson/posts/10155612593965784:0,"With all eyes focused on the customer, leading COOs are turning to AI for insights and impact. We surveyed more than 2,100 COOs around the world. Here’s what the best are doing to outperform their competition: ibm.biz/coostudy",Photo,,,5/12/18 9:30, ,7119,7119,0,10171,10171,0,87,62,86,4,4,9318,6487,0,0,72,0,0,0,0,0,0,0,0,0,0,6,31.0,,8,33.0,,32,9.0,33.0,,43,9.0,34.0,,3,1.0,,3,1.0,,,,,joy,0.474892,positive,0.732737,eyes,Person,eyes,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2J5NTwv,187446750783_10155608633295784,https://www.facebook.com/ibmwatson/posts/10155608633295784,"With over 5,200 branches, Bradesco is one of Brazil’s largest banks. So how are they able to pay attention to each one of their 65 million customers? Learn how they trained Watson to answer questions with accuracy: ",Link,,,5/10/18 10:10, ,3309,3309,0,4712,4712,0,82,48,65,2,3,3631,2518,0,0,71,0,0,0,0,0,0,0,0,0,0,16,48.0,4.0,16,48.0,4.0,24,28.0,,,35,30.0,,,3,,,2,,,How a Brazilian bank pays personal attention to each of their 65 million customers,,https://www.ibm.com/watson/stories/bradesco/,sadness,0.11589,neutral,0,Brazil’s largest banks,"Company, Location",Brazil’s largest banks,Company,sadness,0.452632,neutral,0,"Brazilian bank, personal attention",,Brazilian bank,,joy,0.487799,positive,0.683831,,"Person, Company, Company, Person, Person","Watson is AI from IBM that seamlessly embeds into your workflows while integrating with the leading platforms and tools enterprises already use. Putting AI at your employees' fingertips when they need it - and where they need it - means empowering your teams to focus on what they do best.
There’s even one inside a boat on the Amazon. When branch employees had questions about products or services, they called a central office, but there was often a long wait for answers. This meant the client was also left waiting, and as one manager put it, “No one likes to wait.”
In a business as competitive as banking, if your customers don’t have a great experience, they may not be your customers for long. So Bradesco started looking for a way to increase the speed of service and also improve the level of personalization for each client. That’s when they turned to IBM and Watson.
Their first task was to teach Watson Portuguese, but initially there were some doubts. “It’s more than just learning the language,” said IBM Managing Director Katia Vaskys. “You also need to understand Brazil’s culture, and the regional accents, and the way each region asks a question.”
But after mastering the nuances of Portuguese, Watson was ready to be trained on the business of banking. To do this, Bradesco and IBM worked together to develop a team that taught Watson about the bank’s products and services by asking and answering questions for Watson in natural language—the same way a customer would. 
“Yes, Watson can learn,” said one IBMer, “but it needs people to teach people who are committed and patient.” Because of this team effort, Watson could understand 100% of written questions and 83% of spoken ones after just 5 months of training. And after 10 months, the system was answering 96% of all questions correctly.
Now Watson is trained on 62 products and answers 283,000 questions a month with a 95% accuracy rate, with just 5% requiring calls for further assistance. In some cases, response times have been reduced from 10 minutes to just seconds. “It’s a real wow factor,” exclaimed one manager.
This helps employees have more enriching interactions with clients, because they have time to dedicate to providing the best possible customer experience. “This is when growth happens,” said the Bradesco AI Lead, Marcelo Camara. “Our current clients notice the improved service, which in turn attracts new clients, and this is what helps the bank scale.”
",,Person, , , , , 
https://ibm.co/2ouW1yG,187446750783_10155606845805784,https://www.facebook.com/ibmwatson/posts/10155606845805784,"Machine learning models need to be trained on large amounts of data to ensure that they are accurate, but for many problems, that large data set simply doesn’t exist. IBM Watson CTO Rob High believes this is a solvable problem – learn why via TechCrunch: ",Link,,,5/9/18 13:11, ,10059,10059,0,13860,13860,0,352,218,263,15,15,10629,7626,0,0,290,0,0,0,0,0,0,0,0,0,0,22,154.0,3.0,24,156.0,3.0,111,119.0,,,139,124.0,,,14,1.0,,14,1.0,,"For IBM Watson CTO Rob High, the biggest technological challenge in machine learning right now is figuring out how to train models with less data. ""It's a challenge, it's a goal and there's certainly reason to believe that it's possible,"" High told me during an interview at the annual Mobile World Congress in Barcelona.",https://techcrunch.com/wp-content/uploads/2018/02/img_20180227_171316.jpg?w=533,https://techcrunch.com/2018/02/27/ibm-watson-cto-rob-high-on-bias-and-other-challenges-in-machine-learning/,sadness,0.177177,positive,0.318055,"IBM Watson CTO Rob High, large amounts of data","Person, Company",IBM Watson CTO Rob High,Person,joy,0.506627,positive,0.633511,"IBM Watson CTO Rob High, biggest technological challenge","Person, Company, Organization",IBM Watson CTO Rob High,Person,joy,0.54021,positive,0.485841,IBM  Watson CTO Rob High,"Person, Person, Company, Person, Person, Person, Location, Organization, Person, Company","For IBM  Watson CTO Rob High, the biggest technological challenge in machine learning right now is figuring out how to train models with less data. “It’s a challenge, it’s a goal and there’s certainly reason to believe that it’s possible,” High told me during an interview at the annual Mobile World Congress in Barcelona.
With this, he echoes similar statements all across the industry. Google’s AI chief John Giannandrea, for example, also recently listed this as one of the main challenges the search giant’s machine learning groups are trying to tackle. Typically, machine learning models need to be trained on large amounts of data to ensure that they are accurate, but for many problems, that large data set simply doesn’t exist.
High, however, believes this is a solvable problem. Why? “Because humans do it. We have a data point,” he said. One thing to keep in mind is that even when we see that evidenced in what humans are doing, you have to recognize it’s not just that session, it’s not just that moment that is informing how humans learn. We bring all of this context to the table.” For High, it’s this context that’ll make possible training models with less data, as well as recent advances in transfer learning, that is, the ability to take one trained model and then use this data to kickstart the training of another model where less data may exist.
The challenges for AI — and especially conversational AI — go beyond that, though. “On the other end is really trying to understand how better to interact with humans in ways that they would find natural and that are influential to their thinking,” says High. “Humans are influenced by not just the words that they exchange but also by how we encase those words in vocalizations, inflection, intonation, cadence, temper, facial expression, arm and hand gestures.” High doesn’t think an AI necessarily needs to mimic these in some kind of anthropomorphic form, but maybe in some other form like visual cues on a device.
At the same time, most AI systems also still need to get better at understanding the intent of a question and how that relates to individuals’ previous questions about something, as well as their current state of mind and personality.
That brings up another question, though. Many of these machine learning models that are in use right now are inherently biased because of the data with which they were trained. That often means that a given model will work great for you if you’re a white male but then fails black women, for example. “First of all, I think that there’s two sides to that equation. One is, there may be aggregate bias to this data and we have to be sensitive to that and force ourselves to consider data that broadens the cultural and demographic aspects of the people it represents,” said High. “The flip side of that, though, is that you actually want aggregate bias in these kind of systems over personal bias.”
As an example, High cited work IBM did with the Sloan Kettering Cancer Center. IBM and the hospital trained a model based on the work of some of the best cancer surgeons. “But Sloan Kettering has a particular philosophy about how to do medicine. So that philosophy is embodied in their biases. It’s their institutional biases, it’s their brand. […] And any system that is going to be used outside of Sloan Kettering needs to carry that same philosophy forward.”
“A big part of making sure that these things are biased in the right way is both making sure that you have the right people submitting for and who these people are representative of — of the broader culture.” That’s a discussion that High says now regularly comes up with IBM’s clients, too, which is a positive sign in an industry that still often ignores these kind of topics.
",IBM  Watson CTO Rob High,Person,coal black,stringer (wooden),support,timber,stringer (wooden)
https://ibm.co/2DNYtFb,187446750783_10155603327525784,https://www.facebook.com/ibmwatson/posts/10155603327525784,"Available now, Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI.
",Link,,,5/7/18 19:03, ,13220,13220,0,18320,18320,0,485,285,348,7,7,12177,8594,0,0,390,0,0,0,0,0,0,0,0,0,0,62,223.0,7.0,62,226.0,10.0,148,161.0,,,174,174.0,,,1,6.0,,1,6.0,,"Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity. Consider three distinct examples – 1. Fixing issues with Visual Diagnosis User: A person in the field equipped with an iPhone trying to visually diagnose a problem. Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage. 2. Recommendations based on Visual analysis User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations. Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/03/GettyImages-1086731554.jpg,https://www.ibm.com/blogs/watson/2018/03/ai-everywhere-ibm-watson-apple-core-ml/,anger,0.075048,neutral,0,Watson Visual Recognition Service,"Person, Company, Company",Watson Visual Recognition Service,Person,sadness,0.551904,negative,-0.449804,Visual Diagnosis User,Person,Visual Diagnosis User,Person,joy,0.548225,positive,0.631349,number of users,"Person, HealthCondition, Company, Person, Company","Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity.
Consider three distinct examples –
1. Fixing issues with Visual Diagnosis
User: A person in the field equipped with an iPhone trying to visually diagnose a problem.
Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage.
2. Recommendations based on Visual analysis
User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations.
Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying unknown or complex machine parts to classifying plants or food.
3. Visual triggers for a business process
User: An end user and a trigger for a downstream business process
Usage: Business processes range from creating a work order for repair to updating a shopping cart for purchase; from intervening in quality control to safety procedure in manufacturing; from initiating an insurance claim to a collaborative analysis for experts in medicine.
These are a diverse set of scenarios with a common thread running through them: the need for a low-latency and rich insight for a human or a downstream process.
Imagine a scenario where a user is trying to access results while on-the-go (changing network speeds), or in hard-to-reach places (manufacturing plants, buildings, store interiors, remote areas, etc.). This impacts the user’s ability to do the job, which can have a domino effect on business processes and the bottom line for companies.
The most compelling way to empower that user combines relevant AI insights, at the time of need, without the user having to worry about network connectivity issues.
To set this in motion, you need:
1. A technique to handle tradeoffs between immediate insights, irrespective of connectivity, with richer insights from the cloud, allowing the user to focus on the task at hand.
2. Collaborative methods and tools for users, developers and/or data scientists to build solutions in a way that allows them to focus on the higher end of the solution spectrum.
3. An approach with associated technology that enables a process of rapid iteration to keep up with constantly changing data and other surrounding factors.
Components of this solution are being successfully used by enterprises and consumers across industries and geographies.
Watson services on the IBM Cloud provide rich and relevant insights from a variety of public and enterprise data sources to applications. IBM’s approach to data and privacy with Watson ensures that client data and insights are not shared with IBM or third parties, and that client data does not contribute to training a centralized knowledge graph.
Apple Core ML is a foundational machine learning (ML) framework that lets you integrate ML models into your app. Core ML delivers optimized performance for Apple products with minimal memory footprint and battery consumption impact. User privacy is protected as data is stored locally and encrypted by default.
What’s new – Bringing it together with a seamless experience
Available today, Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI.
These are key aspects of what is now available to the ecosystem of users and developers. Read more about the partnership here.
1. Watson SDK low latency, and offline process for custom Visual Recognition models using Core ML with the rich insights from the Watson services on the cloud.
2. Watson Studio provides a low-code, end-to-end collaborative environment that enables developers to quickly and easily catalog, classify, provision, and train their data and models.
3. Developer assets and best practices including Code Patterns for developers to get started, starter kits to quickly build iOS apps that combine these Watson services with other components, and code examples to get started now.
These offerings are the first step towards mitigating challenges for users, developers, and enterprises. Companies have already started building enhancements to applications that leverage Watson Visual Recognition Service for Core ML.
For the developer, this drives a paradigm for building once and deploying at heterogeneous endpoints. For the user, this translates to growth in the expertise spectrum and higher productivity. For the enterprise, this is an inevitable step toward mobile and AI revolutionizing how we work.
Watch the demo to see how this all comes together for part and issue identification on Arduino boards, a representative for any component.
",number of users,Person,blue,X-ray film,photographic equipment,photographic film,X-ray film
https://ibm.co/2FKkjua,187446750783_10155600377560784,https://www.facebook.com/ibmwatson/posts/10155600377560784,"AI isn't here to replace humans, but augment their capabilities. IBM trains Watson to automate routine tasks, so we can elevate meaningful ones and focus on what's most important. Gain a better understanding: ",Link,,,5/6/18 9:54, ,9144,9144,0,13084,13084,0,114,69,89,2,2,11079,7707,0,0,101,0,0,0,0,0,0,0,0,0,0,18,50.0,4.0,18,50.0,4.0,41,31.0,,,51,38.0,,,1,1.0,,1,1.0,,Harness the power of AI with Watson and turn data into new ways of doing business. http://www.ibm.com/watson,https://i.ytimg.com/vi/Rf1zd2R9CuM/maxresdefault.jpg,https://www.youtube.com/watch?v=Rf1zd2R9CuM,joy,0.178207,positive,0.549125,"routine tasks, better understanding, IBM","Person, Person, Company",routine tasks,Person,joy,0.337835,neutral,0,"new ways, power",Person,new ways,Person,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                   
            

",YouTube,Company,indigo,person,supporting structure,framework,climbing frame
https://ibm.co/2GvWwiS,187446750783_10155599225775784,https://www.facebook.com/ibmwatson/posts/10155599225775784,"When it comes to the capabilities of AI, should organizations consider ethics when utilizing the technology? Rob High, IBM Watson CTO, explains his theory on the concept of ethics in AI via ZDNet: ",Link,,,5/5/18 19:16, ,8595,8595,0,12335,12335,0,131,82,98,2,2,10461,7319,0,0,115,0,0,0,0,0,0,0,0,0,0,15,53.0,2.0,17,53.0,3.0,28,56.0,,,35,63.0,,,1,1.0,,1,1.0,,"Rob High, chief technology officer for IBM Watson, summarizes his presentation from the Mobile World Conference in Barcelona and discusses the state of AI, the relevance of the Turing Test, and what if any limits should be placed on the technology. Read more: https://zd.net/2q4jJ5n",https://zdnet2.cbsistatic.com/hub/i/r/2018/04/03/5af8260a-f9a1-4d92-ad1f-b65cba6941a0/thumbnail/770x578/39c79702589c1f1aa9f84b71b4ca02ae/18-robotic-artificial-intelligence-ai-deep-learning-computer-program-technology.jpg,https://www.zdnet.com/video/ethics-and-responsibilities-of-ai-should-limits-be-placed-on-tech/,disgust,0.155746,neutral,0,"Rob High, IBM Watson CTO, capabilities of AI","Person, Person, Company",Rob High,Person,anger,0.2263,positive,0.517534,"chief technology officer, Rob High, Mobile World Conference","Person, Company",chief technology officer,Person,joy,0.55182,negative,-0.485797,,"Person, Person, Company, Company, Company","Rob High, chief technology officer for IBM Watson, summarizes his presentation from the Mobile World Conference in Barcelona and discusses the state of AI, the relevance of the Turing Test, and what if any limits should be placed on the technology. Read more: https://zd.net/2q4jJ5n
                     Should we build AI weapons?                                                         
                     To spot spammers, Facebook's new algorithm looks at a profile's whole ecosystem                                                         
                     What it takes to make AI projects successful                                                         
                     Tesla Autopilot death: Final report blames Tesla, Apple, and NHTSA                                                         
                     Supply chain analytics might not be ready for coronavirus outbreak                                                         
                     Why AI's equity must improve                                                         
                     Costa Group turns to AI 'maths robot' to improve berry yield predictions                                                         
                     Cognizant‘s AI scientists demonstrate potential via Flappy Bird                                                         
                     Android 11 developer preview: 12 new features                                                         
                     AI strategy: How the EU hopes to put people first                                                         
                     Google’s AI chief explains machine learning for chip design                                                         
                     Europe unveils a new strategy for AI to show it is still a contender in the digital race                                                         
                     LG CNS deploys AI facial recognition gate service                                                         
                     How Intel thinks AI will change in the years to come                                                         
                     Cuttlefish-inspired smart camouflage could make for sneakier soldiers                                                         
Are humans capable of adapting to rapid change?
© 2020 CBS Interactive. All rights reserved.                     Privacy Policy |                     Cookies |                     Ad Choice |                     Advertise |                     Terms of Use |                     Mobile User Agreement                 
",,Person,sea green,X-ray film,photographic equipment,photographic film,X-ray film
https://ibm.co/2KtJMf7,187446750783_10155595993820784,https://www.facebook.com/ibmwatson/posts/10155595993820784,"AI in outer space? The sky's the limit. 
Here's how a 3D-printed assistant called CIMON is speeding up routine tasks for astronauts aboard the ISS: ",Link,,,5/4/18 9:15, ,9250,9250,0,12952,12952,0,195,113,144,2,2,10076,7254,0,0,172,0,0,0,0,0,0,0,0,0,0,31,85.0,7.0,31,86.0,8.0,74,46.0,,,98,46.0,,,2,,,2,,,"The digital assistant CIMON features a version of IBM Watson, and will help astronauts complete tasks on the International Space Station.",https://tr1.cbsistatic.com/hub/i/r/2018/03/02/363a4174-04ab-43b5-a71b-d8224e2a56ec/thumbnail/770x578/5c5aa08f12500550aaab447c83073d23/cimon-new1609.jpg,https://www.techrepublic.com/article/ai-in-space-astronauts-will-get-floating-robot-assistant-thanks-to-ibm-airbus/,joy,0.207944,negative,-0.549972,"3D, outer space, routine tasks",Person,3D,Person,joy,0.060758,neutral,0,"digital assistant CIMON, complete tasks, International Space Station",Company,digital assistant CIMON,Company,joy,0.518007,positive,0.692218,,Person,"Building a slide deck, pitch, or presentation? Here are the big takeaways:
Astronauts on the International Space Station (ISS) will soon gain a new helpful companion: A floating artificial intelligence (AI)-based digital assistant that will help them get work done in space. 
The assistant, CIMON (Crew Interactive MObile CompanioN), was designed by IBM and Airbus. It will take the form of an 11-pound, basketball-sized device that can float alongside the astronauts, according to an Airbus press release. 
Running a modified version of IBM Watson, CIMON is designed to support astronauts in routine tasks, by displaying procedures, or offering solutions to problems, thanks to its neural AI network and its ability to learn. 
CIMON will allow crew members to not only work through checklists and procedures, but to engage with the assistant, making work easier and increasing efficiency, according to Airbus. It can even serve as an early warning system for technical problems, the release noted. 
Insert HAL jokes here. 
SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
""In short, CIMON will be the first AI-based mission and flight assistance system,"" Manfred Jaumann, head of microgravity payloads at Airbus, said in the release. ""We are the first company in Europe to carry a free flyer, a kind of flying brain, to the ISS and to develop artificial intelligence for the crew on board the space station.""
CIMON's entire metal and plastic structure was made with 3D printing, Jaumann said in the release. 
Similar to Siri or Alexa, CIMON can recognize speech, has a synthetic voice, and is capable of some interactions with humans, as noted by our sister site ZDNet. While these assistants have become common on Earth, in space, these interactive capabilities could be even more useful and relevant. 
The Watson AI will go on its first mission to the ISS with astronaut Alexander Gerst during the European Space Agency's Horizons mission, between June and October 2018. CIMON was trained partially using voice samples and photos of Gerst, as well as procedures and plans of the ISS. Gerst helped choose CIMON's screen face and computer voice so he could more easily make friends with his new electronic colleague, the release noted. 
SEE: Exomedicine arrives: How labs in space could pave the way for healthcare breakthroughs on Earth (TechRepublic cover story) | download the PDF version 
After functionally testing the system, Gerst will work with CIMON on the ISS on three tasks: Experimenting with crystals, solving a Rubik's cube, and performing a complex medical experiment using CIMON as a flying camera. 
""In the medium term, aerospace researchers also plan to use the CIMON project to examine group effects that can develop over a long period of time in small teams and that may arise during long-term missions to the Moon or Mars,"" the release noted. ""Social interaction between people and machines, between astronauts and assistance systems equipped with emotional intelligence, could play an important role in the success of long-term missions.""
Here on Earth, CIMON could also potentially be used in the future in hospitals and for social care, Airbus said in the release. 
",,Person,ash grey,engine room,indoors,engine room,-
https://ibm.co/2oCky3W,187446750783_10155593824880784,https://www.facebook.com/ibmwatson/posts/10155593824880784,"From starting her first company as an eight-year-old, to creating the country’s largest AI student group, Allie Miller has always been driven. Now, after receiving an MBA from Wharton and graduating with a degree in Cognitive Science from Dartmouth, Allie is a part of IBM Watson's Visual Recognition team, shaping the future of Watson technologies that help businesses understand the context of their images. ",Link,,,5/3/18 9:46, ,8145,8145,0,11133,11133,0,264,188,236,5,6,9490,6983,0,0,246,0,0,0,0,0,0,0,0,0,0,17,94.0,3.0,19,95.0,3.0,118,84.0,,,146,90.0,,,5,1.0,,4,1.0,,Allie Miller is shaping IBM Watson technologies that help businesses understand Visual Recognition. Learn more about Allie's career and journey into AI.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/02/profileCrop_png_socialTile_022618.png,https://www.ibm.com/blogs/watson/2018/02/redefining-how-we-get-it-done-with-allie-miller-ibm-watson/,joy,0.328354,positive,0.740657,"Cognitive Science, part of IBM Watson","Person, Quantity, Person, Organization, Location, Person",Cognitive Science,Person,joy,0.196497,positive,0.80574,"Allie Miller, IBM Watson technologies, Allie's career","Person, Company",Allie Miller,Person,joy,0.641793,positive,0.797175,,"Person, Person, Person, Company, Person, Company, GeographicFeature, Quantity, Organization","Share this post:
Allie Miller has always been a doer. From starting her first company as an eight-year-old, to creating the country’s largest AI student group, to doing the polar plunge in the Antarctic Ocean – Allie has always found a way to grab life by the horns and get the job done.
Now, after receiving an MBA from Wharton and graduating with a degree in Cognitive Science from Dartmouth, Allie has joined the ultimate get-it-done heavyweight, IBM Watson. As part of the Visual Recognition team, Allie is shaping the future of the Watson technologies that help businesses understand the context of their images, leading to the discovery of actionable insight.
Heading into Think 2018, Allie takes a short break from her aggressive to-do list to talk about how Watson is partnering with professionals to help businesses “get it done” in revolutionary new ways – and what exciting opportunities, but also potential hurdles, are on her radar for 2018.
How did you end up with a career in AI, and what brought you to IBM Watson?
Since I can remember, I’ve been obsessed with the way people process information, and what drives their decision-making. Whether it’s a complicated work challenge or just choosing the route we take to work in the morning, how we as humans reason and problem-solve is fascinating.
Heading to Dartmouth, I knew that’s what I wanted to learn more about. Since the power of AI really lies in augmenting human capabilities, I chose to study Cognitive Science—a blend of Psychology, Philosophy, Linguistics, and Computer Science. This expanded my understanding of the human mind, how it works, and what influences our decision-making. I wanted to take these classes and home in on the technical aspect of cognition, which led me to run a two-and-a-half-year study on natural language. That really laser-focused my career path toward artificial intelligence.
I was offered several AI opportunities, but what drew me to Watson was not only IBM’s early leadership in the space, but also the care and commitment that IBM takes in training and development. I’m constantly learning, growing, being challenged and pushed. I can’t wait to get up every morning and not just read about what’s coming next, but contribute to it every day.
You’re about to take the stage at Think 2018. What’s on your mind to share with the world?
The progress we have made with visual recognition technology in just the past few years, to me, is astounding. Beyond pulling insight out of content, Watson Visual Recognition can really be customized for any use case. And, since Watson can understand industries inside and out, it’s almost like having an instant co-pilot that understands exactly how you live and work, and makes you smarter about what you’re doing. It’s really that simple.
There’s nothing I love more than taking 15 minutes to show someone just how easy it is to adopt Watson into their business – and how it can boost their bottom-line. Once we take away this hesitation and skepticism, the opportunities and possibilities quickly emerge.
But, in addition to running toward these exciting opportunities, I’m constantly mindful of the pitfalls. AI is a powerful technology, and with power comes great responsibility. We need to make sure we innovate at the same rate we create guardrails.
What is the most exciting part of your job?
You mean other than the free Diet Coke? For me, it comes down to the frontier work, the opportunity to affect important change on our world – and collaborating with some of the best, brightest people I’ve ever met.
The beauty of Watson is that it’s for everyone. A large enterprise can integrate AI into their workflows and see immediate, tangible benefits: increased productivity, better insight, and enhanced decision-making. But what’s even more exciting is that today everyone, even smaller businesses and individuals who may have fewer resources or technological know-how, can benefit. We’ve created accessible avenues for small, medium and large companies to access AI. We can deliver big, complex solutions or smaller, scrappier ones. Nothing gets me more excited than when I show someone — a professional, a friend — just how easy it is to instantly implement and benefit from AI.
If you had to sum it up, what will AI do for us this year?
I think AI will make each of us increasingly unstoppable. AI is highly technical, but it’s also immensely humanistic. AI could deepen what it means to be human. By taking everything we produce — the documents we create, photos we share, conversations we have — and extracting insight we never could have seen, we can be better — more creative, more inspired, and more resourceful. The power of having Watson, the ultimate “go-getter”, behind it all is incredible.
Want to hear more from Allie? Register for Think 2018 today and make sure you check out her session. You can read more about Watson services here, and follow Allie on Twitter (@alliekmiller) and LinkedIn.
",,Person,coal black,person,figure,circle,-
https://ibm.co/2FBkKXT,187446750783_10155591695245784,https://www.facebook.com/ibmwatson/posts/10155591695245784,"If you've ever picked up a phone to call customer service, or communicated a problem through a brand's website, you've already interacted with AI. Learn the differences between the 3 most popular types of chatbots that businesses are using today: ",Link,,,5/2/18 11:52, ,7109,7109,0,9976,9976,0,111,69,85,1,1,7842,5690,0,0,90,0,0,0,0,0,0,0,0,0,0,23,41.0,1.0,23,42.0,2.0,33,37.0,,,45,40.0,,,1,,,1,,,"As chatbots continue to gain popularity, our latest blog highlights the three types of business chatbots you can build to better reach and target customers.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/12/Conversation_service_Social1200x628-1.png,https://www.ibm.com/blogs/watson/2017/12/3-types-of-business-chatbots-you-can-build/,anger,0.162405,positive,0.497646,"customer service, popular types of chatbots",Person,customer service,Person,joy,0.425058,positive,0.725044,"types of business chatbots, latest blog",,types of business chatbots,,sadness,0.539365,positive,0.560402,single-turn type bots,"Person, Company","Key Points:
 From a business perspective, here are the 3 most common chatbots that are being built:
 – Support chatbots that are built to master a single domain
 – Skills chatbots that are single-turn type bots that do not require a lot of contextual awareness
 – Assistant chatbots that are the middle ground between a support and skills chatbot, knowing a little bit about a variety of topics
A few years ago when chatbots were just gaining popularity, there was a lot of talk around what a chatbot actually was. With the advent of natural language processing and various machine learning techniques, some of the more advanced conversational applications wanted to separate themselves from their competition. Many began calling themselves “virtual assistants.” This implied that they were somehow bigger or more powerful than existing chatbots, or perhaps were more conversational or could cover a wider range of topics.
However, we quickly discovered that the market did not care how powerful the bot was or about the underlying technology, so long as it solved the right problems. So in a way, many of these different terms for bots became more or less synonymous with each other. It didn’t matter what you called it – you were getting something you could hold a conversation with. We’re now at a point where we know that regardless of what you call the bot, there are usage patterns and differentiation that make chatbots distinct.
When you’ve done your research and are at the point of beginning to build your bot, think carefully about what problems you’re trying to solve and what functionalities you will want to incorporate. Knowing what you want your application to solve for and assist with will decide the type of chatbot, virtual assistant or agent you ought to build. This will impact both your development plan and, as importantly, your end-user experience. The following are the three main types of chatbots I have come across, with background on their particular uses and variations.
Support chatbots are built to master a single domain, like knowledge about a company. Support chatbots need to have personality, multi-turn capability, and context awareness. They should be able to walk a user through any major business processes, and answer a wide range of FAQ-type questions. You will want to have a short-tail and long-tail combo solution when building this type of chatbot. At IBM Watson, we would use the Watson Conversation service for the short-tail, common questions and processes, and Watson Discovery service for the long-tail, but there are many potential solutions for this. Speech is an optional feature, and not a necessity, since users typically have sat down at a desktop and are ready to figure out their solution. The chatbot developer will want to spend the most time making sure it is as easy as possible to navigate the bot, and ensuring it can execute the actions that your users actually care about (for example, just because you want to sell more credit cards doesn’t mean your customers want to open more credit card accounts).
Skills chatbots are typically more single-turn-type bots that do not require a lot of contextual awareness. They have set commands that are intended to make life easier: “Turn on my living room lights,” for example. Speech functionality is recommended for this type of chatbot so the user does not need to turn on a device or click any buttons. They should be able to follow commands quickly, so that your users can multitask while engaging with the bot. These chatbots do not need to worry too much about contextual awareness, unless you want to design a particularly advanced one, as people will quickly learn what to say, and say it appropriately. It’s a nice bonus if you can give a command, and your bot knows – to return to our example – that you are in the kitchen and acts to turn on the correct lights.
However, this is not a necessary function, as users will quickly learn to give the appropriately specific command. When building a skills bot, it is important to focus on integration, especially when controlling a home or personalized objects. Keep integration simple so your users can interact with the bot without worrying about how to use .
Assistant chatbots are more or less a middle ground between the two bots above. They work best when they know a little bit about a variety of topics. Many people envision these bots will someday become navigators of all other bots that are out there now. Want to pay a bill? Ask your assistant bot to talk to the support bot for your bank. Assistant chatbots need to be conversational and respond to just about anything, while being as entertaining as possible. Siri is a good, current example – while she only does so much, people continually ask her for things simply because even when she cannot perform the command, the response she gives tends to be amusing. When building an assistant chatbot, it is important to make it as obvious as possible how the bot is trained. The range of questions a user might ask is large, so making sure you have adequate coverage is going to be the most difficult factor. In many cases, when people do not know what they should ask, they will not ask anything at all. And if you miss the few topics they initially are willing to try, they will not come back for more.
Even though these are the most common types, many bots in production fall somewhere in between two. Some are even a combination of all three. No matter what type of bot you decide to build, it is important to give your bot some life and personality, make it useful, and make sure it’s easy to use. People interact with bots because they want to get something done in a more natural way than was previously possible. Whether it’s something simple like turning on a light, or something complex like applying for a mortgage, every pattern has specific features that make it stand out, so be sure your bot shines brightly in what it’s designed to do. The possibilities are endless.
",single-turn type bots,Person,blue,razor,tool,cutlery,razor
https://ibm.co/2Fom0yT,187446750783_10155588874735784,https://www.facebook.com/ibmwatson/posts/10155588874735784,"Artificial intelligence holds significant power to improve the way we live and work, but AI systems are only as effective as the data they’re trained on. Ensuring a balanced representation of unbiased data sets in AI training is critical, and AI algorithms themselves are playing an increasingly important role in ensuring fairness in the use of AI. Here's what IBM is doing to minimize bias: ",Link,,,5/1/18 8:53, ,6790,6790,0,9482,9482,0,115,81,115,2,2,8213,5897,0,0,108,0,0,0,0,0,0,0,0,0,0,15,44.0,1.0,16,46.0,1.0,46,43.0,,,70,45.0,,,1,1.0,,1,1.0,,"IBM is committed to delivering AI services that are unbiased, explainable, value aligned, and transparent, including Watson Visual recognition service.",https://www.ibm.com/blogs/research/wp-content/uploads/2018/02/Mitigating-bias-table.png,https://www.ibm.com/blogs/research/2018/02/mitigating-bias-ai-models/,joy,0.136825,positive,0.953899,"Artificial intelligence, balanced representation of unbiased data sets, important role, significant power",Person,Artificial intelligence,Person,anger,0.193991,positive,0.766306,"Watson Visual recognition service, IBM",Company,Watson Visual recognition service,Company,sadness,0.148457,positive,0.733046,,"Company, Person, Person, Person, Location","Share this post:
Artificial intelligence (AI) holds significant power to improve the way we live and work, but AI systems are only as effective as the data they’re trained on. Bad training data can lead to higher error rates and biased decision making, even when the underlying model is sound.
As the adoption of AI increases, the issue of minimizing bias in AI models is rising to the forefront. Continually striving to identify and mitigate bias is absolutely essential to building trust and ensuring that these transformative technologies will have a net positive impact on society.
For more than a century, IBM has responsibly ushered revolutionary technologies into the world. We are dedicated to delivering AI services that are built responsibly, are unbiased and explainable. And we are continually working to evaluate and update our services, advancing them in a way that is trustworthy and inclusive.
Ensuring a balanced representation of unbiased data sets in AI training is critical, and AI algorithms themselves are playing an increasingly important role in ensuring fairness in the use of AI. The issue of bias also requires the attention, expertise and engagement of a broad network of informed professionals.
To that end, Joy Buolamwini and Timnit Gebru recently published a paper, “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification,” (Conference on Fairness, Accountability, and Transparency, February 2018) that evaluates three commercial API-based visual recognition tools, including IBM Watson Visual Recognition. The study finds that these services’ facial recognition capabilities are not adequately balanced for gender and skin tone [1]. The authors show that the highest error rates involve images of dark-skinned women, while the most accurate results are for light-skinned men.
For the past nine months, IBM has been working toward substantially increasing the accuracy of its new Watson Visual Recognition service for facial analysis, which now uses broader training datasets and more robust recognition capabilities than the service evaluated in this study. Our new service, which will be released on February 23, demonstrates a nearly ten-fold decrease in error-rate for facial analysis when measured with the testset similar to the one in Buolamwini and Gebru’s paper.
To conduct their study, Buolamwini and Gebru constructed a new facial image dataset, called Pilot Parliaments Benchmark, which is highly balanced across skin phenotype and gender.
To evaluate IBM’s new service in a manner consistent with their study, IBM Research gathered images of parliamentarians from Finland, Iceland, Rwanda, Senegal, South Africa and Sweden. This dataset is very similar to the Pilot Parliaments Benchmark. However, the experiment conducted by IBM Research differs slightly from the one used in the paper [1] in two ways. First, the dataset is slightly different as a new election in Senegal has changed the member photos and Rwanda has a smaller number of photos. Thus, IBM Research used 1,217 faces versus the 1,270 reported in the paper. Secondly, we labeled the “lighter” and “darker” classes for the faces manually without using the Fitzpatrick score. We believe that these two, minute differences do not impact the conclusions of the experiment. The table below illustrates our results.
As seen, the error rates of IBM’s upcoming visual recognition service are significantly lower than those of the three systems presented in the paper. While it is still true that the “darker” category has higher error rates than the “lighter” one, the highest error rate (which is still for darker skinned females) — 3.46 percent — is now just a fraction of what it had been in the old service. This reflects a nearly ten-fold decrease in error with our new Face Model. There was no new training or fine-tuning done based on the dataset.
IBM is deeply committed to delivering services that are unbiased, explainable, value aligned, and transparent. To deal with possible sources of bias, we have several ongoing projects to address dataset bias in facial analysis – including not only gender and skin type, but also bias related to age groups, ethnicities, and factors such as pose, illumination, resolution, expression, and decoration. We are currently creating a million-scale dataset of face images annotated with attributes and identity, leveraging geo-tags from Flickr images to balance data from multiple countries and active learning tools to reduce sample selection bias. We intend to make this data publicly available as a tool for the research community and propose a challenge to encourage the community to improve their algorithms with respect to bias in facial analysis. In addition, as a longer-term project, we are planning to conduct research on cycle-consistent adversarial networks to synthetically generate new training samples with specific attributes to reduce dataset bias across race, gender, and age.
More broadly, we are also developing algorithms for detecting, rating, and correcting bias and discrimination across modalities, both for data and for models. For example:
We are actively working on transferring these and other research contributions into IBM’s core AI offerings. In doing so, we are taking a holistic view in which fairness detection and corrections occur throughout an overall data pipeline in an auditable and transparent manner; this perspective is summarized in a paper presented at the 2017 Data for Good Exchange conference [5].
Moreover, we do not view AI ethics simply from the perspective of easily quantifiable fairness results. Beyond any one product, we are actively pursuing a research agenda that includes explainability, computational morality, value alignment, and other topics that will be translated into IBM product and service offerings.
At IBM, we value multi-stakeholder collaboration on important technical and social questions. As a founding member of the Partnership on AI to Benefit People and Society, IBM is happy to see researchers such as Buolamwini and Gebru contributing positively to the advancement of artificial intelligence. These inquiries and the discussions they prompt are essential to promoting the responsible evolution of these transformative technologies.
Responsibility in the use of data and AI has to be a conversation and commitment that transcends any one company, and we recognize that IBM’s work on responsibility, transparency and accountability will never be complete. But we believe that a continual cycle of bias detection and mitigation — coupled with AI models that are transparent and explainable — is the best, and most responsible, path forward.
References: 
[1] J. Buolamwini and T. Gebru. “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification,” Conference on Fairness, Accountability, and Transparency, New York, NY, February 2018.
[2] N. Madaan, S. Mehta, T. Agrawaal, V. Malhotra, A. Aggarwal, Y. Gupta, and M. Saxena. “Analyze, Detect and Remove Gender Stereotyping from Bollywood Movies,” Conference on Fairness, Accountability, and Transparency, New York, NY, February 2018.
[3] B. Srivastava and F. Rossi. “Towards Composable Bias Rating of AI Services,” AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, New Orleans, LA, February 2018.
[4] F. P. Calmon, D. Wei, B. Vinzamuri, K. N. Ramamurty, and K. R. Varshney. “Optimized Pre-Processing for Discrimination Prevention,” Advances in Neural Information Processing Systems, Long Beach, CA, December 2017.
[5] S. Shaikh, H. Vishwakarma, S. Mehta, K. R. Varshney, K. N. Ramamurthy, and D. Wei. “An End-To-End Machine Learning Pipeline That Ensures Fairness Policies,” Data for Good Exchange Conference, New York, NY, September 2017.
",,Company,gray,crossword puzzle, , , 
https://ibm.co/2BVNJaF,187446750783_10155586804570784,https://www.facebook.com/ibmwatson/posts/10155586804570784,"How is AI being used to resolve real-world problems? Read the story on how Identity Guard, a business designed to protect consumer identities online, is implementing Watson Natural Language Processing to identify instances of cyberbullying to create a safer online environment for kids. ",Link,,,4/30/18 9:21, ,7387,7387,0,10043,10043,0,97,58,75,3,3,8323,6039,0,0,85,0,0,0,0,0,0,0,0,0,0,14,49.0,,14,50.0,,37,25.0,,,48,27.0,,,2,1.0,,2,1.0,,Identity Guard’s cyberbullying features monitor the social media feeds to which both parents and children have given it access.,https://www.ibm.com/blogs/client-voices/wp-content/uploads/2018/02/Meier-tile.jpg,https://www.ibm.com/blogs/client-voices/ai-technology-protect-teens-cyberbullying/,joy,0.330245,positive,0.770353,"Identity Guard, consumer identities, Watson Natural Language",Person,Identity Guard,Person,anger,0.293396,neutral,0,"Identity Guard, social media feeds",,Identity Guard,,joy,0.594566,positive,0.289397,,"Organization, Quantity, Organization, Person, Company, Quantity","An astonishing 87% of youth have witnessed cyberbullying. In 2017 alone, over 13 million American children were bullied or cyberbullied.
For me, the struggle against bullying and cyberbullying is a personal one. In October of 2006, my 13-year-old daughter Megan took her own life as a result of cyberbullying. Committed to helping prevent similar tragedies, I founded the Megan Meier Foundation, a non-profit dedicated to supporting and inspiring actions to end bullying and cyberbullying.
Since its inception in December 2007, our Foundation has reached over 305,000 students, parents, and educators in 270 communities and 38 states. By spreading Megan’s story and educating others on internet safety and the consequences of bullying and cyberbullying, I hope to end these occurrences, helping one child at a time cope with these negative social issues.
In 2016, Identity Guard began consulting with our Foundation and other cyberbullying experts to build an effective solution that protects children and teens without invading their privacy. Using the power of artificial intelligence, Identity Guard’s cyberbullying features monitor the social media feeds to which both parents and children have given it access.
With IBM Watson technologies that enable natural language processing (NLP) and natural language classifiers (NLC), the solution is able to understand and categorize what individuals are sending and receiving. Complex algorithms then identify instances, or potential instances, of cyberbullying or self-harm. If a threat is identified, it triggers an alert that is sent parents.
Within the alert are screenshots that include the dates and times of what caused the warning. If parents agree that this is an instance of cyberbullying or potential self-harm, they are guided to a suite of free resources—including guidance on state laws and school policies—to help them figure out how to respond.
Parents are also directed to my Foundation, where, at no charge, they can talk to an individual to air their concerns, review a checklist of actions, and take a breath before they respond—ensuring that they act from an informed position rather than a state of panic.
Given the proliferation of mobile devices and social media, parents often feel overwhelmed when it comes to their kids engaging online. We’ve worked hard with Identity Guard to create a solution that provides a safe means of engagement. Children and teens can participate in social media with their privacy intact; with parents receiving alerts only if issues are identified.
For the past decade, my Foundation has focused on listening to parents, kids and educators to help them getter a better idea of how to respond, and what actions can be done to help curb bullying and cyberbullying threats.
With this experience and knowledge, we’ve created resources that better equip parents so they can start a dialog with their kids about bullying, cyberbullying and suicide. We focus on helping both parent and child realize that they can address these issues together, as they both learn about what each can do to respond.
Technology isn’t bad; rather it’s how we use it. Social media can be scary for parents as their kids begin to get online, but our Foundation is working with Identity Guard to help parents be knowledgeable and stay informed, while enabling kids to stay safely engaged.
I dream of a world where bullying and cyberbullying no longer exist, for I know firsthand of the possible devastating consequences. I believe that through empowering our society to celebrate individuality and the acceptance of others, we can work together to make a difference and create a safer and kinder world. Identity Guard’s cyberbullying features are a helpful first step in this direction.
",,Organization,coal black,reader,person,scholar,reader
https://ibm.co/2KnH22N,187446750783_10155585498770784,https://www.facebook.com/ibmwatson/posts/10155585498770784,&quot;AI is changing the world by transforming how we work. AI systems have the power to learn at incredibly fast rates —continuously sharpening their skills. They are good at what they do: processing information at a blazingly fast rate. But they don’t reason like we do. We’re creative and capable of real thought. They are there to help us to do what we do best.&quot; Read more about Anamita Guha's experience working on the IBM Watson team and her ambitious side hustle project launching the Bot Asset Exchange community. ,Link,,,4/29/18 17:15, ,8848,8848,0,12285,12285,0,199,147,194,6,6,10602,7628,0,0,171,0,0,0,0,0,0,0,0,0,0,21,61.0,4.0,24,63.0,4.0,97,56.0,,,132,62.0,,,5,1.0,,5,1.0,,"Anamita Guhagrew launched Bot Asset Exchange, a community driven hub for enterprise bot developers to share and build bots powered by IBM Watson Assistant.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/04/blog_execWatson_socialTile_042418.jpg,https://www.ibm.com/blogs/watson/2018/04/decoding-the-brain-aiding-developers-with-watson/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Watson+Women+Blog&cm_mmca1=000000OF&cm_mmca2=10000409,joy,0.6366,positive,0.614441,"Anamita Guha's experience, IBM Watson team","Person, Person",Anamita Guha's experience,Person,sadness,0.169159,neutral,0,"Anamita Guhagrew, Bot Asset Exchange",Company,Anamita Guhagrew,Company,joy,0.624695,positive,0.77211,,"Person, Person, Person, Company, Company, Person","Anamita Guha grew up surrounded by coders and IPOs in the way other kids’ childhoods were filled with trips to the mall or little league. Growing up in San Francisco, where both her parents helped build the Valley we know today, Anamita developed, almost intrinsically, an understanding of the power technology has to connect people and change the world.
And by an early age –we’re talking four years old –Anamita was up and running on her own computer. At nine, she started designing websites as a side-hustle. Out of this early digital relationship and the exposure she received to a diversity of people and ideas in Silicon Valley, Anamita became increasingly intrigued by people –and how they process information, become motivated by their beliefs and ultimately make decisions.
Now at IBM Watson, Anamita has combined her aptitude for technology —along with her passion for understanding the human mind —to create the tools developers rely on to change the world with Watson. We chat with her about her unique background, path in the Valley and how she sees AI changing the world, one decision at a time.
How did you become interested in the human mind, and ultimately AI?
Technology has always fascinated me, but not for what it does –instead, for what it inspires us to do. Growing up in Silicon Valley, I learned at a pretty early age that just by giving people better access to information, it significantly opens our perspective and decision-making capabilities. This process of information to output was so fascinating to me that I actually chose a cognitive science major. I wanted to know: how does the brain work? How do we think about things? And, as interesting as those classes were, I quickly found that what I was really after was a better understanding of human cognition. So, in college, I started shifting my focus to classes in AI, machine learning and computational models of the mind.
What I learned was that these technologies, which were new and growing rapidly at the time, had the potential to extend the possibilities of what humans are capable of –in a way like we’ve never seen before. To me, AI was the next revolution of information. Much like the dot-com era expanded our access to information, and each other –AI will amplify this even further and extend human possibilities in revolutionary new ways. I just kept thinking how exciting it would to be to layer the human brain’s ability to process information, instinct and insight with the capabilities of an AI system. Combined, it’s the ultimate decision-making machine–doctors, lawyers, my barista even –will have better access to more complete and broader information, giving us the ability to make decisions with more confidence, and even greater outcomes.
What’s one example of when you saw the potential AI has to redefine human cognition?
In June 2017, I spearheaded a really exciting a side project at IBM. We launched something called the Bot Asset Exchange, which is a community driven hub for enterprise bot developers to share and build bots powered by IBM Watson Assistant. Since this was a side project, we needed to recruit various people within IBM –it became almost like a scavenger hunt in terms of putting all of the pieces together, but the outcome was hugely impactful.
The platform launched with more than 120 conversational interfaces in various categories and was easy to learn. This tool now provides more ways for developers to communicate directly with one another, so they can discuss bots they are working on and ones that might be added soon. The Bot Asset Exchange also makes it possible for these developers to quickly deploy the backend logic necessary to create conversational interfaces for multiple enterprise and consumer –like chatbots for popular messaging apps or voice apps – to more critical dialogs, like legal and government bots.
What do you think AI’s largest impact on the world will be?
AI is changing the world by transforming how we work. AI systems have the power to learn at incredibly fast rates —continuously sharpening their skills. They are good at what they do: processing information at a blazingly fast rate. But they don’t reason like we do. We’re creative and capable of real thought. They are there to help us to do what we do best.
As businesses transform, I think AI will trend toward personalization. By that, I mean users will perceive the AI systems they are interacting with as being made just for them. We’re already seeing this happen. For example, IBM Watson is helping leading European bank Crédit Mutuel’s 20,000 customer advisors maximize their time. Watson can help them handle the routine queries, giving each customer a personalized approach while giving them more time to meet the needs of customers with more complex needs. I think this kind of personalization means improved service —each customer comes away feeling valued, and like the world has almost personalized just for them.
Click here for more information on Bot Asset Exchange and be sure to follow Anamita on Twitter.
",,Person,coal black,person,person,female,woman
,187446750783_10155582607640784,https://www.facebook.com/ibmwatson/posts/10155582607640784,"The ability of AI to think, learn, interpret and reason is why many organisations are using systems like Watson as virtual agents to liaise with both customers and employees, and help them solve problems or get answers to questions much faster via Mashable",Link,,,4/28/18 9:57, ,16515,16515,0,23173,23173,0,534,330,399,9,9,16437,11831,0,0,428,0,0,0,0,0,0,0,0,0,0,56,241.0,3.0,59,245.0,4.0,160,201.0,,,184,215.0,,,7,2.0,,7,2.0,,,,,joy,0.325831,positive,0.776214,virtual agents,"Person, Person",virtual agents,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2vY54hs,187446750783_10155580700190784,https://www.facebook.com/ibmwatson/posts/10155580700190784,Did you know? The IBM Watson Unity SDK is the first of its kind to bring scalable artificial intelligence services to Unity. That means taking gaming to a whole other level – think virtual and augmented reality in your games. Learn more: ,Link,,,4/27/18 9:50, ,6790,6790,0,9669,9669,0,97,49,55,5,5,8334,5899,0,0,90,0,0,0,0,0,0,0,0,0,0,14,56.0,2.0,14,58.0,2.0,23,26.0,,,25,30.0,,,2,3.0,,2,3.0,,"IBM and Unity are launching the IBM Watson SDK for Unity on the Unity Asset Store, enabling developers to easily integrate Watson cloud services into their...",https://blogs.unity3d.com/wp-content/uploads/2018/02/image2-1.png,https://blogs.unity3d.com/2018/02/20/bringing-the-power-of-ai-to-developers-with-the-ibm-watson-unity-sdk/?_ga=2.89714651.1383049552.1519136253-1097373577.1519136253,anger,0.137791,positive,0.819462,"IBM Watson Unity SDK, scalable artificial intelligence services",Company,IBM Watson Unity SDK,Company,joy,0.056467,neutral,0,"IBM Watson SDK, Unity, IBM, Unity Asset Store",Company,IBM Watson SDK,Company,joy,0.537902,positive,0.856387,IBM Watson SDK,"Company, Person, Person","IBM and Unity are launching the IBM Watson SDK for Unity on the Unity Asset Store, enabling developers to easily integrate Watson cloud services into their Unity applications such as visual recognition, speech to text, and language classification. The SDK makes it easy for developers to take advantage of modern AI techniques through a set of cloud-based services.
Today we are thrilled to announce a partnership with IBM to launch the IBM Watson SDK for Unity on the Unity Asset Store. This SDK is the first asset of its kind to bring scalable AI services to Unity, enabling developers to easily integrate Watson services into their Unity applications. Millions of Unity developers globally will now have access to the powerful cloud-based AI services of Watson directly within the Unity environment.
Although AR and VR are continuously being applied to the gaming industry to immerse players in virtual environments like galaxies or with geolocation environments where the activity happens on real surroundings, we are now experiencing the advancement of applying these concepts into business use cases. With VR, companies can implement employee training programs that teach workers how to perform a job in a virtual environment without any safety risks, and with AR, field workers can hold up their phone or glasses to a pipe to see if it needs to be fixed, when, and where.
As AR and VR technologies mature, there is increasing interest coming from the enterprise market for innovative applications in marketing, design, engineering, manufacturing and analysis. Unity is the market leader in AR and VR for consumer use cases, as well as rapidly emerging as the market leader for enterprise AR and VR.
With its deep AI expertise and industry knowledge, IBM also has been actively exploring the application of AR and VR with clients such as the Immersive Insights demo, which hints at the enormous potential of AR and VR in enterprise applications. Together, Unity and IBM plan to help drive the development of this market by enabling applications that bring contextual expertise and AI capabilities directly into the employee and/or end consumer’s personal and professional sphere of experience.
This partnership exemplifies IBM and Unity’s commitment to accelerating the enterprise developer journey and equipping them with the tools and resources they need to build powerful new AR and VR apps. As an official platinum sponsor for INDEX Conference, the open developer community event, we’re excited to collaborate with IBM to empower the Unity community with powerful AI-driven cloud services to help expand a new frontier of interactivity. The first step of this journey begins with the IBM Watson SDK for Unity.
With the SDK now available on the Asset Store, Unity developers can now configure games and projects to understand speech, talk with users, and understand the intent of a user in natural language.
One of the key features of the SDK is its powerful speech recognition capabilities. With speech services, developers have access to real-time speech recognition providing highly accurate speech recognition directly in your Unity project. Player speech can be recognized and used to trigger in-game events.IBM Watson SDK for Unity also has powerful language translation and language classification capabilities. In conjunction, both language classification and speech recognition can work together seamlessly to provide voice-driven interactivity in your Unity game.
Watch an example of how IBM teamed up with Ubisoft to give players of Star Trek Bridge Crew the ability to issue commands to NPC’s with just their voice using theIBM Watson SDK for Unity.
For developers interested in the power of AI-driven visual recognition, Watson’s Vision API provides the ability for developers to integrate real-time visual recognition within their Unity projects.Take a look at how a team of developers took advantage of theIBM Watson SDK for Unity during an IBM-sponsored Hackathon to create Watson and Waffles, a VR adventure game which requires the player to sketch game objects using the Vive controller. Using the Vision API, Watson identifies user drawings and generates corresponding 3D objects for the player to use.
For more details about the Watson capabilities available within the IBM Watson SDK for Unity you can leverage to get started, please visit: https://www.ibm.com/watson/products-services/
The SDK is simple to set up and can open up your project to new levels of interactivity. Imagine a game with NPC’s powered with visual recognition technology that recognize in-game objects or even a virtual reality experience with interactions driven completely with voice commands.
Receiving access to the IBM Watson SDK for Unity is easy – simply head over to the Asset Store and download the SDK here.
You also can familiarize yourself with this short video series from IBM, which provides an overview of all of the core features of the IBM Watson SDK for Unity..
Visit the Asset Store and download the IBM Watson SDK for Unity today!
We’ve rounded up some key resources to help you get started with the IBM Watson Unity SDK:
",IBM Watson SDK,Company,black,asterism (cluster of stars),nature,asterism (cluster of stars),-
https://ibm.co/2AGsoNR,187446750783_10155578585660784,https://www.facebook.com/ibmwatson/posts/10155578585660784,IBM and Massachusetts Institute of Technology (MIT) are working on a project that can progress AI to interpret what is happening in a video. ,Link,,,4/26/18 8:45, ,9152,9152,0,12480,12480,0,241,144,158,5,5,9617,7052,0,0,201,0,0,0,0,0,0,0,0,0,0,26,111.0,1.0,26,113.0,1.0,44,104.0,,,53,105.0,,,1,4.0,,1,4.0,,Perceiving dynamic actions could be a huge advance in how software makes sense of the world.,https://cdn.technologyreview.com/i/images/videosteachingmachines.png?cx=0&cy=43&cw=4085&ch=2297&sw1200,https://www.technologyreview.com/s/609651/the-next-big-step-for-ai-understanding-video/,joy,0.306418,neutral,0,"Massachusetts Institute of Technology, IBM","Organization, Company, Organization, Person",Massachusetts Institute of Technology,Organization,joy,0.463746,positive,0.725191,"dynamic actions, huge advance",,dynamic actions,,joy,0.60903,positive,0.721154,vast data set of video clips,"Quantity, Organization, Person, Company, Quantity, Person, Company, Company","For a computer, recognizing a cat or a duck in a still image is pretty clever. But a stiffer test for artificial intelligence will be understanding when the cat is riding a Roomba and chasing the duck around a kitchen. 
MIT and IBM this week released a vast data set of video clips painstakingly annotated with details of the action being carried out. The Moments in Time Dataset includes three-second snippets of everything from fishing to break-dancing. 
“A lot of things in the world change from one second to the next,” says Aude Oliva, a principal research scientist at MIT and one of the people behind the project. “If you want to understand why something is happening, motion gives you lot of information that you cannot capture in a single frame.” 
The current boom in artificial intelligence was sparked, in part, by success in teaching computers to recognize the contents of static images by training deep neural networks on large labeled data sets (see “The Revolutionary Technique That Quietly Changed Machine Vision Forever”). 
AI systems that interpret video today, including the systems found in some self-driving cars, often rely on identifying objects in static frames rather than interpreting actions. On Monday Google launched a tool capable of recognizing the objects in video as part of its Cloud Platform, a service that already includes AI tools for processing image, audio, and text. 
The next challenge may be teaching machines to understand not just what a video contains, but what’s happening in the footage as well. That could have some practical benefits, perhaps leading to powerful new ways of searching, annotating, and mining video footage. It also figures to give robots or self-driving cars a better understanding of how the world around them is unfolding. 
The MIT-IBM project is in fact just one of several video data sets designed to spur progress in training machines to understand actions in the physical world. Last year, for example, Google released a set of eight million tagged YouTube videos called YouTube-8M. Facebook is developing an annotated data set of video actions called the Scenes, Actions, and Objects set. 
Olga Russakovsky, an assistant professor at Princeton University who specializes in computer vision, says it has proved difficult to develop useful video data sets because they require more storage and computing power than still images do. “I’m excited to play with this new data,” she says. “I think the three-second length is great—it provides temporal context while keeping the storage and computation requirements low.” 
Others are taking a more creative approach. Twenty Billion Neurons, a startup based in Toronto and Berlin, created a custom data set by paying crowdsourced workers to perform simple tasks. One of the company’s cofounders, Roland Memisevic, says it also uses a neural network designed specifically to process temporal vision information. 
“Networks trained on the other data sets can tell you whether the video shows a soccer match or a party,” he says. “Our networks can tell you whether someone just entered the room.” 
Danny Gutfreund, a researcher at IBM who collaborated on the project, says recognizing actions effectively will require that machines learn about, say, a person taking an action and transfer this knowledge to a case where, say, an animal is performing the same action. Progress in this area, known as transfer learning, will be important for the future of AI. “Let’s see how machines can do this transfer learning, this analogy, that we do very well,” he says. 
Gutfreund adds that the technology could have practical applications. “You could use it for elder care, telling if someone has fallen or if they have taken their medicine,” he says. “You can think of devices that help blind people.” 
",vast data set of video clips,Quantity,sea green,golden hamster,animal,mammal,rodent
https://ibm.co/2qYcHzz,187446750783_10155577242680784,https://www.facebook.com/ibmwatson/posts/10155577242680784,How an IBM Watson developer worked with hip-hop producer Alex Da Kid to find the perfect artist for his next collaboration using AI: ,Link,,,4/25/18 14:47, ,7017,7017,0,9970,9970,0,98,59,75,3,3,8580,6126,0,0,84,0,0,0,0,0,0,0,0,0,0,15,47.0,,15,47.0,,36,26.0,,,48,27.0,,,2,1.0,,2,1.0,,Can AI help a multi-platinum music producer discover the perfect artist for his collaboration? Watch and see as IBM embarks on an exciting and unprecedented ...,https://i.ytimg.com/vi/v784VnyNCNU/maxresdefault.jpg,https://www.youtube.com/watch?v=v784VnyNCNU&feature=youtu.be,joy,0.327472,neutral,0,IBM Watson developer,"Person, Company",IBM Watson developer,Person,joy,0.761468,positive,0.915307,multi-platinum music producer,"Person, Company",multi-platinum music producer,Person,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                                                                                                                                                          
            

",YouTube,Company,blue,people,person,people,-
https://ibm.co/2GhZPhy,187446750783_10155572838965784,https://www.facebook.com/ibmwatson/posts/10155572838965784,"Ever wished for a one-stop shop when it comes to getting questions answered by your bank? Australia-based UBank created a solution: an AI-powered bot that improved response time for more than 400,000 Australian customers. Learn more about RoboBrain: ",Link,,,4/23/18 10:28, ,8493,8493,0,11840,11840,0,161,89,104,6,6,9925,7038,0,0,131,0,0,0,0,0,0,0,0,0,0,24,76.0,2.0,26,77.0,2.0,44,46.0,,,54,50.0,,,4,2.0,,4,2.0,,"Customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank",https://d1902livswy8rb.cloudfront.net/dimg/800x800/dimg/dreamstime_s_34490308-2.jpg,https://www.cmo.com.au/article/635526/ubank-ai-vision-expands-rollout-robobrain/,joy,0.529701,positive,0.436218,"one-stop shop, response time","Company, Location",one-stop shop,Company,joy,0.124299,positive,0.566024,"IBM Watson capabilities, one-stop, one-screen solution, solution","Person, Company",IBM Watson capabilities,Person,joy,0.57428,positive,0.701942,launch of RoboBrain,"Person, Company, Person, Person, Company, Person, Company, Location","UBank’s CMO says the launch of RoboBrain, a hyper-personalised cognitive assistant, is dramatically improving customer response times and a massive leap forward in the bank’s AI journey.   
The digital-only banking group took its first steps into AI last year with the launch of RoboChat, a chatbot designed to help customers through the home loan application process. In less than 12 months, RoboChat has been asked more than 22,000 questions, with over 80 per cent answered correctly on the first attempt.   
“After the success of RoboChat, we wanted to find a solution that our people could use and benefit from directly,” UBank CMO, Jo Kelly, told CMO. 
This led to RoboBrain, designed and developed by UBank’s North Sydney-based team in collaboration with IBM. The customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank.   
In the past, the UBank team had to move between a handful of different platforms in order to find the answer to customer questions, Kelly explained. Consolidating a number of the bank’s knowledge bases, RoboBrain provides immediate information for employees in one spot.   
“Now, thanks to RoboBrain, we’ve got a one-stop portal of information where we can search information and find the answer almost instantly,” she said.     
By typing in a question in natural language, the UBank team on the phone or on LiveChat can find answers in approximately two seconds to thousands of questions asked by customers, such as “what was the interest rate in June 2011?” or “how do I set up a regular transfer?”.    
Kelly said RoboBrain improves on the overall customer experience by making interactions as convenient as possible.    
“Customers don’t want to spend their time talking to their bank, so when they get in touch with us over LiveChat, Secure Mail, Facebook or on the phone, we need to meet their expectations and help them as quickly as we can,” she said.   
Since going live, RoboBrain has sped up processes for more than 40 per cent of UBank’s 200 employees, and improved response time for more than 400,000 Australian customers, cutting down search time by 33 per cent.   
For Kelly, AI is a major focus area - and a key to marketing success - at the digital bank.   
“We see AI as a key enabler in disrupting the home loan market and changing the end to end process of buying a home from applying to approval and then settlement. We believe it’s important to embrace technologies to adapt to the ever-increasing expectations of our customers and create a more personalised experience,” she said.   
Asked what’s next in terms of AI, Kelly said UBank flagged more innovation around customer service. RoboBrain has been trained to display and share complex information in real-time, and like any AI-based solution, the more it’s used, the smarter it gets, she noted.   
RoboBrain will learn and improve by adapting to the search terms used, based on the rating applied, and through ongoing training by UBank experts.   
",launch of RoboBrain,Person,blue,liquid metal reactor,apparatus,nuclear reactor,liquid metal reactor
https://ibm.co/2FafMBI,187446750783_10155570662835784,https://www.facebook.com/ibmwatson/posts/10155570662835784,"&quot;The journey for adopting AI and delivering that for value to clients begins with one very basic proposition, which is, is the AI going to augment and amplify the intelligence of the people using it? Because if it's not doing that, it's probably not going to be very useful.&quot; – Watson VP, CTO Rob High in an interview with TechCrunch: ",Link,,,4/22/18 9:20, ,10187,10187,0,14117,14117,0,181,106,121,5,5,11397,8246,0,0,149,0,0,0,0,0,0,0,0,0,0,30,82.0,1.0,30,82.0,2.0,43,63.0,,,52,69.0,,,2,3.0,,2,3.0,,"TechRepublic spoke to IBM's Rob High about the ethical, privacy, and security obstacles that artificial intelligence has to overcome.",https://tr1.cbsistatic.com/hub/i/r/2018/03/01/005c45e1-7e9b-43df-9012-57f7ee9fa3bc/thumbnail/770x578/ea8d0af3f9eb1dfda64080cabc7cdc79/big-booths-mwc-2016-12.jpg,https://www.techrepublic.com/article/ibm-watson-cto-the-3-ethical-principles-ai-needs-to-embrace/,joy,0.252504,positive,0.416788,basic proposition,"Person, Person",basic proposition,Person,fear,0.228087,negative,-0.589837,"IBM's Rob High, artificial intelligence","Person, Company",IBM's Rob High,Person,joy,0.60699,positive,0.646511,,"Person, Person, Company, Organization","IBM Watson CTO Rob High has done a lot of thinking about the privacy, security, and ethical implications of artificial intelligence. He presented some of those ideas at Mobile World Congress 2018, and we talked to him about some of his key findings.
You can watch the interview above or read the transcript below.  
High said, ""One of the things we have to realize about AI--it's relatively new to all of us. There's a lot about it that we don't all fully understand. Even as a technologist, we know where we're trying to bring the technology, but on the other side there's lots of people for which this technology is new. The experiences around that are going to be different. As with any new technology, it's really important that we be thinking now about how we do that ethically and responsibly. For us, that comes down to three basic principles. Trust, respect, and privacy.
""What that basically means is that when you're using an AI technology, you have to trust that it's going to be doing the right thing. Or you focus on things like, can we create transparency in the AI algorithms? Can we get the algorithms to actually identify your level of confidence (in them), for example.""
SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
""Transparency comes down to can we identify what sources of information are being used? Have we established the right properties, the right principles in place when we train these systems to use data that is representative of who we are, and the information that we're using?"" said High.
""Of course, privacy comes down to recognizing that your data is our data. It should be your choice as to what data you're going to provide in order to gain the benefits these AIs offer. That goes from everything from the privacy of enterprise data, and the data that enterprises bring to the table when they use AIs, maintain separation between each of the enterprises all the way through, to how those enterprises protect the privacy of the data of their clients.""
High added, ""The journey for adopting AI and delivering that for value to clients begins with one very basic proposition, which is, is the AI going to augment and amplify the intelligence of the people using it? Because if it's not doing that, it's probably not going to be very useful. You're going to lose this utility very quickly. First of all, identify what that is. How do you help people do what they do better?
SEE: How to implement AI and machine learning (ZDNet special feature) | Download the report as a PDF (TechRepublic)
""If you get that out of the way then you can begin to look at how to apply the technology, but all through that we really encourage our clients to think about two things. One is, how they're going to protect and preserve the privacy of their institutions, of their clients. But also how do they convey the responsibility of their clients to be aware of what data they're getting across and to challenge those cases where, perhaps they don't want to give up the data they're offering. Or at least to make sure the value they're getting from that data is also very supportive of this idea that's augmented their intelligence.""
",,Person,purplish blue,air terminal, , , 
https://ibm.co/2HQo7eM,187446750783_10155568192115784,https://www.facebook.com/ibmwatson/posts/10155568192115784,"&quot;Deep-Learning-as-a-Service, unveiled at IBM’s annual IT industry conference in Las Vegas, seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power,&quot; via The Wall Street Journal: ",Link,,,4/21/18 8:11, ,11519,11519,0,15681,15681,0,310,190,218,4,4,13373,9693,0,0,267,0,0,0,0,0,0,0,0,0,0,29,147.0,2.0,29,147.0,2.0,74,124.0,,,90,128.0,,,2,2.0,,2,2.0,,"Deep-Learning-as-a-Service, unveiled Tuesday in Las Vegas, aims at easing the complex process of creating deep-learning algorithms for business data, the company said.",//si.wsj.net/public/resources/images/BN-XY012_0320_c_P_20180320173444.jpg,https://blogs.wsj.com/cio/2018/03/20/ibm-tool-seeks-to-bridge-ai-skills-gap/,joy,0.313567,positive,0.521166,"Deep-Learning, IBM’s annual IT industry conference, large amounts","Company, Location",Deep-Learning,Company,joy,0.525414,positive,0.928478,"Deep-Learning, complex process, Las Vegas, a-Service",Location,Deep-Learning,Location,joy,0.473438,positive,0.702652,,"Company, Company, Person, Person, Person, Location","Deep-Learning-as-a-Service, unveiled at IBM’s annual IT industry conference in Las Vegas, seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power, the company said.
The new service allows companies to upload data in Watson Studio, IBM’s cloud-native platform for data scientists, developers and business analysts. There, they can create deep-learning algorithms for datasets – known in AI parlance as a “neural network” – using a drag-and-drop interface to select, configure, design and code the network.
IBM also has automated the repetitive process of fine-tuning deep-learning algorithms, with successive training runs started, monitored and stopped automatically.
For many firms, the complexity of creating smart algorithms from scratch has kept them from leveraging AI to parse massive stores of data for business value, the company said.
Ginni Rometty, IBM’s chairman and chief executive, called data the “basis for competitive advantage,” in her opening remarks at Tuesday’s event.
In today’s cloud-powered markets, she said, businesses need to leverage multiple digital platforms, while embedding smart tools into every process they run. “You’ve got to keep making AI easier to use,” she added.
In a recent Gartner survey, chief information officers ranked AI, along with digital security and the Internet of Things, as the hardest technologies to implement, citing hard-to-find skills required to make them work. The survey included more than 3,000 CIOs across all major industries.
Werner Goertz, a Gartner research director, said skills, expertise and staff around AI “remain in incredibly short supply, and whatever talent is out there is quickly absorbed by the big players.”
“There is an enormous gap” between the available capabilities and the skills required to make them work, Ben Fried, CIO of Google Inc. said earlier this month at WSJ CIO Network’s annual meeting in San Francisco.
Google in January launched Cloud AutoML, a similar AI tool designed to help developers automatically build and train deep-learning models. Google Cloud also offers pre-trained models.
Microsoft Corp., Salesforce.com Inc., Oracle Corp. and other cloud providers have added AI and machine learning capabilities into many of their cloud-based enterprise tools and services.
For IBM, and other tech giants, cloud computing and related services, such as AI, have been a boon. In January, the company reported a 3.6% increase in fourth-quarter revenue to $22.54 billion -- its first quarterly revenue gain since 2012 -- driven in part by a 30% increase in cloud-computing revenue to $5.5 billion, the company said.
",,Company, , , , , 
http://ibm.co/2o1FXp6,187446750783_10155566463960784,https://www.facebook.com/ibmwatson/posts/10155566463960784,"When it comes to learning new skills, there's no time like the present. How one IBMer learned how to code: ",Link,,,4/20/18 9:15, ,7144,7144,0,9779,9779,0,229,172,209,4,4,8605,6275,0,0,207,0,0,0,0,0,0,0,0,0,0,18,69.0,1.0,19,69.0,2.0,50,133.0,,,66,143.0,,,1,3.0,,1,3.0,,"When I was studying political science in college, I had no intention of going into the field of technology. I had friends in STEM, but I was sure I either wanted to pursue a career in politics or business. However, when I saw an opportunity to enter a rotational program at IBM Watson starting in the summer of 2014, I knew I had to pursue it. I got the job and rotated through the sales and marketing departments, where I began learning more about AI technology. As I talked to developers both inside and outside of the company, I found myself wanting to learn how to code with the Watson API’s and create a new product or app. They gave me advice on how to start, but the thought of committing hours of my time to learning a new skill seemed daunting. In the summer of 2016, I mentored a high school student on starting a career…",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/03/Learn-to-Code_Hero.jpg,https://www.ibm.com/blogs/watson/2017/03/im-finally-learning-code/,joy,0.526168,positive,0.796067,new skills,,new skills,,sadness,0.51308,positive,0.49453,,"Person, Company, Person",,Person,joy,0.632418,positive,0.716372,,"Company, Company, Person, Company, Person, Organization, Person, Company, Quantity, Location","When I was studying political science in college, I had no intention of going into the field of technology. I had friends in STEM, but I was sure I either wanted to pursue a career in politics or business. However, when I saw an opportunity to enter a rotational program at IBM Watson starting in the summer of 2014, I knew I had to pursue it. I got the job and rotated through the sales and marketing departments, where I began learning more about AI technology.
As I talked to developers both inside and outside of the company, I found myself wanting to learn how to code with the Watson API’s and create a new product or app. They gave me advice on how to start, but the thought of committing hours of my time to learning a new skill seemed daunting. In the summer of 2016, I mentored a high school student on starting a career in STEM through the program Girls Who Code and I was very impressed with the girls’ ability to create an app in just a few weeks. They inspired me to take a free HTML Codecademy course, which acquainted me with programming, however I barely kept up with my novice skills.
In my day job today as an offering manager for IBM Digital, I work on a website called the IBM Learning Lab, which offers interactive courses and real-world use cases on emerging tech to help professionals gain new skills. Use cases include everything from building a chatbot in 20 minutes to creating your very own Harry Potter sorting hat. The website also features courses from partners such as General Assembly – a company that trains employees and individuals around the world in coding, data science, design, marketing and product management.
I decided it was time to practice what I preach, dive into the coding deep end, and take one of General Assembly’s immersive coding courses. I’m going to skill-up, learn the language of the 21st century, and hopefully begin a journey of learning different programming languages.
So, I recently began General Assembly’s HTML, CSS, and Web Design course with the intention of building a website that chronicles free workout opportunities in NYC. In addition, I am going to build a chat bot with Watson’s Conversation API so you can ask it questions like “What are free yoga classes in NYC,” or “What free workout classes are happening at 6:30 PM in Brooklyn?” I look to highlight the great people and organizations that offer free workout opportunities for New Yorkers.
I’m both excited and nervous to begin this journey of learning how to code. Since this is something I’ve wanted to pursue for almost 2 years now, I am treading optimistically that I will enjoy programming and continue to learn new languages once this course is over.
This is part 1 of a 2 part-series. In the next post, I will chronicle my 10-week coding experience – including all of the ups and downs that occur when learning new skills.
",,Company,purple,limiter (electronics),electrical device,limiter (electronics),-
https://ibm.co/2JYSyS7,187446750783_10155564527505784,https://www.facebook.com/ibmwatson/posts/10155564527505784,Do you consider yourself helpful and analytical? Are you the type to volunteer for social causes? Watson Personality Insights applies linguistic analytics to your Twitter or blog to analyze your personal traits. Try it out: ,Link,,,4/19/18 10:24, ,6862,6862,0,9057,9057,0,104,65,94,3,3,7933,5967,0,0,90,0,0,0,0,0,0,0,0,0,0,18,47.0,1.0,20,47.0,1.0,33,34.0,,,55,39.0,,,,3.0,,,3.0,,"Predict personality characteristics, needs and values through written text.",,https://www.ibm.com/watson/services/personality-insights/,anger,0.136174,neutral,0,"Watson Personality Insights, social causes","Person, Company",Watson Personality Insights,Person,sadness,0.220109,neutral,0,personality characteristics,,personality characteristics,,joy,0.147804,positive,0.768909,social media measurement platform,"Company, Company, Company","                         Predict personality characteristics, needs and values through written text. Understand your customers’ habits and preferences on an individual level, and at scale.                     
                                                     Use linguistic analytics to infer individuals' personality characteristics, including Big Five, Needs, and Values, from digital communications such as email, blogs, tweets, and forum posts.                                                 
                                                     Look at a users inclination to pursue different products, services, and activities, including shopping, music, movies, and more.                                                 
                                                     Understand individual customers for segmentation, personalized product recommendations, and highly targeted messaging.                                                 
                                                             Powering a social media measurement platform with IBM Cloud and cognitive technology.                                                         
                                                           A social marketing company enables businesses to gain clear insight toward customer affinities in real time when it integrates its platform with IBM Watson technology.                                                         
                                                           Reinventing social influencer marketing with AI from IBM Watson.                                                         
                                                     Watson Premium plans offer a higher level of security and isolation to help customers with sensitive data requirements.                                                 
",social media measurement platform,Company, , , , , 
https://ibm.co/2EvwDhZ,187446750783_10155562749155784,https://www.facebook.com/ibmwatson/posts/10155562749155784,"&quot;There are a lot of chatbots out there today that operate on what we call a single-turn exchange... but when somebody asks &quot;what's my account balance?&quot; they may need to know what their account balance is, but that's really not their problem. Their problem is that they're getting ready to buy something or they're trying to figure out how to save up for their kid's education or they're trying to figure out how to pay their bills – there's something behind the question.&quot; – IBM Watson CTO Rob High on the differences between conversational agents. ",Link,,,4/18/18 12:18, ,6769,6769,0,9088,9088,0,173,116,142,3,3,7838,5747,0,0,139,0,0,0,0,0,0,0,0,0,0,16,63.0,,17,66.0,,78,52.0,,,88,54.0,,,1,2.0,,1,2.0,,Find out the key differences between chatbots vs. virtual assistants vs. conversational agents from IBM Watson VP and CTO Rob High.,https://cdn.ttgtmedia.com/visuals/German/article/chatbot-2-fotolia.jpg,https://searchcio.techtarget.com/feature/Comparing-chatbots-vs-virtual-assistants-vs-conversational-agents,fear,0.360787,negative,-0.859924,"account balance, kid's education","Person, Company",account balance,Person,joy,0.040039,neutral,0,key differences,"Company, Person",key differences,Company,joy,0.524255,positive,0.613699,conversational agent,"Person, Company, Company","interchangeably, but do those terms really describe the same thing? Not according to Rob High, vice president and CTO at IBM Watson and an IBM Fellow.
In this Q&A, High explains the subtle but distinct differences between those three conversation-based technology terms and the intent behind them. One rule of thumb: The extent to which these technologies engage the user is key to understanding their differences.
What are the differences between terms like chatbot, conversational agent, virtual assistant, etc.?
Rob High: All those terms are used kind of loosely. There are lots of examples in which the terms have been used interchangeably. At IBM, we tend to think of these things somewhat distinctively, and it largely has to do with the degree to which they engage the end user in solving the problem.
   Rob High  
A simple example of this is that there are a lot of chatbots out there today that operate on what we call a single-turn exchange. Somebody says something like 'Alexa, turn on the lights' or 'OK, Google, what's the tallest mountain in the world?' Those are independent, single-turn exchanges. The end user expresses an utterance, the utterance is interpreted or recognized for its intent, and then that intent is mapped onto a specific task.
That's all good, but when somebody asks 'what's my account balance?' they may need to know what their account balance is, but that's really not their problem. Their problem is that they're getting ready to buy something or they're trying to figure out how to save up for their kids' education or they're trying to figure out how to pay their bills -- there's something behind the question.
In my mind, a conversational agent is one that engages the end user into really understanding the nature of the problem behind the question. Part of that includes determining when it's appropriate to dig in deeper but also recognizing that, often, there is a bigger problem there. The conversational agent must be prepared to go to the next level and solicit end users to better understand the problem. Sometimes [conversational agents] have to help [end users] figure out for themselves what the problem is because, sometimes, we'll just go in with a question and we don't really know what it is that we're after.
This is especially important when you're dealing with customer support or servicing a product because if you're having a problem with something that you bought, the first thing that you need to do is describe the problem, but that might just be describing the symptoms and not necessarily the real issue.
It's going to take more than that to figure out what is really going on with the product and what is the issue and whether it's a problem with the product or a problem with the way it's being used or whether it's some transient situation. There are lots of different things that could be behind all that. A conversational agent has to be able to get to that.
You use the term conversational agent, but a lot of people use the term virtual or personal assistant. Which of those terms should we be using, or are they distinct?
High: They're kind of two different sides of the same coin, in some sense. A conversational agent is more focused on what it takes in order to maintain a conversation. With virtual agents or personal assistants, those terms tend to be more relevant in cases where you're trying to create this sense that the conversational agent you're dealing with has its own personality and is somehow uniquely associated with you.
At least for me, the term virtual assistant sort of metaphorically conjures the idea of your own personal butler -- someone who is there with you all the time, knows you deeply, but is dedicated to just you and serving your needs. When a conversational agent is coupled with that kind of personalized knowledge and acts and behaves in a way that gives you the feeling that it's there only for you, I think there becomes an intersection between the two ideas.
For it to serve you on a personal level, any kind of good personal assistant or virtual assistant needs to retain a great deal of context about you, but then use that context as a way of interacting with you -- to use the conversational agent technique for not just anticipating your need but responding to your need and getting to know you better to be able to respond to that need better in the future.
So personal assistants are good at natural language processing and can use machine learning to keep getting better. Do you see chatbots and the various kinds of conversational agents evolving side by side or do you see one overtaking the other?
High: I think both are useful for their own purposes and, to some extent, there's a continuum. But there's certainly a demarcation when it comes to the philosophy of what you're trying to do [and] the tools that you need to be able to do it with and the underlying technologies that are necessary to enable it.
I could imagine a world where chatbots are just chatbots and they do what they've done and they do it well but they don't do much more than that. There may be a use for that, but [I could imagine] other places where there's a lot of utility in going beyond just simply the chatbot to help people with their problems. A lot of that is driven by what kind of utility is called for.
We believe at IBM that the real purpose of AI is to augment human intelligence, not to replace human intelligence. When you think about that, you begin to realize that augmenting human cognition requires getting into a deeper level of understanding of a human and being able to recognize what problems they're trying to get to in a conversation space. [AI] must recognize that humans express themselves in sometimes very subtle ways, and that the intention behind that expression is something that requires a certain degree of reasoning.
The systems have to be trained [using machine learning]; you can't just program them to be able to do all these things. They have to learn. Ultimately, they have to interact with us like we're humans. They have to know something about the fact that, as humans, we have emotions, and our emotions can vary throughout the course of a conversation. [Conversational agents] have to know how to interact with somebody in order to amplify their thinking. There's more to it than just what you typically see today as a chatbot.
So I think both will continue to exist, but a demarcation will occur between those simple things that people can do quickly and easily without a whole lot of additional exploration, versus those situations in which there's a lot of economic value in amplifying human cognition.
How can technologies like chatbots and virtual assistants drive business value? Beyond handling conversational tasks, what's their potential in the enterprise?
High: I think chatbots may be an entry point for almost any enterprise. It's hard to operate an enterprise without having some kind of interface to your clients -- even the simplest of interfaces like those that might occur when you're carrying your smartphone around with you. Almost every institution out there is trying to engage their clients at a deeper level.
Part of that is about getting to know your clients better so that you can serve them better and part of it is about trying to create a higher degree of trust and loyalty. Some of it is about trying to deal with the burgeoning growth in call center expenses as more and more of these relationships drive more hand-holding or deep touch.
I think all of that is conspiring to suggest that going into the digital age, enterprises can only be successful if they're thinking about employing these conversational agents as a way of augmenting their own staff, but, even more so, augmenting the intelligence of their staff and their relationship with their clients and augmenting the intelligence of the clients to create a stronger relationship with the institution.
",conversational agent,Person,jade green,spectrum of colors, , , 
https://ibm.co/2J5NTwv,187446750783_10155560867700784,https://www.facebook.com/ibmwatson/posts/10155560867700784,"With over 5,200 branches, Bradesco is one of Brazil’s largest banks. So how are they able to pay attention to each one of their 65 million customers? Learn how they trained Watson to answer questions with accuracy: ",Link,,,4/17/18 13:12, ,3423,3423,0,4733,4733,0,115,64,83,0,0,3710,2616,0,0,101,0,0,0,0,0,0,0,0,0,0,16,61.0,,16,61.0,,32,36.0,,,43,40.0,,,,,,,,,How a Brazilian bank pays personal attention to each of their 65 million customers,,https://www.ibm.com/watson/stories/bradesco/,sadness,0.11589,neutral,0,Brazil’s largest banks,"Company, Location",Brazil’s largest banks,Company,sadness,0.452632,neutral,0,"Brazilian bank, personal attention",,Brazilian bank,,joy,0.487799,positive,0.683831,,"Person, Company, Company, Person, Person","Watson is AI from IBM that seamlessly embeds into your workflows while integrating with the leading platforms and tools enterprises already use. Putting AI at your employees' fingertips when they need it - and where they need it - means empowering your teams to focus on what they do best.
There’s even one inside a boat on the Amazon. When branch employees had questions about products or services, they called a central office, but there was often a long wait for answers. This meant the client was also left waiting, and as one manager put it, “No one likes to wait.”
In a business as competitive as banking, if your customers don’t have a great experience, they may not be your customers for long. So Bradesco started looking for a way to increase the speed of service and also improve the level of personalization for each client. That’s when they turned to IBM and Watson.
Their first task was to teach Watson Portuguese, but initially there were some doubts. “It’s more than just learning the language,” said IBM Managing Director Katia Vaskys. “You also need to understand Brazil’s culture, and the regional accents, and the way each region asks a question.”
But after mastering the nuances of Portuguese, Watson was ready to be trained on the business of banking. To do this, Bradesco and IBM worked together to develop a team that taught Watson about the bank’s products and services by asking and answering questions for Watson in natural language—the same way a customer would. 
“Yes, Watson can learn,” said one IBMer, “but it needs people to teach people who are committed and patient.” Because of this team effort, Watson could understand 100% of written questions and 83% of spoken ones after just 5 months of training. And after 10 months, the system was answering 96% of all questions correctly.
Now Watson is trained on 62 products and answers 283,000 questions a month with a 95% accuracy rate, with just 5% requiring calls for further assistance. In some cases, response times have been reduced from 10 minutes to just seconds. “It’s a real wow factor,” exclaimed one manager.
This helps employees have more enriching interactions with clients, because they have time to dedicate to providing the best possible customer experience. “This is when growth happens,” said the Bradesco AI Lead, Marcelo Camara. “Our current clients notice the improved service, which in turn attracts new clients, and this is what helps the bank scale.”
",,Person, , , , , 
https://ibm.co/2H82BmD,187446750783_10155558663325784,https://www.facebook.com/ibmwatson/posts/10155558663325784,"Don't miss out on learning about the hottest tech topics – data privacy, consumer vs business AI, getting started with AI – during our upcoming post-Think webinar on 4/17 at 1pm EDT. Here's your chance to learn all you need to know from Think 2018 and hear it straight from IBM Watson CTO Rob High and VP of Watson Implementations Toby Cappello. Register now: ",Link,,,4/16/18 12:00, ,5865,5865,0,8032,8032,0,89,65,82,4,4,7168,5251,0,0,82,0,0,0,0,0,0,0,0,0,0,6,28.0,,6,29.0,,34,32.0,,,46,36.0,,,3,1.0,,3,1.0,,"Tuesday, April 17, 2018 at 12:56 PM Eastern Daylight Time. ",,https://event.on24.com/wcc/r/1650686/5342F58F5F9B25A6C833D8A457BBA6BD?partnerref=facebook,anger,0.073262,negative,-0.368363,"hottest tech topics, IBM Watson CTO Rob High","Person, Person",hottest tech topics,Person,joy,0.292596,neutral,0,"Eastern Daylight Time, April",,Eastern Daylight Time,,anger,0.177102,neutral,0,"Real answers, questions",,"Real answers to your AI questions
",Real answers,, , , , , 
https://ibm.co/2zBV7TA,187446750783_10155556315005784,https://www.facebook.com/ibmwatson/posts/10155556315005784,"“How do I turn on my rear defroster?” Questions that once required consulting a car manual no more – introducing Ask Mercedes, the new virtual assistant powered by Watson. ",Link,,,4/15/18 9:00, ,8040,8040,0,11561,11561,0,120,70,87,4,4,9732,6892,0,0,109,0,0,0,0,0,0,0,0,0,0,18,56.0,1.0,19,57.0,1.0,32,42.0,,,44,43.0,,,1,3.0,,1,3.0,,"“How do I turn on my rear defroster?” and “What type of fuel does this car need?” are the kinds of questions that can send new car owners diving into glovebox for the car manual. Or, they simply start pressing random buttons, hoping for the best. Those days, however, may be over. Daimler AG and IBM have jointly developed the virtual assistant, “Ask Mercedes,” based on IBM Watson conversational technology and the IBM Cloud. The chatbot helps drivers get immediate responses to questions about their cars. From December on available in South Africa and Malaysia (India and Hongkong following in 2018) in the E- and S-Class, the intelligent chatbot Ask Mercedes leaves (almost) no questions about the functionalities of these vehicles unanswered. Ask Mercedes is designed to help not only Mercedes owners – who are getting behind the wheel of increasingly feature-rich vehicles – but also users of car sharing or rental services who may be particularly unfamiliar with newer updates. Ask Mercedes can either…",https://www.ibm.com/blogs/think/wp-content/uploads/2017/11/ibm-mercedes-app-800.jpg,https://www.ibm.com/blogs/think/2017/11/end-of-the-car-manual/,fear,0.10553,neutral,0,"Questions, Ask Mercedes",Person,Questions,Person,joy,0.528373,positive,0.626421,"intelligent chatbot Ask, South Africa, S-Class","Company, Company",intelligent chatbot Ask,Company,joy,0.508104,positive,0.807184,intelligent chatbot Ask,"Company, Company, Company, Person, Company, Company, Location, Location","Share this post:
“How do I turn on my rear defroster?” and “What type of fuel does this car need?” are the kinds of questions that can send new car owners diving into glovebox for the car manual. Or, they simply start pressing random buttons, hoping for the best. Those days, however, may be over.
Daimler AG and IBM have jointly developed the virtual assistant, “Ask Mercedes,” based on IBM Watson conversational technology and the IBM Cloud. The chatbot helps drivers get immediate responses to questions about their cars. From December on available in South Africa and Malaysia (India and Hongkong following in 2018) in the E- and S-Class, the intelligent chatbot Ask Mercedes leaves (almost) no questions about the functionalities of these vehicles unanswered.
Ask Mercedes is designed to help not only Mercedes owners – who are getting behind the wheel of increasingly feature-rich vehicles – but also users of car sharing or rental services who may be particularly unfamiliar with newer updates. Ask Mercedes can either be downloaded as an app or accessed via Facebook and other messenger services, with future plans to embed this AI assistant in the vehicle itself.
Car manuals are usually consulted only as a last resort, and sometimes not at all – which can compound what might start out as a relatively minor issue. Mercedes’ goal is to ensure that all drivers are able to quickly and easily access accurate information about their vehicles.
Recognizing that many users are more willing to query an app, rather than flip through a manual or phone a call center, Mercedes has brought AI from IBM Watson to the experience – introducing an application that knows the car and its functionalities by heart. Users can pose questions specifically about their vehicle, as they would to a knowledgeable Mercedes expert, and can also ask general question about Mercedes features, such as the new EQ design for Mercedes electric vehicles.
By making Ask Mercedes available on multiple channels – including via Facebook Messenger – Mercedes is helping to provide drivers with a consistently high level of support, whether they’re asking a quick question or investigating a more complex issue. Either way, the carmaker wants to ensure that drivers can get back on the road quickly and safely.
To make sure drivers are getting the most precise information, Ask Mercedes can also pose follow up questions to better understand what the driver is asking. It can also answer questions with the aid of multi-media content, such as graphics or drawings.
But the chatbot also knows its limits: If it realizes that it cannot answer a question, it refers the user to additional information or the call center.  As the vehicles become ever more sophisticated, technology can also play a role in enhancing the driver’s comfort with these changes. Above all, technology like Watson is a tool to assist humans – to help them make better-informed decisions, to help answer their of-the-moment questions and sometimes, to help with a smoother ride.
",intelligent chatbot Ask,Company,blue,telephone,telecommunication,telephone,-
https://ibm.co/2G3RIRX,187446750783_10155554394905784,https://www.facebook.com/ibmwatson/posts/10155554394905784,IBM Watson and Salesforce will double down on their relationship with AI – these two top tech firms connecting their artificial intelligence platforms reinforces the growing value of AI and big data in the enterprise. ,Link,,,4/14/18 9:30, ,19335,19335,0,26625,26625,0,879,632,804,12,13,17283,12544,0,0,441,0,0,0,0,0,0,0,0,0,0,52,290.0,20.0,54,299.0,24.0,403,264.0,,,529,275.0,,,6,7.0,,5,7.0,,"The expanded partnership, focused on delivering deeper insights, will see each firm become a preferred provider for the other.",https://tr2.cbsistatic.com/hub/i/r/2018/01/19/8ad55407-aa17-48f7-b14f-fd468ab5a10d/thumbnail/770x578/fe82c6875bb7a84ae16cbe4faa220069/ibmsfceos.jpg,https://www.techrepublic.com/article/ibm-and-salesforce-double-down-on-ai-announce-watson-einstein-collaboration/,sadness,0.170555,neutral,0,"IBM Watson, top tech firms, artificial intelligence platforms","Company, Company, Person",IBM Watson,Company,joy,0.344865,positive,0.724147,expanded partnership,,expanded partnership,,joy,0.157112,positive,0.683074,"Salesforce Quip, Watson services, power of IBM Cloud","Company, Company, Person, Person, Person, Person"," 	Building a slide deck, pitch, or presentation? Here are the big takeaways: 
 	Salesforce and IBM announced an expansion of their strategic partnership on Friday, with the firms combining the power of IBM Cloud and Watson services with Salesforce Quip and Salesforce Service Cloud Einstein, the firms announced in a joint  	press release Friday.
 	Two top tech firms like Salesforce and IBM connecting their artificial intelligence (AI) platforms reinforces the growing value of AI and big data in the enterprise. AI, especially, is taking center stage as one of the battleground technologies for business, and this is a clear example of two CEOs making a move to reinforce that with their partnership.
 	In the release, IBM CEO Ginni Rometty said that the combination of Watson and Einstein will ""help enterprises make smarter business decisions."" Salesforce CEO Marc Benioff echoed this sentiment, saying in the release that the combo will ""deliver even more innovation to empower companies to connect with their customers in a whole new way, leveraging the power of the cloud and AI.""
 	 	SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
 	Specifically, the Watson/Einstein combination will provide actionable next steps in a given process, the release said. This could potentially help users strengthen customer relationships, or automate more processes with custom-triggered actions based on how the AI interprets a recent call or chat experience.
 	In addition to the firms connecting their AI platforms, they will share preferred vendor status for one another in specific areas. For Salesforce, IBM will become a preferred cloud services provider and, for IBM, Salesforce will become a preferred customer engagement platform, the release said.
 	Another result of the partnership will be the development of some IBM Watson Quip Live Apps. With these apps, which can be embedded into a Quip document, users will have access to Watson's cognitive computing when working in the document creation and editing platform, the release said.
 	The expansion builds on a joint solutions partnership that was originally  	announced by the companies back in March 2017. Currently, the partnership serves more than 4,000 joint customers, the release said, including Autodesk.
 	""Combining the AI power of Watson and IBM Cloud with insights from Salesforce has helped Autodesk better understand its customers and ultimately create a transformed customer experience,"" Rachael Cotton, senior manager of machine assisted service engagement for Autodesk, said in the release.
",Salesforce Quip,Company,coal black,couple,person,couple,-
https://ibm.co/2H82BmD,187446750783_10155552364850784,https://www.facebook.com/ibmwatson/posts/10155552364850784,"Data privacy, consumer vs business AI, getting started with AI - all topics discussed in this actionable AI webinar. Hear straight answers from Watson experts who share client results and tips to work with AI. And, Coca-Cola, Thomson Reuters and Honda share their lessons learned. Register now:  ",Status,,,4/13/18 9:27, ,1526,1526,0,2195,2195,0,23,11,17,1,1,1819,1240,0,0,17,0,0,0,0,0,0,0,0,0,0,3,14.0,,3,14.0,,8,4.0,,,13,4.0,,,,1.0,,,1.0,,"Tuesday, April 17, 2018 at 12:56 PM Eastern Daylight Time. ",,https://event.on24.com/wcc/r/1650686/5342F58F5F9B25A6C833D8A457BBA6BD?partnerref=facebook,joy,0.423653,positive,0.511901,"Coca-Cola, Data privacy, Thomson Reuters","Person, Company, Person",Coca-Cola,Person,joy,0.292596,neutral,0,"Eastern Daylight Time, April",,Eastern Daylight Time,,anger,0.177102,neutral,0,"Real answers, questions",,"Real answers to your AI questions
",Real answers,, , , , , 
https://ibm.co/2INwXuq,187446750783_10155550804690784,https://www.facebook.com/ibmwatson/posts/10155550804690784,"We are pleased to announce that in &quot;The Forrester New Wave™: Conversational Computing Platforms, Q2 2018,&quot; IBM Watson Assistant is named as a Leader in conversational computing: ",Photo,,,4/12/18 15:21, ,11874,11874,0,16974,16974,0,337,242,353,4,4,10136,7258,0,0,209,0,0,0,0,0,0,0,0,0,0,44,114.0,2.0,48,117.0,3.0,156,52.0,62.0,,208,60.0,85.0,,4,,,4,,,"Improve customer and employee experiences with market leading AI

, IBM account registration",https://1.www.s81c.com/common/images/ibm-leadspace-1200x627.jpg,https://www.ibm.com/account/reg/us-en/signup?formid=urx-31820&cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Conversation-_-WW_WW-_-Forrester+Wave+Facebook+&cm_mmca1=000027BD&cm_mmca2=10006919&,joy,0.750694,positive,0.673213,"Conversational Computing Platforms, Forrester New Wave",Company,Conversational Computing Platforms,Company,sadness,0.130895,neutral,0,"IBM account registration, employee experiences, customer","Person, Company",IBM account registration,Person,joy,0.507004,positive,0.943004,"business-critical area, IBM Watson Assistant, related matters","Company, Company, Person","Learn why Forrester named IBM Watson Assistant as a leader in the business-critical area of conversational computing in the The Forrester New Wave™: Conversational Computing Platforms. You’ll discover why it is increasingly important for businesses to build engaging interactions that deliver value to their customers. 
Enter your information now to read the report. 
Or,  r  ead more about conversational AI with Watson.
Learn why Forrester named IBM Watson Assistant as a leader in the business-critical area of conversational computing in the The Forrester New Wave™: Conversational Computing Platforms. You’ll discover why it is increasingly important for businesses to build engaging interactions that deliver value to their customers. 
Enter your information now to read the report. 
Or,  r  ead more about conversational AI with Watson.
We use phone in order to reach you for account related matters or, with your permission, to contact you related to other products and services.   
",business-critical area,Company, , , , , 
https://ibm.co/2piRDl0,187446750783_10155550195145784,https://www.facebook.com/ibmwatson/posts/10155550195145784,"Meet &quot;Olli,&quot; a self-driving bus created by Locol Motors and IBM Watson that uses #AI technology to assist people with disabilities. ",Link,,,4/12/18 9:30, ,8316,8316,0,11652,11652,0,199,111,126,5,5,9669,7017,0,0,161,0,0,0,0,0,0,0,0,0,0,21,96.0,2.0,22,99.0,3.0,60,53.0,1.0,,69,56.0,1.0,,2,3.0,,2,3.0,,Local Motors and IBM are equipping an autonomous electric shuttle bus with technology that assists people with a range of disabilities.,https://cdn.technologyreview.com/i/images/copy-of-olli-at-phoenix-lm-2.jpg?cx=0&cy=458&cw=3000&ch=1687&sw1200,https://www.technologyreview.com/s/604116/a-self-driving-bus-that-can-speak-sign-language/,joy,0.096537,neutral,0,"Locol Motors, IBM Watson, quot","Company, Company, Hashtag",Locol Motors,Company,sadness,0.092443,negative,-0.625597,"Local Motors, autonomous electric shuttle bus",Company,Local Motors,Company,sadness,0.461357,negative,-0.297226,city buses,"Person, Person, Company, Company, Company, HealthCondition, Person","It’s been 15 years since a degenerative eye disease forced Erich Manser to stop driving. Today, he commutes to his job as an accessibility consultant via commuter trains and city buses, but he has trouble locating empty seats sometimes and must ask strangers for guidance. 
A step toward solving Manser’s predicament could arrive as soon as next year. Manser’s employer, IBM, and an independent carmaker called Local Motors are developing a self-driving, electric shuttle bus that combines artificial intelligence, augmented reality, and smartphone apps to serve people with vision, hearing, physical, and cognitive disabilities. The buses, dubbed “Olli,” are designed to transport people around neighborhoods at speeds below 35 miles per hour and will be sold to cities, counties, airports, companies, and universities. If the buses enter production in summer 2018, as planned, they could be among the earliest self-driving vehicles on U.S. roads. 
Since Olli is fully autonomous and does not have a human driver, it uses IBM’s AI-powered Watson technology to converse with passengers (via voice and text displayed on an iPad). Olli navigates using radar, lidar, and optical cameras from a company called Meridian Autonomous. Before deploying in a neighborhood, Meridian Autonomous constructs 3-D maps of the area that Local Motors says are accurate to the half-inch. A human fleet manager then determines the bus route. When Olli detects an emergency via its various sensors, it will stop, notify a (human) remote supervisor, and independently run through a checklist of possible problems. “If a passenger has a medical problem or [there’s a safety issue], Olli will call the authorities or drive itself to a hospital or police station,” says Gina O’Connell, a Local Motors general manager who is leading the project. 
Local Motors and IBM started collaborating on Olli in early 2016 and produced a first iteration of the bus in June 2016. That vehicle is currently in trials in Germany and Switzerland. It is the next—second—generation of Olli that will include assistive technologies. That version, which the companies call “Accessible Olli,” will be manufactured starting in 2018, and will retain Watson as a tool for communicating with passengers and add additional Watson features. 
Local Motors and IBM are still testing technologies, but have already identified some capabilities they are likely to add. Future Ollis, for example, might direct visually impaired passengers to empty seats using machine vision to identify open spots, and audio cues and a mobile app to direct the passenger. Olli could also guide passengers via a special type of haptic feedback that uses ultrasound to project sensations through the air. An array of haptic sensors could be designed into every seat, and when people walk down the aisle they would feel a vibration on their hand or arm to alert them that they were at an empty seat, explains Drew LaHart, the program director for IBM’s accessibility division.  
For deaf people, the buses could employ machine vision and augmented reality to read and speak sign language via onboard screens or passengers’ smartphones. LaHart says that Olli could be trained to recognize sign language using machine learning and Watson’s image recognition capabilities. If the bus were equipped with AR technology, it might be able to respond via a hologram of a person signing. 
Machine vision could also enable Olli to recognize passengers waiting at bus stops who have walkers and wheelchairs. The bus would then activate an automated ramp to help them board and then deploy equipment that would secure their assistive devices, locking a wheelchair into place, for example. 
Another potential Olli technology combines machine vision and sensors to detect when passengers leave items under their seats and issues alerts so the possessions can be retrieved, a feature meant to benefit people with age-related dementia and other cognitive disabilities. 
This would all be a significant improvement over the typical bus accommodations of today, which are limited to wheelchair ramps and lifts and audible and visual bus route updates. Local Motors, IBM, and the CTA Foundation, the charitable arm of the Consumer Technology Association, a trade group for the consumer electronics industry, and a partner in Accessible Olli, have spent the past three months soliciting ideas from disability rights organizations and retirement communities, among others. Manser, who works for IBM Accessibility, has organized a workshop with blindness organizations and public transit agencies and attended an MIT assistive technologies hackathon in March to explain the challenges he encounters on public transportation. 
Local Motors plans to keep soliciting public input for several more months. In July, it will devise an engineering plan for the new version of Olli, select suppliers, and calculate the cost of fabricating the bus. It aims to sell the vehicle for about $250,000 and will also offer a leasing-subscription service that would cost $10,000 to $12,000 a month and include hardware upgrades. Because Olli is mostly manufactured on-demand, through 3-D printing, its design can be tweaked quickly in response to user feedback, says O’Connell. 
The company expects public transportation operators will be its main customers and hopes that cities will buy the buses to fill in gaps in their regular transit systems and not just as paratransit vehicles for disabled people. 
For those with disabilities, though, Olli could be a big improvement over the current options.  Door-to-door paratransit service tends to be slow, has to be scheduled ahead of time, and is only available to people who qualify for it, says Henry Claypool, who is the policy director of the Community Living Policy Center at the University of California, San Francisco, and a wheelchair user. “It’s much more reliable to be able to get on and off a bus at the same place and have a predictable schedule, especially if the bus has this type of assistive technology,” he says. 
Olli offers a way to address important limitations of public bus and train systems as well, says Susan Henderson, the executive director of the Disability Rights Education and Defense Fund. The Americans with Disabilities Act mandates only that “key” train and subway stations be accessible, which means that people with wheelchairs, walkers, and scooters often have to travel several stops out of their way to get home or to a destination, says Henderson. “If I still had 10 blocks to go after getting off at my local station, having an Olli rolling around my neighborhood would make a big difference,” she says. 
",city buses,Person,steel blue,shuttle bus, , , 
https://ibm.co/2FafMBI,187446750783_10155545723090784,https://www.facebook.com/ibmwatson/posts/10155545723090784,"&quot;One of the things we have to realize about AI—it's relatively new to all of us. There's a lot about it that we don't all fully understand...As with any new technology, it's really important that we be thinking now about how we do that ethically and responsibly. For us, that comes down to three basic principles: trust, respect, and privacy.&quot; 

Read more on what IBM Watson CTO Rob High says about these 3 ethical principles via TechRepublic: ",Link,,,4/10/18 8:15, ,9402,9402,0,13071,13071,0,205,155,188,5,5,10285,7398,0,0,148,0,0,0,0,0,0,0,0,0,0,16,68.0,2.0,18,69.0,2.0,98,62.0,,,121,67.0,,,1,4.0,,1,4.0,,"TechRepublic spoke to IBM's Rob High about the ethical, privacy, and security obstacles that artificial intelligence has to overcome.",https://tr1.cbsistatic.com/hub/i/r/2018/03/01/005c45e1-7e9b-43df-9012-57f7ee9fa3bc/thumbnail/770x578/ea8d0af3f9eb1dfda64080cabc7cdc79/big-booths-mwc-2016-12.jpg,https://www.techrepublic.com/article/ibm-watson-cto-the-3-ethical-principles-ai-needs-to-embrace/,joy,0.759845,positive,0.756399,"IBM Watson CTO Rob High, basic principles, ethical principles","Person, Person",IBM Watson CTO Rob High,Person,fear,0.228087,negative,-0.589837,"IBM's Rob High, artificial intelligence","Person, Company",IBM's Rob High,Person,joy,0.60699,positive,0.646511,,"Person, Person, Company, Organization","IBM Watson CTO Rob High has done a lot of thinking about the privacy, security, and ethical implications of artificial intelligence. He presented some of those ideas at Mobile World Congress 2018, and we talked to him about some of his key findings.
You can watch the interview above or read the transcript below.  
High said, ""One of the things we have to realize about AI--it's relatively new to all of us. There's a lot about it that we don't all fully understand. Even as a technologist, we know where we're trying to bring the technology, but on the other side there's lots of people for which this technology is new. The experiences around that are going to be different. As with any new technology, it's really important that we be thinking now about how we do that ethically and responsibly. For us, that comes down to three basic principles. Trust, respect, and privacy.
""What that basically means is that when you're using an AI technology, you have to trust that it's going to be doing the right thing. Or you focus on things like, can we create transparency in the AI algorithms? Can we get the algorithms to actually identify your level of confidence (in them), for example.""
SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
""Transparency comes down to can we identify what sources of information are being used? Have we established the right properties, the right principles in place when we train these systems to use data that is representative of who we are, and the information that we're using?"" said High.
""Of course, privacy comes down to recognizing that your data is our data. It should be your choice as to what data you're going to provide in order to gain the benefits these AIs offer. That goes from everything from the privacy of enterprise data, and the data that enterprises bring to the table when they use AIs, maintain separation between each of the enterprises all the way through, to how those enterprises protect the privacy of the data of their clients.""
High added, ""The journey for adopting AI and delivering that for value to clients begins with one very basic proposition, which is, is the AI going to augment and amplify the intelligence of the people using it? Because if it's not doing that, it's probably not going to be very useful. You're going to lose this utility very quickly. First of all, identify what that is. How do you help people do what they do better?
SEE: How to implement AI and machine learning (ZDNet special feature) | Download the report as a PDF (TechRepublic)
""If you get that out of the way then you can begin to look at how to apply the technology, but all through that we really encourage our clients to think about two things. One is, how they're going to protect and preserve the privacy of their institutions, of their clients. But also how do they convey the responsibility of their clients to be aware of what data they're getting across and to challenge those cases where, perhaps they don't want to give up the data they're offering. Or at least to make sure the value they're getting from that data is also very supportive of this idea that's augmented their intelligence.""
",,Person,purplish blue,air terminal, , , 
https://ibm.co/2qi276h,187446750783_10155543539415784,https://www.facebook.com/ibmwatson/posts/10155543539415784,"Watson Assistant will allow enterprises to build virtual assistants for customer service or sales and customize them, while keeping the data that flows through it private. ",Link,,,4/9/18 9:00, ,5715,5715,0,8065,8065,0,82,41,46,6,6,7231,4991,0,0,69,0,0,0,0,0,0,0,0,0,0,12,41.0,,13,42.0,,25,18.0,,,26,20.0,,,4,2.0,,4,2.0,,The IBM Watson Assistant will let businesses build virtual assistants and brand them as their own. The service's flexibility and data privacy make it stand out.,https://cdn.ttgtmedia.com/visuals/searchBusinessAnalytics/BI_management/businessanalytics_article_002.jpg,https://searchunifiedcommunications.techtarget.com/news/252438500/IBM-Watson-Assistant-offers-flexibility-data-privacy,joy,0.228862,positive,0.700289,"Watson Assistant, customer service, virtual assistants",Person,Watson Assistant,Person,joy,0.147478,positive,0.605791,"IBM Watson Assistant, service's flexibility",Company,IBM Watson Assistant,Company,joy,0.166883,positive,0.585379,"release of a virtual assistant developer toolkit, IBM Watson Assistant","Company, Person","This email address doesn’t appear to be valid.
IoT devices with the release of a virtual assistant developer toolkit. The ability to customize the IBM Watson Assistant -- and keep the data that flows through it private -- could boost adoption of virtual assistants in the enterprise market.
Virtual assistants like Siri and Alexa have gained popularity in the consumer market, but IBM is offering its new product exclusively to businesses. The IBM Watson Assistant will allow enterprises to build virtual assistants for customer service or sales and brand them as their own.
IBM also gives businesses more control over the information that flows through these virtual assistants than do products such as Alexa for Business and Google Assistant. Enterprises can guard competitive insights and sensitive information by running the IBM Watson Assistant in private data centers.
""IBM's approach of adding artificial intelligence to everything will open up the use cases to a broad range of products and services, including unified communications and collaboration,"" said Juan Manuel González, an analyst at Frost & Sullivan.
IBM is marketing the Watson Assistant primarily as an instrument for improving customer experiences and reducing contact center costs. The company also released special tools for integrating virtual assistants with vehicles (for navigation and locating nearby destinations) and hotel rooms (for ordering room service and concierge services).
But the IBM product could also be used to add chatbots and AI voice assistants to collaboration apps and meeting room devices. With such integrations, workers could command video conferencing gear to begin a meeting, ask their desk phone to call a co-worker or tell a team collaboration app like Slack to open a recent file.
""I would like to see IBM provide deeper integration of Watson Assistant within their collaboration portfolio, enabling people to chat with their email, calendar, contacts and social networking applications,"" said Alan Lepofsky, an analyst at Constellation Research.
There are some enterprise AI voice assistants on the market that require less developer expertise. Vendors have tied those assistants to specific devices and applications, such as Cortana, which Microsoft will soon add to Teams, and the Spark Assistant, which Cisco released in beta in November 2017.
The IBM Watson Assistant gives enterprises device flexibility and control over their own data, but many may still prefer prebuilt platforms such as Alexa for Business, which runs on Amazon Echo devices.
The release of IBM Watson Assistant underscores the rapid growth of virtual assistant products and services, but that growth may be outpacing market demand, said Irwin Lazar, an analyst at Nemertes Research, based in Mokena, Ill.
End-user spending on AI voice assistant devices is expected to grow from $720 million in 2016 to $3.52 billion in 2021, according to Gartner. But consumers will drive most of that demand. The firm expects enterprise adoption will accelerate in 2019, beginning with hospitality and healthcare.  
""Our research shows that companies are interested in these kinds of capabilities, but it will take some time until there are clear business cases that will drive procurement budgets,"" Lazar said.
",release of a virtual assistant developer toolkit,Company,greenish blue,person,memory device,compact disk,-
https://ibm.co/2H82BmD,187446750783_10155542423780784,https://www.facebook.com/ibmwatson/posts/10155542423780784:0,"Think 2018 was the first time all of IBM’s technology took the stage to showcase how we’re putting innovation to work. If you couldn’t attend, now is your chance to learn all the insights from our top speakers during a webinar on April 17th. Watch key moments from Think, hear from IBM Watson CTO Rob High and other experts and gain the opportunity to participate in a live Q&amp;A. 

Click here to register now: ",Photo,,,4/8/18 18:20, ,99852,9246,93360,151243,13048,138195,1173,948,1194,8,10,21475,10299,10850,3428,313,0,0,0,0,0,0,0,0,0,0,34,256.0,7.0,37,259.0,8.0,446,167.0,417.0,,515,196.0,483.0,,4,2.0,4.0,3,2.0,4.0,"Tuesday, April 17, 2018 at 12:56 PM Eastern Daylight Time. ",,https://event.on24.com/wcc/r/1650686/5342F58F5F9B25A6C833D8A457BBA6BD?partnerref=facebook,joy,0.427385,positive,0.700836,"key moments, IBM Watson CTO Rob High, IBM’s technology","Company, Person",key moments,Company,joy,0.292596,neutral,0,"Eastern Daylight Time, April",,Eastern Daylight Time,,anger,0.177102,neutral,0,"Real answers, questions",,"Real answers to your AI questions
",Real answers,, , , , , 
http://ibm.co/2nndb0Q via TechRepublic,187446750783_10155539400045784,https://www.facebook.com/ibmwatson/posts/10155539400045784,How is AI is being used to assist human problem-solving? Here are 10 practical scenarios: ,Link,,,4/7/18 9:30, ,19628,19628,0,26702,26702,0,956,721,836,16,17,19672,14720,0,0,803,0,0,0,0,0,0,0,0,0,0,66,317.0,6.0,69,325.0,7.0,190,585.0,,,232,604.0,,,8,9.0,,7,9.0,,For more than a century IBM has been dedicated to every client's success and to creating innovations that matter for the world,,https://www.ibm.com/us-en/?ar=1,sadness,0.129807,neutral,0,,Person,,Person,joy,0.856488,positive,0.979896,"century IBM, client's success",Company,century IBM,Company,joy,0.844333,positive,0.835611,IBM POWER9,"Company, Quantity, Person","Celebrate Women’s History Month with IBMers who are changing the world and inspiring the next generation
From chatbots to drug discovery, these IBMers push the frontiers of AI
 									Meet the women inspiring a new generation of researchers → 								
World’s most powerful supercomputer identifies 77 promising drug compounds
 									Learn how IBM POWER9 is accelerating the search for a cure → 								
A big network outage welcomed her to IBM. She helped it run at 100% since.
 									Find out about this VP, transformation agent and soccer mom → 								
IBM has laid the foundation for a new era of technology and business
 									Read about a year  of growth — and plans for the future → 								
Accelerate your journey to AI with a cloud‑native data platform
Build AI solutions to find relevant answers in complex data
Try IBM Z mainframe software capabilities with no installation required
Create, move and deploy your Java applications on the cloud in minutes
How would you use technology to take on climate change?
How would you use technology to take on climate change?
Get help today for the IBM services and software you own →
Explore technical topics, find trial software and join the community →
",IBM POWER9,Company, , , , , 
https://ibm.co/2BVNJaF,187446750783_10155535237855784,https://www.facebook.com/ibmwatson/posts/10155535237855784,"To protect teens from cyberbullying, Identity Guard uses IBM Watson's Natural Language Processing to build a solution that is able to understand and categorize what individuals are sending and receiving. If a threat is identified, it triggers an alert that is sent parents. Learn more: ",Link,,,4/5/18 9:00, ,11809,11809,0,16606,16606,0,316,179,247,7,7,11871,8586,0,0,230,0,0,0,0,0,0,0,0,0,0,56,158.0,6.0,56,160.0,6.0,114,87.0,,,156,91.0,,,2,5.0,,2,5.0,,Identity Guard’s cyberbullying features monitor the social media feeds to which both parents and children have given it access.,https://www.ibm.com/blogs/client-voices/wp-content/uploads/2018/02/Meier-tile.jpg,https://www.ibm.com/blogs/client-voices/ai-technology-protect-teens-cyberbullying/,fear,0.120075,negative,-0.329662,"IBM Watson's Natural Language, Identity Guard","Organization, Person",IBM Watson's Natural Language,Organization,anger,0.293396,neutral,0,"Identity Guard, social media feeds",,Identity Guard,,joy,0.594566,positive,0.289397,,"Organization, Quantity, Organization, Person, Company, Quantity","An astonishing 87% of youth have witnessed cyberbullying. In 2017 alone, over 13 million American children were bullied or cyberbullied.
For me, the struggle against bullying and cyberbullying is a personal one. In October of 2006, my 13-year-old daughter Megan took her own life as a result of cyberbullying. Committed to helping prevent similar tragedies, I founded the Megan Meier Foundation, a non-profit dedicated to supporting and inspiring actions to end bullying and cyberbullying.
Since its inception in December 2007, our Foundation has reached over 305,000 students, parents, and educators in 270 communities and 38 states. By spreading Megan’s story and educating others on internet safety and the consequences of bullying and cyberbullying, I hope to end these occurrences, helping one child at a time cope with these negative social issues.
In 2016, Identity Guard began consulting with our Foundation and other cyberbullying experts to build an effective solution that protects children and teens without invading their privacy. Using the power of artificial intelligence, Identity Guard’s cyberbullying features monitor the social media feeds to which both parents and children have given it access.
With IBM Watson technologies that enable natural language processing (NLP) and natural language classifiers (NLC), the solution is able to understand and categorize what individuals are sending and receiving. Complex algorithms then identify instances, or potential instances, of cyberbullying or self-harm. If a threat is identified, it triggers an alert that is sent parents.
Within the alert are screenshots that include the dates and times of what caused the warning. If parents agree that this is an instance of cyberbullying or potential self-harm, they are guided to a suite of free resources—including guidance on state laws and school policies—to help them figure out how to respond.
Parents are also directed to my Foundation, where, at no charge, they can talk to an individual to air their concerns, review a checklist of actions, and take a breath before they respond—ensuring that they act from an informed position rather than a state of panic.
Given the proliferation of mobile devices and social media, parents often feel overwhelmed when it comes to their kids engaging online. We’ve worked hard with Identity Guard to create a solution that provides a safe means of engagement. Children and teens can participate in social media with their privacy intact; with parents receiving alerts only if issues are identified.
For the past decade, my Foundation has focused on listening to parents, kids and educators to help them getter a better idea of how to respond, and what actions can be done to help curb bullying and cyberbullying threats.
With this experience and knowledge, we’ve created resources that better equip parents so they can start a dialog with their kids about bullying, cyberbullying and suicide. We focus on helping both parent and child realize that they can address these issues together, as they both learn about what each can do to respond.
Technology isn’t bad; rather it’s how we use it. Social media can be scary for parents as their kids begin to get online, but our Foundation is working with Identity Guard to help parents be knowledgeable and stay informed, while enabling kids to stay safely engaged.
I dream of a world where bullying and cyberbullying no longer exist, for I know firsthand of the possible devastating consequences. I believe that through empowering our society to celebrate individuality and the acceptance of others, we can work together to make a difference and create a safer and kinder world. Identity Guard’s cyberbullying features are a helpful first step in this direction.
",,Organization,coal black,reader,person,scholar,reader
https://ibm.co/2opSEck,187446750783_10155533575460784,https://www.facebook.com/ibmwatson/posts/10155533575460784,"Meet CIMON, the Watson-powered astro-assistant designed by Airbus Space to support the International Space Station. ",Link,,,4/4/18 12:00, ,10049,10049,0,13694,13694,0,218,139,185,5,5,10656,7818,0,0,180,0,0,0,0,0,0,0,0,0,0,28,105.0,5.0,28,110.0,7.0,80,72.0,,,106,79.0,,,2,3.0,,2,3.0,,"In June, German astronaut Alexander Gerst will embark on his second six-month mission to the International Space Station (ISS), serving as station commander in the second half of his stay. On this mission, Gerst and his team will receive some unusual support: CIMON (Crew Interactive Mobile Companion) will be on board – a medicine ball-sized device, weighing about 11-pounds. CIMON is currently being developed by Airbus on behalf of the German Aerospace Center (DLR) as an intelligent, mobile and interactive astronaut assistance system. This new technology will be tested on the ISS as part of the Horizons mission of the European Space Agency. CIMON, using IBM’s Watson technology, will help astronaut Gerst to perform three tasks: Together they will experiment with crystals, solve the Rubik magic cube based on videos and conduct a complex medical experiment using CIMON as an ‘intelligent’ flying camera. CIMON’s digital face, voice and use of artificial intelligence make it a “colleague” to…",https://www.ibm.com/blogs/think/wp-content/uploads/2018/02/cimon-floating.jpg,https://www.ibm.com/blogs/think/2018/02/watson-space/,joy,0.221715,neutral,0,"Meet CIMON, International Space Station","Person, Company",Meet CIMON,Person,joy,0.22886,positive,0.797114,German astronaut Alexander Gerst,"Person, Person, Quantity, Organization",German astronaut Alexander Gerst,Person,joy,0.564615,positive,0.767846,,Person,"Share this post:
In June, German astronaut Alexander Gerst will embark on his second six-month mission to the International Space Station (ISS), serving as station commander in the second half of his stay. On this mission, Gerst and his team will receive some unusual support: CIMON (Crew Interactive Mobile Companion) will be on board – a medicine ball-sized device, weighing about 11-pounds.
CIMON is currently being developed by Airbus on behalf of the German Aerospace Center (DLR) as an intelligent, mobile and interactive astronaut assistance system. This new technology will be tested on the ISS as part of the Horizons mission of the European Space Agency.
CIMON, using IBM’s Watson technology, will help astronaut Gerst to perform three tasks: Together they will experiment with crystals, solve the Rubik magic cube based on videos and conduct a complex medical experiment using CIMON as an ‘intelligent’ flying camera.
CIMON’s digital face, voice and use of artificial intelligence make it a “colleague” to the crew members. This collegial “working relationship” facilitates how astronauts work through their prescribed checklists of experiments, now entering into a genuine dialogue with their interactive assistant. The developers responsible for CIMON predict that this will help reduce astronauts’ stress and at the same time improve efficiency. In addition, CIMON helps enhance safety, because it can also serve as an early warning system in case of technical problems in the future.
How CIMON learns
CIMON is currently being trained to identify its environment and its human interaction partners. AI gives the space assistant text, speech and image processing capabilities, as well as the ability to retrieve specific information and findings. These skills, which can be trained individually and deepened in the context of a given assignment, are developed based on the principle of understanding – reasoning – learning.
Watson speech and vision technologies helped train CIMON to recognize Alexander Gerst, using voice samples and Gerst, as well as “non-Gerst” images. It also used the Watson Visual Recognition service to learn the construction plans of the Columbus module on the International Space Station to be able to easily move around. CIMON also learned all the procedures to help carrying out the on-board experiments. Experiments sometimes consist of more than 100 different steps, CIMON knows them all.
AI from the Cloud – proprietary data in a protected space 
IBM Watson services run on the IBM Cloud, which provides a further advantage for users, in general, and for use on the ISS in particular: sensitive, proprietary data can remain where it is created, such as in the protected area of your own server or database. You don’t need to upload it to an external cloud for it to be enriched with appropriate AI capabilities.
The IBM model for data and privacy allows you to train your own AI models with Watson technology without having to integrate proprietary or sensitive data into a public model. No other company, no other organization – not even IBM – can use this data for the further development of AI applications. This ensures that users can keep their critical information private and proprietary. What’s more, a company’s intellectual property and data serve to enhance only its own competitive advantage. This was one of the main reasons why Airbus chose IBM as its partner to develop CIMON.
In the mid-term, the CIMON project will also be devoted to psychological group effects that can develop in small teams over a long period of time and occur during long-term space missions. CIMON’s creators are confident that social interactions between humans and machines, in this case between astronauts and a space attendant, equipped with emotional intelligence could make an important contribution to mission success. We predict that assistance systems of this kind also have a bright future right here on earth, such as in hospitals or to support nursing care.
",,Person,ash grey,electric meter,measuring instrument,meter,electric meter
https://ibm.co/2mbU5Jl,187446750783_10155531146165784,https://www.facebook.com/ibmwatson/posts/10155531146165784,"Immerse yourself in all the ways IBM Watson is changing the landscape in the way we work and live. From airlines and insurance to wineries and puppies, read stories about the different businesses that are using AI to transform their mission: ",Link,,,4/3/18 9:06, ,8336,8336,0,11821,11821,0,135,82,97,3,3,9335,6674,0,0,108,0,0,0,0,0,0,0,0,0,0,22,63.0,,24,66.0,,40,47.0,,,49,48.0,,,,3.0,,,3.0,,Stories about how Watson and AI are changing business.,,https://www.ibm.com/watson/ai-stories/,joy,0.402559,positive,0.909417,"ways IBM Watson, different businesses",Company,ways IBM Watson,Company,joy,0.225965,neutral,0,"Stories, Watson, AI","Person, Person",Stories,Person,joy,0.632922,positive,0.870709,,"Person, Person","               IBM Watson Stories
                                                                                                                                                                                                                                        United States
           
         
                    IBM®
                        Site map
           
                                                        Search                                                                                                                     
                        
         
       
                                        Watson
                                                          About
                 Products
                                    Use Cases                                        AI for customer service
                     AI for financial services
                     AI for enterprise search
                     AI for contract governance
                   
                 
                 Stories
                                    Learn                                         Build a chatbot
                     Natural language processing
                     Explainable AI
                     Developers
                     Dev tools
                     Data privacy 
                   
                 
                 With Watson
                 Get Started Free Get Started Free
               
             
           
                                                                                                                                                                   
                                                                        This is a world
 with Watson
                   
                                      
                 
               
               
                                
               
                                         
                                                                        This is a world
 with Watson
                   
                                      
                 
               
                                                                             Watson AI is changing how business gets done.
                 
               
                                Professionals are working with Watson to make better-informed decisions, augment their teams' creativity, and produce their best work.

 How can Watson help you?
               
                                                                              
                                                Humana, a leading health insurance provider, reduced costly pre-service calls and improved the provider experience with conversational AI.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, ESPN Fantasy Football managers can combine their football savvy with AI-powered insights and player sentiment analysis to beat the competition.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Automotive giant General Motors is unifying its audit, risk, and control activities with IBM OpenPages — providing holistic insight to help make smarter decisions.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, the US Open is creating the future of the fan experience – for today's game.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Creval is transforming banking support with an AI-powered virtual assistant.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Crédit Mutuel is building upon its strength in customer service expertise with AI.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson and Apple's Core ML, technicians can make the right repairs the first time – anywhere.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Brazilian bank Bradesco is giving personal attention to each of its 65 million customers with Watson.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, Lucy and Equals 3 is delivering results to Fortune 1000 companies and the agencies serving them.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, KPMG is driving innovation and empowering its employees.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Thomson Reuters is working with Watson to help clients deepen their expertise on global data privacy laws.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson IoT, KONE is analyzing data in elevators and escalators around the world to keep people moving smoothly, safely, and efficiently.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, Woodside Energy can retain the knowledge of senior experts and pass it to new employees.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                Autodesk used Watson to develop a virtual agent that interacts with customers and speeds response times by 99 percent.
                       
                     
                                            Read the case study on IBM.com →
                     
                   
                                                                
                                                Insurance company employees are working with Watson to assess insurance claims 25 percent faster.
                       
                     
                                            Read full story →
                     
                   
                                                                
                                                With Watson, Korean Air is developing an intelligent detection system to improve operational efficiency and on-time performance.
                       
                     
                                            Read full story →
                     
                   
                                       
                
       
                                        
                            Industry Solutions
                                Advertising
                 Customer Engagement
                 Education
                 Financial Services
                 Health
                 IoT
                 Media
                 Talent
                 Work
               
             
                            Developers
                                Documentation
                 Developer tools
                 SDKs
                 Stack Overflow
                 developerWorks
               
             
                            Company
                                With Watson
                 Watson Blog
                 Watson webinars
                 Contact sales
               
             
           
                        
                                                                                                            Industry Solutions
                     
                                                                                                Customer Engagement
                           Education
                           Financial Services
                           Health
                           IoT
                           Media
                           Talent
                           Work
                         
                       
                     
                   
                                                                      Developers
                     
                                                                                                Documentation
                           Developer tools
                           SDKs
                           Stack Overflow
                           developerWorks
                         
                       
                     
                   
                                                                      Company
                     
                                                                                                With Watson
                           Watson Blog
                           Watson webinars
                           Contact sales
                         
                       
                     
                   
                 
               
             
           
                                        
                
     
                        

",,Person, , , , , 
https://ibm.co/2GvWwiS,187446750783_10155529399155784,https://www.facebook.com/ibmwatson/posts/10155529399155784,"Should limits exist in the capabilities of artificial intelligence technology? Rob High, IBM Watson CTO, explains his theory on the concept of ethics in AI via ZDNet: ",Link,,,4/2/18 13:21, ,9520,9520,0,13312,13312,0,142,86,136,5,5,10851,7817,0,0,108,0,0,0,0,0,0,0,0,0,0,16,54.0,,19,54.0,,31,61.0,,,60,76.0,,,4,1.0,,4,1.0,,"Rob High, chief technology officer for IBM Watson, summarizes his presentation from the Mobile World Conference in Barcelona and discusses the state of AI, the relevance of the Turing Test, and what if any limits should be placed on the technology. Read more: https://zd.net/2q4jJ5n",https://zdnet2.cbsistatic.com/hub/i/r/2018/04/03/5af8260a-f9a1-4d92-ad1f-b65cba6941a0/thumbnail/770x578/39c79702589c1f1aa9f84b71b4ca02ae/18-robotic-artificial-intelligence-ai-deep-learning-computer-program-technology.jpg,https://www.zdnet.com/video/ethics-and-responsibilities-of-ai-should-limits-be-placed-on-tech/,anger,0.093168,neutral,0,"Rob High, IBM Watson CTO","Person, Company",Rob High,Person,anger,0.2263,positive,0.517534,"chief technology officer, Rob High, Mobile World Conference","Person, Company",chief technology officer,Person,joy,0.55182,negative,-0.485797,,"Person, Person, Company, Company, Company","Rob High, chief technology officer for IBM Watson, summarizes his presentation from the Mobile World Conference in Barcelona and discusses the state of AI, the relevance of the Turing Test, and what if any limits should be placed on the technology. Read more: https://zd.net/2q4jJ5n
                     Should we build AI weapons?                                                         
                     To spot spammers, Facebook's new algorithm looks at a profile's whole ecosystem                                                         
                     What it takes to make AI projects successful                                                         
                     Tesla Autopilot death: Final report blames Tesla, Apple, and NHTSA                                                         
                     Supply chain analytics might not be ready for coronavirus outbreak                                                         
                     Why AI's equity must improve                                                         
                     Costa Group turns to AI 'maths robot' to improve berry yield predictions                                                         
                     Cognizant‘s AI scientists demonstrate potential via Flappy Bird                                                         
                     Android 11 developer preview: 12 new features                                                         
                     AI strategy: How the EU hopes to put people first                                                         
                     Google’s AI chief explains machine learning for chip design                                                         
                     Europe unveils a new strategy for AI to show it is still a contender in the digital race                                                         
                     LG CNS deploys AI facial recognition gate service                                                         
                     How Intel thinks AI will change in the years to come                                                         
                     Cuttlefish-inspired smart camouflage could make for sneakier soldiers                                                         
Are humans capable of adapting to rapid change?
© 2020 CBS Interactive. All rights reserved.                     Privacy Policy |                     Cookies |                     Ad Choice |                     Advertise |                     Terms of Use |                     Mobile User Agreement                 
",,Person,sea green,X-ray film,photographic equipment,photographic film,X-ray film
https://ibm.co/2B2mebh,187446750783_10155526679735784,https://www.facebook.com/ibmwatson/posts/10155526679735784,Technologies like machine learning and artificial intelligence are already impacting many industries. Here are five jobs that will get the biggest productivity boost via ZDNet: ,Link,,,4/1/18 10:00, ,10904,10904,0,15186,15186,0,250,182,226,9,9,12572,8964,0,0,210,0,0,0,0,0,0,0,0,0,0,21,68.0,3.0,22,69.0,3.0,55,142.0,,,78,148.0,,,5,4.0,,5,4.0,,Technologies like machine learning and artificial intelligence are already impacting many industries. Here are five jobs that will get the biggest productivity boost.,https://zdnet4.cbsistatic.com/hub/i/r/2017/11/20/c7f6317d-aee7-49b4-b6f5-c735c89fcd0a/thumbnail/770x578/f7bec20243f3ca0b1d26d188936de9b0/aijobs.jpg,https://www.zdnet.com/article/five-tech-jobs-that-ai-and-automation-will-make-radically-more-efficient/?linkId=45489103,joy,0.539121,positive,0.684355,"machine learning, artificial intelligence, Technologies, jobs, biggest productivity boost",Company,machine learning,Company,joy,0.510987,positive,0.886319,"machine learning, artificial intelligence, Technologies",,machine learning,,joy,0.503687,positive,0.588463,,"Person, Person, Person, Company, Quantity"," 	The robot revolution has undoubtedly begun, but the jury is still out on exactly how many jobs will be lost to the machines, and how long it will take to happen. In the meantime, though, artificial intelligence (AI) is already impacting jobs in a variety of industries, changing the way a lot of work is getting done.
 	Whether it's the implementation of chatbots or machine learning-boosted big data tools, professionals are capturing the value of AI to increase their productivity. However, every job won't be impacted equally when it comes to these emerging technologies.
 	SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
 	Here are the five jobs that will see the biggest increase in efficiency from AI and automation.
 	1. Security professionals
 	The cybersecurity field has been utilizing AI and machine learning for some time, with platforms like IBM's Watson being used to complement the work of human practitioners. For example, many products use AI to determine the patterns of normal users, and alert human security professionals when abnormal behavior is detected.
 	""Currently, security relies on AI to target risk and to develop proactive threat management systems,"" said Gartner research director Carlton Sapp. ""However, we see this as aggressively advancing their capabilities, leading to more advanced threat management systems that automatically learn through reinforced training and more innovative ways to reduce risk.""
 	The biggest barrier to capturing the value of AI in security is trust. A recent Radware report stated that 57 percent of executives trust AI security systems ""as much or more than"" humans, but there's still room for growth.
On the other side of the fence, AI is also being used to develop cyber attacks. Security researchers created an AI-infused malware that was able to move past an anti-malware system by modifying itself to slip past the filters. This means that security professionals will likely need to fight AI tools used by hackers with AI tools of their own.
 	2. Business intelligence (BI)
 	Business intelligence, with its heavy focus on data analytics, stands to benefit heavily from the proliferation of AI. In addition to providing more in-depth insights, AI will also lessen the amount of work needed to build custom BI apps and tools.
 	Technologies such as Natural Language Processing (NLP) and Natural Language Generation (NLG) will help with the development of drag-and-drop graphical user interfaces (GUI) for BI, making it easier to get insights without custom coding a solution, according to Boris Evelson, vice president and principal analyst at Forrester Research. This means that data analytics will be ""directly available to non-data professionals,"" Evelson said.
 	AI will also make it easier for BI to process unstructured data, Evelson said. ""AI-infused BI will somewhat, albeit not completely, automate all of the steps necessary to transform data into formats and models that BI tools can work with -- relational structures, and so on,"" Evelson said. ""This includes machine learning-based data discovery and machine learning-based data curation -- cleansing, integration and so on.""
 	These changes will essentially make more data available for analysis, which will grow the number of jobs for data analysts as well, Evelson noted.
 	3. Help desk
 	The help desk is the ""the starting point for many machine learning projects"" in the enterprise, according to Nick Patience, co-founder and research vice president at 451 Research. A big part of this has to do with the introduction of chatbots, conversation-based robots that can handle simple questions via text-based input.
 	Chatbots have been used in customer service and on retail websites in recent years, but they are now growing in use for help desk requests. J.P. Gownder, vice president and principal analyst at Forrester Research, said that chatbots will soon be leveraged to handle tasks like employee onboarding and password resets, freeing up help desk pros to handle higher-level problems.
 	""In some cases, automation will replace human headcount in this space, allowing companies to redeploy technology talent elsewhere,"" Gownder said.
 	4. Software engineers/web developers
 	According to Gartner's Sapp, ""AI will become the new UI as it transforms how we enhance the user experience."" This has major implications for consumers, as it changes how they interact with devices or services, but it will also impact the engineers and developers designing those experiences.
SEE: Hiring kit: User experience specialist (Tech Pro Research)
 	Mobile developers may find it easier to create contextual experiences for users, since AI will automatically bring in the most relevant information. On the software side of things, AI will help in the creation of the product itself, automating security and possibly even the development of additional features.
 	""Software engineers will see radical changes on using AI to develop more resilient systems and applications, ranging from self-healing applications to automated code development,"" Sapp said.
 	5. CIO
 	In addition to affecting the work of frontline employees, AI and automation will also impact the lives of IT leaders and management. CIOs, in particular, will see a major change in the way they view the organization, said Forrester's Gownder.
 	""The CIO's workforce will be comprised of a mix of digital workers -- RPA bots, AI programs, chatbots -- and humans, and, keeping this mixed workforce in mind, the CIO will need to hire and train human workers for RQ -- the Robotics Quotient, Forrester's term for the skills required to work well with machines and AI,"" Gownder said.
 	This new organizational structure could make it easier for the CIO to more effectively delegate workforce resources, setting their human employees on the most pressing tasks.
 	There's also the augmentation of the personal assistant. While only the most senior executives tend to have a human assistant, said 451 Research's Patience, in the future every worker will have access to an AI-powered one. This will lead to more efficient scheduling, making it easier for CIOs to plan meetings that work for everyone.
",,Person,purplish blue,source of illumination,lamp,electric lamp,light bulb
https://ibm.co/2pRDP1T,187446750783_10155522189365784,https://www.facebook.com/ibmwatson/posts/10155522189365784,"&quot;One of Watson’s greatest values is being able to train it on specific industries and their corresponding data. It’s highly attuned to what our clients need. What’s exciting about my role is I get to sit at this critical intersection — my role is one that helps connect our IBM Cloud technology with Watson. &quot; Get to know Kelly Abuelsaad from the IBM Watson and Cloud platform team, who has more than 35 patents in her name. 
",Link,,,3/30/18 10:00, ,9054,9054,0,12591,12591,0,120,84,103,4,4,10582,7640,0,0,99,0,0,0,0,0,0,0,0,0,0,12,51.0,2.0,12,53.0,3.0,53,34.0,,,67,36.0,,,4,,,4,,,"With over 35 patents, Kelly Abuelsaad is a member of the IBM Watson and Cloud Platform team, where she helps bring AI to clients.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/03/blog_kellyWatson_png_socialTile_032818.png,https://www.ibm.com/blogs/watson/2018/03/how-watson-ushers-creativity-through-collaboration/,joy,0.188572,positive,0.883383,"Watson’s greatest values, critical intersection","Person, Person, Company",Watson’s greatest values,Person,joy,0.081766,neutral,0,"Kelly Abuelsaad, member of the IBM Watson, patents","Person, Company",Kelly Abuelsaad,Person,joy,0.652825,positive,0.742267,,"Company, Person, Person, Person, Person","Share this post:
With over 35 patents, Kelly Abuelsaad has always had a passion for creating, whether she’s been playing guitar or finding a new way to apply technology to everyday tasks.
Kelly is a member of the IBM Watson and Cloud Platform team, where she helps bring AI to clients via the cloud. From tinkering on projects in her studio to working within a large group to find answers and patent new technologies, Kelly never stops thinking about what’s possible with AI.
Kelly expands on her career path in AI, the value of teamwork during the creative process, how she strives to improve efficiency through inventing — and the role her team has played in helping IBM achieve 25 years of patent leadership.
 How did you become a Master Inventor at IBM? What’s the process of inventing something?
Technology has always fascinated me. It holds such opportunity and great promise that I couldn’t help but tinker in computers and science at a very early age. I took BASIC in high school and was hooked. I ended up majoring in information technology because in IT, you work with an entire system. You build and orchestrate a whole data center and you get to understand how things intertwine and operate from the ground up. At IBM, my first job was as a systems administrator on a developer team. I was struck by how great the technology was, but it needed to be simpler. It needed to be easy for customers to understand and use.
That’s how I eventually came to be a Master Inventor at IBM. A Master Inventor is frequently involved in a number of areas – including inventing new products and services, mentoring others and evaluating ideas. One thing I’ve learned is that solving technical issues is only one part of what it means to be a successful innovator. Inventing involves brainstorming with colleagues and working to develop applications that could become patents or core services for our clients. It’s about being collaborative, sharing ideas – and knowing how to work with people. I’ve always been what I consider to be a “tech person.” I enjoy tinkering on my own, and still do that quite frequently – but I’ve grown to understand the value of creativity and the perspective of others. I honestly have found the whole brainstorming process fun and addictive.
An invention is a solution to a problem, and there are always multiple solutions to any given problem. I start by asking, “Is the solution I’m developing unique?” Then I next ask, “Is the solution I’m coming up with better than other solutions?” For example, if you need a better way to tie your shoes and you develop an invention to help this problem but it takes five minutes longer, it’s technically unique, but not very useful. If what I’m creating makes a process faster and more adaptable, that’s when I think there might be something there. I also factor in if it’s useful for IBM, in terms of it positively impacting our business.
How are you helping to change the way businesses work? 
One of Watson’s greatest values is being able to train it on specific industries and their corresponding data. It’s highly attuned to what our clients need.
What’s exciting about my role is I get to sit at this critical intersection — my role is one that helps connect our IBM Cloud technology with Watson. The amount of data that’s in the world is exploding. Tools like Watson help us make sense of all that information and knowledge, while advanced cloud platforms can process and securely manage that data. Without both those pieces, neither is as valuable. I’m responsible for continuing to connect these dots, making the process more seamless and intuitive by creatively applying these technologies.
A tangible output of that, which gets me out of bed in the morning? AI is evolving, scaling and becoming more accessible, every day. The progress this industry has made in just a few years is incredible. We are constantly improving Watson so it can learn better, make more sense of data and easily train models according to each industry.
My job is to create common components so our brilliant IBMers who are creating the internal intelligence of Watson can continue focusing on those algorithms without being hindered. The result is that the capabilities of Watson are improving at a faster rate and we have better response times for training and serving models.
You play guitar. You’re a new mom. How do you think these important roles and skills outside of technology have improved your technological creativity? 
If you’re playing an instrument, you can read the music notes off a sheet and play a song. In the same vein, if you’re a software developer, you can get design plans and write the code to create a program. You do both by following the requirements; you’re following someone else’s instructions.
You can create wonderfully beautiful things this way and have lots of fun doing it. However, I’ve found a whole new level of enjoyment and empowerment in coming up with my own ideas – writing that song myself, kickstarting a new invention myself. This can be very hard because putting your own ideas out there for others to listen to makes you vulnerable. But if having a son has taught me one thing, it’s to not take myself too seriously. I’ve learned that parenting often involves coming up with creative solutions. Some ideas end up being great, and some end up being less than stellar. But in the process, I’ve learned how creative I can be by just allowing myself to take a chance.
I encourage everyone I work with to be creative in many different ways. The more experience you have, the more things you’ll learn and the better perspective you’ll have. I’ve learned, quite by accident as I never thought of myself as a creative person, that creativity is a skill that is earned through experience. Get out, try new things — and most importantly, enjoy what you do.
For more information about IBM Watson, visit ibm.com/watson. You can also follow Kelly on Twitter at @kellyabls.
",,Company,coal black,woman,person,female,woman
https://ibm.co/2GhZPhy,187446750783_10155519285910784,https://www.facebook.com/ibmwatson/posts/10155519285910784,How a digital-only bank created a Watson-powered chatbot called RoboBrain that improved response rates for customers by more than 40%: ,Link,,,3/29/18 11:22, ,10197,10197,0,13843,13843,0,244,136,158,2,2,10561,7628,0,0,195,0,0,0,0,0,0,0,0,0,0,32,108.0,2.0,33,109.0,2.0,55,89.0,,,64,94.0,,,1,1.0,,1,1.0,,"Customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank",https://d1902livswy8rb.cloudfront.net/dimg/800x800/dimg/dreamstime_s_34490308-2.jpg,https://www.cmo.com.au/article/635526/ubank-ai-vision-expands-rollout-robobrain/,joy,0.111889,positive,0.692266,response rates,Quantity,response rates,Quantity,joy,0.124299,positive,0.566024,"IBM Watson capabilities, one-stop, one-screen solution, solution","Person, Company",IBM Watson capabilities,Person,joy,0.57428,positive,0.701942,launch of RoboBrain,"Person, Company, Person, Person, Company, Person, Company, Location","UBank’s CMO says the launch of RoboBrain, a hyper-personalised cognitive assistant, is dramatically improving customer response times and a massive leap forward in the bank’s AI journey.   
The digital-only banking group took its first steps into AI last year with the launch of RoboChat, a chatbot designed to help customers through the home loan application process. In less than 12 months, RoboChat has been asked more than 22,000 questions, with over 80 per cent answered correctly on the first attempt.   
“After the success of RoboChat, we wanted to find a solution that our people could use and benefit from directly,” UBank CMO, Jo Kelly, told CMO. 
This led to RoboBrain, designed and developed by UBank’s North Sydney-based team in collaboration with IBM. The customised AI solution relies on IBM Watson capabilities to create a one-stop, one-screen solution for searching information at UBank.   
In the past, the UBank team had to move between a handful of different platforms in order to find the answer to customer questions, Kelly explained. Consolidating a number of the bank’s knowledge bases, RoboBrain provides immediate information for employees in one spot.   
“Now, thanks to RoboBrain, we’ve got a one-stop portal of information where we can search information and find the answer almost instantly,” she said.     
By typing in a question in natural language, the UBank team on the phone or on LiveChat can find answers in approximately two seconds to thousands of questions asked by customers, such as “what was the interest rate in June 2011?” or “how do I set up a regular transfer?”.    
Kelly said RoboBrain improves on the overall customer experience by making interactions as convenient as possible.    
“Customers don’t want to spend their time talking to their bank, so when they get in touch with us over LiveChat, Secure Mail, Facebook or on the phone, we need to meet their expectations and help them as quickly as we can,” she said.   
Since going live, RoboBrain has sped up processes for more than 40 per cent of UBank’s 200 employees, and improved response time for more than 400,000 Australian customers, cutting down search time by 33 per cent.   
For Kelly, AI is a major focus area - and a key to marketing success - at the digital bank.   
“We see AI as a key enabler in disrupting the home loan market and changing the end to end process of buying a home from applying to approval and then settlement. We believe it’s important to embrace technologies to adapt to the ever-increasing expectations of our customers and create a more personalised experience,” she said.   
Asked what’s next in terms of AI, Kelly said UBank flagged more innovation around customer service. RoboBrain has been trained to display and share complex information in real-time, and like any AI-based solution, the more it’s used, the smarter it gets, she noted.   
RoboBrain will learn and improve by adapting to the search terms used, based on the rating applied, and through ongoing training by UBank experts.   
",launch of RoboBrain,Person,blue,liquid metal reactor,apparatus,nuclear reactor,liquid metal reactor
https://ibm.co/2CKVBZB,187446750783_10155515662205784,https://www.facebook.com/ibmwatson/posts/10155515662205784,"One of the solutions on the mission to use tech for global social justice issues is to increase the number of women in the pipeline—from a very young age, starting with kindergarten...to help address that, IBM partnered with the American Federation of Teachers, national education leaders and teachers with support from the Stavros Niarchos, Carnegie, and Ford Foundations to launch Teacher Advisor With Watson for students in grades K through five. Since its launch last year, 6,000 teachers have signed on for the free curriculum.  ",Link,,,3/28/18 10:00, ,7866,7866,0,10698,10698,0,112,65,72,7,8,9204,6764,0,0,89,0,0,0,0,0,0,0,0,0,0,12,52.0,1.0,12,53.0,1.0,42,24.0,,,47,25.0,,,6,2.0,,5,2.0,,,,https://www.huffingtonpost.com/entry/tools-for-filling-stem-pipeline-saving-the-world-with_us_5a2e94c1e4b04e0bc8f3b6bb,sadness,0.381942,positive,0.842379,"American Federation of Teachers, global social justice issues","Person, Organization, Company, Company, Person",American Federation of Teachers,Person, , , , , , , , ,joy,0.59164,positive,0.524457,,"Person, Person, Company, Person, Person, Person, Person, Person, Person, Person, PrintMedia, Organization, Person, Person, Company, Company, Organization, Organization, Company, Person, Organization, Company, Quantity","“This is an opportunity for women and girls. We need to start early in terms of identity and building skills,” says Crozier, who was awarded The Overture Catalyst Award at the event that included speakers  Malika Saada Saar, senior counsel on Civil & Human Rights at Google; Roya Mahboob, CEO of Afghan Citadel Software Company; Rochelle King, Global VP of product design and insights at Spotify;  Sarah Kauss, CEO and founder of S'Well; Lakshmi Puri, Assistant Secretary-General of the United Nations and Deputy Executive Director of UN Women; Antonia Hylton, correspondent and producer for VICE; Seema Kumar, VP, Innovation, Global Health, and Policy Communication at Johnson & Johnson; and Valerie Jarrett, Civic Leader and Former Senior Advisor to President Obama, who received  theOverture Digital Humanitarian Award.
“The most influential factors behind fewer women in STEM programs are the stereotypes that have been applied to women for centuries. Some of these stereotypes include ‘women aren’t good at math, women cannot raise a family and have a successful career,’ and the most damaging, ‘girls create drama,’” write Hannah Christensen and Christina Christensen in Ashland Daily Tidings.
To help address that, IBM partnered with the American Federation of Teachers, national education leaders and teachers with support from the Stavros Niarchos, Carnegie, and Ford Foundations to launch Teacher Advisor With Watson for students in grades K through five. Since its launch earlier this year, 6,000 teachers have signed on for the free curriculum.
“Elementary school teachers have expressed a critical need for easy-to-use, well-designed math resources and ongoing support, as they are faced with the pressures of limited time, higher academic standards, diverse student needs, and the responsibility to teach many subjects and multiple grade levels,” according to the IBM release.
“The UNESCO Institute for Statistics estimates that only around 30  percent of researchers worldwide are women . Similarly, according to the Economics and Statistics Administration of the US Department of Commerce only 24 per cent of STEM jobs are held by women , with individual disciplines like Engineering having a significantly worse gender bias,” according to the site, Stem Women.
“There’s also extensive literature on biases against  women in STEM affecting all aspects of academia, including hiring, publishing, citation counts and teaching. Given these disheartening statistics, it is clear that there is still a long way to go before we can even start thinking about gender equality in STEM,” according to STEM Women.
",,Person, , , , , 
,187446750783_10155513073485784,https://www.facebook.com/ibmwatson/posts/10155513073485784,"Watch a replay of the talk by Watson's young developer, 14-year-old Tanmay Bakshi on using deep learning to save young lives from Think 2018.",Link,,,3/27/18 11:47, ,7907,7907,0,10849,10849,0,139,94,115,0,0,9368,6795,0,0,118,0,0,0,0,0,0,0,0,0,0,14,50.0,,15,51.0,,43,57.0,,,51,64.0,,,,,,,,,,,,joy,0.459293,positive,0.778153,"deep learning, Watson's young developer, 14-year-old Tanmay Bakshi, replay of the talk","Person, Quantity, Person",deep learning,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2DNYtFb,187446750783_10155509793210784,https://www.facebook.com/ibmwatson/posts/10155509793210784,"Available now, Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI.
",Link,,,3/26/18 10:10, ,14471,14471,0,20638,20638,0,483,281,334,10,10,13250,9592,0,0,372,0,0,0,0,0,0,0,0,0,0,62,227.0,2.0,63,233.0,2.0,131,167.0,,,161,173.0,,,6,4.0,,6,4.0,,"Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity. Consider three distinct examples – 1. Fixing issues with Visual Diagnosis User: A person in the field equipped with an iPhone trying to visually diagnose a problem. Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage. 2. Recommendations based on Visual analysis User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations. Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying…",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/03/GettyImages-1086731554.jpg,https://www.ibm.com/blogs/watson/2018/03/ai-everywhere-ibm-watson-apple-core-ml/,anger,0.075048,neutral,0,Watson Visual Recognition Service,"Person, Company, Company",Watson Visual Recognition Service,Person,sadness,0.551904,negative,-0.449804,Visual Diagnosis User,Person,Visual Diagnosis User,Person,joy,0.548225,positive,0.631349,number of users,"Person, HealthCondition, Company, Person, Company","Integrating AI in everyday enterprise and consumer applications is steadily becoming the new normal. In a mobile-first world, the number of users accessing AI through apps on their devices is rapidly growing. Very often, their experience is hindered by inconsistencies in the quality or availability of network connectivity.
Consider three distinct examples –
1. Fixing issues with Visual Diagnosis
User: A person in the field equipped with an iPhone trying to visually diagnose a problem.
Usage: This could be applied in various forms of diagnosis, from issues in home appliances to jet engines; from faulty wiring to metal pipe rust; from error codes in machines to electronic component damage.
2. Recommendations based on Visual analysis
User: A person using an iPhone or iPad to examine an unfamiliar item and receiving additional information and recommendations.
Usage: This could be used for recommendations – from places or scenes for travel assistance to new products in retail store; from identifying unknown or complex machine parts to classifying plants or food.
3. Visual triggers for a business process
User: An end user and a trigger for a downstream business process
Usage: Business processes range from creating a work order for repair to updating a shopping cart for purchase; from intervening in quality control to safety procedure in manufacturing; from initiating an insurance claim to a collaborative analysis for experts in medicine.
These are a diverse set of scenarios with a common thread running through them: the need for a low-latency and rich insight for a human or a downstream process.
Imagine a scenario where a user is trying to access results while on-the-go (changing network speeds), or in hard-to-reach places (manufacturing plants, buildings, store interiors, remote areas, etc.). This impacts the user’s ability to do the job, which can have a domino effect on business processes and the bottom line for companies.
The most compelling way to empower that user combines relevant AI insights, at the time of need, without the user having to worry about network connectivity issues.
To set this in motion, you need:
1. A technique to handle tradeoffs between immediate insights, irrespective of connectivity, with richer insights from the cloud, allowing the user to focus on the task at hand.
2. Collaborative methods and tools for users, developers and/or data scientists to build solutions in a way that allows them to focus on the higher end of the solution spectrum.
3. An approach with associated technology that enables a process of rapid iteration to keep up with constantly changing data and other surrounding factors.
Components of this solution are being successfully used by enterprises and consumers across industries and geographies.
Watson services on the IBM Cloud provide rich and relevant insights from a variety of public and enterprise data sources to applications. IBM’s approach to data and privacy with Watson ensures that client data and insights are not shared with IBM or third parties, and that client data does not contribute to training a centralized knowledge graph.
Apple Core ML is a foundational machine learning (ML) framework that lets you integrate ML models into your app. Core ML delivers optimized performance for Apple products with minimal memory footprint and battery consumption impact. User privacy is protected as data is stored locally and encrypted by default.
What’s new – Bringing it together with a seamless experience
Available today, Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI.
These are key aspects of what is now available to the ecosystem of users and developers. Read more about the partnership here.
1. Watson SDK low latency, and offline process for custom Visual Recognition models using Core ML with the rich insights from the Watson services on the cloud.
2. Watson Studio provides a low-code, end-to-end collaborative environment that enables developers to quickly and easily catalog, classify, provision, and train their data and models.
3. Developer assets and best practices including Code Patterns for developers to get started, starter kits to quickly build iOS apps that combine these Watson services with other components, and code examples to get started now.
These offerings are the first step towards mitigating challenges for users, developers, and enterprises. Companies have already started building enhancements to applications that leverage Watson Visual Recognition Service for Core ML.
For the developer, this drives a paradigm for building once and deploying at heterogeneous endpoints. For the user, this translates to growth in the expertise spectrum and higher productivity. For the enterprise, this is an inevitable step toward mobile and AI revolutionizing how we work.
Watch the demo to see how this all comes together for part and issue identification on Arduino boards, a representative for any component.
",number of users,Person,blue,X-ray film,photographic equipment,photographic film,X-ray film
https://ibm.co/2BQvtMb,187446750783_10155507301705784,https://www.facebook.com/ibmwatson/posts/10155507301705784,"Whenever you ask your phone for directions, order paper towels from a virtual assistant, or give any non-human entity a command, you’re speaking to a device powered by AI. Explore deeper into Watson capabilities via Mashable: ",Link,,,3/25/18 11:00, ,7590,7590,0,10404,10404,0,124,64,73,5,5,8461,6023,0,0,108,0,0,0,0,0,0,0,0,0,0,12,66.0,1.0,12,67.0,1.0,30,37.0,,,34,39.0,,,3,2.0,,3,2.0,,"AI may seem like a confusing phenomenon, but we often interact with artificial intelligence technology on a daily basis.",https://mondrian.mashable.com/2017%252F12%252F21%252F6b%252F3d312f1f63af4fc99a8ceb433c2e2ee9.dd1ec.jpg%252F1200x630.jpg?signature=kcqxN0T_UIzf3OptSIumYQrUYXs=,https://mashable.com/2018/01/17/ways-interact-artificial-intelligence/#TeGG1Rp9Ksq3,anger,0.28562,neutral,0,"order paper towels, virtual assistant","Person, Person",order paper towels,Person,sadness,0.364451,positive,0.295635,"daily basis, confusing phenomenon",Person,daily basis,Person,joy,0.509032,positive,0.580654,artificial intelligence,"Person, Person, Person, Person, Company, Company, Person, Company, Person","If someone were to say to you that you’ve spent all day interacting with artificial intelligence, you’d probably stop and try to recount any instances of accidentally running into a robot. 
Despite what’s constantly being hammered into our brains via science fiction movies and television, AI comes in many forms, which may surprise you. Not only has artificial intelligence become integrated within a number of industries, but it’s teaching people how to streamline business and optimize their lives.
From social media to public service, some people are interacting with artificial intelligence every single day and it may surprise you how broadly it is being adopted. Here are some ways we’re already using AI on the daily. 
Sometimes the integration of artificial intelligence presents itself in a more obvious manner. Take virtual assistants, for example: Increasingly when you sign onto a website and are greeted with a chatbot, you’re more likely to interact with a computer-generated assistant and referred to a human only if your question is quite complex. You'll know pretty quickly whether it's a human or a robot, like how UBank's Robochat introduces itself.
UBank recently launched RoboChat, an IBM Watson-powered supercomputer that can answer questions about home loan applications. 
“In essence, we’re trying to make it as easy as we can for customers to do what some of them consider to be a cumbersome process,” said UBank’s head of digital Jeremy Hubbard, in an interview with The Australian. RoboChat is designed to answer questions relating to home loan applications through natural language processing – that means the bot can understand the intent of what you’re asking and carry a conversation like a human would. 
RoboChat is powered by IBM Watson, which is an artificial intelligence platform that ingests and comprehends massive amounts of data. For UBank, Watson provided the conversational capability. 
As far as one’s daily interactions with artificial intelligence, you get a front-row seat to the simplicity of AI every time you speak to a virtual assistant. 
Whenever you ask your phone for directions, order paper towels from a virtual assistant, or give any non-human entity a command, you’re speaking to a device powered by AI. Virtual assistants use natural language processing (NLP) to understand what you say to then provide a response to your query.
Social media is another platform that benefits from the ever-expanding brain of artificial intelligence — Twitter recently brought Watson on board to help prevent abuse by tracking problematic accounts. 
""Watson is really good at understanding nuances in language and intention,” said vice president of data strategy at Twitter Chris Moody, in an interview with The Telegraph, ""What we want to do is be able to identify abuse patterns early and stop this behaviour before it starts."" The technology scans accounts engaged in abusive behaviour by seeking out certain harmful keywords from users and applying an understanding of the context in which they are written.  
Another area where AI has made its way into our everyday lives? Transportation. Ride-share companies utilize AI to improve the function and precision of their apps. Machine learning helps provide ETAs for arrivals using data from millions of past trips — in addition to things like distance and speed limit — to provide estimated arrival times. 
Although it may seem like a natural fit for a tech company to use artificial intelligence, there are even more surprising ways AI impacts our lives that we may not realize. Take your evening glass of wine, for example. AI has found its way into one New Jersey vineyard and streamlined the way grapes are grown.
E. & J. Gallo Winery recently looked to Watson to develop an intelligent irrigation system. Watson monitors weather reports and uses remote sensor data to measure and distribute the optimal amount of water that each grapevine needs to survive and flourish. By mining data from sources like The Weather Company, which has data from over two billion locations, E. & J. Gallo Winery has developed a custom irrigation plan that’s allowed them to reduce water usage by 25 percent.
While the prospect of an AI-engrained life may seem a bit intimidating, it’s humans who are really in control. In fact, humans often supervise artificial intelligence processes, which is the case with “Deep Learning.”
Deep learning is a computation model that can interpret and make sense of information in ways that previously were not possible with traditional computing. In a way, it learns like a human does, taking on feedback and adjusting to improve. 
Although deep learning allows machines to learn like humans, they do not have the ability of human judgement. No matter how much data you present to a deep learning model, it is not able to reason and judge what is happening on its own. Rather, it requires humans to oversee and draw conclusions from the AI processes.
“Deep learning has been successful for well-defined kinds of problems where there’s lots of labelled data, and it’s good at perception and classification problems rather than real reasoning problems,” said IBM Distinguished Researcher Murray Campbell. “The next big opportunity is to do for reasoning what deep learning did for perception and classification.”
So, what will a machine be able to do with the type of skills associated with deep learning? Researchers hope that they’ll be able to solve problems that involve human traits like common sense.
“Humans know that if you put an object on the table, it’s likely to stay on the table unless the table’s tilted,” explained IBM Director of AI and Cognitive Analytics Research Aya Soffer.
“But nobody writes that in a book — it’s something implicit. Systems don’t have this common-sense capability.”
The AI landscape is constantly changing and improving. Because of the strides IBM has made with Watson, the current state of artificial intelligence is one that is as equally impressive as it is necessary. We’ve already grown so dependant on artificial intelligence to give us directions, provide public service, help us with taxes, and keep us safe in the air.
Some may find that a day with artificial intelligence is virtually indistinguishable from a day without it, others couldn’t imagine going to work without Watson’s intuitive brain. What AI’s touch will look like 50 years from now is anyone’s guess.
",artificial intelligence,Person,emerald,shower room,indoors,shower room,-
https://ibm.co/2G9HSxm,187446750783_10155504845270784,https://www.facebook.com/ibmwatson/posts/10155504845270784,"The job market will continue to shift in 2018, as technologies such as artificial intelligence impact many industries, and mobile changes the way people find and apply for jobs via TechCrunch: ",Link,,,3/24/18 10:00, ,10722,10722,0,14537,14537,0,251,174,192,5,5,12202,8761,0,0,217,0,0,0,0,0,0,0,0,0,0,15,82.0,3.0,17,82.0,3.0,38,142.0,,,46,146.0,,,2,3.0,,2,3.0,,"AI and a tech jobs boom are poised to change the employment landscape in 2018, according to Glassdoor.",https://tr3.cbsistatic.com/hub/i/r/2017/12/19/208acec2-2087-4326-8cc5-e5d798e74cdc/thumbnail/770x578/4b07d8839aea6569758022ab9916227b/istock-655801624.jpg,https://www.techrepublic.com/article/the-5-most-important-tech-job-trends-for-2018/,sadness,0.252061,neutral,0,"job market, artificial intelligence impact, way people",,job market,,joy,0.343617,positive,0.58156,tech jobs boom,Person,tech jobs boom,Person,joy,0.501719,positive,0.61787,job market,"Person, Person, Organization, Company, Quantity, Quantity, Person, GeographicFeature","The job market will continue to shift in 2018, as technologies such as artificial intelligence (AI) impact many industries, and mobile changes the way people find and apply for jobs, according to a new report from job search site Glassdoor. 
Despite two major hurricanes and political challenges, the US economy experienced a strong year, Andrew Chamberlain, Glassdoor's chief economist, wrote in the report: 1.9 million new jobs were added in 11 months, and stock markets reached an all-time high. Additionally, the nation's unemployment rate dropped to a 17-year low, fueling a talent war in tech, healthcare, e-commerce, and other professional services, he added. 
""This year has been good for many--but not all--workers,"" Chamberlain wrote. ""Job seekers who've mastered key skills in data science, software development, and health professions are seeing rising pay and benefits. At the same time, average wages for many remain stubbornly flat. Despite a healthy job market overall, job growth is sharply divided, with tech skills earning a premium and others being left behind by rising artificial intelligence (AI) and automation."" 
SEE: IT jobs 2018: Hiring priorities, growth areas, and strategies to fill open roles (Tech Pro Research)
Tech jobs continue to spread: In 2017, a growing number of employers in  finance, retail, manufacturing, and other traditional industries began creating more tech roles. And a growing share of tech hiring is happening far from Silicon Valley, in more affordable tech clusters such as Seattle, Austin, Detroit, Dallas, and Raleigh, Glassdoor found. 
Here are five job disruptions to watch for 2018, according to Chamberlain. 
1. AI changing the future of work
AI and automation will impact nearly every facet of the workforce in some way in the future. However, certain industries--particularly human resources and finance--are more likely to see big changes in 2018. New AI tools are complementing the skills of human workers in these areas, and changing many established roles that are easy to automate. 
2. Modernization of mobile job applications
Since most job application systems were created in the past, applying for a job via a mobile device can be a difficult process, Chamberlain said. It's likely that 2018 will see growth in mobile application platforms, though it may take time before they are commonly used.
3. Job growth in tech, healthcare, and labor-intensive roles
Innovations in tech will drive job creation in 2018, in both tech and traditionally non-tech industries, Chamberlain said. Significant demographic shifts, such as the aging population, will also lead to massive workforce changes. Many traditional jobs, such as waiters and truck drivers, that cannot be automated easily in the near terms will continue to grow in number, he predicted.
4. Increased transparency in the application and interview process
The online job application process remains opaque for many employees, Chamberlain said. In 2018, it's likely that job seekers will gain more visibility into both the application process and the status of job applications in real time.
5. Encouraging employee passions through role experimentation
Companies are increasingly finding ways for employees to experiment with different roles within the company, to tap the changing skills and passions of their workforce, reduce turnover, and better match talent to positions, Chamberlain said. It's likely this will continue and expand in the new year. 
",job market,Person,gray,checkout counter,furniture,table,checkout counter
https://ibm.co/2ouW1yG,187446750783_10155502606165784,https://www.facebook.com/ibmwatson/posts/10155502606165784,"Machine learning models need to be trained on large amounts of data to ensure that they are accurate, but for many problems, that large data  set simply doesn’t exist. IBM Watson CTO Rob High believes this is a solvable problem – learn why via TechCrunch: ",Link,,,3/23/18 11:09, ,11022,11022,0,14906,14906,0,362,201,230,6,6,12695,9196,0,0,320,0,0,0,0,0,0,0,0,0,0,29,185.0,2.0,30,190.0,2.0,69,138.0,,,82,148.0,,,3,3.0,,3,3.0,,"For IBM Watson CTO Rob High, the biggest technological challenge in machine learning right now is figuring out how to train models with less data. ""It's a challenge, it's a goal and there's certainly reason to believe that it's possible,"" High told me during an interview at the annual Mobile World Congress in Barcelona.",https://techcrunch.com/wp-content/uploads/2018/02/img_20180227_171316.jpg?w=533,https://techcrunch.com/2018/02/27/ibm-watson-cto-rob-high-on-bias-and-other-challenges-in-machine-learning/,sadness,0.177177,positive,0.318055,"IBM Watson CTO Rob High, large amounts of data","Person, Company",IBM Watson CTO Rob High,Person,joy,0.506627,positive,0.633511,"IBM Watson CTO Rob High, biggest technological challenge","Person, Company, Organization",IBM Watson CTO Rob High,Person,joy,0.54021,positive,0.485841,IBM  Watson CTO Rob High,"Person, Person, Company, Person, Person, Person, Location, Organization, Person, Company","For IBM  Watson CTO Rob High, the biggest technological challenge in machine learning right now is figuring out how to train models with less data. “It’s a challenge, it’s a goal and there’s certainly reason to believe that it’s possible,” High told me during an interview at the annual Mobile World Congress in Barcelona.
With this, he echoes similar statements all across the industry. Google’s AI chief John Giannandrea, for example, also recently listed this as one of the main challenges the search giant’s machine learning groups are trying to tackle. Typically, machine learning models need to be trained on large amounts of data to ensure that they are accurate, but for many problems, that large data set simply doesn’t exist.
High, however, believes this is a solvable problem. Why? “Because humans do it. We have a data point,” he said. One thing to keep in mind is that even when we see that evidenced in what humans are doing, you have to recognize it’s not just that session, it’s not just that moment that is informing how humans learn. We bring all of this context to the table.” For High, it’s this context that’ll make possible training models with less data, as well as recent advances in transfer learning, that is, the ability to take one trained model and then use this data to kickstart the training of another model where less data may exist.
The challenges for AI — and especially conversational AI — go beyond that, though. “On the other end is really trying to understand how better to interact with humans in ways that they would find natural and that are influential to their thinking,” says High. “Humans are influenced by not just the words that they exchange but also by how we encase those words in vocalizations, inflection, intonation, cadence, temper, facial expression, arm and hand gestures.” High doesn’t think an AI necessarily needs to mimic these in some kind of anthropomorphic form, but maybe in some other form like visual cues on a device.
At the same time, most AI systems also still need to get better at understanding the intent of a question and how that relates to individuals’ previous questions about something, as well as their current state of mind and personality.
That brings up another question, though. Many of these machine learning models that are in use right now are inherently biased because of the data with which they were trained. That often means that a given model will work great for you if you’re a white male but then fails black women, for example. “First of all, I think that there’s two sides to that equation. One is, there may be aggregate bias to this data and we have to be sensitive to that and force ourselves to consider data that broadens the cultural and demographic aspects of the people it represents,” said High. “The flip side of that, though, is that you actually want aggregate bias in these kind of systems over personal bias.”
As an example, High cited work IBM did with the Sloan Kettering Cancer Center. IBM and the hospital trained a model based on the work of some of the best cancer surgeons. “But Sloan Kettering has a particular philosophy about how to do medicine. So that philosophy is embodied in their biases. It’s their institutional biases, it’s their brand. […] And any system that is going to be used outside of Sloan Kettering needs to carry that same philosophy forward.”
“A big part of making sure that these things are biased in the right way is both making sure that you have the right people submitting for and who these people are representative of — of the broader culture.” That’s a discussion that High says now regularly comes up with IBM’s clients, too, which is a positive sign in an industry that still often ignores these kind of topics.
",IBM  Watson CTO Rob High,Person,coal black,stringer (wooden),support,timber,stringer (wooden)
,187446750783_10155497802905784,https://www.facebook.com/ibmwatson/posts/10155497802905784,Watch a live demo of TJBot here at Think!,SharedVideo,,,3/21/18 9:21, ,3126,3126,0,4281,4281,0,94,77,113,2,2,3815,2761,0,0,86,0,0,0,0,627,670,0,0,0,1053526,,24.0,1.0,,24.0,1.0,75,5.0,,,108,5.0,,,,2.0,,,2.0,,,,,joy,0.558922,positive,0.714622,live demo of TJBot,,live demo of TJBot,, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2HQo7eM,187446750783_10155496532915784,https://www.facebook.com/ibmwatson/posts/10155496532915784,"&quot;Deep-Learning-as-a-Service, unveiled at IBM’s annual IT industry conference in Las Vegas, seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power,&quot; via The Wall Street Journal: ",Link,,,3/20/18 19:13, ,10857,10857,0,14768,14768,0,340,218,260,7,7,11958,8718,0,0,290,0,0,0,0,0,0,0,0,0,0,24,157.0,1.0,24,160.0,2.0,101,134.0,,,119,141.0,,,3,4.0,,3,4.0,,"Deep-Learning-as-a-Service, unveiled Tuesday in Las Vegas, aims at easing the complex process of creating deep-learning algorithms for business data, the company said.",//si.wsj.net/public/resources/images/BN-XY012_0320_c_P_20180320173444.jpg,https://blogs.wsj.com/cio/2018/03/20/ibm-tool-seeks-to-bridge-ai-skills-gap/,joy,0.313567,positive,0.521166,"Deep-Learning, IBM’s annual IT industry conference, large amounts","Company, Location",Deep-Learning,Company,joy,0.525414,positive,0.928478,"Deep-Learning, complex process, Las Vegas, a-Service",Location,Deep-Learning,Location,joy,0.473438,positive,0.702652,,"Company, Company, Person, Person, Person, Location","Deep-Learning-as-a-Service, unveiled at IBM’s annual IT industry conference in Las Vegas, seeks to lower barriers to deploying AI and deep-learning tools, a complex and painstakingly repetitive process that requires large amounts of computing power, the company said.
The new service allows companies to upload data in Watson Studio, IBM’s cloud-native platform for data scientists, developers and business analysts. There, they can create deep-learning algorithms for datasets – known in AI parlance as a “neural network” – using a drag-and-drop interface to select, configure, design and code the network.
IBM also has automated the repetitive process of fine-tuning deep-learning algorithms, with successive training runs started, monitored and stopped automatically.
For many firms, the complexity of creating smart algorithms from scratch has kept them from leveraging AI to parse massive stores of data for business value, the company said.
Ginni Rometty, IBM’s chairman and chief executive, called data the “basis for competitive advantage,” in her opening remarks at Tuesday’s event.
In today’s cloud-powered markets, she said, businesses need to leverage multiple digital platforms, while embedding smart tools into every process they run. “You’ve got to keep making AI easier to use,” she added.
In a recent Gartner survey, chief information officers ranked AI, along with digital security and the Internet of Things, as the hardest technologies to implement, citing hard-to-find skills required to make them work. The survey included more than 3,000 CIOs across all major industries.
Werner Goertz, a Gartner research director, said skills, expertise and staff around AI “remain in incredibly short supply, and whatever talent is out there is quickly absorbed by the big players.”
“There is an enormous gap” between the available capabilities and the skills required to make them work, Ben Fried, CIO of Google Inc. said earlier this month at WSJ CIO Network’s annual meeting in San Francisco.
Google in January launched Cloud AutoML, a similar AI tool designed to help developers automatically build and train deep-learning models. Google Cloud also offers pre-trained models.
Microsoft Corp., Salesforce.com Inc., Oracle Corp. and other cloud providers have added AI and machine learning capabilities into many of their cloud-based enterprise tools and services.
For IBM, and other tech giants, cloud computing and related services, such as AI, have been a boon. In January, the company reported a 3.6% increase in fourth-quarter revenue to $22.54 billion -- its first quarterly revenue gain since 2012 -- driven in part by a 30% increase in cloud-computing revenue to $5.5 billion, the company said.
",,Company, , , , , 
http://ibm.biz/Think2018Live,187446750783_10155492148190784,https://www.facebook.com/ibmwatson/posts/10155492148190784,We're on the ground at IBM's Think conference. Follow us on Twitter at @IBMWatson to stay informed of highlights during today's agenda. You can watch live streams of important keynotes here: ,Link,,,3/19/18 11:43, ,6556,6556,0,9050,9050,0,163,92,121,3,3,7276,5266,0,0,133,0,0,0,0,0,0,0,0,0,0,16,81.0,,17,83.0,,40,59.0,,,52,69.0,,,2,1.0,,2,1.0,,Watch IBM Think 2020 in San Francisco with live video streaming available throughout the conference. Learn from inspiring speakers and top experts with video streaming live May 4 - 7.,https://www.ibm.com/events/shared/img/think2019/think-og.jpg,https://www.ibm.com/events/think/watch/,joy,0.232941,neutral,0,"live streams of important keynotes, IBM's Think conference","TwitterHandle, Company, Company",live streams of important keynotes,TwitterHandle,joy,0.7887,positive,0.766797,"Watch IBM Think, live video, San Francisco","Company, Location",Watch IBM Think,Company,joy,0.279726,positive,0.752317,,"Person, Company, Person, Person, Person, Person, Person, Person, Person, Company, Person, Person, Person, Person, Company, Person"," 		 		Watch Think live | IBM Think 2020 | The first-of-its-kind business and technology event
 		 		 		 		 		 		 		 		 		  		  		 		  		 		 		 		 		 		 		 		 		 		 		 		 		 		  		  		 		 		 		 		 		 		  					 		 		 	 	 					   	 		 			United States
 		
 	
 	 		IBM®
 		 			Site map
 		
 		 			 				 					Search 					 					 					 					 					 					 				
 			 		
 	
 
 		 		 							  	Think 2020
 	 		 	
 
    	 				Virtual conference experience 		powered by IBM Watson Media - Free Trial. 	
 	
 					  		 			 					 		 			 				Watch Think 2019 replays and videos on demand
 				Revisit your favorite sessions. Catch all the moments you missed. Share insights with your network. These playlists and videos offer you the chance to relive the highlights of Think 2019.
 			
 		
 		 			 		
 	
  	 		 			 				 					Featured Playlists 				 			
 			 				 					Watch all sessions 				 			
 		
 	
  	  									 					 						Trends and Directions (6)
 						See all videos 					
  					 						 	                
     
     
                                                 Trends and Directions                             (6)                          
 
  					
  					 																					 									 	                
     
     
                                                 6925: Digitizing the Flow of Goods, Information and Money with Blockchain                          
 
  								
 																												 									 	                
     
     
                                                 6926: Managing the Hybrid Multicloud World for Digital Transformation                          
 
  								
 																												 									 	                
     
     
                                                 6931: Access the Future Today: Quantum Computing                          
 
  								
 																												 									 	                
     
     
                                                 6930: Modernizing Your Data Estates for an AI and Multicloud World                          
 
  								
 																																												
 				
 							 					 						Women in Tech (7)
 						See all videos 					
  					 						 	                
     
     
                                                 Women in Tech                             (7)                          
 
  					
  					 																					 									 	                
     
     
                                                 6941: Human-robot Interaction                          
 
  								
 																												 									 	                
     
     
                                                 7820: Mycelia - Connecting the Dots for Music Makers                          
 
  								
 																												 									 	                
     
     
                                                 6904:  How AI and Blockchain Will Change the Game                          
 
  								
 																												 									 	                
     
     
                                                 6943: Reaching Straight to Mars and Beyond                          
 
  								
 																																																									
 				
 							 					 						Deliver game changing capabilities with modern infrastructure  (10)
 						See all videos 					
  					 						 	                
     
     
                                                 Deliver game changing capabilities with modern infrastructure                              (10)                          
 
  					
  					 																					 									 	                
     
     
                                                 6950: The Future of Infrastructure                          
 
  								
 																												 									 	                
     
     
                                                 7252: Trust and Ethics in Technology                          
 
  								
 																												 									 	                
     
     
                                                 7287: Building Computing Architecture for the Era of Multicloud and AI                          
 
  								
 																												 									 	                
     
     
                                                 2388: Storage for the Data-Driven AI World                          
 
  								
 																																																																																																
 				
 							 					 						The Best of the Marketing, Commerce & Supply Chain Exchange (3)
 						See all videos 					
  					 						 	                
     
     
                                                 The Best of the Marketing, Commerce & Supply Chain Exchange                             (3)                          
 
  					
  					 																					 									 	                
     
     
                                                 6877: The Next Generation of Customer Experience                          
 
  								
 																												 									 	                
     
     
                                                 6904:  How AI and Blockchain Will Change the Game                          
 
  								
 																												 									 	                
     
     
                                                 6907:  Reinventing the Way Your Business Delivers                          
 
  								
 																		
 				
 							 					 						There is no AI without IA (7)
 						See all videos 					
  					 						 	                
     
     
                                                 There is no AI without IA                             (7)                          
 
  					
  					 																					 									 	                
     
     
                                                 6920: Think 2019 Chairman's Address: Building Cognitive Enterprises                          
 
  								
 																												 									 	                
     
     
                                                 6922: Accelerating the Journey to AI                          
 
  								
 																												 									 	                
     
     
                                                 7695: Accelerating Your Business with AI                           
 
  								
 																												 									 	                
     
     
                                                 6852: Put AI to Work for Business with IBM Data Science                          
 
  								
 																																																									
 				
 							 					 						Opening up about open source (5)
 						See all videos 					
  					 						 	                
     
     
                                                 Opening up about open source                             (5)                          
 
  					
  					 																					 									 	                
     
     
                                                 7741: Open Source: The Cornerstone to Innovation and Future for the Enterprise                          
 
  								
 																												 									 	                
     
     
                                                 8020: Predicting the Future the Red Hat Way                          
 
  								
 																												 									 	                
     
     
                                                 6936: Simplifying Support Services with Automation and Insights Innovation                          
 
  								
 																												 									 	                
     
     
                                                 7226: Put Open Source to Work for Data and AI                          
 
  								
 																															
 				
 							 					 						Making predictions and unlocking potential (6)
 						See all videos 					
  					 						 	                
     
     
                                                 Making predictions and unlocking potential                             (6)                          
 
  					
  					 																					 									 	                
     
     
                                                 6921: IBM Research Science Slam                          
 
  								
 																												 									 	                
     
     
                                                 6931: Access the Future Today: Quantum Computing                          
 
  								
 																												 									 	                
     
     
                                                 6932: Unlocking New Value From IoT, with AI and Advanced Analytics                          
 
  								
 																												 									 	                
     
     
                                                 8020: Predicting the Future the Red Hat Way                          
 
  								
 																																												
 				
 							 					 						Clearing things up in the cloud (3)
 						See all videos 					
  					 						 	                
     
     
                                                 Clearing things up in the cloud                             (3)                          
 
  					
  					 																					 									 	                
     
     
                                                 6923: Hybrid, Multicloud by Design. Accelerating the Enterprise Cloud Journey                          
 
  								
 																												 									 	                
     
     
                                                 6926: Managing the Hybrid Multicloud World for Digital Transformation                          
 
  								
 																												 									 	                
     
     
                                                 7476: Simplifying Enterprise Workloads with Modern Cloud Infrastructure                          
 
  								
 																		
 				
 							 					 						Democratizing technology and advancing humanity (5)
 						See all videos 					
  					 						 	                
     
     
                                                 Democratizing technology and advancing humanity                             (5)                          
 
  					
  					 																					 									 	                
     
     
                                                 6922: Accelerating the Journey to AI                          
 
  								
 																												 									 	                
     
     
                                                 6921: IBM Research Science Slam                          
 
  								
 																												 									 	                
     
     
                                                 6967: The State of Quantum Computing in 2019                          
 
  								
 																												 									 	                
     
     
                                                 8025: A Practical Guide for the Use of AI in Human Rights Due Diligence                          
 
  								
 																															
 				
 							 					 						Building trust, and keeping it (6)
 						See all videos 					
  					 						 	                
     
     
                                                 Building trust, and keeping it                             (6)                          
 
  					
  					 																					 									 	                
     
     
                                                 6921: IBM Research Science Slam                          
 
  								
 																												 									 	                
     
     
                                                 5600: Cognitive, AI, Machine Learning—Whatever You Call It—Can Make Your Applications More Secure                          
 
  								
 																												 									 	                
     
     
                                                 6924: The Blueprint for Smart Businesses                          
 
  								
 																												 									 	                
     
     
                                                 7252: Trust and Ethics in Technology                          
 
  								
 																																												
 				
 							 					 						Accelerating your journey to the Cognitive Enterprise (5)
 						See all videos 					
  					 						 	                
     
     
                                                 Accelerating your journey to the Cognitive Enterprise                             (5)                          
 
  					
  					 																					 									 	                
     
     
                                                 6923: Hybrid, Multicloud by Design. Accelerating the Enterprise Cloud Journey                          
 
  								
 																												 									 	                
     
     
                                                 6922: Accelerating the Journey to AI                          
 
  								
 																												 									 	                
     
     
                                                 6924: The Blueprint for Smart Businesses                          
 
  								
 																												 									 	                
     
     
                                                 6920: Think 2019 Chairman's Address: Building Cognitive Enterprises                          
 
  								
 																															
 				
 							 					 						Keynotes (5)
 						See all videos 					
  					 						 	                
     
     
                                                 Keynotes                             (5)                          
 
  					
  					 																					 									 	                
     
     
                                                 6920: Think 2019 Chairman's Address: Building Cognitive Enterprises                          
 
  								
 																												 									 	                
     
     
                                                 6921: IBM Research Science Slam                          
 
  								
 																												 									 	                
     
     
                                                 6922: Accelerating the Journey to AI                          
 
  								
 																												 									 	                
     
     
                                                 6923: Hybrid, Multicloud by Design. Accelerating the Enterprise Cloud Journey                          
 
  								
 																															
 				
 							 					 						Innovation Talks (5)
 						See all videos 					
  					 						 	                
     
     
                                                 Innovation Talks                             (5)                          
 
  					
  					 																					 									 	                
     
     
                                                 6944: Disruptive Robotic Technologies Augmenting Human Performance                          
 
  								
 																												 									 	                
     
     
                                                 6943: Reaching Straight to Mars and Beyond                          
 
  								
 																												 									 	                
     
     
                                                 6942: Empowering the World with an Innovative Social Platform                          
 
  								
 																												 									 	                
     
     
                                                 7736: Zucked                          
 
  								
 																															
 				
 					 	
  	 		   	 		 		 	
 	 		 			Search 			 				 			
 		 	
    	 		   	 		Clear 		Filter replays
 		 			Filter replays 		
 	
  	 		 			                 Topics 			
             				 					 					                         Automation 						 							(3) 						 					 				
             				 					 					                         Blockchain 						 							(10) 						 					 				
             				 					 					                         Cloud 						 							(21) 						 					 				
             				 					 					                         Code 						 							(11) 						 					 				
             				 					 					                         Collaboration Solutions 						 							(1) 						 					 				
             				 					 					                         Commerce 						 							(1) 						 					 				
             				 					 					                         Data and Analytics 						 							(18) 						 					 				
             				 					 					                         Human Resources and Talent 						 							(3) 						 					 				
             				 					 					                         IBM Research 						 							(3) 						 					 				
             				 					 					                         Industry Solutions 						 							(5) 						 					 				
             				 					 					                         Infrastructure 						 							(14) 						 					 				
             				 					 					                         Internet of Things 						 							(3) 						 					 				
             				 					 					                         Marketing 						 							(3) 						 					 				
             				 					 					                         Marketing and Commerce 						 							(1) 						 					 				
             				 					 					                         Marketing, Commerce, Supply Chain 						 							(2) 						 					 				
             				 					 					                         Security and Resiliency 						 							(24) 						 					 				
             				 					 					                         Services 						 							(17) 						 					 				
             				 					 					                         Smarter Business 						 							(30) 						 					 				
             				 					 					                         Supply Chain 						 							(4) 						 					 				
             				 					 					                         The Cube 						 							(36) 						 					 				
             				 					 					                         Watson 						 							(11) 						 					 				
             		
  		 			 				Duration 			
 			 				 				                     6 minutes or shorter 					 						(20) 					 				 			
 			 				 				                     6-30 mintues 					 						(99) 					 				 			
 			 				 				                     30 minutes or longer 					 						(102) 					 				 			
  		
 	
 
  	
 	  		 			 				 					 				
 									No replays correspond to your search.
 					0 replays found.
 							
  							 											 	   	 		          
     
     
                                                 8146: DevOps and the Modern IBM i                          
 
 	
 	 		 			8146: DevOps and the Modern IBM i 		
 		 			Code 		 			
   											 	   	 		          
     
     
                                                 7608: Blockchain Anywhere: The Next-Generation Blockchain Platform has Emerged                          
 
 	
 	 		 			7608: Blockchain Anywhere: The Next-Generation Blockchain Platform has Emerged 		
 		 			Blockchain 		 					 				Speakers: 															Joan Zerkovich,  																				E. P. Moffatt,  																				Marley Gray,  																				Gari Singh,  																				Eileen Lowry,  																				Gennaro A. Cuomo 												
 			
   											 	   	 		          
     
     
                                                 7412: Veeam and IBM Cloud Deliver Hyper-Availability for Critical Workloads                          
 
 	
 	 		 			7412: Veeam and IBM Cloud Deliver Hyper-Availability for Critical Workloads 		
 		 			Cloud 		 					 				Speaker: 															Sam Fischer 												
 			
   											 	   	 		          
     
     
                                                 6935: Beyond Esthetics, Debbie Vavangas' Design View                          
 
 	
 	 		 			6935: Beyond Esthetics, Debbie Vavangas' Design View 		
 		 			Services 		 					 				Speakers: 															Debbie Vavangas,  																				Rachel Higham,  																				Claire Dickson 												
 			
   											 	   	 		          
     
     
                                                 7308: Real-world Modernization - Sangita Singh                          
 
 	
 	 		 			7308: Real-world Modernization - Sangita Singh 		
 		 			Cloud 		 					 				Speakers: 															Denis Kennelly,  																				Claus Torp Jensen,  																				James Lang,  																				Sean Erswell-Liljefelt,  																				Sangita Singh 												
 			
   											 	   	 		          
     
     
                                                 6923: The Next Chapter: Mission critical systems on the cloud                          
 
 	
 	 		 			6923: The Next Chapter: Mission critical systems on the cloud 		
 		 			Smarter Business 		 					 				Speakers: 															Hillery Hunter,  																				Arvind Krishna,  																				Pat Gelsinger,  																				Paul Cormier,  																				Sarp Uzkan,  																				Colleen Speer,  																				Devin Miller,  																				Juan Antonio Zufiria Zatarain 												
 			
   											 	   	 		          
     
     
                                                 6924: The Cognitive Enterprise: A New Model for Competitive Advantage                          
 
 	
 	 		 			6924: The Cognitive Enterprise: A New Model for Competitive Advantage 		
 		 			Smarter Business 		 					 				Speakers: 															Mark Foster,  																				Kelly Chambliss,  																				Claire Dickson,  																				Sorabh Saxena 												
 			
   											 	   	 		          
     
     
                                                 6904: How AI and Blockchain will change the Game - HarperCollins                          
 
 	
 	 		 			6904: How AI and Blockchain will change the Game - HarperCollins 		
 		 			Marketing 		 			
   											 	   	 		          
     
     
                                                 6904: How AI and Blockchain will change the Game - Husqvarna                          
 
 	
 	 		 			6904: How AI and Blockchain will change the Game - Husqvarna 		
 		 			Marketing, Commerce, Supply Chain 		 			
   											 	   	 		          
     
     
                                                 6938: 5 Trends for the Supply Chain of the Future - REI                          
 
 	
 	 		 			6938: 5 Trends for the Supply Chain of the Future - REI 		
 		 			Supply Chain 		 			
   											 	   	 		          
     
     
                                                 7309: How to Engineer Modern Marketing for Business Growth - Paul Papas                          
 
 	
 	 		 			7309: How to Engineer Modern Marketing for Business Growth - Paul Papas 		
 		 			Marketing 		 					 				Speakers: 															Paul Papas,  																				Ari Sheinkin,  																				Kim Leible,  																				Jason Dennis,  																				Becky Waddell,  																				Greg Riedel 												
 			
   											 	   	 		          
     
     
                                                 6926: Managing the Hybrid Multicloud World for Digital Transformation: Client Interview with Arun Sh                          
 
 	
 	 		 			6926: Managing the Hybrid Multicloud World for Digital Transformation: Client Interview with Arun Sh 		
 		 			Cloud 		 					 				Speakers: 															Arun Sharma,  																				Robin Hernandez,  																				Robert Erickson 												
 			
   											 	   	 		          
     
     
                                                 6920: Jim Whitehurst, Red Hat - Partnership/tech landscape                          
 
 	
 	 		 			6920: Jim Whitehurst, Red Hat - Partnership/tech landscape 		
 		 			Smarter Business 		 			
   											 	   	 		          
     
     
                                                 6920: John Donovan, AT&T - End-to-end digital transformation                          
 
 	
 	 		 			6920: John Donovan, AT&T - End-to-end digital transformation 		
 		 			Smarter Business 		 			
   											 	   	 		          
     
     
                                                 6920: Ted Chung, Hyundai Card - Scaling AI and Digital                          
 
 	
 	 		 			6920: Ted Chung, Hyundai Card - Scaling AI and Digital 		
 		 			Smarter Business 		 			
   											 	   	 		          
     
     
                                                 6920: Greg Kalinsky, GEICO - Journey of Digitization                          
 
 	
 	 		 			6920: Greg Kalinsky, GEICO - Journey of Digitization 		
 		 			Smarter Business 		 			
   											 	   	 		          
     
     
                                                 6920: Bernard Tyson, Kaiser Permanente - Cloud in regulated industry                          
 
 	
 	 		 			6920: Bernard Tyson, Kaiser Permanente - Cloud in regulated industry 		
 		 			Smarter Business 		 			
   											 	   	 		          
     
     
                                                 7741: Steve O'Grady - Open Source Momentum                          
 
 	
 	 		 			7741: Steve O'Grady - Open Source Momentum 		
 		 			Code 		 					 				Speakers: 															Ginni Rometty,  																				Bob Lord,  																				Abby Kearns,  																				Jim Zemlin,  																				Steve O'Grady,  																				Dr. Marcelo Labre,  																				Andre Fuetsch 												
 			
   											 	   	 		          
     
     
                                                 7741: Dr. Marcelo Labre - Open Source Myth                          
 
 	
 	 		 			7741: Dr. Marcelo Labre - Open Source Myth 		
 		 			Code 		 					 				Speakers: 															Ginni Rometty,  																				Bob Lord,  																				Abby Kearns,  																				Jim Zemlin,  																				Steve O'Grady,  																				Dr. Marcelo Labre,  																				Andre Fuetsch 												
 			
   											 	   	 		          
     
     
                                                 7741: Ginni Rometty - Business Value of Open Source                          
 
 	
 	 		 			7741: Ginni Rometty - Business Value of Open Source 		
 		 			Code 		 					 				Speakers: 															Ginni Rometty,  																				Bob Lord,  																				Abby Kearns,  																				Jim Zemlin,  																				Steve O'Grady,  																				Dr. Marcelo Labre,  																				Andre Fuetsch 												
 			
   											 	   	 		          
     
     
                                                 7741: Jim Zemlin - Momentum of Open Source                          
 
 	
 	 		 			7741: Jim Zemlin - Momentum of Open Source 		
 		 			Code 		 					 				Speakers: 															Ginni Rometty,  																				Bob Lord,  																				Abby Kearns,  																				Jim Zemlin,  																				Steve O'Grady,  																				Dr. Marcelo Labre,  																				Andre Fuetsch 												
 			
   											 	   	 		          
     
     
                                                 7741: Bob Lord - IBM Open by Design                          
 
 	
 	 		 			7741: Bob Lord - IBM Open by Design 		
 		 			Code 		 					 				Speakers: 															Ginni Rometty,  																				Bob Lord,  																				Abby Kearns,  																				Jim Zemlin,  																				Steve O'Grady,  																				Dr. Marcelo Labre,  																				Andre Fuetsch 												
 			
   											 	   	 		          
     
     
                                                 7741: Abby Kearns - Myth and Hope                          
 
 	
 	 		 			7741: Abby Kearns - Myth and Hope 		
 		 			Code 		 					 				Speakers: 															Ginni Rometty,  																				Bob Lord,  																				Abby Kearns,  																				Jim Zemlin,  																				Steve O'Grady,  																				Dr. Marcelo Labre,  																				Andre Fuetsch 												
 			
   											 	   	 		          
     
     
                                                 7741: Andre Fuetsch - Open Source                          
 
 	
 	 		 			7741: Andre Fuetsch - Open Source 		
 		 			Code 		 					 				Speakers: 															Ginni Rometty,  																				Bob Lord,  																				Abby Kearns,  																				Jim Zemlin,  																				Steve O'Grady,  																				Dr. Marcelo Labre,  																				Andre Fuetsch 												
 			
   											 	   	 		          
     
     
                                                 6929: Innovation Doesn't Happen Without Security. And Security Needs Innovation.                          
 
 	
 	 		 			6929: Innovation Doesn't Happen Without Security. And Security Needs Innovation. 		
 		 			Security and Resiliency 		 					 				Speakers: 															Mary O'Brien,  																				Andy Powell,  																				Danica Patrick,  																				Kevin Baker 												
 			
   											 	   	 		          
     
     
                                                 6937: How Smarter Leadership Delivers Transformative Outcomes in the Age of Disruption: Tim Skeen, A                          
 
 	
 	 		 			6937: How Smarter Leadership Delivers Transformative Outcomes in the Age of Disruption: Tim Skeen, A 		
 		 			Services 		 					 				Speakers: 															Gary Delooze,  																				John Granger,  																				Tim Skeen,  																				Philip Guido,  																				Charlene Li 												
 			
   											 	   	 		          
     
     
                                                 6950: The future of infrastructure: From hybrid multicloud to IT talent                          
 
 	
 	 		 			6950: The future of infrastructure: From hybrid multicloud to IT talent 		
 		 			Infrastructure 		 					 				Speakers: 															Tom Rosamilia,  																				Rich Karlgaard,  																				Hilary Mason,  																				Jeff Jonas 												
 			
   											 	   	 		          
     
     
                                                 6928: Diane Gherson & Bob Schultz                           
 
 	
 	 		 			6928: Diane Gherson & Bob Schultz  		
 		 			Human Resources and Talent 		 					 				Speakers: 															Bob Schultz,  																				Diane Gherson,  																				Barbry McGann,  																				Amy Wright,  																				Pat Wadors 												
 			
   											 	   	 		          
     
     
                                                 6933: Pushing the boundaries of how AI learns with Watson                          
 
 	
 	 		 			6933: Pushing the boundaries of how AI learns with Watson 		
 		 			Watson 		 					 				Speakers: 															Jamie Gutfreund,  																				Beth Smith,  																				James M. Lee,  																				Naresh Vyas,  																				Judd Smith 												
 			
   											 	   	 		          
     
     
                                                 6927: How to harness the value of great ideas and turn them into business value - with IBM Cloud                          
 
 	
 	 		 			6927: How to harness the value of great ideas and turn them into business value - with IBM Cloud 		
 		 			Cloud 		 					 				Speakers: 															Mark Lack,  																				Jason McGee,  																				Stephanie L. Trunzo,  																				Barry Pellas,  																				Yousif Yousif,  																				Briana Frank 												
 			
   											 	   	 		          
     
     
                                                 6921: IBM Research Science Slam Prediction 5: Jeannette Garcia                          
 
 	
 	 		 			6921: IBM Research Science Slam Prediction 5: Jeannette Garcia 		
 		 			Smarter Business 		 					 				Speakers: 															Geraud Dubois,  																				Arvind Krishna,  																				Jeannette M. Garcia,  																				Donna N. Dillenberger,  																				Juliet Mutahi,  																				Sriram Raghavan 												
 			
   											 	   	 		          
     
     
                                                 6921: IBM Research Science Slam Prediction 2: Sriram Raghavan                          
 
 	
 	 		 			6921: IBM Research Science Slam Prediction 2: Sriram Raghavan 		
 		 			Smarter Business 		 					 				Speakers: 															Geraud Dubois,  																				Arvind Krishna,  																				Jeannette M. Garcia,  																				Donna N. Dillenberger,  																				Juliet Mutahi,  																				Sriram Raghavan 												
 			
   											 	   	 		          
     
     
                                                 6921: IBM Research Science Slam Prediction 4: Donna Dillenberger                          
 
 	
 	 		 			6921: IBM Research Science Slam Prediction 4: Donna Dillenberger 		
 		 			Smarter Business 		 					 				Speakers: 															Geraud Dubois,  																				Arvind Krishna,  																				Jeannette M. Garcia,  																				Donna N. Dillenberger,  																				Juliet Mutahi,  																				Sriram Raghavan 												
 			
   											 	   	 		          
     
     
                                                 6921: IBM Research Science Slam Prediction 3: Geraud Dubois                          
 
 	
 	 		 			6921: IBM Research Science Slam Prediction 3: Geraud Dubois 		
 		 			Smarter Business 		 					 				Speakers: 															Geraud Dubois,  																				Arvind Krishna,  																				Jeannette M. Garcia,  																				Donna N. Dillenberger,  																				Juliet Mutahi,  																				Sriram Raghavan 												
 			
   											 	   	 		          
     
     
                                                 6921: IBM Research Science Slam Prediction 1: Juliet Mutahi                          
 
 	
 	 		 			6921: IBM Research Science Slam Prediction 1: Juliet Mutahi 		
 		 			Smarter Business 		 					 				Speakers: 															Geraud Dubois,  																				Arvind Krishna,  																				Jeannette M. Garcia,  																				Donna N. Dillenberger,  																				Juliet Mutahi,  																				Sriram Raghavan 												
 			
   											 	   	 		          
     
     
                                                 7515: Artificial Intelligence and the Business of Government                          
 
 	
 	 		 			7515: Artificial Intelligence and the Business of Government 		
 		 			Industry Solutions 		 					 				Speakers: 															Erwin Rademaker,  																				Sreeram Visvanathan 												
 			
   											 	   	 		          
     
     
                                                 6932: Improving operational efficiency and reducing costs with IoT Data and AI                          
 
 	
 	 		 			6932: Improving operational efficiency and reducing costs with IoT Data and AI 		
 		 			Internet of Things 		 					 				Speakers: 															Kareem Yusuf, Ph.D,  																				Stephane Lannuzel,  																				Ayumu Mitera,  																				Dr. Siegmar Haasis,  																				Olabisi Boyle 												
 			
   											 	   	 		          
     
     
                                                 7751: The Magical Living Room-Building and Nurturing Developer Communities PGM                          
 
 	
 	 		 			7751: The Magical Living Room-Building and Nurturing Developer Communities PGM 		
 		 			Code 		 			
   											 	   	 		          
     
     
                                                 6931: The Three Fundamentals of Quantum Computing                          
 
 	
 	 		 			6931: The Three Fundamentals of Quantum Computing 		
 		 			IBM Research 		 					 				Speakers: 															Dr. Dario Gil,  																				Ben Boeser 												
 			
   											 	   	 		          
     
     
                                                 6929: Using the Cloud for Solve the Security Problem                          
 
 	
 	 		 			6929: Using the Cloud for Solve the Security Problem 		
 		 			Security and Resiliency 		 					 				Speakers: 															Mary O'Brien,  																				Andy Powell,  																				Danica Patrick,  																				Kevin Baker 												
 			
   											 	   	 		          
     
     
                                                 7307:  We're the Movers - Migrating Cloud from Anywhere to Anywhere:  Interview with Christopher Cat                          
 
 	
 	 		 			7307:  We're the Movers - Migrating Cloud from Anywhere to Anywhere:  Interview with Christopher Cat 		
 		 			Cloud 		 					 				Speakers: 															Laurence Guihard-Joly,  																				Harish Grama,  																				Ajay Patel,  																				Christopher Catterfeld 												
 			
   											 	   	 		          
     
     
                                                 6938: Learn how Petco embraced AI with IBM Supply Chain Business Network                          
 
 	
 	 		 			6938: Learn how Petco embraced AI with IBM Supply Chain Business Network 		
 		 			Supply Chain 		 			
   											 	   	 		          
     
     
                                                 6220: InnerCircle Keynote: The Cloud Journey-A Hybrid Approach to Multicloud Environments                          
 
 	
 	 		 			6220: InnerCircle Keynote: The Cloud Journey-A Hybrid Approach to Multicloud Environments 		
 		 			Cloud 		 			
   											 	   	 		          
     
     
                                                 6907:  Reinventing the Way Your Business Delivers                          
 
 	
 	 		 			6907:  Reinventing the Way Your Business Delivers 		
 		 			Supply Chain 		 			
   											 	   	 		          
     
     
                                                 6904:  How AI and Blockchain Will Change the Game                          
 
 	
 	 		 			6904:  How AI and Blockchain Will Change the Game 		
 		 			Marketing, Commerce, Supply Chain 		 			
   											 	   	 		          
     
     
                                                 6877: The Next Generation of Customer Experience                          
 
 	
 	 		 			6877: The Next Generation of Customer Experience 		
 		 			Marketing and Commerce 		 			
   											 	   	 		          
     
     
                                                 Interview with Scot Henney and Marcus Venth                          
 
 	
 	 		 			Interview with Scot Henney and Marcus Venth 		
 		 			The Cube 		 			
   											 	   	 		          
     
     
                                                 Interview with Jeff Gatz and Craig Reese                          
 
 	
 	 		 			Interview with Jeff Gatz and Craig Reese 		
 		 			The Cube 		 			
   											 	   	 		          
     
     
                                                 4922: Shipping in the Age of Blockchain: Streamlining Supply Chains End-to-End for You and Your Part                          
 
 	
 	 		 			4922: Shipping in the Age of Blockchain: Streamlining Supply Chains End-to-End for You and Your Part 		
 		 			Blockchain 		 					 				Speakers: 															M. T. Erdly,  																				Mike White 												
 			
   											 	   	 		          
     
     
                                                 6825: Modernizing Your Data Platform and Making Your Data Ready for AI                          
 
 	
 	 		 			6825: Modernizing Your Data Platform and Making Your Data Ready for AI 		
 		 			Data and Analytics 		 					 				Speakers: 															Albert Martin,  																				Jeff Jonas 												
 			
   											 	   	 		          
     
     
                                                 6930: Gain confidence in your AI with IBM Watson OpenScale                          
 
 	
 	 		 			6930: Gain confidence in your AI with IBM Watson OpenScale 		
 		 			Data and Analytics 		 					 				Speakers: 															David Bernert,  																				Dinesh Nirmal,  																				Jenna Goldberg 												
 			
   											 	   	 		          
     
     
                                                 6928: Re-inventing the Approach to Talent in the Era of AI                          
 
 	
 	 		 			6928: Re-inventing the Approach to Talent in the Era of AI 		
 		 			Human Resources and Talent 		 					 				Speakers: 															Bob Schultz,  																				Diane Gherson,  																				Barbry McGann,  																				Amy Wright,  																				Pat Wadors 												
 			
   											 	   	 		          
     
     
                                                 6927: From Idea to MVP: Cloud Garage Live                          
 
 	
 	 		 			6927: From Idea to MVP: Cloud Garage Live 		
 		 			Cloud 		 					 				Speakers: 															Mark Lack,  																				Jason McGee,  																				Stephanie L. Trunzo,  																				Barry Pellas,  																				Yousif Yousif,  																				Briana Frank 												
 			
   											 	   	 		          
     
     
                                                 Interview with Murali Nemani and Joe Damassa                          
 
 	
 	 		 			Interview with Murali Nemani and Joe Damassa 		
 		 			The Cube 		 					 				Speakers: 															Murali Nemani,  																				Joe Damassa 												
 			
   											 	   	 		          
     
     
                                                 1408: How Do 51 Quintillion Cells Factor into Ancestry's FP&A Process and Subscription Revenue Model                          
 
 	
 	 		 			1408: How Do 51 Quintillion Cells Factor into Ancestry's FP&A Process and Subscription Revenue Model 		
 		 			Data and Analytics 		 					 				Speakers: 															Curtis Tripoli,  																				Hans Mize 												
 			
   											 	   	 		          
     
     
                                                 7684: Intersectionality, Marketplace Strategy, and the Future of Inclusion                          
 
 	
 	 		 			7684: Intersectionality, Marketplace Strategy, and the Future of Inclusion 		
 		 			Smarter Business 		 					 				Speakers: 															Tia Silas,  																				David Galloreese,  																				Jennifer Brown 												
 			
   											 	   	 		          
     
     
                                                 6922: AI is the new electricity.  See how to harness it.                          
 
 	
 	 		 			6922: AI is the new electricity.  See how to harness it. 		
 		 			Smarter Business 		 					 				Speakers: 															Jack McCarthy,  																				Arvind Krishna,  																				Robert Thomas,  																				Dr. Dario Gil,  																				Laurent Prudhon,  																				Reena Ganga,  																				Guy Taylor,  																				Kelly Combs 												
 			
   											 	   	 		          
     
     
                                                 7280: IBM Storage Solutions for IBM Blockchain                          
 
 	
 	 		 			7280: IBM Storage Solutions for IBM Blockchain 		
 		 			Infrastructure 		 					 				Speaker: 															Antoine Sater 												
 			
   											 	   	 		          
     
     
                                                 8094: Co-Create to Differentiate: The Digital Makers Lab                          
 
 	
 	 		 			8094: Co-Create to Differentiate: The Digital Makers Lab 		
 		 			Cloud 		 					 				Speakers: 															Hiroki Shibayama,  																				Kei Shimada 												
 			
   											 	   	 		          
     
     
                                                 7284: BLANC & FISCHER's IBM Cloud Identity Journey                          
 
 	
 	 		 			7284: BLANC & FISCHER's IBM Cloud Identity Journey 		
 		 			Security and Resiliency 		 					 				Speakers: 															Dinesh Jain,  																				Manfred Leistner,  																				Daniel Lutz 												
 			
   											 	   	 		          
     
     
                                                 6302: Don't Get Lost in Translation: Apply Business Context to Your Data Risk                          
 
 	
 	 		 			6302: Don't Get Lost in Translation: Apply Business Context to Your Data Risk 		
 		 			Security and Resiliency 		 					 				Speaker: 															Nagendra Ramamurthy Pattavardhanam 												
 			
   											 	   	 		          
     
     
                                                 7647: Travelping's Journey to a Connected Car Mobile Platform                          
 
 	
 	 		 			7647: Travelping's Journey to a Connected Car Mobile Platform 		
 		 			Cloud 		 					 				Speaker: 															Holger Winkelmann 												
 			
   											 	   	 		          
     
     
                                                 4427: Muscling Up Midsize Banks with Enterprise-Grade Mobile Fraud Protection                          
 
 	
 	 		 			4427: Muscling Up Midsize Banks with Enterprise-Grade Mobile Fraud Protection 		
 		 			Security and Resiliency 		 					 				Speakers: 															Bob Burgarino,  																				Craig Pawling 												
 			
   											 	   	 		          
     
     
                                                 7885: Trust Your AI Models: IBM Watson OpenScale and IBM Cloud Private for Data                          
 
 	
 	 		 			7885: Trust Your AI Models: IBM Watson OpenScale and IBM Cloud Private for Data 		
 		 			Data and Analytics 		 					 				Speakers: 															Tanmay Sinha,  																				Susannah Shattuck 												
 			
   											 	   	 		          
     
     
                                                 8135: GRC Platform Thinking                          
 
 	
 	 		 			8135: GRC Platform Thinking 		
 		 			Watson 		 					 				Speaker: 															Katie Baker 												
 			
   											 	   	 		          
     
     
                                                 7574: How a Major Retailer is Transforming Its Business with IBM Analytics                          
 
 	
 	 		 			7574: How a Major Retailer is Transforming Its Business with IBM Analytics 		
 		 			Data and Analytics 		 					 				Speakers: 															Jaydeep Vasani,  																				David Albert,  																				Jacky Patel 												
 			
   											 	   	 		          
     
     
                                                 7487: Beyond the Hype: Clients in Retail, Banking and Healthcare Share Results and Lessons Learned w                          
 
 	
 	 		 			7487: Beyond the Hype: Clients in Retail, Banking and Healthcare Share Results and Lessons Learned w 		
 		 			Watson 		 					 				Speakers: 															Laura Donaldson,  																				Rachel Cordrey,  																				Yanni Kotziagkiaouridis,  																				Robert H. High,  																				Kevin Murphy 												
 			
   											 	   	 		          
     
     
                                                 7856: GROW: Bold Decisions for Career Growth                          
 
 	
 	 		 			7856: GROW: Bold Decisions for Career Growth 		
 		 			Smarter Business 		 					 				Speakers: 															Rachel Reinitz,  																				Opal Perry,  																				Stephanie Carullo,  																				Tracey Welson-Rossman,  																				Xiaojun Huang 												
 			
   											 	   	 		          
     
     
                                                 7222: From Space to Earth... and Back Again                          
 
 	
 	 		 			7222: From Space to Earth... and Back Again 		
 		 			Smarter Business 		 					 				Speakers: 															Taylor Richardson,  																				Matthias Biniok,  																				Steve Smith,  																				Emily Calandrelli,  																				Homer Ahr 												
 			
   											 	   	 		          
     
     
                                                 6941: Human-robot Interaction                          
 
 	
 	 		 			6941: Human-robot Interaction 		
 		 			Smarter Business 		 					 				Speaker: 															Dr. Kate Darling 												
 			
   											 	   	 		          
     
     
                                                 7960: Infrastructure Matters: Benefits of Moving to the IBM Cloud with VMWare, IBM and Intel                          
 
 	
 	 		 			7960: Infrastructure Matters: Benefits of Moving to the IBM Cloud with VMWare, IBM and Intel 		
 		 			Cloud 		 					 				Speakers: 															Dale Hoffman,  																				Gene Quaglia 												
 			
   											 	   	 		          
     
     
                                                 3749: How Dillards.com Scales to Meet Aggressive Growth Targets                          
 
 	
 	 		 			3749: How Dillards.com Scales to Meet Aggressive Growth Targets 		
 		 			Services 		 					 				Speakers: 															Jack Oaks,  																				Rama Vedula,  																				Steven Preston,  																				David S. Hallagan 												
 			
   											 	   	 		          
     
     
                                                 7737: Be a Champion                          
 
 	
 	 		 			7737: Be a Champion 		
 		 			Smarter Business 		 					 				Speakers: 															Paul Papas,  																				Jen Taylor,  																				Eric Berridge,  																				Parisa Naseralavi 												
 			
   											 	   	 		          
     
     
                                                 4146: Cyber Resilience Maturity Assessment                          
 
 	
 	 		 			4146: Cyber Resilience Maturity Assessment 		
 		 			Security a",,Person,ultramarine,coral reef,nature,ridge,coral reef
https://ibm.co/2IAF8uy,187446750783_10155489294875784,https://www.facebook.com/ibmwatson/posts/10155489294875784,"&quot;IBM's now one of the big dogs in the new high-stakes world of modern enterprise IT centered on how cloud, AI, blockchain, machine learning, and advanced cybersecurity can help businesses get, manage and exploit data to make better decisions, dazzle customers and trounce competitors.&quot; ",Link,,,3/18/18 10:00, ,27918,27918,0,38683,38683,0,1661,1251,1645,22,22,25691,19093,0,0,1178,0,0,0,0,0,0,0,0,0,0,99,564.0,10.0,105,590.0,10.0,513,889.0,,,680,965.0,,,12,10.0,,12,10.0,,A resurgent IBM becomes one of the world's top 3 enterprise-cloud providers under the courageous leadership of CEO Ginni Rometty as cloud revenue topped $17 billion for 2017 and hit $5.5 billion--up 30%--in Q4. IBM's achievement proves why conventional wisdom is useless in our unconventional world.,https://thumbor.forbes.com/thumbor/fit-in/1200x0/filters%3Aformat%28jpg%29/https%3A%2F%2Fspecials-images.forbesimg.com%2Fdam%2Fimageserve%2F503702202%2F0x0.jpg%3Ffit%3Dscale,https://www.forbes.com/sites/bobevans1/2018/01/19/ibm-joins-microsoft-amazon-atop-cloud-world-booming-cloud-business-ends-long-revenue-decline/#46fa6c9e49c4,joy,0.566134,positive,0.937289,machine learning,Company,machine learning,Company,joy,0.47765,negative,-0.381805,"resurgent IBM, conventional wisdom","Person, Company, Quantity, Quantity, Quantity",resurgent IBM,Person,sadness,0.591304,positive,0.657601,"IBM's cloud revenue, CLOUD WARS","Company, Person, Company, Quantity, Quantity","(Note: After an award-winning career in the media business covering the tech industry, Bob Evans was VP of Strategic Communications at SAP in 2011, and Chief Communications Officer at Oracle from 2012 to 2016. He now runs his own firm, Evans Strategic Communications LLC.)
CLOUD WARS -- Accelerating its remarkable turnaround and establishing itself among the top 3 enterprise-cloud players, IBM's cloud revenue for the year rose 24% to $17 billion and jumped $30% in the fourth quarter to $5.5 billion.
With cloud revenue now making up 21% of IBM's total revenue of $79.1 billion, IBM's reinvigorated technology and market focus have allowed the company to snap an agonizing streak of 20+ quarters of declining revenue as CEO Ginni Rometty's heroic transformation of the iconic 106-year-old company has come full circle.
With its multifaceted cloud business leading the way, IBM's ""strategic imperatives""—cloud, security, analytics and mobile—grew 14% in the fourth quarter and now account for close to 50% of the company's revenue.
This type of resurgence in the dynamic and rapidly evolving tech sector is supposed to be impossible—for several years now, the prophets of doom have been saying IBM had lost its way, couldn't afford to invest in advanced technology, was overinvested in services, didn't get the cloud, and was hopelessly trapped in a death spiral.
But proving yet again that conventional wisdom in today's unconventional enterprise-IT world is utterly worthless, IBM reported growth across the board and projected continued growth throughout 2018.
And Rometty solidified her reputation as not only a courageous CEO willing to take on the near-impossible task of turning around a slumping giant, but also as a visionary strategist who several years ago set a bold new vision for the company centered on powerful new technologies, defied critics who said IBM should be sold off in pieces, and forcefully recreated IBM as one of the world's pre-eminent sources of innovation and business value.
""During 2017, we strengthened our position as the leading enterprise cloud provider and established IBM as the blockchain leader for business,"" Rometty said in a press release announcing its financial results, adding that IBM is ""uniquely positioned to help clients use data and AI to build smarter businesses.""
""Strengthened,"" indeed. In the red-hot enterprise-cloud sector, here are some highlights of what IBM achieved in the fourth quarter and for all of 2017 as it defied the doomsayers and joined Microsoft and Amazon among the three biggest and most-influential cloud vendors.
And in an internal move that will create huge new scaling capabilities for the IBM Cloud, senior vice-president Martin Schroeter said on the earnings call that IBM would be moving its massive services business—the current backlog is $120 billion—onto the IBM Cloud platform.
""So not only are we building and moving new SaaS properties into the cloud—which have great margins—and not only are we building our Platform as a Service and building ecosystems around that, but we also have north of $120 billion backlog in our services business that we're in the process of moving to the cloud,"" Schroeter told the analysts per the earnings-call transcript on SeekingAlpha.com.
""So when we talk scale, we're moving our whole services platform on to the IBM Cloud, and that's going to give us the scale we need, not just for that infrastructure layer but it's going to give us the scale we need to manage applications, it's going to give us to scale we need to deliver SaaS as effectively as possible and efficiently as possible. So we've got a lot of scale coming our way.""
So IBM is not just ""back""—IBM's now one of the big dogs in the new high-stakes world of modern enterprise IT centered on how cloud, AI, blockchain, machine learning, and advanced cybersecurity can help businesses get, manage and exploit data to make better decisions, dazzle customers and trounce competitors.
And IBM fully deserves to be regarded as one of the Big Three in the Cloud Wars along with Microsoft and Amazon.
I've analyzed and written about the enterprise-tech business for more than 20 years from the media side as an editor-in-chief and chief content officer, and more recently as Chief Communications Officer at Oracle from 2012-2016. I've written thousands of articles and columns about business innovation, competitive advantage, strategy, leadership, disruptive technology, customer case-studies, CEO profiles, digital transformation and cloud computing. Late last year, I resigned from Oracle to launch my own company, Evans Strategic Communications, which helps businesses grow via thought leadership and innovative storytelling.
",IBM's cloud revenue,Company,blue,celebrity,person,adult,celebrity
https://ibm.co/2EvwDhZ,187446750783_10155486517565784,https://www.facebook.com/ibmwatson/posts/10155486517565784,"We've all seen terms like &quot;chatbot,&quot; &quot;virtual assistant&quot; and &quot;conversational agent&quot; used interchangeably, but do they really mean the same thing? Not according to #IBMWatson VP and CTO @rhigh. Learn why: ",Link,,,3/17/18 9:14, ,8334,8334,0,11461,11461,0,154,99,107,3,3,10425,7538,0,0,142,0,0,0,0,0,0,0,0,0,0,8,61.0,,8,62.0,,30,73.0,,,34,73.0,,,,3.0,,,3.0,,Find out the key differences between chatbots vs. virtual assistants vs. conversational agents from IBM Watson VP and CTO Rob High.,https://cdn.ttgtmedia.com/visuals/German/article/chatbot-2-fotolia.jpg,https://searchcio.techtarget.com/feature/Comparing-chatbots-vs-virtual-assistants-vs-conversational-agents,fear,0.174265,neutral,0,"quot, seen terms, virtual assistant","Company, Company",quot,Company,joy,0.040039,neutral,0,key differences,"Company, Person",key differences,Company,joy,0.524255,positive,0.613699,conversational agent,"Person, Company, Company","interchangeably, but do those terms really describe the same thing? Not according to Rob High, vice president and CTO at IBM Watson and an IBM Fellow.
In this Q&A, High explains the subtle but distinct differences between those three conversation-based technology terms and the intent behind them. One rule of thumb: The extent to which these technologies engage the user is key to understanding their differences.
What are the differences between terms like chatbot, conversational agent, virtual assistant, etc.?
Rob High: All those terms are used kind of loosely. There are lots of examples in which the terms have been used interchangeably. At IBM, we tend to think of these things somewhat distinctively, and it largely has to do with the degree to which they engage the end user in solving the problem.
   Rob High  
A simple example of this is that there are a lot of chatbots out there today that operate on what we call a single-turn exchange. Somebody says something like 'Alexa, turn on the lights' or 'OK, Google, what's the tallest mountain in the world?' Those are independent, single-turn exchanges. The end user expresses an utterance, the utterance is interpreted or recognized for its intent, and then that intent is mapped onto a specific task.
That's all good, but when somebody asks 'what's my account balance?' they may need to know what their account balance is, but that's really not their problem. Their problem is that they're getting ready to buy something or they're trying to figure out how to save up for their kids' education or they're trying to figure out how to pay their bills -- there's something behind the question.
In my mind, a conversational agent is one that engages the end user into really understanding the nature of the problem behind the question. Part of that includes determining when it's appropriate to dig in deeper but also recognizing that, often, there is a bigger problem there. The conversational agent must be prepared to go to the next level and solicit end users to better understand the problem. Sometimes [conversational agents] have to help [end users] figure out for themselves what the problem is because, sometimes, we'll just go in with a question and we don't really know what it is that we're after.
This is especially important when you're dealing with customer support or servicing a product because if you're having a problem with something that you bought, the first thing that you need to do is describe the problem, but that might just be describing the symptoms and not necessarily the real issue.
It's going to take more than that to figure out what is really going on with the product and what is the issue and whether it's a problem with the product or a problem with the way it's being used or whether it's some transient situation. There are lots of different things that could be behind all that. A conversational agent has to be able to get to that.
You use the term conversational agent, but a lot of people use the term virtual or personal assistant. Which of those terms should we be using, or are they distinct?
High: They're kind of two different sides of the same coin, in some sense. A conversational agent is more focused on what it takes in order to maintain a conversation. With virtual agents or personal assistants, those terms tend to be more relevant in cases where you're trying to create this sense that the conversational agent you're dealing with has its own personality and is somehow uniquely associated with you.
At least for me, the term virtual assistant sort of metaphorically conjures the idea of your own personal butler -- someone who is there with you all the time, knows you deeply, but is dedicated to just you and serving your needs. When a conversational agent is coupled with that kind of personalized knowledge and acts and behaves in a way that gives you the feeling that it's there only for you, I think there becomes an intersection between the two ideas.
For it to serve you on a personal level, any kind of good personal assistant or virtual assistant needs to retain a great deal of context about you, but then use that context as a way of interacting with you -- to use the conversational agent technique for not just anticipating your need but responding to your need and getting to know you better to be able to respond to that need better in the future.
So personal assistants are good at natural language processing and can use machine learning to keep getting better. Do you see chatbots and the various kinds of conversational agents evolving side by side or do you see one overtaking the other?
High: I think both are useful for their own purposes and, to some extent, there's a continuum. But there's certainly a demarcation when it comes to the philosophy of what you're trying to do [and] the tools that you need to be able to do it with and the underlying technologies that are necessary to enable it.
I could imagine a world where chatbots are just chatbots and they do what they've done and they do it well but they don't do much more than that. There may be a use for that, but [I could imagine] other places where there's a lot of utility in going beyond just simply the chatbot to help people with their problems. A lot of that is driven by what kind of utility is called for.
We believe at IBM that the real purpose of AI is to augment human intelligence, not to replace human intelligence. When you think about that, you begin to realize that augmenting human cognition requires getting into a deeper level of understanding of a human and being able to recognize what problems they're trying to get to in a conversation space. [AI] must recognize that humans express themselves in sometimes very subtle ways, and that the intention behind that expression is something that requires a certain degree of reasoning.
The systems have to be trained [using machine learning]; you can't just program them to be able to do all these things. They have to learn. Ultimately, they have to interact with us like we're humans. They have to know something about the fact that, as humans, we have emotions, and our emotions can vary throughout the course of a conversation. [Conversational agents] have to know how to interact with somebody in order to amplify their thinking. There's more to it than just what you typically see today as a chatbot.
So I think both will continue to exist, but a demarcation will occur between those simple things that people can do quickly and easily without a whole lot of additional exploration, versus those situations in which there's a lot of economic value in amplifying human cognition.
How can technologies like chatbots and virtual assistants drive business value? Beyond handling conversational tasks, what's their potential in the enterprise?
High: I think chatbots may be an entry point for almost any enterprise. It's hard to operate an enterprise without having some kind of interface to your clients -- even the simplest of interfaces like those that might occur when you're carrying your smartphone around with you. Almost every institution out there is trying to engage their clients at a deeper level.
Part of that is about getting to know your clients better so that you can serve them better and part of it is about trying to create a higher degree of trust and loyalty. Some of it is about trying to deal with the burgeoning growth in call center expenses as more and more of these relationships drive more hand-holding or deep touch.
I think all of that is conspiring to suggest that going into the digital age, enterprises can only be successful if they're thinking about employing these conversational agents as a way of augmenting their own staff, but, even more so, augmenting the intelligence of their staff and their relationship with their clients and augmenting the intelligence of the clients to create a stronger relationship with the institution.
",conversational agent,Person,jade green,spectrum of colors, , , 
https://ibm.co/2tSzcKn,187446750783_10155484368940784,https://www.facebook.com/ibmwatson/posts/10155484368940784,"We'll be on the ground at Think 2018 from March 19–22 in Las Vegas to cover IBM's biggest event of the year. Tune in to the IBM Watson Twitter (@IBMWatson) to gain an insider's view of all the action, including live streams of our biggest keynotes, demos, announcements and more.

Follow us: ",Link,,,3/16/18 12:44, ,9887,9887,0,13299,13299,0,229,112,147,5,5,11307,8348,0,0,198,0,0,0,0,0,0,0,0,0,0,18,132.0,2.0,20,132.0,3.0,54,67.0,,,75,72.0,,,1,4.0,,1,4.0,,"The latest Tweets from IBM Watson (@IBMWatson). Watson is AI for professionals, designed for your business. New York, NY",,https://twitter.com/ibmwatson,joy,0.080863,positive,0.742445,"IBM's biggest event, IBM Watson Twitter","Company, Location, Company",IBM's biggest event,Company,anger,0.068927,neutral,0,"latest Tweets, IBM Watson, New York","Company, Person, Person",latest Tweets,Company,sadness,0.505754,negative,-0.814708,,,"                                                                                            
Something went wrong, but don’t fret — let’s give it another shot. 





          

",,, , , , , 
,187446750783_10155481153640784,https://www.facebook.com/ibmwatson/posts/10155481153640784,"IBM's biggest event of the year is right around the corner. At Think 2018, hear from some of the brightest minds in their fields and from experts across all IBM technology. Not attending? You can still tune into our live stream next week.",Link,,,3/15/18 9:00, ,8527,8527,0,11430,11430,0,146,86,106,3,3,9649,7116,0,0,128,0,0,0,0,0,0,0,0,0,0,20,62.0,1.0,20,63.0,1.0,48,44.0,,,59,47.0,,,1,2.0,,1,2.0,,,,,joy,0.493926,positive,0.663288,"IBM's biggest event, brightest minds, live stream",Company,IBM's biggest event,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2oMMaEo,187446750783_10155478617045784,https://www.facebook.com/ibmwatson/posts/10155478617045784,Lingmo International is an Australian start-up that used Watson to create a device that translates conversations in real time. Learn how they expanded to add new languages and developed a smartwatch for the service: ,Link,,,3/14/18 8:41, ,8005,8005,0,10816,10816,0,161,98,131,4,5,9125,6811,0,0,128,0,0,0,0,0,0,0,0,0,0,19,77.0,1.0,20,78.0,1.0,49,60.0,,,70,61.0,,,1,4.0,,1,3.0,,  The Australian startup which launched an earpiece that can instantly translate nine languages now has a smartwatch and a messaging service.,https://edge.alluremedia.com.au/uploads/businessinsider/2018/03/two-watches.jpg,https://www.businessinsider.com.au/lingmo-smartwatch-translates-languages-2018-3,joy,0.543755,neutral,0,"Lingmo International, Australian start-up","Company, Person",Lingmo International,Company,joy,0.490414,positive,0.586758,Australian startup,,Australian startup,,joy,0.586879,positive,0.590356,Lingmo International,"Company, Person, Person, Quantity, Company, Person, Quantity, Quantity, Quantity, Organization, Location, Person, Company, Quantity, Quantity, Location, Quantity","The Australian startup which launched an earpiece that can instantly translate nine languages now has a smartwatch and a messaging service.
In less than a year since he launched the TranslateOne2One device at a United Nations event in Switzerland, former plumber Danny May has become an unlikely, but extremely busy, advocate for IBM’s AI technology, Watson.
Watson takes 30-second blocks of conversation in English, Japanese, French, Chinese, Italian, Spanish, German, Portuguese and Arabic and returns it to the One2One earpiece coherently in any of those languages.
May began working on the technology five years ago when he struggled to communicate effectively while on a business trip to China.
His startup, Lingmo International, released the $279 earpiece in October last year, even beating Google’s Pixel Bud translation service to the market, with the major advantage over its competitors of using a SIM card to operate independently of a phone.
But by December, feedback proved to May that an earpiece isn’t a good fit for everybody. So here’s another way to chat with someone in nine different languages:
It’s called the Time2Translate and you can buy it tomorrow, with delivery expected in April, anywhere in the world.
“People loved the One2One tech and loved what it was doing, but some people found it hard to use on the ears,” May says. “The tech was never in question, it was always just a matter of how we could put it into a better user experience.”
The smartwatch also knocks out some extra features that people weren’t really using on the earpiece.
“There was too much going on, people just wanted a translation device,” May says.
Lingmo kept Google Maps — it is essentially a travel accessory — and Bluetooth capability if people don’t want to connect to Lingmo’s prepaid SIM network. Google Play is available for downloads, but other app stores have been axed.
In return, the Time2Translate gets a four-hour constant use battery life (14 hours standby) and extra memory.
And most importantly, it’s on your wrist.
As if speaking into a watch like you have in all your spy film dreams isn’t impressive enough, Lingmo is also launching new software along with the Time2Translate which enables real-time messaging in nine languages.
So you can send a voice message in English on your watch and the recipient will receive it in Chinese. But what is truly extrordinary is the watch will enable up to 1,000 users to converse in a group chat across all nine languages.
Those languages represent 90% of the world’s spoken words.
May said Lingmo burned through five protoypes to find speakers for the side of the watch that met the standard required for speaking English into, and hearing Arabic out of up to two metres away. 
And because Lingmo is working with Watson every second to improve its service, the translation is far beyond the typical clunky word-for-word systems you might be used to online.
But for a premium service, expect to pay a premium price – the watch starts from $US699 for the Lifestyle model. Here’s the complete spec rundown: 
“We just wanted to turn those (earpiece) negatives into positives,” May says about developing the smartwatch. “Interest has been really positive around the world, and we’re now dealing with some proof of concepts with major airlines and US multinationals. 
“We’re slowly getting there; it’s just about doing it right and being a startup it’s just about focusing on the little things and getting them right first.”
 Yes, it has speakers. Loud ones. Picture: Supplied
Since the October rollout of One2One, Lingmo International has moved into new office on the NSW central coast and grown its staff from three to more than 20. It also now has offices in the Middle East and China, and a virtual office in Silicon Valley which it is looking to make permanent.
May says it’s been a challenging time in his life, but he doesn’t miss sticking his hand down the toilet.
“It’s what you start a company for. You have your hard times but you just have to keep pushing on and that’s what it’s all about with the watch.
“You just have to keep innovating.”
His ultimate goal is to see Lingmo’s product line include the “holy grail”, where anyone can pick up a phone and make a call which instantly translates to the other end and back again.
“We’re making slow inroads,” he says. “The software on the watch is a significant step towards that.”
Follow Business Insider Australia on Facebook, Twitter, LinkedIn, and Instagram.
",Lingmo International,Company,charcoal,addiction,person,person,addiction
,187446750783_10155473570265784,https://www.facebook.com/ibmwatson/posts/10155473570265784,"The ability of AI to think, learn, interpret and reason is why many organisations are using systems like Watson as virtual agents to liaise with both customers and employees, and help them solve problems or get answers to questions much faster via Mashable: 
",Link,,,3/12/18 10:04, ,10309,10309,0,14379,14379,0,344,212,239,1,1,11377,7984,0,0,301,0,0,0,0,0,0,0,0,0,0,27,155.0,,32,158.0,,81,141.0,,,90,149.0,,,1,,,1,,,,,,joy,0.295185,positive,0.865628,virtual agents,"Person, Person",virtual agents,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2DITGXe,187446750783_10155470576455784,https://www.facebook.com/ibmwatson/posts/10155470576455784,"&quot;Whether you’re a doctor, engineer, lawyer, music producer, teacher—or CEO—we are all going to do our work with the aid of analytics and forms of AI.&quot; – IBM CEO Ginni Rometty via The Wall Street Journal: ",Link,,,3/11/18 9:30, ,38912,38912,0,53969,53969,0,2193,1537,1996,26,26,29832,21320,0,0,1331,0,0,0,0,0,0,0,0,0,0,177,733.0,29.0,192,767.0,36.0,825,806.0,,,1128,868.0,,,13,13.0,,13,13.0,,,,https://www.wsj.com/articles/ginni-rometty-on-how-ai-is-going-to-transform-jobsall-of-them-1516201040,joy,0.470462,positive,0.592575,"music producer, aid of analytics, forms of AI","Person, Person, Company",music producer,Person, , , , , , , , ,joy,0.623026,negative,-0.236678,"number of recent studies, new tools, distinct minority of the world, artificial intelligence",Company,"Today, the technologies grouped together under “artificial intelligence” are entering mainstream business and daily life. As often happens with radically new tools, some people worry it will destroy jobs. 
The good news? A number of recent studies, including one commissioned by IBM, indicate that history is likely to repeat itself. Some occupations will go away, and new ones will be created, but even together, those will be a distinct minority of the world’s occupations. 
",number of recent studies,Company, , , , , 
https://ibm.co/2BQvtMb,187446750783_10155468335380784,https://www.facebook.com/ibmwatson/posts/10155468335380784,"From social media to public service, some people are interacting with artificial intelligence every single day and it may surprise you how broadly it is being adopted. Here are some ways we’re already using AI on the daily via Mashable: ",Link,,,3/10/18 11:10, ,8703,8703,0,12670,12670,0,243,142,172,10,10,9938,6682,0,0,212,0,0,0,0,0,0,0,0,0,0,26,115.0,,26,117.0,,46,104.0,,,55,117.0,,,2,8.0,,2,8.0,,"AI may seem like a confusing phenomenon, but we often interact with artificial intelligence technology on a daily basis.",https://mondrian.mashable.com/2017%252F12%252F21%252F6b%252F3d312f1f63af4fc99a8ceb433c2e2ee9.dd1ec.jpg%252F1200x630.jpg?signature=kcqxN0T_UIzf3OptSIumYQrUYXs=,https://mashable.com/2018/01/17/ways-interact-artificial-intelligence/#TeGG1Rp9Ksq3,joy,0.38171,positive,0.839895,"social media, public service, artificial intelligence",Person,social media,Person,sadness,0.364451,positive,0.295635,"daily basis, confusing phenomenon",Person,daily basis,Person,joy,0.509032,positive,0.580654,artificial intelligence,"Person, Person, Person, Person, Company, Company, Person, Company, Person","If someone were to say to you that you’ve spent all day interacting with artificial intelligence, you’d probably stop and try to recount any instances of accidentally running into a robot. 
Despite what’s constantly being hammered into our brains via science fiction movies and television, AI comes in many forms, which may surprise you. Not only has artificial intelligence become integrated within a number of industries, but it’s teaching people how to streamline business and optimize their lives.
From social media to public service, some people are interacting with artificial intelligence every single day and it may surprise you how broadly it is being adopted. Here are some ways we’re already using AI on the daily. 
Sometimes the integration of artificial intelligence presents itself in a more obvious manner. Take virtual assistants, for example: Increasingly when you sign onto a website and are greeted with a chatbot, you’re more likely to interact with a computer-generated assistant and referred to a human only if your question is quite complex. You'll know pretty quickly whether it's a human or a robot, like how UBank's Robochat introduces itself.
UBank recently launched RoboChat, an IBM Watson-powered supercomputer that can answer questions about home loan applications. 
“In essence, we’re trying to make it as easy as we can for customers to do what some of them consider to be a cumbersome process,” said UBank’s head of digital Jeremy Hubbard, in an interview with The Australian. RoboChat is designed to answer questions relating to home loan applications through natural language processing – that means the bot can understand the intent of what you’re asking and carry a conversation like a human would. 
RoboChat is powered by IBM Watson, which is an artificial intelligence platform that ingests and comprehends massive amounts of data. For UBank, Watson provided the conversational capability. 
As far as one’s daily interactions with artificial intelligence, you get a front-row seat to the simplicity of AI every time you speak to a virtual assistant. 
Whenever you ask your phone for directions, order paper towels from a virtual assistant, or give any non-human entity a command, you’re speaking to a device powered by AI. Virtual assistants use natural language processing (NLP) to understand what you say to then provide a response to your query.
Social media is another platform that benefits from the ever-expanding brain of artificial intelligence — Twitter recently brought Watson on board to help prevent abuse by tracking problematic accounts. 
""Watson is really good at understanding nuances in language and intention,” said vice president of data strategy at Twitter Chris Moody, in an interview with The Telegraph, ""What we want to do is be able to identify abuse patterns early and stop this behaviour before it starts."" The technology scans accounts engaged in abusive behaviour by seeking out certain harmful keywords from users and applying an understanding of the context in which they are written.  
Another area where AI has made its way into our everyday lives? Transportation. Ride-share companies utilize AI to improve the function and precision of their apps. Machine learning helps provide ETAs for arrivals using data from millions of past trips — in addition to things like distance and speed limit — to provide estimated arrival times. 
Although it may seem like a natural fit for a tech company to use artificial intelligence, there are even more surprising ways AI impacts our lives that we may not realize. Take your evening glass of wine, for example. AI has found its way into one New Jersey vineyard and streamlined the way grapes are grown.
E. & J. Gallo Winery recently looked to Watson to develop an intelligent irrigation system. Watson monitors weather reports and uses remote sensor data to measure and distribute the optimal amount of water that each grapevine needs to survive and flourish. By mining data from sources like The Weather Company, which has data from over two billion locations, E. & J. Gallo Winery has developed a custom irrigation plan that’s allowed them to reduce water usage by 25 percent.
While the prospect of an AI-engrained life may seem a bit intimidating, it’s humans who are really in control. In fact, humans often supervise artificial intelligence processes, which is the case with “Deep Learning.”
Deep learning is a computation model that can interpret and make sense of information in ways that previously were not possible with traditional computing. In a way, it learns like a human does, taking on feedback and adjusting to improve. 
Although deep learning allows machines to learn like humans, they do not have the ability of human judgement. No matter how much data you present to a deep learning model, it is not able to reason and judge what is happening on its own. Rather, it requires humans to oversee and draw conclusions from the AI processes.
“Deep learning has been successful for well-defined kinds of problems where there’s lots of labelled data, and it’s good at perception and classification problems rather than real reasoning problems,” said IBM Distinguished Researcher Murray Campbell. “The next big opportunity is to do for reasoning what deep learning did for perception and classification.”
So, what will a machine be able to do with the type of skills associated with deep learning? Researchers hope that they’ll be able to solve problems that involve human traits like common sense.
“Humans know that if you put an object on the table, it’s likely to stay on the table unless the table’s tilted,” explained IBM Director of AI and Cognitive Analytics Research Aya Soffer.
“But nobody writes that in a book — it’s something implicit. Systems don’t have this common-sense capability.”
The AI landscape is constantly changing and improving. Because of the strides IBM has made with Watson, the current state of artificial intelligence is one that is as equally impressive as it is necessary. We’ve already grown so dependant on artificial intelligence to give us directions, provide public service, help us with taxes, and keep us safe in the air.
Some may find that a day with artificial intelligence is virtually indistinguishable from a day without it, others couldn’t imagine going to work without Watson’s intuitive brain. What AI’s touch will look like 50 years from now is anyone’s guess.
",artificial intelligence,Person,emerald,shower room,indoors,shower room,-
https://ibm.biz/BdjC9P,187446750783_10155465677000784,https://www.facebook.com/ibmwatson/videos/10155465677000784/,"Technical innovation is outpacing the ability of many companies to adapt. At IBM's Think 2018, gather with the boldest and brightest to discover the power of AI and cloud to stay ahead. Join us March 19 – 22 in Las Vegas, and let's think together. Save $300 by using our promo code TK18WVIP and selecting 'Watson' as your interest: ",Video,,,3/9/18 10:16, ,3714,3714,0,5377,5377,0,224,185,227,2,2,4175,2839,0,0,139,660,712,0,0,1659,1829,0,0,3892,8148,9,47.0,2.0,9,48.0,2.0,69,10.0,,126.0,84,13.0,,130.0,,2.0,,,2.0,,"The digital-first IBM business and technology event will take place May 5â7, 2020. Learn about the latest advancements in open technologies from hybrid multicloud to data and AI and interact with luminaries who are using them to transform our lives.Â ",https://www.ibm.com/events/shared/img/think2020/think-og2.jpg,https://www.ibm.com/events/think/?cm_mmc=OSocial_Facebook-_-xIBM+Events_Global+Conferences-_-WW_WW-_-fbWatsonCore&cm_mmca1=000021TD&cm_mmca2=10001376&,joy,0.531793,positive,0.846408,"Technical innovation, IBM's Think","Company, Quantity, Location",Technical innovation,Company,joy,0.359078,positive,0.94015,"digital-first IBM business, latest advancements","Company, Person",digital-first IBM business,Company,joy,0.557024,positive,0.810422,,"Company, Person, Company, Person","Since becoming CEO in January 2012, Ginni has led IBM through the most significant transformation in its history, reinventing the company to lead in the new era of AI, blockchain, cybersecurity and quantum technologies, all delivered on IBM’s enterprise-strength cloud platform. Today, IBM is the world leader in AI and cloud computing for business, underpinned with trust and security.
IBM’s commitment to diversity and inclusion also has advanced under Ginni’s leadership. This includes extending parental leave and making it easier for women to return to the workforce through a “returnships” program with hands-on work experience in emerging technologies. This pioneering work was recognized in 2018 by the prestigious Catalyst Award for advancing diversity and women’s initiatives. IBM is the only tech company to have earned this recognition in the last 20 years and the only company ever to be honored four times.
Arvind Krishna leads the IBM business unit that provides the cloud and data platforms on which the company’s clients build the future. His responsibilities include IBM Research, IBM Cloud, IBM Data and AI, and IBM’s Security and Cognitive Applications businesses. He also drove the company’s 2019 acquisition of Red Hat.
Arvind leads the unit’s strategy, product design, offering development, marketing, sales and service. He also guides IBM’s overall strategy in technologies including artificial intelligence, quantum computing, blockchain, cloud platform services, data-driven solutions, and nanotechnology.
Jim Whitehurst is president and chief executive officer of Red Hat, the world’s leading provider of open source enterprise IT software solutions and services. An avid advocate for open software as a catalyst for business innovation, Whitehurst has proven expertise in helping companies flourish—even in the most challenging economic and business environments.
Whitehurst has grown Red Hat and its influence by reaching key milestones—most notably in 2012, when Red Hat became the first US$1 billion open source software company. Company revenue reached almost US$3 billion in 2018.
In 2015, Whitehurst published The Open Organization: Igniting Passion and Performance, a book that shows how open management principles can help organizations succeed in a fast-paced, connected era.
Amal Clooney is a barrister who specializes in international law and human rights. Through international courts, she frequently represents political prisoners, journalists and victims of mass atrocities.
Ms Clooney served as a Sr. Advisor to Kofi Annan. She was appointed to the UK’s panel of experts on combatting sexual violence and to a panel on public international law. She was also appointed as the UK’s Special Envoy for Media Freedom by the UK Foreign Secretary and she serves as vice-chair of a High-Level Panel of Legal Experts on Media Freedom.
Ms Clooney is a Visiting Professor at Columbia Law School, where she co-teaches the Human Rights course, and she is co-author of a forthcoming book titled ‘The Right to a Fair Trial in International Law’ to be published in 2020.
Mayim Bialik is known for her role on the hit CBS comedy, The Big Bang Theory as Amy Farrah Fowler, for which she has received two Critics Choice Awards, four Emmy Award nominations and a SAG Award nomination. Bialik has appeared in numerous beloved roles throughout her dynamic acting career.
An acclaimed author, Bialik has written two #1 New York Times bestsellers, Girling Up: How to Be Strong, Smart and Spectacular, and the recently released Boying Up: How to Be Brave, Bold and Brilliant. She has also written a parenting book, Beyond the Sling, and a cookbook, Mayim’s Vegan Table. Bialik has recently dedicated her skills as a writer, actress, neuroscientist and mother to driving the lifestyle website GrokNation.com, which she started.
",,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2CH8kgJ,187446750783_10155463495100784,https://www.facebook.com/ibmwatson/posts/10155463495100784,3 popular types of chatbots companies are building to enhance customer experience: ,Link,,,3/8/18 14:27, ,9466,9466,0,13156,13156,0,242,171,202,4,4,10439,7744,0,0,212,0,0,0,0,0,0,0,0,0,0,19,81.0,2.0,20,85.0,4.0,64,118.0,,,76,126.0,,,2,2.0,,2,2.0,,"As chatbots continue to gain popularity, our latest blog highlights the three types of business chatbots you can build to better reach and target customers.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/12/Conversation_service_Social1200x628-1.png,https://www.ibm.com/blogs/watson/2017/12/3-types-of-business-chatbots-you-can-build/,joy,0.075351,positive,0.752174,"popular types of chatbots companies, customer experience",,popular types of chatbots companies,,joy,0.425058,positive,0.725044,"types of business chatbots, latest blog",,types of business chatbots,,sadness,0.539365,positive,0.560402,single-turn type bots,"Person, Company","Key Points:
 From a business perspective, here are the 3 most common chatbots that are being built:
 – Support chatbots that are built to master a single domain
 – Skills chatbots that are single-turn type bots that do not require a lot of contextual awareness
 – Assistant chatbots that are the middle ground between a support and skills chatbot, knowing a little bit about a variety of topics
A few years ago when chatbots were just gaining popularity, there was a lot of talk around what a chatbot actually was. With the advent of natural language processing and various machine learning techniques, some of the more advanced conversational applications wanted to separate themselves from their competition. Many began calling themselves “virtual assistants.” This implied that they were somehow bigger or more powerful than existing chatbots, or perhaps were more conversational or could cover a wider range of topics.
However, we quickly discovered that the market did not care how powerful the bot was or about the underlying technology, so long as it solved the right problems. So in a way, many of these different terms for bots became more or less synonymous with each other. It didn’t matter what you called it – you were getting something you could hold a conversation with. We’re now at a point where we know that regardless of what you call the bot, there are usage patterns and differentiation that make chatbots distinct.
When you’ve done your research and are at the point of beginning to build your bot, think carefully about what problems you’re trying to solve and what functionalities you will want to incorporate. Knowing what you want your application to solve for and assist with will decide the type of chatbot, virtual assistant or agent you ought to build. This will impact both your development plan and, as importantly, your end-user experience. The following are the three main types of chatbots I have come across, with background on their particular uses and variations.
Support chatbots are built to master a single domain, like knowledge about a company. Support chatbots need to have personality, multi-turn capability, and context awareness. They should be able to walk a user through any major business processes, and answer a wide range of FAQ-type questions. You will want to have a short-tail and long-tail combo solution when building this type of chatbot. At IBM Watson, we would use the Watson Conversation service for the short-tail, common questions and processes, and Watson Discovery service for the long-tail, but there are many potential solutions for this. Speech is an optional feature, and not a necessity, since users typically have sat down at a desktop and are ready to figure out their solution. The chatbot developer will want to spend the most time making sure it is as easy as possible to navigate the bot, and ensuring it can execute the actions that your users actually care about (for example, just because you want to sell more credit cards doesn’t mean your customers want to open more credit card accounts).
Skills chatbots are typically more single-turn-type bots that do not require a lot of contextual awareness. They have set commands that are intended to make life easier: “Turn on my living room lights,” for example. Speech functionality is recommended for this type of chatbot so the user does not need to turn on a device or click any buttons. They should be able to follow commands quickly, so that your users can multitask while engaging with the bot. These chatbots do not need to worry too much about contextual awareness, unless you want to design a particularly advanced one, as people will quickly learn what to say, and say it appropriately. It’s a nice bonus if you can give a command, and your bot knows – to return to our example – that you are in the kitchen and acts to turn on the correct lights.
However, this is not a necessary function, as users will quickly learn to give the appropriately specific command. When building a skills bot, it is important to focus on integration, especially when controlling a home or personalized objects. Keep integration simple so your users can interact with the bot without worrying about how to use .
Assistant chatbots are more or less a middle ground between the two bots above. They work best when they know a little bit about a variety of topics. Many people envision these bots will someday become navigators of all other bots that are out there now. Want to pay a bill? Ask your assistant bot to talk to the support bot for your bank. Assistant chatbots need to be conversational and respond to just about anything, while being as entertaining as possible. Siri is a good, current example – while she only does so much, people continually ask her for things simply because even when she cannot perform the command, the response she gives tends to be amusing. When building an assistant chatbot, it is important to make it as obvious as possible how the bot is trained. The range of questions a user might ask is large, so making sure you have adequate coverage is going to be the most difficult factor. In many cases, when people do not know what they should ask, they will not ask anything at all. And if you miss the few topics they initially are willing to try, they will not come back for more.
Even though these are the most common types, many bots in production fall somewhere in between two. Some are even a combination of all three. No matter what type of bot you decide to build, it is important to give your bot some life and personality, make it useful, and make sure it’s easy to use. People interact with bots because they want to get something done in a more natural way than was previously possible. Whether it’s something simple like turning on a light, or something complex like applying for a mortgage, every pattern has specific features that make it stand out, so be sure your bot shines brightly in what it’s designed to do. The possibilities are endless.
",single-turn type bots,Person,blue,razor,tool,cutlery,razor
https://ibm.co/2G3RIRX,187446750783_10155460366890784,https://www.facebook.com/ibmwatson/posts/10155460366890784,IBM Watson and Salesforce will double down on their relationship with AI – these two top tech firms connecting their artificial intelligence platforms reinforces the growing value of AI and big data in the enterprise. ,Link,,,3/7/18 11:00, ,15525,15525,0,21121,21121,0,668,440,519,11,11,17032,12610,0,0,561,0,0,0,0,0,0,0,0,0,0,39,296.0,10.0,39,300.0,10.0,236,234.0,,,277,242.0,,,9,2.0,,9,2.0,,"The expanded partnership, focused on delivering deeper insights, will see each firm become a preferred provider for the other.",https://tr2.cbsistatic.com/hub/i/r/2018/01/19/8ad55407-aa17-48f7-b14f-fd468ab5a10d/thumbnail/770x578/fe82c6875bb7a84ae16cbe4faa220069/ibmsfceos.jpg,https://www.techrepublic.com/article/ibm-and-salesforce-double-down-on-ai-announce-watson-einstein-collaboration/,sadness,0.170555,neutral,0,"IBM Watson, top tech firms, artificial intelligence platforms","Company, Company, Person",IBM Watson,Company,joy,0.344865,positive,0.724147,expanded partnership,,expanded partnership,,joy,0.157112,positive,0.683074,"Salesforce Quip, Watson services, power of IBM Cloud","Company, Company, Person, Person, Person, Person"," 	Building a slide deck, pitch, or presentation? Here are the big takeaways: 
 	Salesforce and IBM announced an expansion of their strategic partnership on Friday, with the firms combining the power of IBM Cloud and Watson services with Salesforce Quip and Salesforce Service Cloud Einstein, the firms announced in a joint  	press release Friday.
 	Two top tech firms like Salesforce and IBM connecting their artificial intelligence (AI) platforms reinforces the growing value of AI and big data in the enterprise. AI, especially, is taking center stage as one of the battleground technologies for business, and this is a clear example of two CEOs making a move to reinforce that with their partnership.
 	In the release, IBM CEO Ginni Rometty said that the combination of Watson and Einstein will ""help enterprises make smarter business decisions."" Salesforce CEO Marc Benioff echoed this sentiment, saying in the release that the combo will ""deliver even more innovation to empower companies to connect with their customers in a whole new way, leveraging the power of the cloud and AI.""
 	 	SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
 	Specifically, the Watson/Einstein combination will provide actionable next steps in a given process, the release said. This could potentially help users strengthen customer relationships, or automate more processes with custom-triggered actions based on how the AI interprets a recent call or chat experience.
 	In addition to the firms connecting their AI platforms, they will share preferred vendor status for one another in specific areas. For Salesforce, IBM will become a preferred cloud services provider and, for IBM, Salesforce will become a preferred customer engagement platform, the release said.
 	Another result of the partnership will be the development of some IBM Watson Quip Live Apps. With these apps, which can be embedded into a Quip document, users will have access to Watson's cognitive computing when working in the document creation and editing platform, the release said.
 	The expansion builds on a joint solutions partnership that was originally  	announced by the companies back in March 2017. Currently, the partnership serves more than 4,000 joint customers, the release said, including Autodesk.
 	""Combining the AI power of Watson and IBM Cloud with insights from Salesforce has helped Autodesk better understand its customers and ultimately create a transformed customer experience,"" Rachael Cotton, senior manager of machine assisted service engagement for Autodesk, said in the release.
",Salesforce Quip,Company,coal black,couple,person,couple,-
https://ibm.biz/BdjC9P,187446750783_10155457629920784,https://www.facebook.com/ibmwatson/posts/10155457629920784,"Appointed as the first US Chief Data Scientist by President Obama, DJ Patil was tasked with making the U.S. Federal Government a data-driven enterprise. Hear him live at Think 2018. Register w/code TK18WVIP and select Watson as your interest for $300 off: ",Photo,,,3/6/18 8:50, ,6042,6042,0,8027,8027,0,140,90,109,1,1,7027,5286,0,0,105,0,0,0,0,0,0,0,0,0,0,5,57.0,2.0,6,57.0,2.0,50,11.0,35.0,,59,11.0,39.0,,1,,,1,,,"The digital-first IBM business and technology event will take place May 5â7, 2020. Learn about the latest advancements in open technologies from hybrid multicloud to data and AI and interact with luminaries who are using them to transform our lives.Â ",https://www.ibm.com/events/shared/img/think2020/think-og2.jpg,https://www.ibm.com/events/think/?cm_mmc=OSocial_Facebook-_-xIBM+Events_Global+Conferences-_-WW_WW-_-fbWatsonCore&cm_mmca1=000021TD&cm_mmca2=10001376&,joy,0.439542,neutral,0,"first US Chief Data Scientist, President Obama","Person, Organization, Person",first US Chief Data Scientist,Person,joy,0.359078,positive,0.94015,"digital-first IBM business, latest advancements","Company, Person",digital-first IBM business,Company,joy,0.557024,positive,0.810422,,"Company, Person, Company, Person","Since becoming CEO in January 2012, Ginni has led IBM through the most significant transformation in its history, reinventing the company to lead in the new era of AI, blockchain, cybersecurity and quantum technologies, all delivered on IBM’s enterprise-strength cloud platform. Today, IBM is the world leader in AI and cloud computing for business, underpinned with trust and security.
IBM’s commitment to diversity and inclusion also has advanced under Ginni’s leadership. This includes extending parental leave and making it easier for women to return to the workforce through a “returnships” program with hands-on work experience in emerging technologies. This pioneering work was recognized in 2018 by the prestigious Catalyst Award for advancing diversity and women’s initiatives. IBM is the only tech company to have earned this recognition in the last 20 years and the only company ever to be honored four times.
Arvind Krishna leads the IBM business unit that provides the cloud and data platforms on which the company’s clients build the future. His responsibilities include IBM Research, IBM Cloud, IBM Data and AI, and IBM’s Security and Cognitive Applications businesses. He also drove the company’s 2019 acquisition of Red Hat.
Arvind leads the unit’s strategy, product design, offering development, marketing, sales and service. He also guides IBM’s overall strategy in technologies including artificial intelligence, quantum computing, blockchain, cloud platform services, data-driven solutions, and nanotechnology.
Jim Whitehurst is president and chief executive officer of Red Hat, the world’s leading provider of open source enterprise IT software solutions and services. An avid advocate for open software as a catalyst for business innovation, Whitehurst has proven expertise in helping companies flourish—even in the most challenging economic and business environments.
Whitehurst has grown Red Hat and its influence by reaching key milestones—most notably in 2012, when Red Hat became the first US$1 billion open source software company. Company revenue reached almost US$3 billion in 2018.
In 2015, Whitehurst published The Open Organization: Igniting Passion and Performance, a book that shows how open management principles can help organizations succeed in a fast-paced, connected era.
Amal Clooney is a barrister who specializes in international law and human rights. Through international courts, she frequently represents political prisoners, journalists and victims of mass atrocities.
Ms Clooney served as a Sr. Advisor to Kofi Annan. She was appointed to the UK’s panel of experts on combatting sexual violence and to a panel on public international law. She was also appointed as the UK’s Special Envoy for Media Freedom by the UK Foreign Secretary and she serves as vice-chair of a High-Level Panel of Legal Experts on Media Freedom.
Ms Clooney is a Visiting Professor at Columbia Law School, where she co-teaches the Human Rights course, and she is co-author of a forthcoming book titled ‘The Right to a Fair Trial in International Law’ to be published in 2020.
Mayim Bialik is known for her role on the hit CBS comedy, The Big Bang Theory as Amy Farrah Fowler, for which she has received two Critics Choice Awards, four Emmy Award nominations and a SAG Award nomination. Bialik has appeared in numerous beloved roles throughout her dynamic acting career.
An acclaimed author, Bialik has written two #1 New York Times bestsellers, Girling Up: How to Be Strong, Smart and Spectacular, and the recently released Boying Up: How to Be Brave, Bold and Brilliant. She has also written a parenting book, Beyond the Sling, and a cookbook, Mayim’s Vegan Table. Bialik has recently dedicated her skills as a writer, actress, neuroscientist and mother to driving the lifestyle website GrokNation.com, which she started.
",,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2F4Hy6I,187446750783_10155455325930784,https://www.facebook.com/ibmwatson/posts/10155455325930784,"For Michelle Peluso, the climb to becoming IBM's first-ever CMO was met with learning curves. From leading an online travel company in the wake of 9/11 to becoming the CEO of Gilt.com, here's how she managed it all as a working mom: ",Link,,,3/5/18 11:09, ,13403,13403,0,18140,18140,0,526,412,518,8,8,14262,10650,0,0,417,0,0,0,0,0,0,0,0,0,0,21,141.0,2.0,26,141.0,2.0,197,273.0,,,236,282.0,,,1,7.0,,1,7.0,,The executive's career is full of tough challenges and strong leadership.,https://www.workingmother.com/sites/workingmother.com/files/styles/opengraph_1_91x1/public/images/2017/10/michellepeluso_copy.jpg?itok=NCmTHxaW,https://www.workingmother.com/how-michelle-peluso-lead-by-example-and-became-an-ibm-executive,joy,0.564134,positive,0.829971,"Michelle Peluso, online travel company","Person, Company",Michelle Peluso,Person,joy,0.395693,neutral,0,"strong leadership, tough challenges, career",,strong leadership,,joy,0.623643,positive,0.46949,,"Quantity, Person, Person, Company, Person, Quantity, Person"," Kids: Auden, 9, and Cole, 7
Fifteen-minute meetings. Making quick decisions. Leading by example. That’s what’s helped Michelle Peluso win the respect of managers and reports—and get home to her family at a reasonable hour every day, despite her lofty titles and mountains of responsibilities. That’s not to say she hasn’t struggled along the way. “It looks like my career has been charmed and easy,” she says. ""But I’ve had plenty of failures. I’ve wondered, Am I doing the best I can as a mom, as a professional? There have been lots of moments of reflection and concern. Humility and self-reflection can be profound sources of inspiration.”
Michelle adds that the best thing to do is to stay determined and set an example for future female executives. “You don’t always get it right. You’re going to fail and mess up and disappoint your kids, yourself and your boss sometimes,” she admits. “But it’s worth it to show the girls who come behind us that we opened the door for them even farther. You’ve gotta pick yourself back up.”
Case in point: In the wake of 9/11, the revenues on her now-defunct online travel company, Site59, hit rock-bottom. “We were a couple of blocks from Ground Zero. I had a devastated employee group. Our business model was in jeopardy. Investors were freaking out. We had stranded travelers. We had to operate on all fronts in crisis mode. It took ruthless prioritizing and incredible focus—with huge heart. I poured everything I could into motivating and inspiring the team. The greatest leadership lesson of my life came out of that.” Just a few months later, the business was acquired by Travelocity, which led to a senior vice president position there, and eventually, her next CEO gig.
Her advice to other working moms: “Bring your whole personality and authenticity to work. Take grace along, and find humor in it all.”
""I took 10 weeks’ maternity leave when I had my daughter while at Travelocity. When I started going to the office, our nanny would walk my daughter over to nurse. But I ended up going right from Travelocity to Citi, and I wasn’t fully off the grid. I was home, but I’d join calls remotely.""
""Boston Consulting Group gave me an offer straight out of college. But I wanted to continue my education and broaden my horizons. I got a scholarship to Oxford. Learning philosophy strengthened my abilities. In my last year of grad school, I restarted the conversation with BCG. I worked there for three years.""
""My dad and grandparents are entrepreneurs, so I understood starting a company from my family. I wanted to get back to the business world after the White House, and I knew if I didn’t start something then, I never would. BCG wanted me to come back, but instead, they gave me seed money.""
",,Quantity,coal black,call center,building,call center,-
https://ibm.co/2opSEck,187446750783_10155452659470784,https://www.facebook.com/ibmwatson/posts/10155452659470784,"Meet CIMON, the Watson-powered astro-assistant designed by Airbus Space to support the International Space Station on its next space mission: ",Link,,,3/4/18 10:00, ,12909,12909,0,18241,18241,0,320,197,253,5,5,14250,10071,0,0,269,0,0,0,0,0,0,0,0,0,0,42,146.0,2.0,44,146.0,2.0,109,103.0,,,149,104.0,,,1,4.0,,1,4.0,,"In June, German astronaut Alexander Gerst will embark on his second six-month mission to the International Space Station (ISS), serving as station commander in the second half of his stay. On this mission, Gerst and his team will receive some unusual support: CIMON (Crew Interactive Mobile Companion) will be on board – a medicine ball-sized device, weighing about 11-pounds. CIMON is currently being developed by Airbus on behalf of the German Aerospace Center (DLR) as an intelligent, mobile and interactive astronaut assistance system. This new technology will be tested on the ISS as part of the Horizons mission of the European Space Agency. CIMON, using IBM’s Watson technology, will help astronaut Gerst to perform three tasks: Together they will experiment with crystals, solve the Rubik magic cube based on videos and conduct a complex medical experiment using CIMON as an ‘intelligent’ flying camera. CIMON’s digital face, voice and use of artificial intelligence make it a “colleague” to…",https://www.ibm.com/blogs/think/wp-content/uploads/2018/02/cimon-floating.jpg,https://www.ibm.com/blogs/think/2018/02/watson-space/,joy,0.225934,neutral,0,"Meet CIMON, International Space Station","Person, Company",Meet CIMON,Person,joy,0.22886,positive,0.797114,German astronaut Alexander Gerst,"Person, Person, Quantity, Organization",German astronaut Alexander Gerst,Person,joy,0.564615,positive,0.767846,,Person,"Share this post:
In June, German astronaut Alexander Gerst will embark on his second six-month mission to the International Space Station (ISS), serving as station commander in the second half of his stay. On this mission, Gerst and his team will receive some unusual support: CIMON (Crew Interactive Mobile Companion) will be on board – a medicine ball-sized device, weighing about 11-pounds.
CIMON is currently being developed by Airbus on behalf of the German Aerospace Center (DLR) as an intelligent, mobile and interactive astronaut assistance system. This new technology will be tested on the ISS as part of the Horizons mission of the European Space Agency.
CIMON, using IBM’s Watson technology, will help astronaut Gerst to perform three tasks: Together they will experiment with crystals, solve the Rubik magic cube based on videos and conduct a complex medical experiment using CIMON as an ‘intelligent’ flying camera.
CIMON’s digital face, voice and use of artificial intelligence make it a “colleague” to the crew members. This collegial “working relationship” facilitates how astronauts work through their prescribed checklists of experiments, now entering into a genuine dialogue with their interactive assistant. The developers responsible for CIMON predict that this will help reduce astronauts’ stress and at the same time improve efficiency. In addition, CIMON helps enhance safety, because it can also serve as an early warning system in case of technical problems in the future.
How CIMON learns
CIMON is currently being trained to identify its environment and its human interaction partners. AI gives the space assistant text, speech and image processing capabilities, as well as the ability to retrieve specific information and findings. These skills, which can be trained individually and deepened in the context of a given assignment, are developed based on the principle of understanding – reasoning – learning.
Watson speech and vision technologies helped train CIMON to recognize Alexander Gerst, using voice samples and Gerst, as well as “non-Gerst” images. It also used the Watson Visual Recognition service to learn the construction plans of the Columbus module on the International Space Station to be able to easily move around. CIMON also learned all the procedures to help carrying out the on-board experiments. Experiments sometimes consist of more than 100 different steps, CIMON knows them all.
AI from the Cloud – proprietary data in a protected space 
IBM Watson services run on the IBM Cloud, which provides a further advantage for users, in general, and for use on the ISS in particular: sensitive, proprietary data can remain where it is created, such as in the protected area of your own server or database. You don’t need to upload it to an external cloud for it to be enriched with appropriate AI capabilities.
The IBM model for data and privacy allows you to train your own AI models with Watson technology without having to integrate proprietary or sensitive data into a public model. No other company, no other organization – not even IBM – can use this data for the further development of AI applications. This ensures that users can keep their critical information private and proprietary. What’s more, a company’s intellectual property and data serve to enhance only its own competitive advantage. This was one of the main reasons why Airbus chose IBM as its partner to develop CIMON.
In the mid-term, the CIMON project will also be devoted to psychological group effects that can develop in small teams over a long period of time and occur during long-term space missions. CIMON’s creators are confident that social interactions between humans and machines, in this case between astronauts and a space attendant, equipped with emotional intelligence could make an important contribution to mission success. We predict that assistance systems of this kind also have a bright future right here on earth, such as in hospitals or to support nursing care.
",,Person,ash grey,electric meter,measuring instrument,meter,electric meter
https://ibm.co/2FafMBI,187446750783_10155450002230784,https://www.facebook.com/ibmwatson/posts/10155450002230784,"&quot;The journey for adopting AI and delivering that for value to clients begins with one very basic proposition, which is, is the AI going to augment and amplify the intelligence of the people using it? Because if it's not doing that, it's probably not going to be very useful. You're going to lose this utility very quickly.&quot; – Watson VP, CTO Rob High in an interview with TechCrunch: ",Link,,,3/3/18 9:45, ,12751,12751,0,18190,18190,0,307,196,232,10,10,13863,10073,0,0,260,0,0,0,0,0,0,0,0,0,0,32,133.0,,35,134.0,,104,97.0,,,129,103.0,,,6,4.0,,6,4.0,,"TechRepublic spoke to IBM's Rob High about the ethical, privacy, and security obstacles that artificial intelligence has to overcome.",https://tr1.cbsistatic.com/hub/i/r/2018/03/01/005c45e1-7e9b-43df-9012-57f7ee9fa3bc/thumbnail/770x578/ea8d0af3f9eb1dfda64080cabc7cdc79/big-booths-mwc-2016-12.jpg,https://www.techrepublic.com/article/ibm-watson-cto-the-3-ethical-principles-ai-needs-to-embrace/,fear,0.137485,negative,-0.477543,basic proposition,"Person, Person",basic proposition,Person,fear,0.228087,negative,-0.589837,"IBM's Rob High, artificial intelligence","Person, Company",IBM's Rob High,Person,joy,0.60699,positive,0.646511,,"Person, Person, Company, Organization","IBM Watson CTO Rob High has done a lot of thinking about the privacy, security, and ethical implications of artificial intelligence. He presented some of those ideas at Mobile World Congress 2018, and we talked to him about some of his key findings.
You can watch the interview above or read the transcript below.  
High said, ""One of the things we have to realize about AI--it's relatively new to all of us. There's a lot about it that we don't all fully understand. Even as a technologist, we know where we're trying to bring the technology, but on the other side there's lots of people for which this technology is new. The experiences around that are going to be different. As with any new technology, it's really important that we be thinking now about how we do that ethically and responsibly. For us, that comes down to three basic principles. Trust, respect, and privacy.
""What that basically means is that when you're using an AI technology, you have to trust that it's going to be doing the right thing. Or you focus on things like, can we create transparency in the AI algorithms? Can we get the algorithms to actually identify your level of confidence (in them), for example.""
SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
""Transparency comes down to can we identify what sources of information are being used? Have we established the right properties, the right principles in place when we train these systems to use data that is representative of who we are, and the information that we're using?"" said High.
""Of course, privacy comes down to recognizing that your data is our data. It should be your choice as to what data you're going to provide in order to gain the benefits these AIs offer. That goes from everything from the privacy of enterprise data, and the data that enterprises bring to the table when they use AIs, maintain separation between each of the enterprises all the way through, to how those enterprises protect the privacy of the data of their clients.""
High added, ""The journey for adopting AI and delivering that for value to clients begins with one very basic proposition, which is, is the AI going to augment and amplify the intelligence of the people using it? Because if it's not doing that, it's probably not going to be very useful. You're going to lose this utility very quickly. First of all, identify what that is. How do you help people do what they do better?
SEE: How to implement AI and machine learning (ZDNet special feature) | Download the report as a PDF (TechRepublic)
""If you get that out of the way then you can begin to look at how to apply the technology, but all through that we really encourage our clients to think about two things. One is, how they're going to protect and preserve the privacy of their institutions, of their clients. But also how do they convey the responsibility of their clients to be aware of what data they're getting across and to challenge those cases where, perhaps they don't want to give up the data they're offering. Or at least to make sure the value they're getting from that data is also very supportive of this idea that's augmented their intelligence.""
",,Person,purplish blue,air terminal, , , 
https://ibm.co/2oCky3W,187446750783_10155447232105784,https://www.facebook.com/ibmwatson/posts/10155447232105784,"From starting her first company as an eight-year-old, to creating the country’s largest AI student group, Allie Miller has always been driven. Now, after receiving an MBA from Wharton and graduating with a degree in Cognitive Science from Dartmouth, Allie is a part of IBM Watson's Visual Recognition team, shaping the future of Watson technologies that help businesses understand the context of their images. ",Link,,,3/2/18 8:39, ,14499,14499,0,19264,19264,0,596,451,609,10,10,14977,11324,0,0,490,0,0,0,0,0,0,0,0,0,0,43,197.0,6.0,47,207.0,6.0,326,147.0,,,457,152.0,,,4,6.0,,4,6.0,,Allie Miller is shaping IBM Watson technologies that help businesses understand Visual Recognition. Learn more about Allie's career and journey into AI.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/02/profileCrop_png_socialTile_022618.png,https://www.ibm.com/blogs/watson/2018/02/redefining-how-we-get-it-done-with-allie-miller-ibm-watson/,joy,0.328354,positive,0.740657,"Cognitive Science, part of IBM Watson","Person, Quantity, Person, Organization, Location, Person",Cognitive Science,Person,joy,0.196497,positive,0.80574,"Allie Miller, IBM Watson technologies, Allie's career","Person, Company",Allie Miller,Person,joy,0.641793,positive,0.797175,,"Person, Person, Person, Company, Person, Company, GeographicFeature, Quantity, Organization","Share this post:
Allie Miller has always been a doer. From starting her first company as an eight-year-old, to creating the country’s largest AI student group, to doing the polar plunge in the Antarctic Ocean – Allie has always found a way to grab life by the horns and get the job done.
Now, after receiving an MBA from Wharton and graduating with a degree in Cognitive Science from Dartmouth, Allie has joined the ultimate get-it-done heavyweight, IBM Watson. As part of the Visual Recognition team, Allie is shaping the future of the Watson technologies that help businesses understand the context of their images, leading to the discovery of actionable insight.
Heading into Think 2018, Allie takes a short break from her aggressive to-do list to talk about how Watson is partnering with professionals to help businesses “get it done” in revolutionary new ways – and what exciting opportunities, but also potential hurdles, are on her radar for 2018.
How did you end up with a career in AI, and what brought you to IBM Watson?
Since I can remember, I’ve been obsessed with the way people process information, and what drives their decision-making. Whether it’s a complicated work challenge or just choosing the route we take to work in the morning, how we as humans reason and problem-solve is fascinating.
Heading to Dartmouth, I knew that’s what I wanted to learn more about. Since the power of AI really lies in augmenting human capabilities, I chose to study Cognitive Science—a blend of Psychology, Philosophy, Linguistics, and Computer Science. This expanded my understanding of the human mind, how it works, and what influences our decision-making. I wanted to take these classes and home in on the technical aspect of cognition, which led me to run a two-and-a-half-year study on natural language. That really laser-focused my career path toward artificial intelligence.
I was offered several AI opportunities, but what drew me to Watson was not only IBM’s early leadership in the space, but also the care and commitment that IBM takes in training and development. I’m constantly learning, growing, being challenged and pushed. I can’t wait to get up every morning and not just read about what’s coming next, but contribute to it every day.
You’re about to take the stage at Think 2018. What’s on your mind to share with the world?
The progress we have made with visual recognition technology in just the past few years, to me, is astounding. Beyond pulling insight out of content, Watson Visual Recognition can really be customized for any use case. And, since Watson can understand industries inside and out, it’s almost like having an instant co-pilot that understands exactly how you live and work, and makes you smarter about what you’re doing. It’s really that simple.
There’s nothing I love more than taking 15 minutes to show someone just how easy it is to adopt Watson into their business – and how it can boost their bottom-line. Once we take away this hesitation and skepticism, the opportunities and possibilities quickly emerge.
But, in addition to running toward these exciting opportunities, I’m constantly mindful of the pitfalls. AI is a powerful technology, and with power comes great responsibility. We need to make sure we innovate at the same rate we create guardrails.
What is the most exciting part of your job?
You mean other than the free Diet Coke? For me, it comes down to the frontier work, the opportunity to affect important change on our world – and collaborating with some of the best, brightest people I’ve ever met.
The beauty of Watson is that it’s for everyone. A large enterprise can integrate AI into their workflows and see immediate, tangible benefits: increased productivity, better insight, and enhanced decision-making. But what’s even more exciting is that today everyone, even smaller businesses and individuals who may have fewer resources or technological know-how, can benefit. We’ve created accessible avenues for small, medium and large companies to access AI. We can deliver big, complex solutions or smaller, scrappier ones. Nothing gets me more excited than when I show someone — a professional, a friend — just how easy it is to instantly implement and benefit from AI.
If you had to sum it up, what will AI do for us this year?
I think AI will make each of us increasingly unstoppable. AI is highly technical, but it’s also immensely humanistic. AI could deepen what it means to be human. By taking everything we produce — the documents we create, photos we share, conversations we have — and extracting insight we never could have seen, we can be better — more creative, more inspired, and more resourceful. The power of having Watson, the ultimate “go-getter”, behind it all is incredible.
Want to hear more from Allie? Register for Think 2018 today and make sure you check out her session. You can read more about Watson services here, and follow Allie on Twitter (@alliekmiller) and LinkedIn.
",,Person,coal black,person,figure,circle,-
https://ibm.biz/BdjC9P,187446750783_10155444874055784,https://www.facebook.com/ibmwatson/posts/10155444874055784,"THINK 2018 is a first-of-its-kind conference that will gather visionaries and innovators from around the world—allowing the best and the brightest to shine. Find your community at IBM's only event this year that will bring together the power of all of our technology – AI, blockchain, cloud, security, data and more – on one stage. Learn more about the conference and get $300 off your VIP ticket using our offer code TK18WVIP and selecting 'Watson' as your interest: ",Link,,,3/1/18 11:04, ,10021,10021,0,13578,13578,0,301,202,250,6,6,10083,7401,0,0,246,0,0,0,0,0,0,0,0,0,0,32,130.0,2.0,33,130.0,2.0,132,85.0,,,162,88.0,,,1,5.0,,1,5.0,,"The digital-first IBM business and technology event will take place May 5â7, 2020. Learn about the latest advancements in open technologies from hybrid multicloud to data and AI and interact with luminaries who are using them to transform our lives.Â ",https://www.ibm.com/events/shared/img/think2020/think-og2.jpg,https://www.ibm.com/events/think/?cm_mmc=OSocial_Facebook-_-xIBM+Events_Global+Conferences-_-WW_WW-_-fbWatsonCore&cm_mmca1=000021TD&cm_mmca2=10001376&,joy,0.732122,positive,0.884157,"IBM's only event, kind conference","Company, Quantity",IBM's only event,Company,joy,0.359078,positive,0.94015,"digital-first IBM business, latest advancements","Company, Person",digital-first IBM business,Company,joy,0.557024,positive,0.810422,,"Company, Person, Company, Person","Since becoming CEO in January 2012, Ginni has led IBM through the most significant transformation in its history, reinventing the company to lead in the new era of AI, blockchain, cybersecurity and quantum technologies, all delivered on IBM’s enterprise-strength cloud platform. Today, IBM is the world leader in AI and cloud computing for business, underpinned with trust and security.
IBM’s commitment to diversity and inclusion also has advanced under Ginni’s leadership. This includes extending parental leave and making it easier for women to return to the workforce through a “returnships” program with hands-on work experience in emerging technologies. This pioneering work was recognized in 2018 by the prestigious Catalyst Award for advancing diversity and women’s initiatives. IBM is the only tech company to have earned this recognition in the last 20 years and the only company ever to be honored four times.
Arvind Krishna leads the IBM business unit that provides the cloud and data platforms on which the company’s clients build the future. His responsibilities include IBM Research, IBM Cloud, IBM Data and AI, and IBM’s Security and Cognitive Applications businesses. He also drove the company’s 2019 acquisition of Red Hat.
Arvind leads the unit’s strategy, product design, offering development, marketing, sales and service. He also guides IBM’s overall strategy in technologies including artificial intelligence, quantum computing, blockchain, cloud platform services, data-driven solutions, and nanotechnology.
Jim Whitehurst is president and chief executive officer of Red Hat, the world’s leading provider of open source enterprise IT software solutions and services. An avid advocate for open software as a catalyst for business innovation, Whitehurst has proven expertise in helping companies flourish—even in the most challenging economic and business environments.
Whitehurst has grown Red Hat and its influence by reaching key milestones—most notably in 2012, when Red Hat became the first US$1 billion open source software company. Company revenue reached almost US$3 billion in 2018.
In 2015, Whitehurst published The Open Organization: Igniting Passion and Performance, a book that shows how open management principles can help organizations succeed in a fast-paced, connected era.
Amal Clooney is a barrister who specializes in international law and human rights. Through international courts, she frequently represents political prisoners, journalists and victims of mass atrocities.
Ms Clooney served as a Sr. Advisor to Kofi Annan. She was appointed to the UK’s panel of experts on combatting sexual violence and to a panel on public international law. She was also appointed as the UK’s Special Envoy for Media Freedom by the UK Foreign Secretary and she serves as vice-chair of a High-Level Panel of Legal Experts on Media Freedom.
Ms Clooney is a Visiting Professor at Columbia Law School, where she co-teaches the Human Rights course, and she is co-author of a forthcoming book titled ‘The Right to a Fair Trial in International Law’ to be published in 2020.
Mayim Bialik is known for her role on the hit CBS comedy, The Big Bang Theory as Amy Farrah Fowler, for which she has received two Critics Choice Awards, four Emmy Award nominations and a SAG Award nomination. Bialik has appeared in numerous beloved roles throughout her dynamic acting career.
An acclaimed author, Bialik has written two #1 New York Times bestsellers, Girling Up: How to Be Strong, Smart and Spectacular, and the recently released Boying Up: How to Be Brave, Bold and Brilliant. She has also written a parenting book, Beyond the Sling, and a cookbook, Mayim’s Vegan Table. Bialik has recently dedicated her skills as a writer, actress, neuroscientist and mother to driving the lifestyle website GrokNation.com, which she started.
",,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2EWGxJA,187446750783_10155442627760784,https://www.facebook.com/ibmwatson/posts/10155442627760784,"&quot;Artificial intelligence is the opportunity of our time, and skills are the issue of our time. Some jobs will be displaced, but 100% of jobs will be augmented by AI,” according to IBM CEO Ginni Rometty. &quot;Technology companies are inventing these technologies, so we have the responsibility to help people adapt to it — and I don’t mean just giving them tablets or PCs, but lifelong learning systems.” via The New York Times: ",Link,,,2/28/18 12:35, ,11263,11263,0,15091,15091,0,273,180,207,9,9,12226,9333,0,0,232,0,0,0,0,0,0,0,0,0,0,23,101.0,1.0,24,106.0,1.0,125,61.0,,,143,64.0,,,4,5.0,,4,5.0,,Technology is advancing by leaps and bounds.,https://static01.nyt.com/images/2018/01/17/opinion/17friedman2/merlin_132380423_eb6e2d98-1190-43ed-9195-fc76a0a0223a-facebookJumbo.jpg,https://www.nytimes.com/2018/01/16/opinion/while-you-were-sleeping.html?linkId=47053575,joy,0.452167,positive,0.760342,"Technology companies, jobs","Quantity, Person, Person, Company",Technology companies,Quantity,joy,0.349447,positive,0.759353,"Technology, leaps",,Technology,,joy,0.478115,positive,0.462031,,"Company, Organization, Person, Location","Donald Trump poses a huge dilemma for commentators: to ignore his daily outrages is to normalize his behavior, but to constantly write about them is to stop learning. Like others, I struggle to get this balance right, which is why I pause today to point out some incredible technological changes happening while Trump has kept us focused on him — changes that will pose as big an adaptation challenge to American workers as transitioning from farms to factories once did.
Two and half years ago I was researching a book that included a section on IBM’s cognitive computer, “Watson,” which had perfected the use of artificial intelligence enough to defeat the two all-time “Jeopardy!” champions. After my IBM hosts had shown me Watson at its Yorktown Heights, N.Y., lab, they took me through a room where a small group of IBM scientists were experimenting with something futuristic called “quantum computing.” They left me thinking this was Star Wars stuff — a galaxy and many years far away.
Last week I visited the same lab, where my hosts showed me the world’s first quantum computer that can handle 50 quantum bits, or qubits, which it unveiled in November. They still may need a decade to make this computer powerful enough and reliable enough for groundbreaking industrial applications, but clearly quantum computing has gone from science fiction to nonfiction faster than most anyone expected.
Who cares? Well, if you think it’s scary what we can now do with artificial intelligence produced by classical binary digital electronic computers built with transistors — like make cars that can drive themselves and software that can write news stories or produce humanlike speech — remember this: These “old” computers still don’t have enough memory or processing power to solve what IBM calls “historically intractable problems.” Quantum computers, paired with classical computers via the cloud, have the potential to do that in minutes or seconds.
For instance, “while today’s supercomputers can simulate … simple molecules,” notes MIT Technology Review, “they quickly become overwhelmed.” So chemical modelers — who attempt to come up with new compounds for things like better batteries and lifesaving drugs — “are forced to approximate how an unknown molecule might behave, then test it in the real world to see if it works as expected. The promise of quantum computing is to vastly simplify that process by exactly predicting the structure of a new molecule, and how it will interact with other compounds.”
Quantum computers process information, using the capabilities of quantum physics, differently from traditional computers. “Whereas normal computers store information as either a 1 or a 0, quantum computers exploit two phenomena — entanglement and superposition — to process information,” explains MIT Technology Review. The result is computers that may one day “operate 100,000 times faster than they do today,” adds Wired magazine.
Talia Gershon, an IBM researcher, posted a fun video explaining the power of quantum computers to optimize and model problems with an exponential number of variables. She displayed a picture of a table at her wedding set for 10 guests, and posed this question: How many different ways can you seat 10 people? It turns out, she explained, there are “3.6 million ways to arrange 10 people for dinner.”
Classical computers don’t solve “big versions of this problem very well at all,” she said, like trying to crack sophisticated encrypted codes, where you need to try a massive number of variables, or modeling molecules where you need to account for an exponential number of interactions. Quantum computers, with their exponential processing power, will be able to crack most encryption without breaking a sweat.
It’s just another reason China, the N.S.A., IBM, Intel, Microsoft and Google are now all racing — full of sweat — to build usable quantum systems.
“If I try to map a caffeine molecule problem on a normal computer, that computer would have to be one-tenth the volume of this planet in size,” said Arvind Krishna, head of research at IBM. “A quantum computer just three or four times the size of those we’ve built today should be able to solve that problem.”
And then there are all those problems we never even imagined we could model and solve. Universities and companies are already accessing three IBM quantum systems (ranging from 5 to 16 qubits) that are online and open source at ibm.com/IBMQ, and they’ve already run two million quantum programs to prove out, and write papers on, theories that we never had the processing power before to prove.
But, again, look at where we are today thanks to artificial intelligence from digital computers — and the amount of middle-skill and even high-skill work they’re supplanting — and then factor in how all of this could be supercharged in a decade by quantum computing.
As education-to-work expert Heather McGowan (www.futureislearning.com) points out: “In October 2016, Budweiser transported a truckload of beer 120 miles with an empty driver’s seat. … In December 2016, Amazon announced plans for the Amazon Go automated grocery store, in which a combination of computer vision and deep-learning technologies track items and only charges customers when they remove the items from the store. In February 2017, Bank of America began testing three ‘employee-less’ branch locations that offer full-service banking automatically, with access to a human, when necessary, via video teleconference.”
This will be a challenge for developed countries, but even more so for countries like Egypt, Pakistan, Iran, Syria, Saudi Arabia, China and India — where huge numbers of youths are already unemployed because they lack the education for even this middle-skill work THAT’S now being automated.
It’s why IBM’s C.E.O., Ginni Rometty, remarked to me in an interview: “Every job will require some technology, and therefore we’ll need to revamp education. The K-12 curriculum is obvious, but it’s the adult retraining — lifelong learning systems — that will be even more important.”
Artificial intelligence “is the opportunity of our time, and skills are the issue of our time. Some jobs will be displaced, but 100 percent of jobs will be augmented by A.I.,” added Rometty. Technology companies “are inventing these technologies, so we have the responsibility to help people adapt to it — and I don’t mean just giving them tablets or P.C.s, but lifelong learning systems.”
To back that up, said Rometty, IBM designed Pathways in Technology (P-Tech) schools, partnering with close to 100 public high schools and community colleges to create a six-year program that serves large numbers of low-income students. P-Tech schools offer calculus and physics alongside workplace skills — problem solving, writing and job interviewing. These skills are reinforced through mentorships and internships with IBM and more than 300 other companies. Kids graduate in six years or less with both a high school diploma and an associate junior college degree.
“The graduation rates are four times the average, and those getting jobs are at two times the median salary,” said Rometty, “and many are going on to four-year colleges.”
Each time work gets outsourced or tasks get handed off to a machine, “we must reach up and learn a new skill or in some ways expand our capabilities as humans in order to fully realize our collaborative potential,” McGowan said.
Therefore, education needs to shift “from education as a content transfer to learning as a continuous process where the focused outcome is the ability to learn and adapt with agency as opposed to the transactional action of acquiring a set skill,” said McGowan. “Instructors/teachers move from guiding and accessing that transfer process to providing social and emotional support to the individual as they move into the role of driving their own continuous learning.”
Anyway, I didn’t mean to distract from the “Trump Reality Show,” but I just thought I’d mention that Star Wars technology is coming not only to a theater near you, but to a job near you. We need to be discussing and adapting to its implications as much as we do Trump’s tweets.
",,Company,gray,furnace room,indoors,furnace room,-
https://ibm.co/2HhhcM6,187446750783_10155440065195784,https://www.facebook.com/ibmwatson/posts/10155440065195784:0,Curious as to how AI will analyze the way you think? Try Watson Personality Insights to get a closer look for free: ,Photo,,,2/27/18 13:00, ,6320,6320,0,8545,8545,0,215,136,178,1,1,6509,4924,0,0,174,0,0,0,0,0,0,0,0,0,0,19,93.0,1.0,24,95.0,1.0,51,69.0,34.0,,59,77.0,42.0,,,1.0,,,1.0,,,,https://personality-insights-demo.ng.bluemix.net/,anger,0.188445,positive,0.543883,"Watson Personality Insights, closer look","Person, Person",Watson Personality Insights,Person, , , , , , , , ,joy,0.550066,positive,0.477382,"Gain insight, Twitter users",Quantity,"           Gain insight into how and why people think, act, and feel the way they do. This service applies linguistic analytics and personality theory to infer attributes from a person's unstructured text.           
         You need text written by the person whose personality you're interested in. It should contain words about every day experiences, thoughts, and responses.       
             The scores you see are all percentiles. They are comparing one person to a broader population. For example, a 90% on Extraversion does not mean that the person is 90% extroverted. It means that for that single trait, the person is more extroverted than 90% of the people in the population.           
                            Our sample population consists of Twitter users who tweet in their respective languages                          and whose personalities we calculated using our model.           
",Gain insight,Quantity, , , , , 
https://ibm.biz/BdjC9P,187446750783_10155437116360784,https://www.facebook.com/ibmwatson/posts/10155437116360784:0,"An inductee of both the National Women's Hall of Fame &amp; International Space Hall of Fame, Dr. Mae Jemison is an American engineer, physician, and NASA astronaut who became the first woman of color in the world to go into space. Learn from her in-person along with other brilliant minds of our time at Think 2018. Register now – get $300 off VIP using the code TK18WVIP and selecting Watson as your interest: ",Photo,,,2/26/18 9:12, ,5616,5616,0,7630,7630,0,96,66,80,1,1,7046,5252,0,0,83,0,0,0,0,0,0,0,0,0,0,2,42.0,,2,42.0,,38,3.0,29.0,,46,3.0,31.0,,1,,,1,,,"The digital-first IBM business and technology event will take place May 5â7, 2020. Learn about the latest advancements in open technologies from hybrid multicloud to data and AI and interact with luminaries who are using them to transform our lives.Â ",https://www.ibm.com/events/shared/img/think2020/think-og2.jpg,https://www.ibm.com/events/think/?cm_mmc=OSocial_Facebook-_-xIBM+Events_Global+Conferences-_-WW_WW-_-fbWatsonCore&cm_mmca1=000021TD&cm_mmca2=10001376&,joy,0.677806,positive,0.956175,"National Women's Hall, American engineer, International Space Hall of Fame, NASA astronaut, Dr. Mae Jemison","Facility, Facility, Person, Organization",National Women's Hall,Facility,joy,0.359078,positive,0.94015,"digital-first IBM business, latest advancements","Company, Person",digital-first IBM business,Company,joy,0.557024,positive,0.810422,,"Company, Person, Company, Person","Since becoming CEO in January 2012, Ginni has led IBM through the most significant transformation in its history, reinventing the company to lead in the new era of AI, blockchain, cybersecurity and quantum technologies, all delivered on IBM’s enterprise-strength cloud platform. Today, IBM is the world leader in AI and cloud computing for business, underpinned with trust and security.
IBM’s commitment to diversity and inclusion also has advanced under Ginni’s leadership. This includes extending parental leave and making it easier for women to return to the workforce through a “returnships” program with hands-on work experience in emerging technologies. This pioneering work was recognized in 2018 by the prestigious Catalyst Award for advancing diversity and women’s initiatives. IBM is the only tech company to have earned this recognition in the last 20 years and the only company ever to be honored four times.
Arvind Krishna leads the IBM business unit that provides the cloud and data platforms on which the company’s clients build the future. His responsibilities include IBM Research, IBM Cloud, IBM Data and AI, and IBM’s Security and Cognitive Applications businesses. He also drove the company’s 2019 acquisition of Red Hat.
Arvind leads the unit’s strategy, product design, offering development, marketing, sales and service. He also guides IBM’s overall strategy in technologies including artificial intelligence, quantum computing, blockchain, cloud platform services, data-driven solutions, and nanotechnology.
Jim Whitehurst is president and chief executive officer of Red Hat, the world’s leading provider of open source enterprise IT software solutions and services. An avid advocate for open software as a catalyst for business innovation, Whitehurst has proven expertise in helping companies flourish—even in the most challenging economic and business environments.
Whitehurst has grown Red Hat and its influence by reaching key milestones—most notably in 2012, when Red Hat became the first US$1 billion open source software company. Company revenue reached almost US$3 billion in 2018.
In 2015, Whitehurst published The Open Organization: Igniting Passion and Performance, a book that shows how open management principles can help organizations succeed in a fast-paced, connected era.
Amal Clooney is a barrister who specializes in international law and human rights. Through international courts, she frequently represents political prisoners, journalists and victims of mass atrocities.
Ms Clooney served as a Sr. Advisor to Kofi Annan. She was appointed to the UK’s panel of experts on combatting sexual violence and to a panel on public international law. She was also appointed as the UK’s Special Envoy for Media Freedom by the UK Foreign Secretary and she serves as vice-chair of a High-Level Panel of Legal Experts on Media Freedom.
Ms Clooney is a Visiting Professor at Columbia Law School, where she co-teaches the Human Rights course, and she is co-author of a forthcoming book titled ‘The Right to a Fair Trial in International Law’ to be published in 2020.
Mayim Bialik is known for her role on the hit CBS comedy, The Big Bang Theory as Amy Farrah Fowler, for which she has received two Critics Choice Awards, four Emmy Award nominations and a SAG Award nomination. Bialik has appeared in numerous beloved roles throughout her dynamic acting career.
An acclaimed author, Bialik has written two #1 New York Times bestsellers, Girling Up: How to Be Strong, Smart and Spectacular, and the recently released Boying Up: How to Be Brave, Bold and Brilliant. She has also written a parenting book, Beyond the Sling, and a cookbook, Mayim’s Vegan Table. Bialik has recently dedicated her skills as a writer, actress, neuroscientist and mother to driving the lifestyle website GrokNation.com, which she started.
",,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2sWNMjE,187446750783_10155434698890784,https://www.facebook.com/ibmwatson/posts/10155434698890784,Is there a code of ethics brands should follow when using a chatbot for their business? It comes down to following 5 simple rules. ,Link,,,2/25/18 9:30, ,10493,10493,0,14737,14737,0,199,139,169,4,4,11506,8185,0,0,166,0,0,0,0,0,0,0,0,0,0,27,64.0,2.0,34,65.0,2.0,66,76.0,2.0,,83,84.0,2.0,,1,3.0,,1,3.0,,"Businesses often overlook important issues related to morals and ethics of chatbots and AI. Customers need to know when they are communicating with a machine, and that brands will protect their privacy and data in today’s interconnected world.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/06/AI-and-chatbots-ibm-contact-center-1200x628-c2-4.jpg,https://www.ibm.com/blogs/watson/2017/10/the-code-of-ethics-for-ai-and-chatbots-that-every-brand-should-follow/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Conversation-_-WW_WW-_-Code+of+Ethics+Every+Chatbot+Should+Follow+Blog+Oct+27&cm_mmca1=0000,joy,0.388597,neutral,0,"code of ethics brands, simple rules",,code of ethics brands,,joy,0.265401,positive,0.71056,"important issues, Customers",Person,important issues,Person,joy,0.507241,positive,0.452234,,"Person, Person","Key Points:
 – Businesses often overlook important issues related to morals and ethics of chatbots and AI
 – Customers need to know when they are communicating with a machine and not an actual human
 – Ownership of information shared with a bot is another key ethical consideration and can create intellectual property issues
 – The privacy and protection of user data is paramount in today’s interconnected world
(Read the full article “Ethics And Artificial Intelligence With IBM Watson’s Rob High” on Forbes.com. You can also listen to The Modern Customer Podcast with Rob High here.)
See how AI is shaping customer service
Businesses are rapidly waking up to the need for chatbots and other self-service technology. From automating basic communications and customer service, to reducing call center costs and providing a platform for conversational commerce, chatots offer many new opportunities to delight and better serve consumers.
Chatbots can offer 24/7 customer service, rapidly engaging users, answering their queries as whenever they arrive. Millennials in particular are impatient when engaging with brands and expect real-time responses. More than 22% of millennials expect a response within 10 minutes of reaching out to a brand via social media, according to a recent Desk.com study. And 52% of them will abandon online purchases if they can’t find a quick answer.
The need for speed in customer service has never been higher. Leading brands like Staples are increasingly turning to chatbots to provide a solution for this need for speed.
The topic of chatbot ethics is complex and spans a wide area including privacy, data ownership, abuse and transparency.
Rob High, CTO of IBM Watson was recently featured in an article on Forbes.com titled “Ethics And Artificial Intelligence With IBM Watson’s Rob High.” In the article, Rob talks about how in order to keep AI ethical, it needs to be transparent. Rob advises that when customers interact with a brand’s chatbot, for example, they need to know they are communicating with a machine and not an actual human.
“AI, like most other technology tools, is most effective when it is used to extend the natural capabilities of humans instead of replacing them. That means that AI and humans are best when they work together and can trust each other.”
 — Rob High, CTO IBM Watson
Ethics form the foundation of how a bot is built, and more importantly, they dictate how a bot interacts with users. How a bot behaves has the potential to influence how an organization can be perceived and unethical behavior can lead to consumer mistrust and litigation issues. Ethical bots can promote brand loyalty and help boost profit margins.
1. Who should a chatbot serve?
When building a chatbot, an organization must decide who it primarily serves: the needs of the business or the needs of a customer. Amir Shevat, Director of Developer Relations at Slack discusses this topic in his blog post “Hard questions about bot ethics.”
Here, you must determine the exact purpose and business value of the chatbot. One built mainly to provide recommendations to customers can only be ethical if it meets the needs of the customer. Whereas a bot built for internal business improvement should be made to suit the company’s need.
In general, where or not a bot is customer-facing, an ethical organization should always put the needs of the customer before the needs of the business. This means providing the product best suited to those customers, rather than the one with the best profit margin or the speediest implementation. An option for users to provide feedback on the service will help detect issues, improve customer satisfaction and maintain ethical behavior. Bots utilizing machine learning and algorithms to display product offerings or recommendations should also have regular health checks built in for this exact purpose.
2. Am I talking to a chatbot or a human?
Building trust between humans and machines is just like building trust between humans. Brands can build trust by being transparent, aligning expectations to reality, learning from mistakes and continually correcting them, and listening to customer feedback.
When building a chatbot, transparency is a critical consideration. This boils down to the question – is it clear whether the user is talking to a bot or a human? Customers are savvy enough to be able to tell the difference and expect brands to be honest with them. Customers don’t expect chatbots to be perfect, but they want to know what they can and cannot do, and that they are reliable — within reason. Transparency about both failure and success can build trust faster than virtually any other approach.
To work on transparency and reliability, start by asking yourself some basic questions like:
Where sensitive information (like bank details) and life-altering interactions (health and finance) is being communicated, you need to build additional checks for transparency and security. This means providing the user with clarity. Be upfront and build into the introduction that the user is talking to a bot and what personal information is being accessed, analyzed, saved or shared and with whom. Also always provide an option where the user can be immediately be connected to a human if they have concerns that a bot cannot address..
3. Who owns the data shared with a chatbot?
Ownership of information shared with a bot is another key ethical consideration and can create intellectual property issues if not handled correctly.
Does the bot service-provider or the user own their favorite custom pizza creation? If a bot builds a playlist based on the users preferences – who owns it? These are the kind of ethical questions that need to be considered and the answer can fluctuate based on the intent of a bot. A personal-assistant bot would lean towards user ownership, while a representative-bot leans towards service-provider ownership.
Whatever the type of bot, this is another question of transparency. Businesses building bots should provide clarity about who owns what and should include language asking users to agree with their terms of service first.
4. Preventing chatbot abuse
When building a chatbot, it is important to consider how a bot handles abuse. This includes both the giving and receiving of abuse. Here, the ethical stance is to follow Isaac Asimov’s Three Laws of Robotics: “a robot may not injure a human being or, through inaction, allow a human being to come to harm”.
A chatbot should be built with profanity recognition. Upon receiving abuse, the developer has two options. The first is to ignore the abuse by building in a non-response situation where the user abuses the bot. Or, add a default neutral response such as “I’m sorry, I don’t understand your request.” Depending on the severity of abuse — for example death threats or racism — it is important to build in a report function, sending the transcript to a relevant party.
It is of critical importance that chatbots do not abuse humans even if it’s learned behavior that’s a result of what the human has been feeding the bot. Requests from users to end communication should have a built in protocol to end the chat, preventing the bot from harassing or spamming a user. Language filters should be applied for any bots utilizing machine learning algorithms. There have been a few instances over the last year where some bots went rogue after being subverted by online trolls and began tweeting racist propaganda.
5. How should chatbots handle privacy?
The privacy and protection of user data is paramount in today’s interconnected world. The launch of the General Data Protection Regulation protecting citizens of the European Union is a reflection of this.
When building a chatbot, developers should consider the ethics of user privacy. This will help answer questions like:
In this situation, businesses can take direction from existing online interactions. Transparency is the best course of action and a publicly-available privacy policy is a must have for any organization. Developers should also build in mechanisms to ensure the privacy of user information in any interaction — an unspoken user-bot confidentiality agreement. This means encryption of all communications and, depending on the sensitivity of the data, transcription deletion after completion of the interaction.
Ethics should be a core consideration of any action taken by a business. With chatbots still in a stage of relative infancy, the discovery of new ethical issues is likely to continue. Businesses should continue to learn from these emerging cases and build their guiding principles and ethical standards. If in doubt, side with the customer, and always provide transparency.
(Read the full article “Ethics And Artificial Intelligence With IBM Watson’s Rob High” on Forbes.com. You can also listen to The Modern Customer Podcast with Rob High here.)
",,Person,light brown,LED display (computer/TV),machine,computer,digital computer
https://ibm.co/2B2mebh,187446750783_10155430629050784,https://www.facebook.com/ibmwatson/posts/10155430629050784,"Technologies like machine learning and artificial intelligence are already impacting many industries. Here are 5 jobs that will get the biggest productivity boost via ZDNet: 
",Link,,,2/23/18 16:00, ,8195,8195,0,11647,11647,0,182,130,154,1,1,8926,6441,0,0,156,0,0,0,0,0,0,0,0,0,0,21,59.0,,22,59.0,,28,107.0,,,41,113.0,,,1,,,1,,,Technologies like machine learning and artificial intelligence are already impacting many industries. Here are five jobs that will get the biggest productivity boost.,https://zdnet4.cbsistatic.com/hub/i/r/2017/11/20/c7f6317d-aee7-49b4-b6f5-c735c89fcd0a/thumbnail/770x578/f7bec20243f3ca0b1d26d188936de9b0/aijobs.jpg,https://www.zdnet.com/article/five-tech-jobs-that-ai-and-automation-will-make-radically-more-efficient/?linkId=45489103,joy,0.581794,positive,0.623651,"machine learning, artificial intelligence, Technologies, jobs, biggest productivity boost",Company,machine learning,Company,joy,0.510987,positive,0.886319,"machine learning, artificial intelligence, Technologies",,machine learning,,joy,0.503687,positive,0.588463,,"Person, Person, Person, Company, Quantity"," 	The robot revolution has undoubtedly begun, but the jury is still out on exactly how many jobs will be lost to the machines, and how long it will take to happen. In the meantime, though, artificial intelligence (AI) is already impacting jobs in a variety of industries, changing the way a lot of work is getting done.
 	Whether it's the implementation of chatbots or machine learning-boosted big data tools, professionals are capturing the value of AI to increase their productivity. However, every job won't be impacted equally when it comes to these emerging technologies.
 	SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
 	Here are the five jobs that will see the biggest increase in efficiency from AI and automation.
 	1. Security professionals
 	The cybersecurity field has been utilizing AI and machine learning for some time, with platforms like IBM's Watson being used to complement the work of human practitioners. For example, many products use AI to determine the patterns of normal users, and alert human security professionals when abnormal behavior is detected.
 	""Currently, security relies on AI to target risk and to develop proactive threat management systems,"" said Gartner research director Carlton Sapp. ""However, we see this as aggressively advancing their capabilities, leading to more advanced threat management systems that automatically learn through reinforced training and more innovative ways to reduce risk.""
 	The biggest barrier to capturing the value of AI in security is trust. A recent Radware report stated that 57 percent of executives trust AI security systems ""as much or more than"" humans, but there's still room for growth.
On the other side of the fence, AI is also being used to develop cyber attacks. Security researchers created an AI-infused malware that was able to move past an anti-malware system by modifying itself to slip past the filters. This means that security professionals will likely need to fight AI tools used by hackers with AI tools of their own.
 	2. Business intelligence (BI)
 	Business intelligence, with its heavy focus on data analytics, stands to benefit heavily from the proliferation of AI. In addition to providing more in-depth insights, AI will also lessen the amount of work needed to build custom BI apps and tools.
 	Technologies such as Natural Language Processing (NLP) and Natural Language Generation (NLG) will help with the development of drag-and-drop graphical user interfaces (GUI) for BI, making it easier to get insights without custom coding a solution, according to Boris Evelson, vice president and principal analyst at Forrester Research. This means that data analytics will be ""directly available to non-data professionals,"" Evelson said.
 	AI will also make it easier for BI to process unstructured data, Evelson said. ""AI-infused BI will somewhat, albeit not completely, automate all of the steps necessary to transform data into formats and models that BI tools can work with -- relational structures, and so on,"" Evelson said. ""This includes machine learning-based data discovery and machine learning-based data curation -- cleansing, integration and so on.""
 	These changes will essentially make more data available for analysis, which will grow the number of jobs for data analysts as well, Evelson noted.
 	3. Help desk
 	The help desk is the ""the starting point for many machine learning projects"" in the enterprise, according to Nick Patience, co-founder and research vice president at 451 Research. A big part of this has to do with the introduction of chatbots, conversation-based robots that can handle simple questions via text-based input.
 	Chatbots have been used in customer service and on retail websites in recent years, but they are now growing in use for help desk requests. J.P. Gownder, vice president and principal analyst at Forrester Research, said that chatbots will soon be leveraged to handle tasks like employee onboarding and password resets, freeing up help desk pros to handle higher-level problems.
 	""In some cases, automation will replace human headcount in this space, allowing companies to redeploy technology talent elsewhere,"" Gownder said.
 	4. Software engineers/web developers
 	According to Gartner's Sapp, ""AI will become the new UI as it transforms how we enhance the user experience."" This has major implications for consumers, as it changes how they interact with devices or services, but it will also impact the engineers and developers designing those experiences.
SEE: Hiring kit: User experience specialist (Tech Pro Research)
 	Mobile developers may find it easier to create contextual experiences for users, since AI will automatically bring in the most relevant information. On the software side of things, AI will help in the creation of the product itself, automating security and possibly even the development of additional features.
 	""Software engineers will see radical changes on using AI to develop more resilient systems and applications, ranging from self-healing applications to automated code development,"" Sapp said.
 	5. CIO
 	In addition to affecting the work of frontline employees, AI and automation will also impact the lives of IT leaders and management. CIOs, in particular, will see a major change in the way they view the organization, said Forrester's Gownder.
 	""The CIO's workforce will be comprised of a mix of digital workers -- RPA bots, AI programs, chatbots -- and humans, and, keeping this mixed workforce in mind, the CIO will need to hire and train human workers for RQ -- the Robotics Quotient, Forrester's term for the skills required to work well with machines and AI,"" Gownder said.
 	This new organizational structure could make it easier for the CIO to more effectively delegate workforce resources, setting their human employees on the most pressing tasks.
 	There's also the augmentation of the personal assistant. While only the most senior executives tend to have a human assistant, said 451 Research's Patience, in the future every worker will have access to an AI-powered one. This will lead to more efficient scheduling, making it easier for CIOs to plan meetings that work for everyone.
",,Person,purplish blue,source of illumination,lamp,electric lamp,light bulb
https://ibm.biz/BdjC9P,187446750783_10155427694065784,https://www.facebook.com/ibmwatson/videos/10155427694065784/,"AI and blockchain by day, Train and the Chainsmokers by night. All the hottest topics in technology on one stage at Think 2018 in Vegas. Get $300 off your ticket today by using the offer code TK18WVIP and selecting Watson as your interest: ",Video,,,2/22/18 11:00, ,7453,7453,0,10346,10346,0,227,183,225,1,1,8810,6399,0,0,164,361,363,0,0,1980,2107,0,0,4725,30291,13,47.0,,13,47.0,,100,17.0,,92.0,112,18.0,,95.0,,1.0,,,1.0,,"The digital-first IBM business and technology event will take place May 5â7, 2020. Learn about the latest advancements in open technologies from hybrid multicloud to data and AI and interact with luminaries who are using them to transform our lives.Â ",https://www.ibm.com/events/shared/img/think2020/think-og2.jpg,https://www.ibm.com/events/think/?cm_mmc=OSocial_Facebook-_-xIBM+Events_Global+Conferences-_-WW_WW-_-fbWatsonCore&cm_mmca1=000021TD&cm_mmca2=10001376&,joy,0.306699,positive,0.702004,"ticket today, hottest topics, offer code TK18WVIP","Quantity, Person, Location",ticket today,Quantity,joy,0.359078,positive,0.94015,"digital-first IBM business, latest advancements","Company, Person",digital-first IBM business,Company,joy,0.557024,positive,0.810422,,"Company, Person, Company, Person","Since becoming CEO in January 2012, Ginni has led IBM through the most significant transformation in its history, reinventing the company to lead in the new era of AI, blockchain, cybersecurity and quantum technologies, all delivered on IBM’s enterprise-strength cloud platform. Today, IBM is the world leader in AI and cloud computing for business, underpinned with trust and security.
IBM’s commitment to diversity and inclusion also has advanced under Ginni’s leadership. This includes extending parental leave and making it easier for women to return to the workforce through a “returnships” program with hands-on work experience in emerging technologies. This pioneering work was recognized in 2018 by the prestigious Catalyst Award for advancing diversity and women’s initiatives. IBM is the only tech company to have earned this recognition in the last 20 years and the only company ever to be honored four times.
Arvind Krishna leads the IBM business unit that provides the cloud and data platforms on which the company’s clients build the future. His responsibilities include IBM Research, IBM Cloud, IBM Data and AI, and IBM’s Security and Cognitive Applications businesses. He also drove the company’s 2019 acquisition of Red Hat.
Arvind leads the unit’s strategy, product design, offering development, marketing, sales and service. He also guides IBM’s overall strategy in technologies including artificial intelligence, quantum computing, blockchain, cloud platform services, data-driven solutions, and nanotechnology.
Jim Whitehurst is president and chief executive officer of Red Hat, the world’s leading provider of open source enterprise IT software solutions and services. An avid advocate for open software as a catalyst for business innovation, Whitehurst has proven expertise in helping companies flourish—even in the most challenging economic and business environments.
Whitehurst has grown Red Hat and its influence by reaching key milestones—most notably in 2012, when Red Hat became the first US$1 billion open source software company. Company revenue reached almost US$3 billion in 2018.
In 2015, Whitehurst published The Open Organization: Igniting Passion and Performance, a book that shows how open management principles can help organizations succeed in a fast-paced, connected era.
Amal Clooney is a barrister who specializes in international law and human rights. Through international courts, she frequently represents political prisoners, journalists and victims of mass atrocities.
Ms Clooney served as a Sr. Advisor to Kofi Annan. She was appointed to the UK’s panel of experts on combatting sexual violence and to a panel on public international law. She was also appointed as the UK’s Special Envoy for Media Freedom by the UK Foreign Secretary and she serves as vice-chair of a High-Level Panel of Legal Experts on Media Freedom.
Ms Clooney is a Visiting Professor at Columbia Law School, where she co-teaches the Human Rights course, and she is co-author of a forthcoming book titled ‘The Right to a Fair Trial in International Law’ to be published in 2020.
Mayim Bialik is known for her role on the hit CBS comedy, The Big Bang Theory as Amy Farrah Fowler, for which she has received two Critics Choice Awards, four Emmy Award nominations and a SAG Award nomination. Bialik has appeared in numerous beloved roles throughout her dynamic acting career.
An acclaimed author, Bialik has written two #1 New York Times bestsellers, Girling Up: How to Be Strong, Smart and Spectacular, and the recently released Boying Up: How to Be Brave, Bold and Brilliant. She has also written a parenting book, Beyond the Sling, and a cookbook, Mayim’s Vegan Table. Bialik has recently dedicated her skills as a writer, actress, neuroscientist and mother to driving the lifestyle website GrokNation.com, which she started.
",,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2DXShi2,187446750783_10155425874685784,https://www.facebook.com/ibmwatson/videos/10155425874685784/,"&quot;IBM and the AFT worked together for more than 2 years to develop a solution to the problem of inadequate support for teachers. The result is Teacher Advisor, a free online tool that uses Watson to help teachers find the best-quality content—vetted by a range of education experts and nonprofits—to assist them with their work in the classroom.&quot; ",Video,,,2/21/18 17:00, ,5944,5944,0,8055,8055,0,229,174,236,3,3,5713,4299,0,0,159,4694,5324,0,0,4674,5324,0,0,500,500,18,74.0,4.0,18,76.0,5.0,110,24.0,,62.0,144,27.0,,65.0,,3.0,,,3.0,,Randi Weingarten and Stanley S. Litow explore how we can move past divisiveness on key education issues.,https://www.edweek.org/media/2018/01/08/17-web-comm-weingarten-470x235-socialmedia-copyright-getty.jpg,https://www.edweek.org/ew/articles/2018/01/09/in-education-perfect-must-not-become-the.html,joy,0.724427,positive,0.632325,"free online tool, best-quality content, Teacher Advisor, range of education experts","Company, Quantity, Person",free online tool,Company,joy,0.326735,negative,-0.799388,Randi Weingarten,"Person, Person",Randi Weingarten,Person,joy,0.610601,positive,0.427193,,"Person, Organization, Organization, Organization, Organization, Person, Organization, Person, Location, Location","America’s future, and the futures of our more than 50 million public school students, are one and the same. Essential to this future are the more than 3 million teachers who—more than anyone else besides parents and the students themselves—are responsible for our children’s success. But our dedicated teachers are hamstrung by inadequate funding and a lack of other types of support that are critical to providing our children with high-quality education. That is why all of us must work together to make teacher success our top priority.
Public-private partnerships that allow us to get past divisiveness on key education issues can be critically important to education reform. As the former deputy chancellor of schools in New York City (Stanley Litow) and the former head of the city’s United Federation of Teachers (Randi Weingarten), the two of us know the importance of putting differences aside in service of the greater good. We have learned the hard way that perfect can be the enemy of good and that we must set aside our criticisms if we are to build a sustainable future for our children.
None of us has all the solutions, but one critical challenge on which we agree is our national teacher shortage, which could soon hit crisis levels. A 2016 Learning Policy Institute study projects a shortfall of more than 100,000 teachers by this calendar year, and it’s not hard to see why. Inadequate salaries, poor working conditions, the cost of obtaining qualifications, and deficient teaching and learning resources have contributed to rampant dissatisfaction among teachers. In fact, a recent study by the American Federation of Teachers and the educator-advocacy Badass Teachers Association revealed that two-thirds of teachers usually feel stressed out—twice the level of workers in the general population. (The respondents included 4,000 educators in a public survey and a random sample of 850 AFT educators.)
Stress can be particularly acute for early-grade teachers. Under pressure to improve student achievement, many elementary school teachers are suddenly asked to instruct unfamiliar grade levels or master specialized areas like math without adequate support. This lack of support affects our nation’s youths directly. Children in early grades cannot afford to miss the essential building blocks in math and other subjects, which research indicates are directly connected to overall achievement.
The IBM Foundation and the AFT worked together for more than two years—with the backing of the Carnegie, Ford, and Niarchos foundations and in collaboration with more than 1,000 teachers—to develop a solution to the problem of inadequate support. The result, which was launched nationwide at the start of the current school year, is a free online tool that helps teachers find the best-quality content—vetted by a range of education experts and nonprofits—to assist them with their work in the classroom. Teacher Advisor uses IBM’s artificial-intelligence technology to produce tailored advice for teachers in grades K-5. It delivers relevant material based on teacher queries, drawing from a repository of more than 2,000 high-quality math lessons, proven teaching strategies, and videos. Importantly, Teacher Advisor is a support tool, which will improve with continued training and use. It does not evaluate teacher performance.
The idea for Teacher Advisor sprang from conversations with educators and policymakers across the political spectrum. They set aside polemical differences to support our teachers, and early feedback on the tool has been promising. 
Technology cannot be the only answer to any problem—there are no silver bullets in education. Any new approach needs to be part of a genuine collaboration with teachers, who are in the driver’s seat, to produce gains in student achievement. We believe additional collaborations will be essential to improving how we help teachers and students succeed. And we know that working together—not pointing fingers—will be critical to our nation’s future success. Teacher Advisor is not the only way to help alleviate one of the many challenges facing teachers today, and we certainly hope it won’t be the last. But we believe it is an important step toward harnessing the transformative power of collaboration to improve education.
We cannot afford to continue to undervalue public education. If we do, our nation’s children will have the most to lose. Instead, we can, and should, roll up our sleeves and work together to support our teachers’ tireless efforts to improve kids’ chances of success.
 Notice: We recently upgraded our comments. (Learn more here.) If you are logged in as a subscriber or registered user and already have a Display Name on edweek.org, you can post comments. If you do not already have a Display Name, please create one here. 
",,Person,ultramarine,print,fabric,print,-
https://ibm.co/2EvwDhZ,187446750783_10155422925680784,https://www.facebook.com/ibmwatson/posts/10155422925680784,"Have you ever come across terms like &quot;chatbot,&quot; &quot;virtual assistant&quot; and &quot;conversational agent&quot;,&quot; and wondered what the difference is? Read how IBM Watson VP, CTO Rob High explains the distinctions between conversational technologies: ",Link,,,2/20/18 11:10, ,7670,7670,0,10853,10853,0,146,91,115,3,3,9046,6490,0,0,122,0,0,0,0,0,0,0,0,0,0,12,62.0,,17,67.0,,33,62.0,,,41,74.0,,,2,1.0,,2,1.0,,Find out the key differences between chatbots vs. virtual assistants vs. conversational agents from IBM Watson VP and CTO Rob High.,https://cdn.ttgtmedia.com/visuals/German/article/chatbot-2-fotolia.jpg,https://searchcio.techtarget.com/feature/Comparing-chatbots-vs-virtual-assistants-vs-conversational-agents,sadness,0.106936,neutral,0,"IBM Watson VP, quot, CTO Rob High","Company, Person, Company",IBM Watson VP,Company,joy,0.040039,neutral,0,key differences,"Company, Person",key differences,Company,joy,0.524255,positive,0.613699,conversational agent,"Person, Company, Company","interchangeably, but do those terms really describe the same thing? Not according to Rob High, vice president and CTO at IBM Watson and an IBM Fellow.
In this Q&A, High explains the subtle but distinct differences between those three conversation-based technology terms and the intent behind them. One rule of thumb: The extent to which these technologies engage the user is key to understanding their differences.
What are the differences between terms like chatbot, conversational agent, virtual assistant, etc.?
Rob High: All those terms are used kind of loosely. There are lots of examples in which the terms have been used interchangeably. At IBM, we tend to think of these things somewhat distinctively, and it largely has to do with the degree to which they engage the end user in solving the problem.
   Rob High  
A simple example of this is that there are a lot of chatbots out there today that operate on what we call a single-turn exchange. Somebody says something like 'Alexa, turn on the lights' or 'OK, Google, what's the tallest mountain in the world?' Those are independent, single-turn exchanges. The end user expresses an utterance, the utterance is interpreted or recognized for its intent, and then that intent is mapped onto a specific task.
That's all good, but when somebody asks 'what's my account balance?' they may need to know what their account balance is, but that's really not their problem. Their problem is that they're getting ready to buy something or they're trying to figure out how to save up for their kids' education or they're trying to figure out how to pay their bills -- there's something behind the question.
In my mind, a conversational agent is one that engages the end user into really understanding the nature of the problem behind the question. Part of that includes determining when it's appropriate to dig in deeper but also recognizing that, often, there is a bigger problem there. The conversational agent must be prepared to go to the next level and solicit end users to better understand the problem. Sometimes [conversational agents] have to help [end users] figure out for themselves what the problem is because, sometimes, we'll just go in with a question and we don't really know what it is that we're after.
This is especially important when you're dealing with customer support or servicing a product because if you're having a problem with something that you bought, the first thing that you need to do is describe the problem, but that might just be describing the symptoms and not necessarily the real issue.
It's going to take more than that to figure out what is really going on with the product and what is the issue and whether it's a problem with the product or a problem with the way it's being used or whether it's some transient situation. There are lots of different things that could be behind all that. A conversational agent has to be able to get to that.
You use the term conversational agent, but a lot of people use the term virtual or personal assistant. Which of those terms should we be using, or are they distinct?
High: They're kind of two different sides of the same coin, in some sense. A conversational agent is more focused on what it takes in order to maintain a conversation. With virtual agents or personal assistants, those terms tend to be more relevant in cases where you're trying to create this sense that the conversational agent you're dealing with has its own personality and is somehow uniquely associated with you.
At least for me, the term virtual assistant sort of metaphorically conjures the idea of your own personal butler -- someone who is there with you all the time, knows you deeply, but is dedicated to just you and serving your needs. When a conversational agent is coupled with that kind of personalized knowledge and acts and behaves in a way that gives you the feeling that it's there only for you, I think there becomes an intersection between the two ideas.
For it to serve you on a personal level, any kind of good personal assistant or virtual assistant needs to retain a great deal of context about you, but then use that context as a way of interacting with you -- to use the conversational agent technique for not just anticipating your need but responding to your need and getting to know you better to be able to respond to that need better in the future.
So personal assistants are good at natural language processing and can use machine learning to keep getting better. Do you see chatbots and the various kinds of conversational agents evolving side by side or do you see one overtaking the other?
High: I think both are useful for their own purposes and, to some extent, there's a continuum. But there's certainly a demarcation when it comes to the philosophy of what you're trying to do [and] the tools that you need to be able to do it with and the underlying technologies that are necessary to enable it.
I could imagine a world where chatbots are just chatbots and they do what they've done and they do it well but they don't do much more than that. There may be a use for that, but [I could imagine] other places where there's a lot of utility in going beyond just simply the chatbot to help people with their problems. A lot of that is driven by what kind of utility is called for.
We believe at IBM that the real purpose of AI is to augment human intelligence, not to replace human intelligence. When you think about that, you begin to realize that augmenting human cognition requires getting into a deeper level of understanding of a human and being able to recognize what problems they're trying to get to in a conversation space. [AI] must recognize that humans express themselves in sometimes very subtle ways, and that the intention behind that expression is something that requires a certain degree of reasoning.
The systems have to be trained [using machine learning]; you can't just program them to be able to do all these things. They have to learn. Ultimately, they have to interact with us like we're humans. They have to know something about the fact that, as humans, we have emotions, and our emotions can vary throughout the course of a conversation. [Conversational agents] have to know how to interact with somebody in order to amplify their thinking. There's more to it than just what you typically see today as a chatbot.
So I think both will continue to exist, but a demarcation will occur between those simple things that people can do quickly and easily without a whole lot of additional exploration, versus those situations in which there's a lot of economic value in amplifying human cognition.
How can technologies like chatbots and virtual assistants drive business value? Beyond handling conversational tasks, what's their potential in the enterprise?
High: I think chatbots may be an entry point for almost any enterprise. It's hard to operate an enterprise without having some kind of interface to your clients -- even the simplest of interfaces like those that might occur when you're carrying your smartphone around with you. Almost every institution out there is trying to engage their clients at a deeper level.
Part of that is about getting to know your clients better so that you can serve them better and part of it is about trying to create a higher degree of trust and loyalty. Some of it is about trying to deal with the burgeoning growth in call center expenses as more and more of these relationships drive more hand-holding or deep touch.
I think all of that is conspiring to suggest that going into the digital age, enterprises can only be successful if they're thinking about employing these conversational agents as a way of augmenting their own staff, but, even more so, augmenting the intelligence of their staff and their relationship with their clients and augmenting the intelligence of the clients to create a stronger relationship with the institution.
",conversational agent,Person,jade green,spectrum of colors, , , 
https://ibm.co/2D45S42,187446750783_10155420336515784,https://www.facebook.com/ibmwatson/posts/10155420336515784,"You've heard of chatbots helping businesses, but can they be used to solve issues in the greater world? Read our blog about bots that help people solve legal issues, get therapy, quit smoking and learn to meditate. ",Link,,,2/19/18 9:20, ,9428,9428,0,13014,13014,0,187,131,160,7,7,10259,7236,0,0,156,0,0,0,0,0,0,0,0,0,0,25,64.0,1.0,26,65.0,1.0,47,91.0,2.0,,60,98.0,2.0,,3,4.0,,3,4.0,,"Here are 6 chatbots, developed using AI and cognitive APIs, that are helping improve the world, for everyone.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/06/blog_botsGood_png_blogBanner_061917.png,https://www.ibm.com/blogs/watson/2017/06/bots-for-good-6-helpful-chatbots/?cm_mmc=OSocial_Twitter-_-Watson+Core_Watson+Core+-+Platform-_-WW_WW-_-Bots+for+good&cm_mmca1=000018SW&cm_mmca2=10004432,joy,0.802359,positive,0.477583,legal issues,,legal issues,,joy,0.663787,positive,0.923297,cognitive APIs,,cognitive APIs,,joy,0.565459,positive,0.427483,,"Person, Person, Quantity, Person, Person, Company, Company, Quantity, Quantity, Person, Person, Organization, Quantity, Quantity, Location","Chatbots are great for customer service, ordering tickets, or just giving you weather updates, but others have nobler goals for their bots. Here are 6 bots, developed using a variety of technologies and APIs, and delivered via different interfaces, that are helping improve the world for everyone.
DoNotPay started out as a cheeky service to help drivers get out of parking tickets. Stanford student Joshua Browder became more interested in bots after the online tool automatically challenged over 160,000 of them. People began contacting him asking for help with other legal issues relating to evictions, bankruptcies, and repossessions, so he decided to expand the capabilities of the bot to help homeless people.
Rather than making users fill out a lengthy form, Browder used a natural language interface to gather the data needed to fill out the form. He then used IBM Watson’s Conversation service which helped him improve accuracy by 30%. Browder was only 19 years old when he created this app and Watson’s cognitive APIs helped him build stronger AI into his app in a matter of just weeks. He has since turned his attention to other areas of law, including resolving landlord and travel disputes.
Browder mined 15 years of affordable housing application data, obtained via a Freedom of Information Act (FOIA) request. Then he programmed DoNotPay to ask users personal questions relating to their stated problem. For example, it may ask a resident facing eviction “do you have a right to live here?”. It might ask a person seeking housing “are you legally homeless,” while providing them with a legal definition. It then takes this information and creates an application based on previous success rates, using one of seven default claim letters. His goal with the service is to offer a replacement for what he sees as a subset of predatory lawyers that charge heavy fees to do little more than file paperwork.
Since his success with DoNotPay, Browder, dubbed the ‘Robin Hood of the Internet’ by the BBC, has expanded it to give free legal aid to refugees seeking asylum in the US, Canada and UK.
Created by a team of Stanford psychologists and AI experts, Woebot uses sh0rt chat conversations, sentiment and tone analysis and word games to help people who are looking for inexpensive therapy. Wombat Labs Inc. just launched the commercial version of the chatbot this June. The first 14 sessions with the bot therapist are free after which they offer tiered pricing of $6 – $12 per week depending on what plan you sign up for.
Wombat’s creators gave the bot a fun, casual and friendly personality. For example their website says Woebot is “…ready to listen, 24/7. No couches, no meds, no childhood stuff. Just strategies to improve your mood. And the occasional dorky joke.“
Wombat uses a combination of natural language processing, therapeutic expertise, personalized content, and sense of humor to “create the experience of a therapeutic conversation for all of the people that use him.”
Across the world, young people are concerned about a variety of issues, ranging from climate change to the economy. Unicef created its own bot, U-Report, to give them a voice. The bot, available via Twitter and Facebook Messenger, polls its followers (called ‘U-Reporters’) on a range of topics. The idea is to gather opinion and experiences from these young participants, who now number over three million, and use them to help influence public policy.
U-Report regularly sends out polls on a variety of issues, and assesses the results based on demographic data provided by U-Reporters when they sign up.
The pollster bot has achieved some notable results. In Liberia, it asked 13,000 young people if teachers at their schools were exchanging grades for sex. 86% said yes, uncovering an endemic problem and prompting Liberia’s Minister of Education to work with UNICEF on stamping it out.
It is 2017, and despite smoking bans and punitive taxes, people still continue to light up. Could a chatbot help people to quit smoking? Dr. Amelie G. Ramirez of the University of Texas Health Science Center at San Antonio’s Institute for Health Promotion Research hopes so. She created Quitxt, an SMS-based quitbot designed to help addicted puffers deal with their cravings.
Targeting young adults aged 18-29, the bot consistently encourages smokers to give up and not look back. Smokers can set their quit date and embark on an 8-10 week program, receiving between three and seven text messages per day for the first two weeks, gradually reducing over time. In addition to encouraging words, the bot also provides tips for managing stress and building a support network. Participants can expect links to mobile webpages designed to help people give up smoking.
While some bots exist to help you stop a habit, others want to help you start one. Entrepreneur Eric Rems created MeditateBot as a Facebook Messenger tool to help him remember to meditate. Meditation is a proven health technique, and helps practitioners to remain mindful throughout the day, reducing stress and conflict.
Developed over a weekend, the chatbot teaches the benefits of meditation and advises on different kinds. It also enables people to schedule daily meditation reminders. When creating the bot, Rems focused on keeping the barrier to entry low by not imposing too many requirements on users early on. He avoided collecting too much information from them, so that they could begin using the bot easily without filling out forms that would create a hurdle for them to begin using the bot.
He enabled them to choose when they meditate, and let them choose how long. He also limited the available options. “I’ve seen too many apps that have an endless amounts of options, this makes it hard to select the “right” one — which causes frustration,” he said.
Over 500,000 users have been busy chilling out and improving their mental health using the chatbot, so he must be doing something right.
",,Person,purple,printed circuit,electrical device,computer circuit,printed circuit
https://ibm.co/2oa05nB,187446750783_10155417615030784,https://www.facebook.com/ibmwatson/posts/10155417615030784:0,"Got spare time to catch up on how AI is transforming the customer service industry? Watch an on-demand replay of our virtual summit on the future of call centers as artificial intelligence creates efficiencies in the landscape to enhance the role of call center agents. Hear from our keynote speaker Seth Godin, marketing entrepreneur &amp; best-selling author as well as other leading experts. ",Photo,,,2/18/18 9:00, ,6074,6074,0,8284,8284,0,155,93,115,2,2,6257,4417,0,0,114,0,0,0,0,0,0,0,0,0,0,21,63.0,1.0,23,64.0,1.0,44,8.0,48.0,,55,10.0,50.0,,1,1.0,,1,1.0,,,,https://event.on24.com/eventRegistration/EventLobbyServlet?target=reg20.jsp&partnerref=VirtualSummitLP&eventid=1518904&sessionid=1&key=5D321231EBFB87EE94E13F65079FCFB1&regTag=&sourcepage=register,joy,0.66405,positive,0.932935,"artificial intelligence, keynote speaker Seth Godin, demand replay of our virtual summit, spare time, future of call centers","Person, Person",artificial intelligence,Person, , , , , , , , ,sadness,0.461582,neutral,0,,," 		 		 		Event Registration
 		 		  		 		  		 		 		 		   	 	  		 			 				 			
 			 				 			
 			 				 			
 			             
 		
 		 			 		
 		 			 		
 		 			 		
  		 			 		  		  		 		 	  

",,, , , , , 
https://ibm.biz/BdjC9P,187446750783_10155415471200784,https://www.facebook.com/ibmwatson/posts/10155415471200784:0,"THINK 2018 is a global conference of education for all people. Learn from leading experts in the AI field and a broad array of other speakers such as Lisa Ling, Executive Producer and host of CNN's &quot;This is Life with Lisa Ling.&quot; Get your ticket now – save $300 with the code TK18WVIP and selecting &quot;Watson&quot; as your interest when registering. ",Photo,,,2/17/18 12:04, ,10296,10296,0,14532,14532,0,233,151,183,5,5,12397,8750,0,0,188,0,0,0,0,0,0,0,0,0,0,18,90.0,1.0,18,91.0,1.0,89,20.0,53.0,,100,25.0,58.0,,2,3.0,,2,3.0,,"The digital-first IBM business and technology event will take place May 5â7, 2020. Learn about the latest advancements in open technologies from hybrid multicloud to data and AI and interact with luminaries who are using them to transform our lives.Â ",https://www.ibm.com/events/shared/img/think2020/think-og2.jpg,https://www.ibm.com/events/think/?cm_mmc=OSocial_Facebook-_-xIBM+Events_Global+Conferences-_-WW_WW-_-fbWatsonCore&cm_mmca1=000021TD&cm_mmca2=10001376&,joy,0.546125,positive,0.47617,"Lisa Ling, Executive Producer, broad array of other speakers","Person, Person, Quantity, Company",Lisa Ling,Person,joy,0.359078,positive,0.94015,"digital-first IBM business, latest advancements","Company, Person",digital-first IBM business,Company,joy,0.557024,positive,0.810422,,"Company, Person, Company, Person","Since becoming CEO in January 2012, Ginni has led IBM through the most significant transformation in its history, reinventing the company to lead in the new era of AI, blockchain, cybersecurity and quantum technologies, all delivered on IBM’s enterprise-strength cloud platform. Today, IBM is the world leader in AI and cloud computing for business, underpinned with trust and security.
IBM’s commitment to diversity and inclusion also has advanced under Ginni’s leadership. This includes extending parental leave and making it easier for women to return to the workforce through a “returnships” program with hands-on work experience in emerging technologies. This pioneering work was recognized in 2018 by the prestigious Catalyst Award for advancing diversity and women’s initiatives. IBM is the only tech company to have earned this recognition in the last 20 years and the only company ever to be honored four times.
Arvind Krishna leads the IBM business unit that provides the cloud and data platforms on which the company’s clients build the future. His responsibilities include IBM Research, IBM Cloud, IBM Data and AI, and IBM’s Security and Cognitive Applications businesses. He also drove the company’s 2019 acquisition of Red Hat.
Arvind leads the unit’s strategy, product design, offering development, marketing, sales and service. He also guides IBM’s overall strategy in technologies including artificial intelligence, quantum computing, blockchain, cloud platform services, data-driven solutions, and nanotechnology.
Jim Whitehurst is president and chief executive officer of Red Hat, the world’s leading provider of open source enterprise IT software solutions and services. An avid advocate for open software as a catalyst for business innovation, Whitehurst has proven expertise in helping companies flourish—even in the most challenging economic and business environments.
Whitehurst has grown Red Hat and its influence by reaching key milestones—most notably in 2012, when Red Hat became the first US$1 billion open source software company. Company revenue reached almost US$3 billion in 2018.
In 2015, Whitehurst published The Open Organization: Igniting Passion and Performance, a book that shows how open management principles can help organizations succeed in a fast-paced, connected era.
Amal Clooney is a barrister who specializes in international law and human rights. Through international courts, she frequently represents political prisoners, journalists and victims of mass atrocities.
Ms Clooney served as a Sr. Advisor to Kofi Annan. She was appointed to the UK’s panel of experts on combatting sexual violence and to a panel on public international law. She was also appointed as the UK’s Special Envoy for Media Freedom by the UK Foreign Secretary and she serves as vice-chair of a High-Level Panel of Legal Experts on Media Freedom.
Ms Clooney is a Visiting Professor at Columbia Law School, where she co-teaches the Human Rights course, and she is co-author of a forthcoming book titled ‘The Right to a Fair Trial in International Law’ to be published in 2020.
Mayim Bialik is known for her role on the hit CBS comedy, The Big Bang Theory as Amy Farrah Fowler, for which she has received two Critics Choice Awards, four Emmy Award nominations and a SAG Award nomination. Bialik has appeared in numerous beloved roles throughout her dynamic acting career.
An acclaimed author, Bialik has written two #1 New York Times bestsellers, Girling Up: How to Be Strong, Smart and Spectacular, and the recently released Boying Up: How to Be Brave, Bold and Brilliant. She has also written a parenting book, Beyond the Sling, and a cookbook, Mayim’s Vegan Table. Bialik has recently dedicated her skills as a writer, actress, neuroscientist and mother to driving the lifestyle website GrokNation.com, which she started.
",,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2EMv96k,187446750783_10155413156255784,https://www.facebook.com/ibmwatson/posts/10155413156255784,How is AI is helping to change information overload from killing returns? Accrete.AI uses Watson technologies to empower investors to spend less time searching for insights and more time making informed decisions. ,Link,,,2/16/18 13:30, ,5493,5493,0,7415,7415,0,104,65,83,2,2,6394,4487,0,0,95,0,0,0,0,0,0,0,0,0,0,14,42.0,1.0,16,43.0,2.0,25,40.0,3.0,,38,42.0,3.0,,1,1.0,,1,1.0,,Accrete.AI combines collective human intelligence with machine learning to train machines to be bias-free and contextually adaptive at scale.,https://www.ibm.com/blogs/watson/wp-content/uploads/2018/02/blog_5InnovationsWithAI_png_socialTile_020718.png,https://www.ibm.com/blogs/watson/2018/02/information-overload-is-killing-returns-ai-is-helping-to-change-that/?cm_mmc=OSocial_Facebook-_-Watson+Core_Watson+Core+-+Discovery-_-WW_WW-_-AccretteBlog2Facebook&cm_mmca1=000016UP&cm_mmca2=10006611&cm_mmca3=M00019706&cvosrc=email.Facebook.M00019706&cvo_campaign=000016UP,sadness,0.199767,negative,-0.318777,"Watson technologies, less time, information overload","Company, Company, Person",Watson technologies,Company,joy,0.23371,positive,0.907789,collective human intelligence,Company,collective human intelligence,Company,joy,0.55679,positive,0.582017,,"Company, Company, Company, Person, Company, Facility, Company, Person, Organization","Key points: 
 – Information overload may be the curse of the digital age but it’s definitely the enemy of sound decision-making, which is the daily job of money managers around the globe
 – Artificially intelligent systems are only useful to investors in a practical way if they’re smart enough to adapt to changing conditions
 – IBM is only one of a handful of cloud companies with the computational resources necessary to crunch the mountains of unstructured data that investment managers face every day
Information overload may be the curse of the digital age but it’s definitely the enemy of sound decision-making, which is the daily job of money managers around the globe. Even those investment managers with enormous resources and professional networks are struggling not only to keep up but to discern reality from crowd psychology, and make accurate predictions that outperform benchmark indices on a risk-adjusted basis.
Fortunately for asset managers and their clients, there’s a solution: Augmenting human capabilities with artificial intelligence (AI) to surface actionable insights buried in the nuances of language hidden in large volumes of constantly changing data.
At Accrete.AI, our bias-free, contextually adapted investment tools empower investors to spend less time searching for insights and more time making informed decisions. Our products are helping analysts and portfolio managers detect changes in nuance across key topics mentioned in earnings calls, find actionable M&A rumors, parse confusing Fed-Speak and identify supply chain risk before others.
We apply Watson services with our proprietary AI in three key ways:
There’s no question that successful money managers must build, or accrete, knowledge over time. But, today’s savvy investment managers would need to read millions of documents daily across a variety of domains to even begin to keep up. The real question for today’s investors is: Are you able to accurately account for the new and idiosyncratic nature of volatility resulting from digitally amplified crowd behavior? For most, the answer is no.
That’s why, through our partnership with IBM, we’re embedding Watson technologies into intelligent systems that read, understand and learn at scale across a variety of market domains, continuously compounding knowledge and connecting dots. They’re literally always working to make sense of the digital world and offload cognitive bandwidth so that investors can account for unforeseen risk and take advantage of new opportunities.
Artificially intelligent systems are only useful to investors in a practical way if they’re smart enough to adapt to changing conditions and solve real-world problems. In theory, observers might think that general artificial intelligence would be able to understand fundamental concepts such as Federal Reserve hawkishness or what an actionable M&A rumor looks like. The reality is that machines can only understand context in information with our help. On the other hand, human beings are ill-equipped to constantly teach machines every nuance of human language because in the digital age nuance evolves far faster than humans can keep pace with. Also, if biased humans teach machines, then the machines simply learn and apply those biased perspectives at scale.
AI used in investing must be trained using methods that can reduce or even eliminate bias, and that enable machines to learn new contexts in order to achieve sustained, high levels of accuracy, and enable investors to meet their clients’ performance expectations. That’s what we do.
At Accrete.AI, we combine collective human intelligence with supervised and unsupervised machine learning to train machines to be bias-free and contextually adaptive at scale. IBM Watson Knowledge Studio and Watson Discovery Service play an important role in the supervised learning process.
To help investors solve real-world market problems, we start by defining domain-specific pain points related to information overload.
Then, we train machines to interpret different contexts, for example, where the same word could be used with potentially different meanings. Consider two headlines that read “Apple’s Jobs Rising” and “Jobs sliding at Apple.”
The machine would need to discern whether the word “Jobs” refers to employment opportunities at Apple, or to Apple’s founder Steve Jobs. Those different meanings could have vastly different implications in a market context. This step begins to address meaning and relevance, but it doesn’t fully address bias in context.
To do that, we source and vet domain experts from academia and industry, spanning a variety of perspectives. These formally engaged domain experts identify important entities and relationships in training data we provide to them. Our domain experts don’t know each other and work independently, so when a majority of experts in a particular domain agree upon the importance of a concept, that concept can be characterized as a bias-free ground truth. Then we build ontologies from kernels of ground truth to teach Watson how to speak the vocabulary of a specific domain in a bias-free way, thus seeding our neural networks with trustworthy contextual awareness.
Like a child learning to ride a bicycle using training wheels, our solutions learn over time and need less support. It’s a constant trade-off between supervised and unsupervised learning depending on the amount of available training data and the scope of the domain-specific problem we’re trying to solve. For example, there are only so many ways people reference actionable M&A rumors in social media, and there’s lots of training data available, so the scope of the problem is relatively limited. In contrast, while there’s enough training data covering nuances in earnings calls across each company in the S&P 500 going back 10 years, actually mapping linguistic nuances to key topics is much larger in scope, making it necessary to leave the training wheels on longer.
IBM is only one of a handful of cloud companies with the computational resources necessary to crunch the mountains of unstructured data that investment managers face every day. That’s why we’ve built our smart investment tools on IBM’s infrastructure, and why we’re making them available on IBM’s Financial Solutions Cloud Hub. Accrete.AI leverages expert networks, shallow learning and deep learning techniques to build smart investment tools that solve real-world problems and help investors generate alpha in the digital age.
Read more about Accrete.AI’s unique use of Watson AI.
",,Company,reddish brown,people,person,people,-
,187446750783_10155410100605784,https://www.facebook.com/ibmwatson/posts/10155410100605784,"Catch up on last week's Facebook Live, where Rob High, Watson VP and CTO and Amy Webb, Professor of Strategic Foresight at NYU Stern and bestselling author and founder Future Today Institute discussed how AI will impact professionals and transform businesses.",SharedVideo,,,2/15/18 8:28, ,2088,2088,0,3027,3027,0,42,29,37,0,0,2607,1751,0,0,38,0,0,0,0,144,187,0,0,0,2574101,,16.0,,,16.0,,28,,,,36,,,,,,,,,,,,,joy,0.582849,positive,0.729206,last week's Facebook Live,"Person, Person, Person, Facility, Organization, Company",last week's Facebook Live,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2DqJp40,187446750783_10155408300415784,https://www.facebook.com/ibmwatson/posts/10155408300415784,"AI and a tech jobs boom are poised to change the employment landscape in 2018, according to Glassdoor. ",Link,,,2/14/18 14:30, ,4569,4569,0,6850,6850,0,116,96,120,2,2,4360,2859,0,0,64,0,0,0,0,0,0,0,0,0,0,5,22.0,1.0,7,23.0,1.0,30,76.0,,,41,79.0,,,,2.0,,,2.0,,"AI and a tech jobs boom are poised to change the employment landscape in 2018, according to Glassdoor.",https://tr3.cbsistatic.com/hub/i/r/2017/12/19/208acec2-2087-4326-8cc5-e5d798e74cdc/thumbnail/770x578/4b07d8839aea6569758022ab9916227b/istock-655801624.jpg,https://www.techrepublic.com/article/the-5-most-important-tech-job-trends-for-2018/?ftag=COS-05-10aaa0h&utm_campaign=trueAnthem:%20Trending%20Content&utm_content=5a4659a404d3015b0d788955&utm_medium=trueAnthem&utm_source=facebook,joy,0.343617,positive,0.58156,tech jobs boom,Person,tech jobs boom,Person,joy,0.343617,positive,0.58156,tech jobs boom,Person,tech jobs boom,Person,joy,0.501719,positive,0.61787,job market,"Person, Person, Organization, Company, Quantity, Quantity, Person, GeographicFeature","The job market will continue to shift in 2018, as technologies such as artificial intelligence (AI) impact many industries, and mobile changes the way people find and apply for jobs, according to a new report from job search site Glassdoor. 
Despite two major hurricanes and political challenges, the US economy experienced a strong year, Andrew Chamberlain, Glassdoor's chief economist, wrote in the report: 1.9 million new jobs were added in 11 months, and stock markets reached an all-time high. Additionally, the nation's unemployment rate dropped to a 17-year low, fueling a talent war in tech, healthcare, e-commerce, and other professional services, he added. 
""This year has been good for many--but not all--workers,"" Chamberlain wrote. ""Job seekers who've mastered key skills in data science, software development, and health professions are seeing rising pay and benefits. At the same time, average wages for many remain stubbornly flat. Despite a healthy job market overall, job growth is sharply divided, with tech skills earning a premium and others being left behind by rising artificial intelligence (AI) and automation."" 
SEE: IT jobs 2018: Hiring priorities, growth areas, and strategies to fill open roles (Tech Pro Research)
Tech jobs continue to spread: In 2017, a growing number of employers in  finance, retail, manufacturing, and other traditional industries began creating more tech roles. And a growing share of tech hiring is happening far from Silicon Valley, in more affordable tech clusters such as Seattle, Austin, Detroit, Dallas, and Raleigh, Glassdoor found. 
Here are five job disruptions to watch for 2018, according to Chamberlain. 
1. AI changing the future of work
AI and automation will impact nearly every facet of the workforce in some way in the future. However, certain industries--particularly human resources and finance--are more likely to see big changes in 2018. New AI tools are complementing the skills of human workers in these areas, and changing many established roles that are easy to automate. 
2. Modernization of mobile job applications
Since most job application systems were created in the past, applying for a job via a mobile device can be a difficult process, Chamberlain said. It's likely that 2018 will see growth in mobile application platforms, though it may take time before they are commonly used.
3. Job growth in tech, healthcare, and labor-intensive roles
Innovations in tech will drive job creation in 2018, in both tech and traditionally non-tech industries, Chamberlain said. Significant demographic shifts, such as the aging population, will also lead to massive workforce changes. Many traditional jobs, such as waiters and truck drivers, that cannot be automated easily in the near terms will continue to grow in number, he predicted.
4. Increased transparency in the application and interview process
The online job application process remains opaque for many employees, Chamberlain said. In 2018, it's likely that job seekers will gain more visibility into both the application process and the status of job applications in real time.
5. Encouraging employee passions through role experimentation
Companies are increasingly finding ways for employees to experiment with different roles within the company, to tap the changing skills and passions of their workforce, reduce turnover, and better match talent to positions, Chamberlain said. It's likely this will continue and expand in the new year. 
",job market,Person,gray,checkout counter,furniture,table,checkout counter
https://ibm.biz/BdjC9P,187446750783_10155404881990784,https://www.facebook.com/ibmwatson/posts/10155404881990784:0,"At just 13 years old, Tanmay Bakshi made headlines last year as the youngest Watson developer to work on IBM projects. This year, he'll be speaking onstage about his experiences during THINK 2018 in Vegas. Learn more about the conference and get $300 off your ticket using our offer code TK18WVIP and selecting 'Watson' as your interest: ",Photo,,,2/13/18 8:35, ,15936,15936,0,26500,26500,0,521,316,403,9,9,19850,11608,0,0,359,0,0,0,0,0,0,0,0,0,0,40,225.0,8.0,42,242.0,12.0,186,36.0,132.0,,218,38.0,147.0,,3,6.0,,3,6.0,,"The digital-first IBM business and technology event will take place May 5â7, 2020. Learn about the latest advancements in open technologies from hybrid multicloud to data and AI and interact with luminaries who are using them to transform our lives.Â ",https://www.ibm.com/events/shared/img/think2020/think-og2.jpg,https://www.ibm.com/events/think/?cm_mmc=OSocial_Facebook-_-xIBM+Events_Global+Conferences-_-WW_WW-_-fbWatsonCore&cm_mmca1=000021TD&cm_mmca2=10001376&,joy,0.142652,positive,0.282157,"last year, Tanmay Bakshi","Person, Quantity, Person, Quantity, Company",last year,Person,joy,0.359078,positive,0.94015,"digital-first IBM business, latest advancements","Company, Person",digital-first IBM business,Company,joy,0.557024,positive,0.810422,,"Company, Person, Company, Person","Since becoming CEO in January 2012, Ginni has led IBM through the most significant transformation in its history, reinventing the company to lead in the new era of AI, blockchain, cybersecurity and quantum technologies, all delivered on IBM’s enterprise-strength cloud platform. Today, IBM is the world leader in AI and cloud computing for business, underpinned with trust and security.
IBM’s commitment to diversity and inclusion also has advanced under Ginni’s leadership. This includes extending parental leave and making it easier for women to return to the workforce through a “returnships” program with hands-on work experience in emerging technologies. This pioneering work was recognized in 2018 by the prestigious Catalyst Award for advancing diversity and women’s initiatives. IBM is the only tech company to have earned this recognition in the last 20 years and the only company ever to be honored four times.
Arvind Krishna leads the IBM business unit that provides the cloud and data platforms on which the company’s clients build the future. His responsibilities include IBM Research, IBM Cloud, IBM Data and AI, and IBM’s Security and Cognitive Applications businesses. He also drove the company’s 2019 acquisition of Red Hat.
Arvind leads the unit’s strategy, product design, offering development, marketing, sales and service. He also guides IBM’s overall strategy in technologies including artificial intelligence, quantum computing, blockchain, cloud platform services, data-driven solutions, and nanotechnology.
Jim Whitehurst is president and chief executive officer of Red Hat, the world’s leading provider of open source enterprise IT software solutions and services. An avid advocate for open software as a catalyst for business innovation, Whitehurst has proven expertise in helping companies flourish—even in the most challenging economic and business environments.
Whitehurst has grown Red Hat and its influence by reaching key milestones—most notably in 2012, when Red Hat became the first US$1 billion open source software company. Company revenue reached almost US$3 billion in 2018.
In 2015, Whitehurst published The Open Organization: Igniting Passion and Performance, a book that shows how open management principles can help organizations succeed in a fast-paced, connected era.
Amal Clooney is a barrister who specializes in international law and human rights. Through international courts, she frequently represents political prisoners, journalists and victims of mass atrocities.
Ms Clooney served as a Sr. Advisor to Kofi Annan. She was appointed to the UK’s panel of experts on combatting sexual violence and to a panel on public international law. She was also appointed as the UK’s Special Envoy for Media Freedom by the UK Foreign Secretary and she serves as vice-chair of a High-Level Panel of Legal Experts on Media Freedom.
Ms Clooney is a Visiting Professor at Columbia Law School, where she co-teaches the Human Rights course, and she is co-author of a forthcoming book titled ‘The Right to a Fair Trial in International Law’ to be published in 2020.
Mayim Bialik is known for her role on the hit CBS comedy, The Big Bang Theory as Amy Farrah Fowler, for which she has received two Critics Choice Awards, four Emmy Award nominations and a SAG Award nomination. Bialik has appeared in numerous beloved roles throughout her dynamic acting career.
An acclaimed author, Bialik has written two #1 New York Times bestsellers, Girling Up: How to Be Strong, Smart and Spectacular, and the recently released Boying Up: How to Be Brave, Bold and Brilliant. She has also written a parenting book, Beyond the Sling, and a cookbook, Mayim’s Vegan Table. Bialik has recently dedicated her skills as a writer, actress, neuroscientist and mother to driving the lifestyle website GrokNation.com, which she started.
",,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2DITGXe,187446750783_10155403160150784,https://www.facebook.com/ibmwatson/posts/10155403160150784,"&quot;Whether you’re a doctor, engineer, lawyer, music producer, teacher—or CEO—we are all going to do our work with the aid of analytics and forms of AI.&quot; – IBM CEO Ginni Rometty via The Wall Street Journal: ",Link,,,2/12/18 15:00, ,7257,7257,0,12086,12086,0,327,224,275,6,6,7836,4569,0,0,265,0,0,0,0,0,0,0,0,0,0,30,132.0,4.0,30,135.0,4.0,91,151.0,1.0,,113,161.0,1.0,,3,3.0,,3,3.0,,,,https://www.wsj.com/articles/ginni-rometty-on-how-ai-is-going-to-transform-jobsall-of-them-1516201040,joy,0.470462,positive,0.592575,"music producer, aid of analytics, forms of AI","Person, Person, Company",music producer,Person, , , , , , , , ,joy,0.623026,negative,-0.236678,"number of recent studies, new tools, distinct minority of the world, artificial intelligence",Company,"Today, the technologies grouped together under “artificial intelligence” are entering mainstream business and daily life. As often happens with radically new tools, some people worry it will destroy jobs. 
The good news? A number of recent studies, including one commissioned by IBM, indicate that history is likely to repeat itself. Some occupations will go away, and new ones will be created, but even together, those will be a distinct minority of the world’s occupations. 
",number of recent studies,Company, , , , , 
https://ibm.co/2xVzDR4,187446750783_10155401207295784,https://www.facebook.com/ibmwatson/posts/10155401207295784,Learn how this Watson-powered earpiece can translate 9 different languages in near real-time: ,Link,,,2/11/18 20:00, ,12461,12461,0,22962,22962,0,356,242,296,7,7,16960,9524,0,0,285,0,0,0,0,0,0,0,0,0,0,29,140.0,3.0,32,140.0,3.0,96,162.0,1.0,,122,173.0,1.0,,3,4.0,,3,4.0,,"Travel fluently. Overcoming the language barrier can be the most challenging part of travel. But now, you may never get lost in translation again with Translate One2One from Lingmo. The Watson-powered...",https://66.media.tumblr.com/4c2be36c15cb2a7fa6ab35552798f092/tumblr_ovvl938fQ21s141c3o1_1280.gifv,https://ibmblr.tumblr.com/post/165055938152/travel-fluently-overcoming-the-language#_=_,joy,0.152654,neutral,0,"different languages, real-time, Watson",Person,different languages,Person,joy,0.290877,negative,-0.729264,language barrier,,language barrier,,joy,0.481539,negative,-0.635036,"language barrier, natural language, cultural context, different languages",Company,"Travel fluently.   
Overcoming the language barrier can be the most challenging part of travel. But now, you may never get lost in translation again with Translate One2One from Lingmo. The Watson-powered earpiece can translate 9 different languages in near real-time. Using natural language processing, it also understands syntax and cultural context such as slang—meaning you can ask for a place to chill, without being offered an overcoat. 
Unfortunately IBMblr isn’t as infinite.
We couldn’t find any stories to match your search.
",language barrier,Company,purple,lavaliere (jewelled pendent),figure,star,-
http://ibm.co/2vFxWXg,187446750783_10155398431515784,https://www.facebook.com/ibmwatson/posts/10155398431515784,What exactly is Watson? Everything you ever wanted to know: ,Link,,,2/10/18 18:00, ,11749,11749,0,18888,18888,0,443,305,363,6,6,11664,7416,0,0,341,0,0,0,0,0,0,0,0,0,0,66,159.0,6.0,69,164.0,9.0,84,238.0,,,110,253.0,,,3,3.0,,3,3.0,,IBM's Watson artificial intelligence project is probably a whole lot bigger than you ever imagined.,https://g.foolcdn.com/editorial/images/455078/gettyimages-671750592.jpg,https://www.fool.com/investing/2017/08/30/ibm-watson-everything-you-ever-wanted-to-know.aspx,anger,0.137096,neutral,0,Watson,Person,Watson,Person,joy,0.264969,positive,0.701775,IBM's Watson,"Person, Company",IBM's Watson,Person,joy,0.167143,positive,0.658187,,"Person, Company","In 2011, IBM's (NYSE:IBM) Watson artificial intelligence (AI) supercomputer beat 74-time-straight Jeopardy! champion Ken Jennings in a man-vs.-machine showdown on primetime television. ""Winning"" $77,147 to Jennings' $24,000, Watson arguably proved itself three times as intelligent as his human opponent. In so doing, IBM ushered in the new age of AI, in which humans no longer work for food, and computers do all of our thinking for us.
Oh, wait. That actually didn't happen.
But in the six years since Watson beat Jennings on Jeopardy!, IBM's AI wunderkind has been in the news plenty. Among other projects, Watson has been tasked with tackling two of humanity's biggest challenges: helping Pfizer figure out a cure for cancer and navigating the U.S. tax code for H&R Block. Yet what exactly Watson is remains something of a mystery to many. In an attempt to get a better handle on Watson, I posed some questions via email to IBM Vice President Ed Harbour, head of the IBM Watson project.
Here's what he had to say. (The interview has been edited to aid clarity and brevity).
Rich Smith: What is Watson, exactly? Is it code? Is it servers? What is the clearest way a layman can envision Watson? 
Ed Harbour: Watson is the AI platform for business. It is not one thing, but rather a collection of services and capabilities that include machine learning, reasoning, and decision technologies, as well as language, speech, and vision technologies. These capabilities are designed to learn at scale, reason with purpose, and interact with humans naturally to solve a wide range of practical problems, boost productivity, and foster new discoveries across many industries.
 Watson can turn business data -- even data that is unstructured -- into actionable insights that enhance decision-making. Watson can take many forms, from virtual assistant to care manager, research module to customer service agent. Watson leverages the IBM Cloud, offering access to an unprecedented set of enterprise-grade cloud services that can further enhance its function to meet various business needs.
 Smith: How does Watson differ from more familiar forms of AI such as Apple's Siri and Amazon.com's Alexa? 
Harbour: Watson and Apple's Siri or Amazon's Alexa do totally different things. Their foundation is quite basic and just speech to text to search. Watson delivers a conversation; it delivers answers, alternatives, and evidence-based recommendations with confidence. It learns from interactions and expert training, grows and develops over time. In addition to answers, it offers alternatives and background on why it made the decisions it recommends to users. Watson retains conversations and can understand context and domain. Watson is an AI platform for the enterprise.
Other forms of AI, like Siri or Alexa, rely solely on Q&A and speech to text. They use pre-compiled, human-curated databases or FAQs to look up keywords, as do search engines like Google. Consumer data is not where most of the value is. Eighty percent of the world's data is not on the Web, but rather embedded in businesses and industries, such as client data, financial data, and medical data. Our approach is to build cognitive solutions to help specific industries and businesses tap this data. A key aspect is Watson protects clients' data and any business insights. This is not shared. Watson is also deployed on the IBM Cloud and can be scaled to meet any enterprise needs.
For example, in the case of IBM client H&R Block, Watson was enlisted to understand the ""language"" of tax to provide the most personalized tax-preparation experience. Watson, with the Tax Professional, helped ensure that consumers were getting the best possible tax outcome and also made the entire tax return process a more collaborative, transparent experience. The main differentiator with Watson is the actionable capability and insights it brings to enterprise clients.
 Smith: What would you say is the public's biggest misperception about Watson? What is one thing that folks might think that Watson can do that it actually cannot? 
Harbour: The biggest misperception about Watson is that it's meant to replace humans. Watson works with humans to enhance the abilities of professionals at every level, from highly specialized surgeons to oil drillers, and automates many basic tasks. However, no matter how advanced the technology, some jobs -- specifically, those that rely heavily on empathy, ethical judgment, and social interaction -- will always be performed better by humans.
 Cognitive computing introduces a new level of collaboration between man and machine. It will augment and expand human intelligence, not replace it. 
Smith: Can you name one concrete example of something you would like Watson to be able to do that it cannot quite manage yet? 
Harbour: The future of technology is rooted in artificial intelligence. In the next three to five years, you'll see advancements that crack the uniquely human nature of communication. For example, Watson has started to be able to detect facial expressions, to combine words, voice, and visual interfaces and form a complete understanding of a conversation. IBM is also further developing Watson's ability to understand different vocalizations of words and how that reinforces a person's emotional meaning.
 The true value of Watson and cognitive systems is how it can augment and amplify human abilities. To help us think and perform our jobs better, faster, not to do it for us.
Smith: How human is Watson right now? Would it be possible for someone to interview Watson about Watson? 
Harbour: Watson is trained on specific data sets to unearth insights into different industries, tasks, and specialties. Once trained, with its speech, language, and intelligence capabilities, Watson can learn and understand the intention behind a specific command and provide a refined answer for the specific industry or profession it was trained to help.
While it's technically possible to train Watson to answer questions about its own technology, unlike humans, Watson does not have a personality, so it may not make for the most engaging interview subject. 
Smith: How does Watson get smarter? By adding data? By refining algorithms? Both? 
Harbour: Watson technologies are trained by humans to understand information specific to different industries, specialties, and languages -- in other words, Watson learns in an expert way, not just a general way. This involves training the system to recognize patterns by feeding it large amounts of labeled data and then working with human experts to refine the answers. Through successive rounds of input and feedback from subject-matter experts, Watson's understanding and responses improve. 
 Looking at the implementation of specific Watson technologies -- Natural Language Understanding and Tone Analyzer are designed to allow developers to quickly bake these functionalities into their apps and see value, without a consultant. Watson Conversation Service enables powerful engagement, and Watson Discovery Service allows for unearthing powerful insights often distributed over vast amounts of documents. Even more robust services like Watson Virtual Agent -- a customer-service chatbot -- come pre-trained with over 105 intents and 35,000 utterances and ready for domains such as general customer service, telco, and retail banking. We also built Watson Knowledge Studio, which allows clients to train Watson on the language of their industry, profession, and domain -- easily. We are continually improving and refining the various underlying algorithms that power the Watson platform.
Smith: How expensive is it for a client to use Watson? How is it billed?
Harbour: Our approach to delivering Watson is flexible and tailored to the clients with both industry solutions and APIs available on the IBM Cloud.
We have several business models for Watson. The overarching theme is value-based. It's really focused on driving scale.
Smith: Can you quantify how important Watson is to IBM's business today, in terms of the revenue it produces?
Harbour: Watson is part of our analytics business in our cognitive-solutions segment. In 2Q17, we reported that revenues in this segment grew to $4.6 billion. Over the last 12 months, our strategic imperatives, which includes analytics, has delivered $34.1 billion in revenue, 43% of IBM's total revenue.
Another good indicator of where we are in the cognitive journey is to look at scaling, where we started and where we are now. Watson was just a natural-language machine six years ago. If you want to think of it in terms of a human, it could only ""hear"" or ""read"" and only basic information at that.
 Today, Watson has grown from that one natural-language QA API into a multitude of services. It has gone from simply speaking English to understanding nine languages. We've added more capabilities and have built extensive data sets industry by industry to train Watson to solve complex industry problems.
 It not only can reason over simple trivia; it can reason through complex industry-specific data, like cybersecurity data or cancer data. And it not only ""reads."" It can ""see."" Watson can look at medical images and flag ones for radiologists that are unusual -- and it can understand emotion and tone, too. 
These capabilities are being deployed in enterprises faster. For example, you mentioned cancer research. Watson took a couple of years to learn about oncology after its Jeopardy! win in 2011. But look where we are today. We've entered clinical use in 12 countries and are expanding to more countries later this year. Watson so far has been trained on six types of cancer, with plans to add several more this year.
On taxes, we started with H&R Block last summer. It took us a few months to build a solution for them, and this year somewhere in the ballpark of 11 million people did their taxes at an H&R Block office, powered by Watson.
Another metric of success is embedding Watson across the IBM portfolio. That's our mission. We've been describing Watson as a sliver thread, weaving through multiple areas and segments. We're helping colleagues across our portfolio embed Watson into existing offerings. We've been successful in security, commerce, technology services, and systems, to name a few.
 Smith: In addition to cancer and taxes, you are also using Watson to provide individual health and fitness insights to more than 190 million users of Under Armour's connected-fitness platform, while simultaneously providing traffic information to Chevy, Buick, and GMC drivers through General Motors' OnStar service. Is there a limit on the amount of juggling Watson can do, working for so many customers simultaneously? 
Harbour: Each client gets their own ""instance"" of Watson to train with their data, to meet their needs. We can scale to any number by deploying on the IBM Cloud. The applications for this technology are limitless, and we expect to help more than 1 billion people this year.
We are continuously working to advance this adoption -- drawing more developers to use cognitive engines like Watson to build their own apps, working with more businesses and industries so they can incorporate cognitive solutions into their workflows.
Smith: Put Watson in context versus other AIs. How does it stack up against the competition today?
Harbour: IBM has a significant lead in the industry in applying AI technology, having been researching, developing, and investing in AI technology for more than 50 years. We also have the largest industrial research organization in the world and in 2016 led the industry in AI-related patents held.
Unlike other technologies in the market today that are in the experimental or elementary stage, Watson is a mature platform making a real impact on the industries it touches. Watson solutions are now being built, used, and deployed in more than 45 countries and across 20 different industries, solving big, complex societal problems, like cancer and cybersecurity. IBM has also made meaningful progress in other industries, ranging from education to commerce. 
Smith: And now look 10 years into the future. What are the chances that in 2027, the average consumer will be able to use Watson in daily life?
Harbour: There's a chance that you use Watson already. For example, in addition to people taking their W-2s to H&R Block for cognitive interviews, people may be using Watson when ordering office supplies from Staples, interacting with a gift concierge via 1-800-Flowers' Gwyn system, checking auto recall and warranty information via Honda's ""Ask Dave"" interface, or interacting with Harman/IBM-powered smart rooms.
In the healthcare space, Watson is about more than just cancer treatment. It's available to more than 200 million patients globally, collaborating with doctors, helping improve treatment recommendations and helping deliver more efficient care.
 AI is playing a bigger and bigger role in consumers' day-to-day lives. By the end of this year, IBM Watson will be available to more than a billion consumers of all kinds, helping them discover the right insurance options, make travel reservations, troubleshoot their IT, answer weather-related questions, get faster service from their bank, and more.  
",,Person,ash grey,robot,machine,motor,engine
,187446750783_10155394981980784,https://www.facebook.com/ibmwatson/posts/10155394981980784,"Did you miss our Facebook Live yesterday? Watch an instant recap of the full video where Rob High, IBM Fellow, VP and CTO for IBM Watson and Amy Webb, Professor of Strategic Foresight at NYU Stern School of Business and best-selling author and founder of Future Today Institute discussed AI for business professionals and a Q&amp;A.",SharedVideo,,,2/9/18 11:18, ,3808,3808,0,6676,6676,0,74,56,82,0,0,6204,3504,0,0,64,0,0,0,0,776,883,0,0,0,2574101,,22.0,2.0,,23.0,2.0,52,7.0,,,74,8.0,,,,,,,,,,,,joy,0.22248,positive,0.699569,"instant recap of the full video, IBM Fellow","Person, Person, Company, Organization, Company, Organization",instant recap of the full video,Person, , , , , , , , , , , , , , , , , , , , , , 
,187446750783_10155389186620784,https://www.facebook.com/ibmwatson/videos/10155389186620784/,"AI is top of mind for many business professionals and is on track to change the way we work and live. Join Rob High, IBM Fellow, VP and CTO for IBM Watson and Amy Webb, Professor of Strategic Foresight at NYU Stern School of Business and bestselling author and founder of Future Today Institute for a Facebook Live discussion on what business professionals need to know about AI and the potential it has to transform their business. 
To learn more, please visit: ibm.co/2AVXP7j
 
We look forward to an interesting discussion on AI for business. See you February 8th!",Video,,,2/8/18 11:03, ,158068,35765,119269,476465,62030,414435,3702,3108,4246,16,17,21056,9001,2735,728,813,379,398,86,86,10141,12710,71712,150335,12851,2574101,172,920.0,153.0,184,1186.0,256.0,1129,65.0,,2107.0,1523,76.0,,2646.0,2,12.0,3.0,2,11.0,3.0,,,,joy,0.693281,positive,0.829247,"Join Rob High, business professionals, IBM Fellow","Person, Person, Facility, Company, Person, Organization, Person",Join Rob High,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2B9aGE2,187446750783_10155389401290784,https://www.facebook.com/ibmwatson/posts/10155389401290784,Watson Conversation— helping businesses of all sizes build great chatbots. Learn how to get started. ,Link,,,2/7/18 10:06, ,7151,7151,0,12093,12093,0,149,96,127,4,4,10564,6252,0,0,132,0,0,0,0,0,0,0,0,0,0,21,64.0,2.0,23,64.0,2.0,46,62.0,,,60,67.0,,,2,2.0,,2,2.0,,"Learn how to build a chatbot. Whether you’re a developer looking to build your own chatbot or a business looking to implement one without needing to code from scratch, Watson can help.",https://1.cms.s81c.com/sites/default/files/2019-02-11/assistant_chatbot_static_leadspace_2800x1195_0.jpg,https://www.ibm.com/watson/how-to-build-a-chatbot,joy,0.465226,positive,0.95079,Watson Conversation,Person,Watson Conversation,Person,joy,0.241294,positive,0.784455,own chatbot,Person,own chatbot,Person,joy,0.166655,positive,0.669708,"Watson Assistant, step tutorial",Person,"                          Build, deploy, and optimize chatbots quickly and efficiently with Watson Assistant. Get started with 10,000 free API calls a month.                   
Chatbots use natural language recognition capabilities to discern the intent of what a user is saying, in order to respond to inquiries and requests. The problem is, most chatbots try to mimic human interactions, which can frustrate users when a misunderstanding arises. Watson Assistant is more.
Watson Assistant will determine whether to provide a direct answer or reference search results from a document or database.
Watson Assistant can live in an isolated cloud environment or on-premises, allowing you to build and scale.
Industry-leading AI powers the underlying natural language models and provides training recommendations as you build.
Watson Assistant is the industry leading conversational AI technology powering chatbots. Learn how Watson Assistant interacts and understands your questions in this banking demo.
Use this pattern to learn how to add features like a shopping cart, context store, and custom inventory search to your chatbot.
This app calls out to simple banking services code as an example of how to include external business data in a conversation response.
In this chatbot tutorial, create an artificial intelligence (AI)-powered, conversation based chatbot within Slack.
Learn how to build an Android-native, mobile customer service app that understands spoken requests and provides a response.
Watson Assistant comes packaged with Customer Care, Banking, Insurance, Telco, Utilities, and eCommerce content. For additional content, Watson Assistant integrates with outside domain knowledge artifacts. And of course, our chatbot API integrates with other Watson APIs.
Take a short tutorial of our bot technology, IBM Watson Assistant. You'll create intents and entities and learn how to structure your conversational flow.
Step-by-step tutorial on how to create a chatbot of yourself with Watson.
With Watson Assistant, integrating with other channels (Facebook, Slack, and Intercom) has never been easier.
Learn about the Watson Assistant plugin, which allows you to add your chatbot to your site.
",Watson Assistant,Person, , , , , 
https://ibm.co/2BWU4yW,187446750783_10155387219715784,https://www.facebook.com/ibmwatson/videos/10155387219715784/,"Learn how Accrete.AI is using AI to identify market-moving mergers, spot acquisition rumors, and track changes in sentiment by key topics mentioned in earnings calls, with greater accuracy. Register now to watch the video: ",Video,,,2/6/18 10:02, ,8752,8752,0,14421,14421,0,247,188,232,5,8,13235,8092,0,0,175,151,159,0,0,1855,1936,0,0,4510,40681,14,65.0,1.0,14,66.0,1.0,91,15.0,,95.0,106,17.0,,109.0,,8.0,,,5.0,,"Wednesday, February 07, 2018 at 01:00 PM Eastern Standard Time. ",,https://event.on24.com/wcc/r/1586926/8F4F9F762B3B8ACA69912F0A27826019?partnerref=Facebook,joy,0.694461,positive,0.468487,"spot acquisition rumors, track changes",Company,spot acquisition rumors,Company,joy,0.273364,neutral,0,Eastern Standard Time,,Eastern Standard Time,,joy,0.339762,neutral,0,,Person," Finding Alpha with AI
                               





















































Show Transcript Show Slide Text  

",,Person, , , , , 
,187446750783_10155384558900784,https://www.facebook.com/ibmwatson/posts/10155384558900784:0,"Have you RSVP'd yet for our Facebook Live this week? Be sure to join us this Thursday, February 8, at 2 p.m. ET as we discuss AI and what it means for the business world. We'll also be taking questions live from our Facebook audience for what is bound to be an interesting discussion with Watson CTO Rob High and Amy Webb, Professor of Strategic Foresight at NYU Stern School of Business, bestselling author and founder of Future Today Institute. RSVP: ibm.co/2AVXP7j",Photo,,,2/5/18 8:04, ,8844,8844,0,15799,15799,0,202,160,194,4,4,14735,8210,0,0,135,0,0,0,0,0,0,0,0,0,0,8,54.0,2.0,8,54.0,2.0,49,23.0,98.0,,61,23.0,110.0,,1,3.0,,1,3.0,,,,,joy,0.780065,positive,0.950601,"Facebook Live, Watson CTO Rob High","Company, Person, Person, Person, Organization, Person",Facebook Live,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2G3RIRX,187446750783_10155380553690784,https://www.facebook.com/ibmwatson/posts/10155380553690784,IBM Watson and Salesforce will double down on their relationship with AI – these two top tech firms connecting their artificial intelligence  platforms reinforces the growing value of AI and big data in the enterprise. ,Link,,,2/3/18 17:00, ,22605,22605,0,37874,37874,0,926,635,799,13,13,27293,16276,0,0,676,0,0,0,0,0,0,0,0,0,0,54,352.0,9.0,57,352.0,11.0,402,294.0,,,479,320.0,,,6,7.0,,6,7.0,,"The expanded partnership, focused on delivering deeper insights, will see each firm become a preferred provider for the other.",https://tr2.cbsistatic.com/hub/i/r/2018/01/19/8ad55407-aa17-48f7-b14f-fd468ab5a10d/thumbnail/770x578/fe82c6875bb7a84ae16cbe4faa220069/ibmsfceos.jpg,https://www.techrepublic.com/article/ibm-and-salesforce-double-down-on-ai-announce-watson-einstein-collaboration/,sadness,0.170555,neutral,0,"IBM Watson, top tech firms, artificial intelligence  platforms","Company, Company, Person",IBM Watson,Company,joy,0.344865,positive,0.724147,expanded partnership,,expanded partnership,,joy,0.157112,positive,0.683074,"Salesforce Quip, Watson services, power of IBM Cloud","Company, Company, Person, Person, Person, Person"," 	Building a slide deck, pitch, or presentation? Here are the big takeaways: 
 	Salesforce and IBM announced an expansion of their strategic partnership on Friday, with the firms combining the power of IBM Cloud and Watson services with Salesforce Quip and Salesforce Service Cloud Einstein, the firms announced in a joint  	press release Friday.
 	Two top tech firms like Salesforce and IBM connecting their artificial intelligence (AI) platforms reinforces the growing value of AI and big data in the enterprise. AI, especially, is taking center stage as one of the battleground technologies for business, and this is a clear example of two CEOs making a move to reinforce that with their partnership.
 	In the release, IBM CEO Ginni Rometty said that the combination of Watson and Einstein will ""help enterprises make smarter business decisions."" Salesforce CEO Marc Benioff echoed this sentiment, saying in the release that the combo will ""deliver even more innovation to empower companies to connect with their customers in a whole new way, leveraging the power of the cloud and AI.""
 	 	SEE: IT leader's guide to the future of artificial intelligence (Tech Pro Research)
 	Specifically, the Watson/Einstein combination will provide actionable next steps in a given process, the release said. This could potentially help users strengthen customer relationships, or automate more processes with custom-triggered actions based on how the AI interprets a recent call or chat experience.
 	In addition to the firms connecting their AI platforms, they will share preferred vendor status for one another in specific areas. For Salesforce, IBM will become a preferred cloud services provider and, for IBM, Salesforce will become a preferred customer engagement platform, the release said.
 	Another result of the partnership will be the development of some IBM Watson Quip Live Apps. With these apps, which can be embedded into a Quip document, users will have access to Watson's cognitive computing when working in the document creation and editing platform, the release said.
 	The expansion builds on a joint solutions partnership that was originally  	announced by the companies back in March 2017. Currently, the partnership serves more than 4,000 joint customers, the release said, including Autodesk.
 	""Combining the AI power of Watson and IBM Cloud with insights from Salesforce has helped Autodesk better understand its customers and ultimately create a transformed customer experience,"" Rachael Cotton, senior manager of machine assisted service engagement for Autodesk, said in the release.
",Salesforce Quip,Company,coal black,couple,person,couple,-
https://ibm.co/2BQvtMb,187446750783_10155377807380784,https://www.facebook.com/ibmwatson/posts/10155377807380784,"From social media to public service, some people are interacting with artificial intelligence every single day and it may surprise you how broadly it is being adopted. Here are some ways we’re already using AI on the daily via Mashable: ",Link,,,2/2/18 17:03, ,10772,10772,0,18590,18590,0,261,176,226,8,8,14869,8627,0,0,227,0,0,0,0,0,0,0,0,0,0,21,109.0,2.0,24,111.0,2.0,87,106.0,,,113,113.0,,,1,7.0,,1,7.0,,"AI may seem like a confusing phenomenon, but we often interact with artificial intelligence technology on a daily basis.",https://mondrian.mashable.com/2017%252F12%252F21%252F6b%252F3d312f1f63af4fc99a8ceb433c2e2ee9.dd1ec.jpg%252F1200x630.jpg?signature=kcqxN0T_UIzf3OptSIumYQrUYXs=,https://mashable.com/2018/01/17/ways-interact-artificial-intelligence/#TeGG1Rp9Ksq3,joy,0.38171,positive,0.839895,"social media, public service, artificial intelligence",Person,social media,Person,sadness,0.364451,positive,0.295635,"daily basis, confusing phenomenon",Person,daily basis,Person,joy,0.509032,positive,0.580654,artificial intelligence,"Person, Person, Person, Person, Company, Company, Person, Company, Person","If someone were to say to you that you’ve spent all day interacting with artificial intelligence, you’d probably stop and try to recount any instances of accidentally running into a robot. 
Despite what’s constantly being hammered into our brains via science fiction movies and television, AI comes in many forms, which may surprise you. Not only has artificial intelligence become integrated within a number of industries, but it’s teaching people how to streamline business and optimize their lives.
From social media to public service, some people are interacting with artificial intelligence every single day and it may surprise you how broadly it is being adopted. Here are some ways we’re already using AI on the daily. 
Sometimes the integration of artificial intelligence presents itself in a more obvious manner. Take virtual assistants, for example: Increasingly when you sign onto a website and are greeted with a chatbot, you’re more likely to interact with a computer-generated assistant and referred to a human only if your question is quite complex. You'll know pretty quickly whether it's a human or a robot, like how UBank's Robochat introduces itself.
UBank recently launched RoboChat, an IBM Watson-powered supercomputer that can answer questions about home loan applications. 
“In essence, we’re trying to make it as easy as we can for customers to do what some of them consider to be a cumbersome process,” said UBank’s head of digital Jeremy Hubbard, in an interview with The Australian. RoboChat is designed to answer questions relating to home loan applications through natural language processing – that means the bot can understand the intent of what you’re asking and carry a conversation like a human would. 
RoboChat is powered by IBM Watson, which is an artificial intelligence platform that ingests and comprehends massive amounts of data. For UBank, Watson provided the conversational capability. 
As far as one’s daily interactions with artificial intelligence, you get a front-row seat to the simplicity of AI every time you speak to a virtual assistant. 
Whenever you ask your phone for directions, order paper towels from a virtual assistant, or give any non-human entity a command, you’re speaking to a device powered by AI. Virtual assistants use natural language processing (NLP) to understand what you say to then provide a response to your query.
Social media is another platform that benefits from the ever-expanding brain of artificial intelligence — Twitter recently brought Watson on board to help prevent abuse by tracking problematic accounts. 
""Watson is really good at understanding nuances in language and intention,” said vice president of data strategy at Twitter Chris Moody, in an interview with The Telegraph, ""What we want to do is be able to identify abuse patterns early and stop this behaviour before it starts."" The technology scans accounts engaged in abusive behaviour by seeking out certain harmful keywords from users and applying an understanding of the context in which they are written.  
Another area where AI has made its way into our everyday lives? Transportation. Ride-share companies utilize AI to improve the function and precision of their apps. Machine learning helps provide ETAs for arrivals using data from millions of past trips — in addition to things like distance and speed limit — to provide estimated arrival times. 
Although it may seem like a natural fit for a tech company to use artificial intelligence, there are even more surprising ways AI impacts our lives that we may not realize. Take your evening glass of wine, for example. AI has found its way into one New Jersey vineyard and streamlined the way grapes are grown.
E. & J. Gallo Winery recently looked to Watson to develop an intelligent irrigation system. Watson monitors weather reports and uses remote sensor data to measure and distribute the optimal amount of water that each grapevine needs to survive and flourish. By mining data from sources like The Weather Company, which has data from over two billion locations, E. & J. Gallo Winery has developed a custom irrigation plan that’s allowed them to reduce water usage by 25 percent.
While the prospect of an AI-engrained life may seem a bit intimidating, it’s humans who are really in control. In fact, humans often supervise artificial intelligence processes, which is the case with “Deep Learning.”
Deep learning is a computation model that can interpret and make sense of information in ways that previously were not possible with traditional computing. In a way, it learns like a human does, taking on feedback and adjusting to improve. 
Although deep learning allows machines to learn like humans, they do not have the ability of human judgement. No matter how much data you present to a deep learning model, it is not able to reason and judge what is happening on its own. Rather, it requires humans to oversee and draw conclusions from the AI processes.
“Deep learning has been successful for well-defined kinds of problems where there’s lots of labelled data, and it’s good at perception and classification problems rather than real reasoning problems,” said IBM Distinguished Researcher Murray Campbell. “The next big opportunity is to do for reasoning what deep learning did for perception and classification.”
So, what will a machine be able to do with the type of skills associated with deep learning? Researchers hope that they’ll be able to solve problems that involve human traits like common sense.
“Humans know that if you put an object on the table, it’s likely to stay on the table unless the table’s tilted,” explained IBM Director of AI and Cognitive Analytics Research Aya Soffer.
“But nobody writes that in a book — it’s something implicit. Systems don’t have this common-sense capability.”
The AI landscape is constantly changing and improving. Because of the strides IBM has made with Watson, the current state of artificial intelligence is one that is as equally impressive as it is necessary. We’ve already grown so dependant on artificial intelligence to give us directions, provide public service, help us with taxes, and keep us safe in the air.
Some may find that a day with artificial intelligence is virtually indistinguishable from a day without it, others couldn’t imagine going to work without Watson’s intuitive brain. What AI’s touch will look like 50 years from now is anyone’s guess.
",artificial intelligence,Person,emerald,shower room,indoors,shower room,-
,187446750783_10155374692180784,https://www.facebook.com/ibmwatson/posts/10155374692180784:0,"We're just one week away from our first-ever Facebook Live! We hope you can join us Thursday, February 8th at 2 p.m. ET, as we dive into what business professionals need to know about AI. We'll be joined by Rob High, IBM Fellow, VP and Chief Technology Officer for IBM Watson and Amy Webb, Professor of Strategic Foresight at NYU Stern School of Business and bestselling author and founder of Future Today Institute. RSVP to let us know you're attending: ibm.co/2AVXP7j",Photo,,,2/1/18 11:06, ,11169,11169,0,18593,18593,0,293,177,229,7,7,15889,9367,0,0,224,0,0,0,0,0,0,0,0,0,0,22,123.0,7.0,22,123.0,7.0,108,28.0,65.0,,125,32.0,72.0,,2,5.0,,2,5.0,,,,,joy,0.233309,positive,0.584583,"Chief Technology Officer, IBM Fellow, Rob High","Person, Quantity, Person, Company, Facility, Company, Person, Person, Organization",Chief Technology Officer,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2qz1WpQ,187446750783_10155372342795784,https://www.facebook.com/ibmwatson/posts/10155372342795784,"By 2025, there will be 1 trillion gigabytes of global data, and most of it is in the form of text, documents, call logs, social media posts, research papers, feedback comments and more.

The best way to seek real insight in all this information? Artificial intelligence. ",Link,,,1/31/18 10:50, ,1090,1090,0,1816,1816,0,30,11,15,0,0,1568,940,0,0,26,0,0,0,0,0,0,0,0,0,0,4,16.0,1.0,4,16.0,1.0,6,7.0,,,8,7.0,,,,,,,,,"Most of the world's data is unstructured. IDC forecasts that by 2025 the global datasphere will grow to 163 zettabytes. That's a trillion gigabytes, and most...",https://i.ytimg.com/vi/LFl_1uKiADk/maxresdefault.jpg,https://www.youtube.com/watch?v=LFl_1uKiADk&t=3s,joy,0.182536,positive,0.594551,"gigabytes of global data, research papers",Quantity,gigabytes of global data,Quantity,joy,0.642031,positive,0.384185,"global datasphere, world's data, IDC","Company, Quantity",global datasphere,Company,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                                              
            

",YouTube,Company,coal black,call center,building,call center,-
https://ibm.co/2GuIi27,187446750783_10155370852220784,https://www.facebook.com/ibmwatson/videos/10155370852220784/,"Start the week with unparalleled education in machine learning and AI, end it with entertainment featuring Train, The Chainsmokers and Barenaked Ladies. This is THINK 2018. Join Watson in Las Vegas on March 19-22. Register now: ",Video,,,1/30/18 20:12, ,1362,1362,0,2347,2347,0,74,65,78,1,1,2110,1178,0,0,56,85,85,0,0,383,420,0,0,5120,16988,2,12.0,1.0,2,13.0,1.0,25,6.0,,40.0,27,7.0,,44.0,1,,,1,,,"The digital-first IBM business and technology event will take place May 5â7, 2020. Learn about the latest advancements in open technologies from hybrid multicloud to data and AI and interact with luminaries who are using them to transform our lives.Â ",https://www.ibm.com/events/shared/img/think2020/think-og2.jpg,https://www.ibm.com/events/think/?cm_mmc=OSocial_Facebook-_-xIBM+Events_Global+Conferences-_-WW_WW-_-fbWatsonCore&cm_mmca1=000021TD&cm_mmca2=10001376&,joy,0.279877,positive,0.500997,"machine learning, unparalleled education, Join Watson","Organization, Person, Organization",machine learning,Organization,joy,0.359078,positive,0.94015,"digital-first IBM business, latest advancements","Company, Person",digital-first IBM business,Company,joy,0.557024,positive,0.810422,,"Company, Person, Company, Person","Since becoming CEO in January 2012, Ginni has led IBM through the most significant transformation in its history, reinventing the company to lead in the new era of AI, blockchain, cybersecurity and quantum technologies, all delivered on IBM’s enterprise-strength cloud platform. Today, IBM is the world leader in AI and cloud computing for business, underpinned with trust and security.
IBM’s commitment to diversity and inclusion also has advanced under Ginni’s leadership. This includes extending parental leave and making it easier for women to return to the workforce through a “returnships” program with hands-on work experience in emerging technologies. This pioneering work was recognized in 2018 by the prestigious Catalyst Award for advancing diversity and women’s initiatives. IBM is the only tech company to have earned this recognition in the last 20 years and the only company ever to be honored four times.
Arvind Krishna leads the IBM business unit that provides the cloud and data platforms on which the company’s clients build the future. His responsibilities include IBM Research, IBM Cloud, IBM Data and AI, and IBM’s Security and Cognitive Applications businesses. He also drove the company’s 2019 acquisition of Red Hat.
Arvind leads the unit’s strategy, product design, offering development, marketing, sales and service. He also guides IBM’s overall strategy in technologies including artificial intelligence, quantum computing, blockchain, cloud platform services, data-driven solutions, and nanotechnology.
Jim Whitehurst is president and chief executive officer of Red Hat, the world’s leading provider of open source enterprise IT software solutions and services. An avid advocate for open software as a catalyst for business innovation, Whitehurst has proven expertise in helping companies flourish—even in the most challenging economic and business environments.
Whitehurst has grown Red Hat and its influence by reaching key milestones—most notably in 2012, when Red Hat became the first US$1 billion open source software company. Company revenue reached almost US$3 billion in 2018.
In 2015, Whitehurst published The Open Organization: Igniting Passion and Performance, a book that shows how open management principles can help organizations succeed in a fast-paced, connected era.
Amal Clooney is a barrister who specializes in international law and human rights. Through international courts, she frequently represents political prisoners, journalists and victims of mass atrocities.
Ms Clooney served as a Sr. Advisor to Kofi Annan. She was appointed to the UK’s panel of experts on combatting sexual violence and to a panel on public international law. She was also appointed as the UK’s Special Envoy for Media Freedom by the UK Foreign Secretary and she serves as vice-chair of a High-Level Panel of Legal Experts on Media Freedom.
Ms Clooney is a Visiting Professor at Columbia Law School, where she co-teaches the Human Rights course, and she is co-author of a forthcoming book titled ‘The Right to a Fair Trial in International Law’ to be published in 2020.
Mayim Bialik is known for her role on the hit CBS comedy, The Big Bang Theory as Amy Farrah Fowler, for which she has received two Critics Choice Awards, four Emmy Award nominations and a SAG Award nomination. Bialik has appeared in numerous beloved roles throughout her dynamic acting career.
An acclaimed author, Bialik has written two #1 New York Times bestsellers, Girling Up: How to Be Strong, Smart and Spectacular, and the recently released Boying Up: How to Be Brave, Bold and Brilliant. She has also written a parenting book, Beyond the Sling, and a cookbook, Mayim’s Vegan Table. Bialik has recently dedicated her skills as a writer, actress, neuroscientist and mother to driving the lifestyle website GrokNation.com, which she started.
",,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2BAzl3K,187446750783_10155366590870784,https://www.facebook.com/ibmwatson/posts/10155366590870784,"By applying AI to the data privacy domain, Thomson Reuters is offering legal professionals a deeper understanding of the law and what their data privacy obligations are across multiple global jurisdictions. Learn more about how Thomson Reuters and IBM are bringing AI to data privacy professionals: ",Link,,,1/29/18 9:12, ,6463,6463,0,11545,11545,0,107,55,76,2,2,10616,6011,0,0,99,0,0,0,0,0,0,0,0,0,0,13,56.0,,13,56.0,,31,26.0,,,41,35.0,,,1,1.0,,1,1.0,,"Thomson Reuters and IBM created an AI-powered feature, Ask Watson a Question, which is embedded into Thomson Reuters Data Privacy Advisor solution.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/01/GettyImages-961226836.jpg,https://www.ibm.com/blogs/watson/2018/01/thomson-reuters-ibm-bringing-ai-legal-professionals/,joy,0.142368,positive,0.720693,"Thomson Reuters, legal professionals, data privacy domain","Company, Person",Thomson Reuters,Company,joy,0.10228,neutral,0,Thomson Reuters,"Company, Company",Thomson Reuters,Company,joy,0.510755,positive,0.640968,"data privacy requirements, Question feature","Quantity, Company, Organization, Company, Organization, Person, Location, Organization, Organization, Person","In today’s world, data is the new basis of competitive advantage – and businesses are paying close attention to how they use their data, especially highly-regulated customer information. While the goal is to extract insights and knowledge for better decision making, organizations must also ensure they are abiding by the legal and data privacy requirements. This process can be time-intensive for legal professionals, who must stay on top of ever-changing laws, often across multiple global jurisdictions. And there is a lot at stake, with noncompliance resulting in increasingly higher fines and substantial risk to a business’ reputation.
In the US alone, there are more than 70 government authorities with a legal point of view on data privacy, from states and state agencies, to congress and federal agencies, including the US Attorney General, Department of Justice and the Securities and Exchange Commission. On a global scale, complying with these regulations is becoming more complex, especially with the General Data Protection Regulation (GDPR) coming into effect in the EU later this year. A recent study found that 44% of data privacy professionals claim to already be failing to comply with data privacy regulations.
By applying AI to the data privacy domain, we’re offering legal professionals a deeper understanding of the law and what their data privacy obligations are across multiple global jurisdictions. For example, if a global organization is collecting sales data on customers in four countries, its data privacy team needs to understand specific requirements – like how to store that data, and how long it can be retained – across every national and local jurisdiction where they do business. The team would need to compare competing jurisdictions and find the right information to include to develop a compliant policy.
With the Ask Watson a Question feature in Data Privacy Advisor, a professional can pose natural language questions like “Does Australian law require regulator notification of a data breach?” or “What is the best practice for retaining employee data records?” rather than searching in legal or technical terms. Since the question-answering feature was jointly trained by IBM Watson and Thomson Reuters research scientists and industry professionals including researchers, lawyers and data privacy professionals, it can go beyond simply responding to queries, providing valuable recommendations and insights.
Watson technology is uniquely suited for understanding complex unstructured information such as regulatory requirements. The feature works by delivering a specific answer to questions, supported by relevant documents like statutes, government agency materials, and secondary sources like Corporate Counsel’s Guide to Privacy– rather than simply serving up documents related to keyword search terms. It can also return results that may be related to the search that the professional had not yet considered – such as how a pending law might impact legal obligations.
As the data privacy space evolves, organizations will continue to apply a critical eye to their data practices, ensuring that they are protecting customer privacy and adhering to government regulations. Understanding the complex web of new data privacy regulations – like GDPR – will be a critical component of the data privacy professional’s role. Tools like Data Privacy Advisor can help them achieve this mission, acting as a trusted advisor and empowering professionals to be more efficient while making informed decisions.
",data privacy requirements,Quantity,sage green,person,building,office,-
,187446750783_10155362655450784,https://www.facebook.com/ibmwatson/posts/10155362655450784,IBM Watson,Photo,,,1/27/18 18:14, ,2096,2096,0,3562,3562,0,34,20,27,1,1,3368,1948,0,0,32,0,0,0,0,0,0,0,0,0,0,,16.0,,6,16.0,,16,3.0,3.0,,21,3.0,3.0,,1,,,1,,,,,,anger,0.038377,neutral,0,,Company,,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2CH8kgJ,187446750783_10155358777605784,https://www.facebook.com/ibmwatson/posts/10155358777605784,3 popular types of chatbots companies are building to enhance customer experience: ,Link,,,1/26/18 12:16, ,7763,7763,0,13309,13309,0,182,111,126,4,4,11351,6541,0,0,161,0,0,0,0,0,0,0,0,0,0,25,72.0,2.0,26,75.0,2.0,33,83.0,,,38,88.0,,,1,3.0,,1,3.0,,"As chatbots continue to gain popularity, our latest blog highlights the three types of business chatbots you can build to better reach and target customers.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/12/Conversation_service_Social1200x628-1.png,https://www.ibm.com/blogs/watson/2017/12/3-types-of-business-chatbots-you-can-build/,joy,0.075351,positive,0.752174,"popular types of chatbots companies, customer experience",,popular types of chatbots companies,,joy,0.425058,positive,0.725044,"types of business chatbots, latest blog",,types of business chatbots,,sadness,0.539365,positive,0.560402,single-turn type bots,"Person, Company","Key Points:
 From a business perspective, here are the 3 most common chatbots that are being built:
 – Support chatbots that are built to master a single domain
 – Skills chatbots that are single-turn type bots that do not require a lot of contextual awareness
 – Assistant chatbots that are the middle ground between a support and skills chatbot, knowing a little bit about a variety of topics
A few years ago when chatbots were just gaining popularity, there was a lot of talk around what a chatbot actually was. With the advent of natural language processing and various machine learning techniques, some of the more advanced conversational applications wanted to separate themselves from their competition. Many began calling themselves “virtual assistants.” This implied that they were somehow bigger or more powerful than existing chatbots, or perhaps were more conversational or could cover a wider range of topics.
However, we quickly discovered that the market did not care how powerful the bot was or about the underlying technology, so long as it solved the right problems. So in a way, many of these different terms for bots became more or less synonymous with each other. It didn’t matter what you called it – you were getting something you could hold a conversation with. We’re now at a point where we know that regardless of what you call the bot, there are usage patterns and differentiation that make chatbots distinct.
When you’ve done your research and are at the point of beginning to build your bot, think carefully about what problems you’re trying to solve and what functionalities you will want to incorporate. Knowing what you want your application to solve for and assist with will decide the type of chatbot, virtual assistant or agent you ought to build. This will impact both your development plan and, as importantly, your end-user experience. The following are the three main types of chatbots I have come across, with background on their particular uses and variations.
Support chatbots are built to master a single domain, like knowledge about a company. Support chatbots need to have personality, multi-turn capability, and context awareness. They should be able to walk a user through any major business processes, and answer a wide range of FAQ-type questions. You will want to have a short-tail and long-tail combo solution when building this type of chatbot. At IBM Watson, we would use the Watson Conversation service for the short-tail, common questions and processes, and Watson Discovery service for the long-tail, but there are many potential solutions for this. Speech is an optional feature, and not a necessity, since users typically have sat down at a desktop and are ready to figure out their solution. The chatbot developer will want to spend the most time making sure it is as easy as possible to navigate the bot, and ensuring it can execute the actions that your users actually care about (for example, just because you want to sell more credit cards doesn’t mean your customers want to open more credit card accounts).
Skills chatbots are typically more single-turn-type bots that do not require a lot of contextual awareness. They have set commands that are intended to make life easier: “Turn on my living room lights,” for example. Speech functionality is recommended for this type of chatbot so the user does not need to turn on a device or click any buttons. They should be able to follow commands quickly, so that your users can multitask while engaging with the bot. These chatbots do not need to worry too much about contextual awareness, unless you want to design a particularly advanced one, as people will quickly learn what to say, and say it appropriately. It’s a nice bonus if you can give a command, and your bot knows – to return to our example – that you are in the kitchen and acts to turn on the correct lights.
However, this is not a necessary function, as users will quickly learn to give the appropriately specific command. When building a skills bot, it is important to focus on integration, especially when controlling a home or personalized objects. Keep integration simple so your users can interact with the bot without worrying about how to use .
Assistant chatbots are more or less a middle ground between the two bots above. They work best when they know a little bit about a variety of topics. Many people envision these bots will someday become navigators of all other bots that are out there now. Want to pay a bill? Ask your assistant bot to talk to the support bot for your bank. Assistant chatbots need to be conversational and respond to just about anything, while being as entertaining as possible. Siri is a good, current example – while she only does so much, people continually ask her for things simply because even when she cannot perform the command, the response she gives tends to be amusing. When building an assistant chatbot, it is important to make it as obvious as possible how the bot is trained. The range of questions a user might ask is large, so making sure you have adequate coverage is going to be the most difficult factor. In many cases, when people do not know what they should ask, they will not ask anything at all. And if you miss the few topics they initially are willing to try, they will not come back for more.
Even though these are the most common types, many bots in production fall somewhere in between two. Some are even a combination of all three. No matter what type of bot you decide to build, it is important to give your bot some life and personality, make it useful, and make sure it’s easy to use. People interact with bots because they want to get something done in a more natural way than was previously possible. Whether it’s something simple like turning on a light, or something complex like applying for a mortgage, every pattern has specific features that make it stand out, so be sure your bot shines brightly in what it’s designed to do. The possibilities are endless.
",single-turn type bots,Person,blue,razor,tool,cutlery,razor
https://ibm.co/2Dt8t8t,187446750783_10155355582730784,https://www.facebook.com/ibmwatson/posts/10155355582730784,"Meet Olli, the 3D-printed, AI-powered self-driving bus designed by people with impairments, for people with impairments: ",Link,,,1/25/18 7:49, ,5161,5161,0,9267,9267,0,86,41,47,0,0,8319,4523,0,0,77,0,0,0,0,0,0,0,0,0,0,17,49.0,,18,51.0,,18,25.0,,,19,28.0,,,,,,,,,#AccessibleOlli was a hit at CES2018 with it’s a mission: autonomous for all of us. Learn how this self-driving shuttle creates mobility for the disabled.,https://www.ibm.com/blogs/internet-of-things/wp-content/uploads/2018/01/Facebookaccessibleolli.jpg,https://www.ibm.com/blogs/internet-of-things/iot-accessibleolli-drives-us-forward-at-ces/,joy,0.533961,negative,-0.834361,"Meet Olli, 3D",Person,Meet Olli,Person,joy,0.275864,positive,0.61906,CES2018,Hashtag,CES2018,Hashtag,joy,0.576078,positive,0.579883,,Hashtag,"Share this post:
Did you know that 15 percent of us live with disabilities? That jumps to 25 percent for people 50+. And by the time we’re 65, half of us will have one or more impairments.
That’s why #AccessibleOlli was such a draw at this year’s CES with it’s very worthy mission: autonomous for all of us.
If you aren’t familiar with Olli, it’s an all-electric, partially 3D-printed, self-driving vehicle with a cognitive rider experience. Holding up to 10 people, this autonomous shuttle is the result of a co-creation challenge and rapid prototyping. Taking it a step further with a collaboration between Local Motors, IBM and CTA foundation and 17 other partners, #AccessibleOlli was created. This #AccessibleOlli is 90 percent 3D-printed, and uses technology to provide solutions for those with vision and hearing loss, cognitive disorders and mobile constraints.
 #AccessibleOlli on the Las Vegas Convention Center floor at this year’s CES.
The always-packed CES booth gave visitors an immersive #AccessibleOlli experience to help them, as someone said, “put on their empathy hat.” Because, as Eric Jenney, program director of corporate strategy, SPEED program for IBM, explained, “One of the things we learned early on is that transportation can be a very segregating experience for people with disabilities.”
Attendees met and talked with Erich Manser, part of the IBM Research team. Erich is legally blind, and serves as one of the four personas that #AccessibleOlli can help. He’s also a heavy user of public transportation. And under normal circumstances, finding an unoccupied bus seat can be a problem. But part of the beauty of #AccessibleOlli is its ability to personalize the experience for each user.
 IBMer Erich Manser set the immersive stage for visitors to the #AccessibleOlli booth.
Thanks to an RFID card, similar to a bus pass or metro card, that a user like Erich would carry, riders are “known” in advance to the vehicle. Then, as Erich explained, “Our ability to use things like text to speech, really helps to create audible experiences.”
As all well-designed product do, #AccessibleOlli started with research. Thousands of people with disabilities provided input. Sheila Zinck, IBM accessibility programs director, talked to retirement communities to find out how willing its residents would be to try autonomous transportation.
Concerned that older adults would be resistant to self-driving technology, Shelia was surprised to discover just how willing they were to be early adopters. “You can be in the most beautiful facility in the world, but if you don’t have the agency to easily go out and go shopping, or go to your own doctor’s appointments or go out to dinner, your life just contracts.”
So why is IBM involved in this project? Because the Internet of Things (IoT) offers promising ways to enable people with disabilities through new technology. Olli uses Watson APIs and a Watson-powered assistant, along with IBM IoT for Automotive. And with IoT, you can acquire data through sensors to understand people’s needs. Then you can combine it with additional information through the cloud to create new solutions for extending mobility.
At this year’s CES, the #AccessibleOlli display focused on four disabilities, and each was summarized through a persona:
What’s next for #AccessibleOlli?
After CES, the journey continues, literally.  #AccessibleOlli will be moved to National Harbor, MD, near Washington DC, where it will continue to be a lab, integrating new technologies through ongoing labs and workshops. Along with our partners and contributors, we’ll all continue to build out solutions.
Thank you, #AccessibleOlli, for creating a true “autonomous for all of us” experience. And in the words of our special booth attendee, the musical legend Stevie Wonder, “We all have ability. The difference is in how we use it.”
 IBMer Eric Jenney and Local motors EVP, Matthew Rivett, posed with musical legend Stevie Wonder,
 who made a surprise visit to the #AccessibleOlli booth at CES 2018. 
",,Hashtag,maroon,minibus, , , 
http://ibm.co/2nndb0Q via TechRepublic,187446750783_10155353998930784,https://www.facebook.com/ibmwatson/posts/10155353998930784,"10 practical scenarios in which IBM is using AI to enhance human capabilities – including automatically creating movie trailers, understanding image content and analyzing PDFs: ",Link,,,1/24/18 17:10, ,1550,1550,0,2414,2414,0,35,26,31,0,0,2138,1347,0,0,30,0,0,0,0,0,0,0,0,0,0,3,11.0,,3,11.0,,8,19.0,,,11,20.0,,,,,,,,,For more than a century IBM has been dedicated to every client's success and to creating innovations that matter for the world,,https://www.ibm.com/us-en/?ar=1,joy,0.14297,neutral,0,practical scenarios,Company,practical scenarios,Company,joy,0.856488,positive,0.979896,"century IBM, client's success",Company,century IBM,Company,joy,0.844333,positive,0.835611,IBM POWER9,"Company, Quantity, Person","Celebrate Women’s History Month with IBMers who are changing the world and inspiring the next generation
From chatbots to drug discovery, these IBMers push the frontiers of AI
 									Meet the women inspiring a new generation of researchers → 								
World’s most powerful supercomputer identifies 77 promising drug compounds
 									Learn how IBM POWER9 is accelerating the search for a cure → 								
A big network outage welcomed her to IBM. She helped it run at 100% since.
 									Find out about this VP, transformation agent and soccer mom → 								
IBM has laid the foundation for a new era of technology and business
 									Read about a year  of growth — and plans for the future → 								
Accelerate your journey to AI with a cloud‑native data platform
Build AI solutions to find relevant answers in complex data
Try IBM Z mainframe software capabilities with no installation required
Create, move and deploy your Java applications on the cloud in minutes
How would you use technology to take on climate change?
How would you use technology to take on climate change?
Get help today for the IBM services and software you own →
Explore technical topics, find trial software and join the community →
",IBM POWER9,Company, , , , , 
https://ibm.co/2AVXP7j,187446750783_10155351555710784,https://www.facebook.com/ibmwatson/posts/10155351555710784:0,"Have you RSVP’d for our first-ever Facebook Live? Don’t miss out on Thursday, Feb. 8th as we dive into the what business professionals need to know about AI. Let us know in the event comment section if you have any questions you’d like us to ask our presenters Rob High and Amy Webb. ",Photo,,,1/23/18 20:00, ,3225,3225,0,7183,7183,0,111,72,97,1,1,6628,2859,0,0,89,0,0,0,0,0,0,0,0,0,0,8,36.0,1.0,9,43.0,1.0,27,15.0,35.0,,36,16.0,45.0,,1,,,1,,,,,https://www.facebook.com/events/320911045073672/,sadness,0.291747,negative,-0.372277,"event comment section, business professionals","Company, Person, Person",event comment section,Company, , , , , , , , ,joy,0.279286,neutral,0,Business Professionals,"Company, Person","What Business Professionals Need to know about AI: Facebook Live
Press alt + / to open this menu
Do you want to join Facebook?
What Business Professionals Need to know about AI: Facebook Live
",Business Professionals,Company, , , , , 
https://ibm.co/2x7dX4O,187446750783_10155348832270784,https://www.facebook.com/ibmwatson/posts/10155348832270784,What is the future of #AI-powered chatbots? IBM Watson CTO Rob High shares insights and challenges that lie ahead: ,Link,,,1/22/18 20:00, ,9190,9190,0,16157,16157,0,228,160,186,8,8,14299,8260,0,0,197,0,0,0,0,0,0,0,0,0,0,23,88.0,1.0,23,91.0,1.0,55,113.0,,,65,121.0,,,5,3.0,,5,3.0,,"IBM Watson's CTO describes the opportunities, prospects and challenges that lie ahead for artificial intelligence–powered chatbots",https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2018/04/rob-high-featured-783401625-1523288006792.jpg?fit=2574%2C1647&ssl=1,https://bdtechtalks.com/2017/08/21/rob-high-ibm-watson-cto-artificial-intelligence-chatbots/,joy,0.058719,negative,-0.286086,,"Hashtag, Person, Company",,Hashtag,sadness,0.083853,neutral,0,"IBM Watson's CTO, artificial intelligence","Company, Company",IBM Watson's CTO,Company,joy,0.561325,positive,0.67706,,"Person, Company, Person, Company, Person, Person","Since their first appearance decades ago, chatbots have come a long way thanks to leaps in natural language processing and generation (NLP/NLG), the branches of artificial intelligence that enable us to interact with computers in a conversational manner. Today AI-powered chatbots have established a prominent role in various fields, including customer service, healthcare, banking and more.
Meanwhile, the technologies that power chatbot assistants are growing smarter and more efficient. I had a chance to talk with Rob High, Chief Technology Officer at IBM Watson, on the evolution of chatbots and where the trend is leading to. He shared some very interesting insights on the prospects and challenges that lie ahead.
The next step in chatbot evolution
In a TC Disrupt presentation last year, the cofounder and CEO of Viv Dig Kittlaus, showed that chatbots no longer need to be explicitly commanded to do things. They have evolved to the point where they can discern the meaning of queries by correlating different elements using knowledge graphs.
While this is a huge upgrade from the rudimentary chatbots of old, High says there’s still room for improvement. “The next step in development will crack the uniquely human nature of communication,” he says. “We are going to see a transition from simple command response scenarios where essentially everything is centered around a single turn, moving into deeper conversations. The purpose is to get beyond the surface level utterance to the real issue at hand.”
Most conversation agents are becoming adept at understanding and responding to variations of queries. But those entries usually hide deeper meanings, requests and problems that AI engines need to understand and address.
“For example, when somebody asks what’s my balance, that’s actually not their problem. Their real problem is they are trying to figure out how to buy something, pay a bill or save for their kid’s education. There’s something bigger behind that question,” High explains. “This where we are going to see a major shift in value from what we are seeing today to where this could really go. To get to those deeper issues, AI and cognitive systems have to be able to reason deeply about the nature of the problem that’s being presented in questions or in the conversation.”
Reflecting on High’s comments, I can see a number of fields that can benefit immensely from such developments. Education, where AI is steadily making progress, is one of them. AI-powered chatbots are helping provide personalized content and assistance to students. However, a confused learner often doesn’t even ask the right questions. An AI assistant should be able to find the real cause of misunderstanding and confusion hidden deep within its interaction with users and steer them in the right direction as a human teacher would.
IBM Watson is exploring deep understanding with Floral gift retailer 1-800-Flowers. Watson powers the company’s chatbot GWYN (Gifts When You Need) and helps it detect user tone. GWYN interacts with online customers using natural language and is designed to understand human intention behind each purchase by interpreting and asking several questions. “Through this process, GWYN goes beyond acting merely as an automated tool,” High says.
Earlier this year, in an MIT Technology Review op-ed, Liesl Yearsley, the former CEO of Cognea, an AI company that was acquired by IBM Watson in 2014, revealed that, contrary to general perception, people are more inclined to form relationships and share information with chatbots than they are with other humans.
In the same article, Yeasley warned about the influence that even today’s simple AI agents can have on users, an effect that can become stronger as AI continues to advance.
“As enterprises deploy these conversation agents that have a more direct and personal bearing on the end user, it’s important that these organizations take responsibility for protecting the data that is being presented, maintaining privacy of that person and looking out for their best interests to ensure the user is not unnecessarily revealing details that are not relevant to the problem they are trying to solve,” High said when I asked him how he views the threats that loom ahead as these conversational agents become more ingrained in services and applications that run critical operations.
High also pointed out that companies should be transparent about whether the agent is interacting with is human or AI. “Not just so the end user has that clarity but more specifically to reinforce the importance that the user reveal themselves only in a way that they feel comfortable,” he said.
This is an important point as AI agents become more and more adept at mimicking human behavior. Last year, an AI teaching assistant powered by IBM Watson helped moderate an online forum for a computer science class at Georgia Tech University, and most students didn’t find out they were interacting with AI.
“We have to be very mindful of the uncanny valley and at the same time reinforce we should never attempt to fool the end user into thinking that what they are dealing with is a real person on the other end,” High says. “Avatars will surface in different forms, some more pseudorealistic than others – and those that are pseudorealistic can be quite beneficial under certain circumstances.”
IBM Watson did a pilot with the Australian government around Nadia, a virtual assistant platform that helps disabled people get information about government services.
“One of things we discovered is that people who have hearing impairments are actually able to lip-read the avatar and that was a great benefit for them,” High says.
“It’s very clear that for us to fulfill the objective we have for cognitive computers in amplifying human cognition they’re going to have to have a way of interacting with us that is activating our own imagination and our ability to create ideas,” High says. “That will in turn require that we employ mechanisms for humans to feel more natural – more in tune with the way we naturally communicate with each other as human beings.”
Finally, High laid out three rules that developers must adhere to in order to make sure we can reap the benefits of AI-powered chatbots and artificial intelligence in general:
Chatbots as a concept is going to evolve and become meaningful. They will create more opportunities for new companies to explode from nothing into prominence. They will create many new business strategy opportunities. In my opinion, they will play a large role in online business but not every role.
",,Person,greenishness,sociologist,person,sociologist,-
https://ibm.co/2zBV7TA,187446750783_10155345408400784,https://www.facebook.com/ibmwatson/posts/10155345408400784,"“How do I turn on my rear defroster?” Questions that once required consulting a car manual no more – introducing Ask Mercedes, the new virtual assistant powered by Watson. ",Link,,,1/21/18 15:49, ,14499,14499,0,24717,24717,0,334,216,323,6,6,20719,12258,0,0,290,0,0,0,0,0,0,0,0,0,0,33,144.0,12.0,40,149.0,23.0,134,94.0,,,224,99.0,,,,6.0,,,6.0,,"“How do I turn on my rear defroster?” and “What type of fuel does this car need?” are the kinds of questions that can send new car owners diving into glovebox for the car manual. Or, they simply start pressing random buttons, hoping for the best. Those days, however, may be over. Daimler AG and IBM have jointly developed the virtual assistant, “Ask Mercedes,” based on IBM Watson conversational technology and the IBM Cloud. The chatbot helps drivers get immediate responses to questions about their cars. From December on available in South Africa and Malaysia (India and Hongkong following in 2018) in the E- and S-Class, the intelligent chatbot Ask Mercedes leaves (almost) no questions about the functionalities of these vehicles unanswered. Ask Mercedes is designed to help not only Mercedes owners – who are getting behind the wheel of increasingly feature-rich vehicles – but also users of car sharing or rental services who may be particularly unfamiliar with newer updates. Ask Mercedes can either…",https://www.ibm.com/blogs/think/wp-content/uploads/2017/11/ibm-mercedes-app-800.jpg,https://www.ibm.com/blogs/think/2017/11/end-of-the-car-manual/,fear,0.10553,neutral,0,"Questions, Ask Mercedes",Person,Questions,Person,joy,0.528373,positive,0.626421,"intelligent chatbot Ask, South Africa, S-Class","Company, Company",intelligent chatbot Ask,Company,joy,0.508104,positive,0.807184,intelligent chatbot Ask,"Company, Company, Company, Person, Company, Company, Location, Location","Share this post:
“How do I turn on my rear defroster?” and “What type of fuel does this car need?” are the kinds of questions that can send new car owners diving into glovebox for the car manual. Or, they simply start pressing random buttons, hoping for the best. Those days, however, may be over.
Daimler AG and IBM have jointly developed the virtual assistant, “Ask Mercedes,” based on IBM Watson conversational technology and the IBM Cloud. The chatbot helps drivers get immediate responses to questions about their cars. From December on available in South Africa and Malaysia (India and Hongkong following in 2018) in the E- and S-Class, the intelligent chatbot Ask Mercedes leaves (almost) no questions about the functionalities of these vehicles unanswered.
Ask Mercedes is designed to help not only Mercedes owners – who are getting behind the wheel of increasingly feature-rich vehicles – but also users of car sharing or rental services who may be particularly unfamiliar with newer updates. Ask Mercedes can either be downloaded as an app or accessed via Facebook and other messenger services, with future plans to embed this AI assistant in the vehicle itself.
Car manuals are usually consulted only as a last resort, and sometimes not at all – which can compound what might start out as a relatively minor issue. Mercedes’ goal is to ensure that all drivers are able to quickly and easily access accurate information about their vehicles.
Recognizing that many users are more willing to query an app, rather than flip through a manual or phone a call center, Mercedes has brought AI from IBM Watson to the experience – introducing an application that knows the car and its functionalities by heart. Users can pose questions specifically about their vehicle, as they would to a knowledgeable Mercedes expert, and can also ask general question about Mercedes features, such as the new EQ design for Mercedes electric vehicles.
By making Ask Mercedes available on multiple channels – including via Facebook Messenger – Mercedes is helping to provide drivers with a consistently high level of support, whether they’re asking a quick question or investigating a more complex issue. Either way, the carmaker wants to ensure that drivers can get back on the road quickly and safely.
To make sure drivers are getting the most precise information, Ask Mercedes can also pose follow up questions to better understand what the driver is asking. It can also answer questions with the aid of multi-media content, such as graphics or drawings.
But the chatbot also knows its limits: If it realizes that it cannot answer a question, it refers the user to additional information or the call center.  As the vehicles become ever more sophisticated, technology can also play a role in enhancing the driver’s comfort with these changes. Above all, technology like Watson is a tool to assist humans – to help them make better-informed decisions, to help answer their of-the-moment questions and sometimes, to help with a smoother ride.
",intelligent chatbot Ask,Company,blue,telephone,telecommunication,telephone,-
https://ibm.co/2AVXP7j,187446750783_10155342756805784,https://www.facebook.com/ibmwatson/posts/10155342756805784,"Join IBM Watson's Rob High and Amy Webb, Professor of Strategic Foresight at NYU Stern School of Business as they discuss what business professionals need to know about AI. RSVP now to let us know you'll be attending. ",Link,,,1/20/18 16:15, ,8802,8802,0,15163,15163,0,194,132,165,4,6,14707,8526,0,0,188,0,0,0,0,0,0,0,0,0,0,,77.0,,,81.0,,111,27.0,,,137,28.0,,,3,3.0,,3,2.0,,,,https://www.facebook.com/events/320911045073672/,anger,0.072556,positive,0.812196,"Join IBM Watson's Rob High, business professionals","Company, Person, Person, Organization, Organization",Join IBM Watson's Rob High,Company, , , , , , , , ,joy,0.279286,neutral,0,Business Professionals,"Company, Person","What Business Professionals Need to know about AI: Facebook Live
Press alt + / to open this menu
Do you want to join Facebook?
What Business Professionals Need to know about AI: Facebook Live
",Business Professionals,Company, , , , , 
https://ibm.co/2EUqCLN,187446750783_10155339554525784,https://www.facebook.com/ibmwatson/posts/10155339554525784,"Learn about AI, cloud, data and security, hear from the best and brightest in AI and discover endless possibilities at #THINK2018. Registrations are now open. Let's think together. ",Link,,,1/19/18 13:41, ,9278,9278,0,16224,16224,0,285,157,177,3,3,14273,8238,0,0,254,0,0,0,0,0,0,0,0,0,0,20,140.0,,20,140.0,,44,120.0,,,51,126.0,,,3,,,3,,,"The digital-first IBM business and technology event will take place May 5â7, 2020. Learn about the latest advancements in open technologies from hybrid multicloud to data and AI and interact with luminaries who are using them to transform our lives.Â ",https://www.ibm.com/events/shared/img/think2020/think-og2.jpg,https://www.ibm.com/events/think/?cm_mmc=OSocial_Socialhub-_-xIBM+Events_Global+Conferences-_-WW_WW-_-IBMWatson-THINK2018&cm_mmca1=000021TD&cm_mmca2=10001376&,joy,0.80107,positive,0.944935,AI,"Person, Hashtag",AI,Person,joy,0.359078,positive,0.94015,"digital-first IBM business, latest advancements","Company, Person",digital-first IBM business,Company,joy,0.557024,positive,0.810422,,"Company, Person, Company, Person","Since becoming CEO in January 2012, Ginni has led IBM through the most significant transformation in its history, reinventing the company to lead in the new era of AI, blockchain, cybersecurity and quantum technologies, all delivered on IBM’s enterprise-strength cloud platform. Today, IBM is the world leader in AI and cloud computing for business, underpinned with trust and security.
IBM’s commitment to diversity and inclusion also has advanced under Ginni’s leadership. This includes extending parental leave and making it easier for women to return to the workforce through a “returnships” program with hands-on work experience in emerging technologies. This pioneering work was recognized in 2018 by the prestigious Catalyst Award for advancing diversity and women’s initiatives. IBM is the only tech company to have earned this recognition in the last 20 years and the only company ever to be honored four times.
Arvind Krishna leads the IBM business unit that provides the cloud and data platforms on which the company’s clients build the future. His responsibilities include IBM Research, IBM Cloud, IBM Data and AI, and IBM’s Security and Cognitive Applications businesses. He also drove the company’s 2019 acquisition of Red Hat.
Arvind leads the unit’s strategy, product design, offering development, marketing, sales and service. He also guides IBM’s overall strategy in technologies including artificial intelligence, quantum computing, blockchain, cloud platform services, data-driven solutions, and nanotechnology.
Jim Whitehurst is president and chief executive officer of Red Hat, the world’s leading provider of open source enterprise IT software solutions and services. An avid advocate for open software as a catalyst for business innovation, Whitehurst has proven expertise in helping companies flourish—even in the most challenging economic and business environments.
Whitehurst has grown Red Hat and its influence by reaching key milestones—most notably in 2012, when Red Hat became the first US$1 billion open source software company. Company revenue reached almost US$3 billion in 2018.
In 2015, Whitehurst published The Open Organization: Igniting Passion and Performance, a book that shows how open management principles can help organizations succeed in a fast-paced, connected era.
Amal Clooney is a barrister who specializes in international law and human rights. Through international courts, she frequently represents political prisoners, journalists and victims of mass atrocities.
Ms Clooney served as a Sr. Advisor to Kofi Annan. She was appointed to the UK’s panel of experts on combatting sexual violence and to a panel on public international law. She was also appointed as the UK’s Special Envoy for Media Freedom by the UK Foreign Secretary and she serves as vice-chair of a High-Level Panel of Legal Experts on Media Freedom.
Ms Clooney is a Visiting Professor at Columbia Law School, where she co-teaches the Human Rights course, and she is co-author of a forthcoming book titled ‘The Right to a Fair Trial in International Law’ to be published in 2020.
Mayim Bialik is known for her role on the hit CBS comedy, The Big Bang Theory as Amy Farrah Fowler, for which she has received two Critics Choice Awards, four Emmy Award nominations and a SAG Award nomination. Bialik has appeared in numerous beloved roles throughout her dynamic acting career.
An acclaimed author, Bialik has written two #1 New York Times bestsellers, Girling Up: How to Be Strong, Smart and Spectacular, and the recently released Boying Up: How to Be Brave, Bold and Brilliant. She has also written a parenting book, Beyond the Sling, and a cookbook, Mayim’s Vegan Table. Bialik has recently dedicated her skills as a writer, actress, neuroscientist and mother to driving the lifestyle website GrokNation.com, which she started.
",,Company,blue,blue color,lamp,neon lamp,-
https://ibm.co/2DITGXe,187446750783_10155336708100784,https://www.facebook.com/ibmwatson/posts/10155336708100784,"&quot;Whether you’re a doctor, engineer, lawyer, music producer, teacher—or CEO—we are all going to do our work with the aid of analytics and forms of AI.&quot; – IBM CEO Ginni Rometty via The Wall Street Journal: ",Link,,,1/18/18 11:04, ,29082,29082,0,49356,49356,0,1493,1036,1357,9,9,35513,20553,0,0,1254,0,0,0,0,0,0,0,0,0,0,124,571.0,7.0,124,571.0,7.0,493,664.0,,,615,742.0,,,3,6.0,,3,6.0,,,,https://www.wsj.com/articles/ginni-rometty-on-how-ai-is-going-to-transform-jobsall-of-them-1516201040,joy,0.470462,positive,0.592575,"music producer, aid of analytics, forms of AI","Person, Person, Company",music producer,Person, , , , , , , , ,joy,0.623026,negative,-0.236678,"number of recent studies, new tools, distinct minority of the world, artificial intelligence",Company,"Today, the technologies grouped together under “artificial intelligence” are entering mainstream business and daily life. As often happens with radically new tools, some people worry it will destroy jobs. 
The good news? A number of recent studies, including one commissioned by IBM, indicate that history is likely to repeat itself. Some occupations will go away, and new ones will be created, but even together, those will be a distinct minority of the world’s occupations. 
",number of recent studies,Company, , , , , 
https://ibm.co/2DqJp40,187446750783_10155334146720784,https://www.facebook.com/ibmwatson/posts/10155334146720784,"&quot;AI and automation will impact nearly every facet of the workforce in some way in the future. However, certain industries—particularly human resources and finance—are more likely to see big changes in 2018&quot; via TechRepublic: ",Link,,,1/17/18 10:58, ,6685,6685,0,11750,11750,0,215,151,171,2,3,10002,5856,0,0,190,0,0,0,0,0,0,0,0,0,0,24,65.0,2.0,24,65.0,3.0,38,119.0,,,46,125.0,,,2,1.0,,1,1.0,,"AI and a tech jobs boom are poised to change the employment landscape in 2018, according to Glassdoor.",https://tr3.cbsistatic.com/hub/i/r/2017/12/19/208acec2-2087-4326-8cc5-e5d798e74cdc/thumbnail/770x578/4b07d8839aea6569758022ab9916227b/istock-655801624.jpg,https://www.techrepublic.com/article/the-5-most-important-tech-job-trends-for-2018/?ftag=COS-05-10aaa0h&utm_campaign=trueAnthem:%20Trending%20Content&utm_content=5a4659a404d3015b0d788955&utm_medium=trueAnthem&utm_source=facebook,fear,0.489162,positive,0.92372,"human resources, big changes",,human resources,,joy,0.343617,positive,0.58156,tech jobs boom,Person,tech jobs boom,Person,joy,0.501719,positive,0.61787,job market,"Person, Person, Organization, Company, Quantity, Quantity, Person, GeographicFeature","The job market will continue to shift in 2018, as technologies such as artificial intelligence (AI) impact many industries, and mobile changes the way people find and apply for jobs, according to a new report from job search site Glassdoor. 
Despite two major hurricanes and political challenges, the US economy experienced a strong year, Andrew Chamberlain, Glassdoor's chief economist, wrote in the report: 1.9 million new jobs were added in 11 months, and stock markets reached an all-time high. Additionally, the nation's unemployment rate dropped to a 17-year low, fueling a talent war in tech, healthcare, e-commerce, and other professional services, he added. 
""This year has been good for many--but not all--workers,"" Chamberlain wrote. ""Job seekers who've mastered key skills in data science, software development, and health professions are seeing rising pay and benefits. At the same time, average wages for many remain stubbornly flat. Despite a healthy job market overall, job growth is sharply divided, with tech skills earning a premium and others being left behind by rising artificial intelligence (AI) and automation."" 
SEE: IT jobs 2018: Hiring priorities, growth areas, and strategies to fill open roles (Tech Pro Research)
Tech jobs continue to spread: In 2017, a growing number of employers in  finance, retail, manufacturing, and other traditional industries began creating more tech roles. And a growing share of tech hiring is happening far from Silicon Valley, in more affordable tech clusters such as Seattle, Austin, Detroit, Dallas, and Raleigh, Glassdoor found. 
Here are five job disruptions to watch for 2018, according to Chamberlain. 
1. AI changing the future of work
AI and automation will impact nearly every facet of the workforce in some way in the future. However, certain industries--particularly human resources and finance--are more likely to see big changes in 2018. New AI tools are complementing the skills of human workers in these areas, and changing many established roles that are easy to automate. 
2. Modernization of mobile job applications
Since most job application systems were created in the past, applying for a job via a mobile device can be a difficult process, Chamberlain said. It's likely that 2018 will see growth in mobile application platforms, though it may take time before they are commonly used.
3. Job growth in tech, healthcare, and labor-intensive roles
Innovations in tech will drive job creation in 2018, in both tech and traditionally non-tech industries, Chamberlain said. Significant demographic shifts, such as the aging population, will also lead to massive workforce changes. Many traditional jobs, such as waiters and truck drivers, that cannot be automated easily in the near terms will continue to grow in number, he predicted.
4. Increased transparency in the application and interview process
The online job application process remains opaque for many employees, Chamberlain said. In 2018, it's likely that job seekers will gain more visibility into both the application process and the status of job applications in real time.
5. Encouraging employee passions through role experimentation
Companies are increasingly finding ways for employees to experiment with different roles within the company, to tap the changing skills and passions of their workforce, reduce turnover, and better match talent to positions, Chamberlain said. It's likely this will continue and expand in the new year. 
",job market,Person,gray,checkout counter,furniture,table,checkout counter
https://ibm.co/2AVXP7j,187446750783_10155331517880784,https://www.facebook.com/ibmwatson/posts/10155331517880784:0,"What do you need to know about AI, machine learning and deep learning in 2018? We’re excited to host IBM Watson CTO Rob High and Professor of Strategic Foresight, NYU Stern School of Business, Amy Webb, for our first-ever Facebook Live on February 8th, as they discuss what business professionals need to know and how companies are transforming their businesses with AI. ",Photo,,,1/16/18 9:20, ,9323,9323,0,16381,16381,0,192,131,174,3,3,14957,8765,0,0,171,0,0,0,0,0,0,0,0,0,0,16,90.0,2.0,16,90.0,5.0,78,24.0,47.0,,98,25.0,51.0,,1,2.0,,1,2.0,,,,https://www.facebook.com/events/320911045073672/,joy,0.658381,positive,0.476819,"IBM Watson CTO Rob High, NYU Stern School of Business, business professionals","Person, Organization, Facility, Person, Company",IBM Watson CTO Rob High,Person, , , , , , , , ,joy,0.279286,neutral,0,Business Professionals,"Company, Person","What Business Professionals Need to know about AI: Facebook Live
Press alt + / to open this menu
Do you want to join Facebook?
What Business Professionals Need to know about AI: Facebook Live
",Business Professionals,Company, , , , , 
https://ibm.co/2D5CDBr,187446750783_10155329431155784,https://www.facebook.com/ibmwatson/posts/10155329431155784,Everyone is talking about AI. Are you curious about what exactly the technology entails?  Here's what you should know.  ,Link,,,1/15/18 10:30, ,15661,15661,0,26131,26131,0,531,375,484,5,5,19914,11878,0,0,423,0,0,0,0,0,0,0,0,0,0,69,203.0,7.0,74,203.0,7.0,153,260.0,,,205,279.0,,,1,4.0,,1,4.0,,IBM's Watson artificial intelligence project is probably a whole lot bigger than you ever imagined.,https://g.foolcdn.com/editorial/images/455078/gettyimages-671750592.jpg,https://www.fool.com/investing/2017/08/30/ibm-watson-everything-you-ever-wanted-to-know.aspx,anger,0.386309,neutral,0,technology,Person,technology,Person,joy,0.264969,positive,0.701775,IBM's Watson,"Person, Company",IBM's Watson,Person,joy,0.167143,positive,0.658187,,"Person, Company","In 2011, IBM's (NYSE:IBM) Watson artificial intelligence (AI) supercomputer beat 74-time-straight Jeopardy! champion Ken Jennings in a man-vs.-machine showdown on primetime television. ""Winning"" $77,147 to Jennings' $24,000, Watson arguably proved itself three times as intelligent as his human opponent. In so doing, IBM ushered in the new age of AI, in which humans no longer work for food, and computers do all of our thinking for us.
Oh, wait. That actually didn't happen.
But in the six years since Watson beat Jennings on Jeopardy!, IBM's AI wunderkind has been in the news plenty. Among other projects, Watson has been tasked with tackling two of humanity's biggest challenges: helping Pfizer figure out a cure for cancer and navigating the U.S. tax code for H&R Block. Yet what exactly Watson is remains something of a mystery to many. In an attempt to get a better handle on Watson, I posed some questions via email to IBM Vice President Ed Harbour, head of the IBM Watson project.
Here's what he had to say. (The interview has been edited to aid clarity and brevity).
Rich Smith: What is Watson, exactly? Is it code? Is it servers? What is the clearest way a layman can envision Watson? 
Ed Harbour: Watson is the AI platform for business. It is not one thing, but rather a collection of services and capabilities that include machine learning, reasoning, and decision technologies, as well as language, speech, and vision technologies. These capabilities are designed to learn at scale, reason with purpose, and interact with humans naturally to solve a wide range of practical problems, boost productivity, and foster new discoveries across many industries.
 Watson can turn business data -- even data that is unstructured -- into actionable insights that enhance decision-making. Watson can take many forms, from virtual assistant to care manager, research module to customer service agent. Watson leverages the IBM Cloud, offering access to an unprecedented set of enterprise-grade cloud services that can further enhance its function to meet various business needs.
 Smith: How does Watson differ from more familiar forms of AI such as Apple's Siri and Amazon.com's Alexa? 
Harbour: Watson and Apple's Siri or Amazon's Alexa do totally different things. Their foundation is quite basic and just speech to text to search. Watson delivers a conversation; it delivers answers, alternatives, and evidence-based recommendations with confidence. It learns from interactions and expert training, grows and develops over time. In addition to answers, it offers alternatives and background on why it made the decisions it recommends to users. Watson retains conversations and can understand context and domain. Watson is an AI platform for the enterprise.
Other forms of AI, like Siri or Alexa, rely solely on Q&A and speech to text. They use pre-compiled, human-curated databases or FAQs to look up keywords, as do search engines like Google. Consumer data is not where most of the value is. Eighty percent of the world's data is not on the Web, but rather embedded in businesses and industries, such as client data, financial data, and medical data. Our approach is to build cognitive solutions to help specific industries and businesses tap this data. A key aspect is Watson protects clients' data and any business insights. This is not shared. Watson is also deployed on the IBM Cloud and can be scaled to meet any enterprise needs.
For example, in the case of IBM client H&R Block, Watson was enlisted to understand the ""language"" of tax to provide the most personalized tax-preparation experience. Watson, with the Tax Professional, helped ensure that consumers were getting the best possible tax outcome and also made the entire tax return process a more collaborative, transparent experience. The main differentiator with Watson is the actionable capability and insights it brings to enterprise clients.
 Smith: What would you say is the public's biggest misperception about Watson? What is one thing that folks might think that Watson can do that it actually cannot? 
Harbour: The biggest misperception about Watson is that it's meant to replace humans. Watson works with humans to enhance the abilities of professionals at every level, from highly specialized surgeons to oil drillers, and automates many basic tasks. However, no matter how advanced the technology, some jobs -- specifically, those that rely heavily on empathy, ethical judgment, and social interaction -- will always be performed better by humans.
 Cognitive computing introduces a new level of collaboration between man and machine. It will augment and expand human intelligence, not replace it. 
Smith: Can you name one concrete example of something you would like Watson to be able to do that it cannot quite manage yet? 
Harbour: The future of technology is rooted in artificial intelligence. In the next three to five years, you'll see advancements that crack the uniquely human nature of communication. For example, Watson has started to be able to detect facial expressions, to combine words, voice, and visual interfaces and form a complete understanding of a conversation. IBM is also further developing Watson's ability to understand different vocalizations of words and how that reinforces a person's emotional meaning.
 The true value of Watson and cognitive systems is how it can augment and amplify human abilities. To help us think and perform our jobs better, faster, not to do it for us.
Smith: How human is Watson right now? Would it be possible for someone to interview Watson about Watson? 
Harbour: Watson is trained on specific data sets to unearth insights into different industries, tasks, and specialties. Once trained, with its speech, language, and intelligence capabilities, Watson can learn and understand the intention behind a specific command and provide a refined answer for the specific industry or profession it was trained to help.
While it's technically possible to train Watson to answer questions about its own technology, unlike humans, Watson does not have a personality, so it may not make for the most engaging interview subject. 
Smith: How does Watson get smarter? By adding data? By refining algorithms? Both? 
Harbour: Watson technologies are trained by humans to understand information specific to different industries, specialties, and languages -- in other words, Watson learns in an expert way, not just a general way. This involves training the system to recognize patterns by feeding it large amounts of labeled data and then working with human experts to refine the answers. Through successive rounds of input and feedback from subject-matter experts, Watson's understanding and responses improve. 
 Looking at the implementation of specific Watson technologies -- Natural Language Understanding and Tone Analyzer are designed to allow developers to quickly bake these functionalities into their apps and see value, without a consultant. Watson Conversation Service enables powerful engagement, and Watson Discovery Service allows for unearthing powerful insights often distributed over vast amounts of documents. Even more robust services like Watson Virtual Agent -- a customer-service chatbot -- come pre-trained with over 105 intents and 35,000 utterances and ready for domains such as general customer service, telco, and retail banking. We also built Watson Knowledge Studio, which allows clients to train Watson on the language of their industry, profession, and domain -- easily. We are continually improving and refining the various underlying algorithms that power the Watson platform.
Smith: How expensive is it for a client to use Watson? How is it billed?
Harbour: Our approach to delivering Watson is flexible and tailored to the clients with both industry solutions and APIs available on the IBM Cloud.
We have several business models for Watson. The overarching theme is value-based. It's really focused on driving scale.
Smith: Can you quantify how important Watson is to IBM's business today, in terms of the revenue it produces?
Harbour: Watson is part of our analytics business in our cognitive-solutions segment. In 2Q17, we reported that revenues in this segment grew to $4.6 billion. Over the last 12 months, our strategic imperatives, which includes analytics, has delivered $34.1 billion in revenue, 43% of IBM's total revenue.
Another good indicator of where we are in the cognitive journey is to look at scaling, where we started and where we are now. Watson was just a natural-language machine six years ago. If you want to think of it in terms of a human, it could only ""hear"" or ""read"" and only basic information at that.
 Today, Watson has grown from that one natural-language QA API into a multitude of services. It has gone from simply speaking English to understanding nine languages. We've added more capabilities and have built extensive data sets industry by industry to train Watson to solve complex industry problems.
 It not only can reason over simple trivia; it can reason through complex industry-specific data, like cybersecurity data or cancer data. And it not only ""reads."" It can ""see."" Watson can look at medical images and flag ones for radiologists that are unusual -- and it can understand emotion and tone, too. 
These capabilities are being deployed in enterprises faster. For example, you mentioned cancer research. Watson took a couple of years to learn about oncology after its Jeopardy! win in 2011. But look where we are today. We've entered clinical use in 12 countries and are expanding to more countries later this year. Watson so far has been trained on six types of cancer, with plans to add several more this year.
On taxes, we started with H&R Block last summer. It took us a few months to build a solution for them, and this year somewhere in the ballpark of 11 million people did their taxes at an H&R Block office, powered by Watson.
Another metric of success is embedding Watson across the IBM portfolio. That's our mission. We've been describing Watson as a sliver thread, weaving through multiple areas and segments. We're helping colleagues across our portfolio embed Watson into existing offerings. We've been successful in security, commerce, technology services, and systems, to name a few.
 Smith: In addition to cancer and taxes, you are also using Watson to provide individual health and fitness insights to more than 190 million users of Under Armour's connected-fitness platform, while simultaneously providing traffic information to Chevy, Buick, and GMC drivers through General Motors' OnStar service. Is there a limit on the amount of juggling Watson can do, working for so many customers simultaneously? 
Harbour: Each client gets their own ""instance"" of Watson to train with their data, to meet their needs. We can scale to any number by deploying on the IBM Cloud. The applications for this technology are limitless, and we expect to help more than 1 billion people this year.
We are continuously working to advance this adoption -- drawing more developers to use cognitive engines like Watson to build their own apps, working with more businesses and industries so they can incorporate cognitive solutions into their workflows.
Smith: Put Watson in context versus other AIs. How does it stack up against the competition today?
Harbour: IBM has a significant lead in the industry in applying AI technology, having been researching, developing, and investing in AI technology for more than 50 years. We also have the largest industrial research organization in the world and in 2016 led the industry in AI-related patents held.
Unlike other technologies in the market today that are in the experimental or elementary stage, Watson is a mature platform making a real impact on the industries it touches. Watson solutions are now being built, used, and deployed in more than 45 countries and across 20 different industries, solving big, complex societal problems, like cancer and cybersecurity. IBM has also made meaningful progress in other industries, ranging from education to commerce. 
Smith: And now look 10 years into the future. What are the chances that in 2027, the average consumer will be able to use Watson in daily life?
Harbour: There's a chance that you use Watson already. For example, in addition to people taking their W-2s to H&R Block for cognitive interviews, people may be using Watson when ordering office supplies from Staples, interacting with a gift concierge via 1-800-Flowers' Gwyn system, checking auto recall and warranty information via Honda's ""Ask Dave"" interface, or interacting with Harman/IBM-powered smart rooms.
In the healthcare space, Watson is about more than just cancer treatment. It's available to more than 200 million patients globally, collaborating with doctors, helping improve treatment recommendations and helping deliver more efficient care.
 AI is playing a bigger and bigger role in consumers' day-to-day lives. By the end of this year, IBM Watson will be available to more than a billion consumers of all kinds, helping them discover the right insurance options, make travel reservations, troubleshoot their IT, answer weather-related questions, get faster service from their bank, and more.  
",,Person,ash grey,robot,machine,motor,engine
https://ibm.co/2mzORYR,187446750783_10155325743910784,https://www.facebook.com/ibmwatson/posts/10155325743910784,"At THINK, all of IBM’s essential technologies – Blockchain, AI, Cloud, Data, Security, Systems and more – will be under one roof, on one of the largest stages in the U.S., for 4 days only. Welcome to IBM Think. Join us March 19-22 in Las Vegas. Details: ",Link,,,1/13/18 18:30, ,10054,10054,0,18244,18244,0,195,111,132,3,3,16196,8996,0,0,173,0,0,0,0,0,0,0,0,0,0,18,100.0,1.0,18,101.0,1.0,65,51.0,,,76,56.0,,,2,1.0,,2,1.0,,"Welcome to IBM Think. We invite you to join us March 19-22 in Las Vegas, where you will learn from the best in the industry about the latest AI advances.",https://www.ibm.com/blogs/watson/wp-content/uploads/2018/01/GettyImages-972372234.jpg,https://www.ibm.com/blogs/watson/2018/01/experience-watson-at-think-2018/,joy,0.423961,neutral,0,"IBM’s essential technologies, IBM Think","Company, Quantity",IBM’s essential technologies,Company,joy,0.589992,positive,0.861074,Las Vegas,"Company, Location",Las Vegas,Company,joy,0.201471,positive,0.845181,"Watson activity, Watson Studio, IBM Watson Studio","Company, Person, Person, Company","Want to catch up on all the Watson activity around Think? Check out the latest announcements around how AI is transforming professions.
 We are enhancing our product to accelerate the value of AI in your companies and announcing Watson Studio. IBM Watson Studio is an integrated environment designed to make it easy to develop, train, manage models and deploy AI-powered applications and is a SaaS solution delivered on the IBM Cloud.
Watson Visual Recognition Service for Core ML combines enterprise-grade IBM Watson AI with Apple’s Core ML to take the next step in the evolution of mobile and AI.
Watson Assistant makes it easier for enterprise customers to deliver personalized and engaging experiences.  We’ve also developed domain-specific solutions built on top of Watson Assistant for automotive and hospitality.
Be sure to check back soon for more updates on what’s happening at IBM Think 2018.
",Watson activity,Company,alizarine red,student,person,student,-
https://ibm.co/2AVXP7j,187446750783_10155324869510784,https://www.facebook.com/ibmwatson/posts/10155324869510784,"Join IBM Watson's Rob High and Amy Webb, Professor of Strategic Foresight at NYU Stern School of Business as they discuss what business professionals need to know about AI. RSVP now to let us know you'll be attending. ",Link,,,1/13/18 10:00, ,10391,10391,0,17668,17668,0,237,167,213,2,2,17158,10052,0,0,217,0,0,0,0,0,0,0,0,0,0,,89.0,1.0,,89.0,1.0,148,31.0,,,181,32.0,,,1,1.0,,1,1.0,,,,https://www.facebook.com/events/320911045073672/,anger,0.072556,positive,0.812196,"Join IBM Watson's Rob High, business professionals","Company, Person, Person, Organization, Organization",Join IBM Watson's Rob High,Company, , , , , , , , ,joy,0.279286,neutral,0,Business Professionals,"Company, Person","What Business Professionals Need to know about AI: Facebook Live
Press alt + / to open this menu
Do you want to join Facebook?
What Business Professionals Need to know about AI: Facebook Live
",Business Professionals,Company, , , , , 
https://ibm.co/2zZaWrE,187446750783_10155323329185784,https://www.facebook.com/ibmwatson/posts/10155323329185784:0,"Got some time on your hands this weekend? 

Watson's virtual summit on the future of call centers is available for instant replay. Register for the free recorded session and hear from best-selling author Seth Godin and other industry experts to get up-to-speed on how #AI is transforming customer service: ",Photo,,,1/12/18 17:30, ,8760,8760,0,16166,16166,0,187,126,154,7,7,13945,7883,0,0,154,0,0,0,0,0,0,0,0,0,0,11,68.0,2.0,11,70.0,4.0,52,29.0,54.0,,63,30.0,61.0,,4,3.0,,4,3.0,,"Virtual Summit: Future of the Call Center, IBM account registration",https://1.www.s81c.com/common/images/ibm-leadspace-1200x627.jpg,https://www.ibm.com/account/reg/us-en/signup?formid=urx-20732&cm_mmca2=10004432&cm_mmc=OSocial_Facebook-_-Watson%20Core_Watson%20Core%20-%20Conversation-_-WW_WW-_-Virtual%20Summit%20Recorded%20Session%20Sign%20Up%20Nov%2022&cm_mmca1=000027BD,joy,0.203936,positive,0.931463,"free recorded session, Watson's virtual summit, industry experts, author Seth Godin","Person, Person, Hashtag",free recorded session,Person,sadness,0.172173,neutral,0,Virtual Summit,Company,Virtual Summit,Company,joy,0.562414,positive,0.763058,customer service,"Person, Person, Person, Person, Person, Person, Person, Company, Company, Company, Company","Presented by IBM Watson and LivePerson
Register now to get full access to the sessions and hear from experts in customer service and AI, including:
Keynote  
Seth Godin
Marketing Entrepreneur & Best-selling Author
Seth Godin discusses the importance of delivering excellent customer service and asks how firms will embrace AI as they transform their call centers.
Fireside chat  
Call Center, Meet AI: What you need to know about how AI is transforming call centers
Dario Gil
VP of AI and IBM Q
Brian Cantor
Principal Analyst IQPC Customer Management
Call centers have embraced technology to increase efficiencies and to contain costs but customer experience has often suffered as a result. Brian Cantor talks with Dario Gil to discuss how AI has the potential to strike a balance between the two.
CxO Panel Discussion  
  Tomorrow's Customer: The challenges facing customer service executives today and the solutions they are finding
Michelle Peluso
Senior Vice President, Chief Marketing Officer, IBM
Michelle Peluso discusses with a panel of customer service executives, the challenge of building and maintaining long-lasting client relationships, and best practices to engage and nurture them successfully.
Expert Talk  
Tomorrow's Technology, Today: How to start building the call center of the future
Atul Gupta, IBM Global Business Services, Vice President and Senior Partner, Cognitive Process Services
Toby Cappello, Vice President, Watson and Cloud Platform Expert & Delivery Services
In this session, Atul Gupta discusses strategies to transform even the most out-dated contact center into an omni-channel, AI-enhanced Call Center of the Future and the business benefits that can bring. Toby Cappello then discusses the practical implications of enhancing customer service with AI, drawing on a number of examples from real customer implementations, highlighting lessons learned and pitfalls to watch out for. 
Presented by IBM Watson and LivePerson
Register now to get full access to the sessions and hear from experts in customer service and AI, including:
Keynote  
Seth Godin
Marketing Entrepreneur & Best-selling Author
Seth Godin discusses the importance of delivering excellent customer service and asks how firms will embrace AI as they transform their call centers.
Fireside chat  
Call Center, Meet AI: What you need to know about how AI is transforming call centers
Dario Gil
VP of AI and IBM Q
Brian Cantor
Principal Analyst IQPC Customer Management
Call centers have embraced technology to increase efficiencies and to contain costs but customer experience has often suffered as a result. Brian Cantor talks with Dario Gil to discuss how AI has the potential to strike a balance between the two.
CxO Panel Discussion  
  Tomorrow's Customer: The challenges facing customer service executives today and the solutions they are finding
Michelle Peluso
Senior Vice President, Chief Marketing Officer, IBM
Michelle Peluso discusses with a panel of customer service executives, the challenge of building and maintaining long-lasting client relationships, and best practices to engage and nurture them successfully.
Expert Talk  
Tomorrow's Technology, Today: How to start building the call center of the future
Atul Gupta, IBM Global Business Services, Vice President and Senior Partner, Cognitive Process Services
Toby Cappello, Vice President, Watson and Cloud Platform Expert & Delivery Services
In this session, Atul Gupta discusses strategies to transform even the most out-dated contact center into an omni-channel, AI-enhanced Call Center of the Future and the business benefits that can bring. Toby Cappello then discusses the practical implications of enhancing customer service with AI, drawing on a number of examples from real customer implementations, highlighting lessons learned and pitfalls to watch out for. 
We use phone in order to reach you for account related matters or, with your permission, to contact you related to other products and services.   
",customer service,Person, , , , , 
https://ibm.co/2CH8kgJ,187446750783_10155320388710784,https://www.facebook.com/ibmwatson/posts/10155320388710784,What are the popular types of chatbots companies are building to enhance their customer experience? Learn more from our blog: ,Link,,,1/11/18 11:02, ,2392,2392,0,3628,3628,0,48,30,34,1,1,3336,2225,0,0,39,0,0,0,0,0,0,0,0,0,0,4,20.0,,4,20.0,,11,21.0,,,13,21.0,,,1,,,1,,,"As chatbots continue to gain popularity, our latest blog highlights the three types of business chatbots you can build to better reach and target customers.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/12/Conversation_service_Social1200x628-1.png,https://www.ibm.com/blogs/watson/2017/12/3-types-of-business-chatbots-you-can-build/,joy,0.218109,positive,0.658298,"popular types of chatbots companies, customer experience",,popular types of chatbots companies,,joy,0.425058,positive,0.725044,"types of business chatbots, latest blog",,types of business chatbots,,sadness,0.539365,positive,0.560402,single-turn type bots,"Person, Company","Key Points:
 From a business perspective, here are the 3 most common chatbots that are being built:
 – Support chatbots that are built to master a single domain
 – Skills chatbots that are single-turn type bots that do not require a lot of contextual awareness
 – Assistant chatbots that are the middle ground between a support and skills chatbot, knowing a little bit about a variety of topics
A few years ago when chatbots were just gaining popularity, there was a lot of talk around what a chatbot actually was. With the advent of natural language processing and various machine learning techniques, some of the more advanced conversational applications wanted to separate themselves from their competition. Many began calling themselves “virtual assistants.” This implied that they were somehow bigger or more powerful than existing chatbots, or perhaps were more conversational or could cover a wider range of topics.
However, we quickly discovered that the market did not care how powerful the bot was or about the underlying technology, so long as it solved the right problems. So in a way, many of these different terms for bots became more or less synonymous with each other. It didn’t matter what you called it – you were getting something you could hold a conversation with. We’re now at a point where we know that regardless of what you call the bot, there are usage patterns and differentiation that make chatbots distinct.
When you’ve done your research and are at the point of beginning to build your bot, think carefully about what problems you’re trying to solve and what functionalities you will want to incorporate. Knowing what you want your application to solve for and assist with will decide the type of chatbot, virtual assistant or agent you ought to build. This will impact both your development plan and, as importantly, your end-user experience. The following are the three main types of chatbots I have come across, with background on their particular uses and variations.
Support chatbots are built to master a single domain, like knowledge about a company. Support chatbots need to have personality, multi-turn capability, and context awareness. They should be able to walk a user through any major business processes, and answer a wide range of FAQ-type questions. You will want to have a short-tail and long-tail combo solution when building this type of chatbot. At IBM Watson, we would use the Watson Conversation service for the short-tail, common questions and processes, and Watson Discovery service for the long-tail, but there are many potential solutions for this. Speech is an optional feature, and not a necessity, since users typically have sat down at a desktop and are ready to figure out their solution. The chatbot developer will want to spend the most time making sure it is as easy as possible to navigate the bot, and ensuring it can execute the actions that your users actually care about (for example, just because you want to sell more credit cards doesn’t mean your customers want to open more credit card accounts).
Skills chatbots are typically more single-turn-type bots that do not require a lot of contextual awareness. They have set commands that are intended to make life easier: “Turn on my living room lights,” for example. Speech functionality is recommended for this type of chatbot so the user does not need to turn on a device or click any buttons. They should be able to follow commands quickly, so that your users can multitask while engaging with the bot. These chatbots do not need to worry too much about contextual awareness, unless you want to design a particularly advanced one, as people will quickly learn what to say, and say it appropriately. It’s a nice bonus if you can give a command, and your bot knows – to return to our example – that you are in the kitchen and acts to turn on the correct lights.
However, this is not a necessary function, as users will quickly learn to give the appropriately specific command. When building a skills bot, it is important to focus on integration, especially when controlling a home or personalized objects. Keep integration simple so your users can interact with the bot without worrying about how to use .
Assistant chatbots are more or less a middle ground between the two bots above. They work best when they know a little bit about a variety of topics. Many people envision these bots will someday become navigators of all other bots that are out there now. Want to pay a bill? Ask your assistant bot to talk to the support bot for your bank. Assistant chatbots need to be conversational and respond to just about anything, while being as entertaining as possible. Siri is a good, current example – while she only does so much, people continually ask her for things simply because even when she cannot perform the command, the response she gives tends to be amusing. When building an assistant chatbot, it is important to make it as obvious as possible how the bot is trained. The range of questions a user might ask is large, so making sure you have adequate coverage is going to be the most difficult factor. In many cases, when people do not know what they should ask, they will not ask anything at all. And if you miss the few topics they initially are willing to try, they will not come back for more.
Even though these are the most common types, many bots in production fall somewhere in between two. Some are even a combination of all three. No matter what type of bot you decide to build, it is important to give your bot some life and personality, make it useful, and make sure it’s easy to use. People interact with bots because they want to get something done in a more natural way than was previously possible. Whether it’s something simple like turning on a light, or something complex like applying for a mortgage, every pattern has specific features that make it stand out, so be sure your bot shines brightly in what it’s designed to do. The possibilities are endless.
",single-turn type bots,Person,blue,razor,tool,cutlery,razor
https://ibm.co/2BU0q6h,187446750783_10155318071085784,https://www.facebook.com/ibmwatson/posts/10155318071085784,"If artificial intelligence already impacts our lives at work and at home, what will it look like in the future? Find out the ways AI will impact law enforcement, cyber security, the automotive industry and more in the next decade: ",Link,,,1/10/18 10:08, ,6371,6371,0,10165,10165,0,183,112,134,1,1,8208,5223,0,0,150,0,0,0,0,0,0,0,0,0,0,27,77.0,1.0,28,79.0,1.0,49,70.0,,,58,76.0,,,1,,,1,,,AI already impacts many aspects of our daily lives at work and at home. Here are the top 10 ways that AI will impact business over the next decade.,https://www.ibm.com/blogs/watson/wp-content/uploads/2017/11/blog_Top10_png_socialTile_081117.png,https://www.ibm.com/blogs/watson/2017/11/top-10-ways-ai-will-impact-business-in-the-next-decade/,sadness,0.37773,negative,-0.255167,"artificial intelligence, law enforcement, cyber security, automotive industry",Person,artificial intelligence,Person,joy,0.49316,negative,-0.52988,aspects of our daily lives,Person,aspects of our daily lives,Person,fear,0.519226,positive,0.461173,,"Person, Quantity, Quantity, Company, Quantity, Company","Key Points:
 – AI already impacts many aspects of our daily lives at work and at home
 – Over the next decade, AI enterprise software revenue will grow from $644 million to nearly $39 billion
 – Here are the ways that we predict AI will impact business over the next decade including vehicular object detection, predictive maintenance and intelligent recruitment.
Artificial intelligence already impacts many aspects of our daily lives at work, at home and as we move about. Over the next decade, analyst firm Tractica predicts that annual Global AI enterprise software revenue will grow from $644 million in 2016 to nearly $39 billion by 2025. Services-related revenue should reach almost $150 billion. They report that there are 6 artificial intelligence segments which will account for a significant percentage of these revenues:
1. Machine learning
 2. Natural Language Processing and Understanding
 3. Computer vision
 4. Machine reasoning
 5. Strong AI
 6. Deep learning
These functional areas are applicable to many use cases, industries, and generate benefits to both businesses and individuals. Here are the top use cases which will reap financial rewards for AI technology product and service companies, and a broad spectrum of benefits for everyone else.
Machine and vehicular object detection, identification and avoidance
Self-driving cars and other autonomous vehicles are consistently called the “next revolution” in transportation, technology and, some say, in civilization in general. Some predict that, along with the growth of the electric vehicle segment, it could bring an end (or the beginning of the end) to car ownership as we know it as soon as 2030.
Just as with cloud and computing as a service, it will be interesting to see how consumers and businesses can get the transportation value of a vehicle without the maintenance, storage, upgrades and depreciation costs of vehicle ownership. Would they would be willing to either rent out their vehicle on a site like Turo, or rent someone else’s car for a daily rate? Sharing economy leaders Lyft, Uber and new entrants can easily leverage autonomous cars to facilitate getting a vehicle from one car rental customer to another.
Autonomous forklifts, drones and other robot warehouse workers are already retrieving boxes for shipment for thriving e-commerce companies.  Vehicles are now equipped with sensors to calculate distance and routes to their destination and spatial room between vehicles, and to identify potential hazards like pedestrians, poor road conditions and other vehicles. AI-enabled machines and vehicles don’t cause accidents while texting, they don’t fall asleep at the wheel, and they don’t need lunch breaks. A vehicle which can prioritize driving into the ditch or a tree instead of a person can save lives and reduce insurance costs.
Advances in IoT, geospatial applications and artificial intelligence have aligned to make autonomous vehicles a reality. Autonomous vehicles like Olli aren’t science fiction, they’re reality.
Visual recognition, classification and tagging
In industries like law enforcement, media and entertainment, AI provides organizations with the ability to process large volumes of photographs and NSO images, and prepare them for discovery and reuse.
Financial services data is fast-moving, is highly regulated and Exchange Traded Fund (ETF) data requires a high level of security. Unlike human traders that rely on intuition, AI-driven algorithms like Watson’s Equbot can analyze a 10-year history of stocks and real estate holdings in fractions of seconds, as opposed to hours or days.
Watson can help investors make data-driven decisions on when to buy, hold and sell equities. It can also help regulators identify rogue traders who are making fraudulent securities transactions. Watson Financial Services reduces the risk of misconduct, while addressing the multitude of regulatory requirements trading firms must adhere to on an ongoing basis.
It goes without saying that self-driving cars need up-to-the minute details on the roads and road conditions that it is driving on. It also needs to maintain Simultaneous Localization and Mapping so the autonomous vehicle doesn’t “SLAM” into other cars and trucks on the roadway. AI helps to guide vehicles to their intended destination, relative to other vehicles, buildings and obstructions.
For autonomous vehicles, robots, drones and cargo-carrying transportation governed by AI, geospatial applications can play a role in tracking trends in location-related business data. It could track the locations of customers that buy a certain manufacturer’s product, or identifying regions with an ideal demographic for propensity to buy high-end electronics, for example. Companies can use this data to improve their marketing, customer service and product value.
For manufacturers with high-value machinery, airlines with large fleets of planes or car rental chains with many vehicles, protecting the value of their assets is critical. AI can help these companies (and others) to keep track of when wearable parts were last replaced when servicing needs to be completed next, and how long equipment or vehicles are in service.
Predictive maintenance reduces the frequency of equipment failures, as preventative action can be taken to refurbish or tune assets on a scheduled basis. Maintenance can take place relative to manufacturing or service requirements. For example, if certain equipment is required for a specific product run, it can be serviced outside of those parameters. Or, when a ship is scheduled to be in port for a specific time period, it can be serviced such that it won’t impact service level agreements.
AI can determine the possible outcome if maintenance doesn’t occur, and make accurate determination when equipment or vehicles should be taken out of a service rotation based on failure patterns or age. Sensors can monitor asset performance and transmit the data back to a cognitive analytics hub through IoT.
Government organizations, commercial enterprises and freelance white hat security experts try valiantly to keep ahead of the latest spyware, botnets, DDoS attack patterns, and other threats in cyberspace. Yet hackers are constantly seeking new vulnerabilities to exploit and encryption defenses to topple.
Cognitive Security systems scour the vast amounts of threat intelligence available on the internet, and help companies and public sector organizations to re-mediate their network and service perimeters before hackers can prey upon them. Human security analysts do their best to keep pace with the latest threats, but in many cases they are overwhelmed by Zero Day viruses and other emerging threats. Cognitive security is a way for companies to gain leverage through deep learning and strong AI.
Cognitive capture leverages AI and Machine Learning to expedite the process of “training” their systems to recognize key metadata (like employee numbers, invoice numbers, or loan numbers) and digitize records more effectively. It also liberates companies from scanning application and service vendor lock-ins.
Cognitive capture leverages innovative cloud, machine learning, and open source architecture to convert unstructured data into powerful insights through analytics. It also helps companies meet regulatory requirements without the burden of storing paper records, and increases the speed and accuracy of information discovery. Instead of just extracting the text, images and signatures from documents, cognitive capture learns the context of documents. It can then trigger workflows accordingly, to either file documents away in a repository, or send it to a case management system, accounts receivable or other application for immediate attention.
Traditional applicant tracking systems can be great at filtering out unqualified online job applications, yet they can sometimes eliminate qualified candidates in the process, should a resume not be optimized based on the right keyword phrases. AI makes finding the right candidate a more intelligent, data-driven process. By going beyond the basic words on a resume to determine job fit, it adds context based on reasoning and human inputs.
AI also enhances traditional HR information systems by recommending career paths for certain employees and the best way to coach, motivate and engage employees based on their personality, mindset and other characteristics. Making better hires is a good start: however, retaining employees and ensuring they are mentored and challenged to do their best is part science, part art-form and part algorithm.
These are some of the leading market sectors which are generating revenue for developers of AI software, and service providers in this space. There are other segments like public safety, customer service and more which are growing, and other use cases will continue to emerge.
If you are looking for ways to create efficiencies, disrupt your industry and innovate by leveraging the power of cognitive computing and AI, discover the Watson products and services that best meet your business needs.
",,Person,greenish blue,spin dryer,appliance,dryer,spin dryer
https://ibm.co/2EnvMzs,187446750783_10155315349725784,https://www.facebook.com/ibmwatson/posts/10155315349725784:0,Businesses often overlook important issues related to morals and ethics of chatbots and AI – here are the guidelines companies should follow: ,Photo,,,1/9/18 7:10, ,7743,7743,0,13349,13349,0,123,81,96,5,5,11881,6910,0,0,105,0,0,0,0,0,0,0,0,0,0,13,53.0,,14,53.0,,32,21.0,35.0,,38,22.0,36.0,,3,2.0,,3,2.0,,"Businesses often overlook important issues related to morals and ethics of chatbots and AI. Customers need to know when they are communicating with a machine, and that brands will protect their privacy and data in today’s interconnected world.",https://www.ibm.com/blogs/watson/wp-content/uploads/2017/06/AI-and-chatbots-ibm-contact-center-1200x628-c2-4.jpg,https://www.ibm.com/blogs/watson/2017/10/the-code-of-ethics-for-ai-and-chatbots-that-every-brand-should-follow/,sadness,0.1593,neutral,0,"important issues, Businesses",Person,important issues,Person,joy,0.265401,positive,0.71056,"important issues, Customers",Person,important issues,Person,joy,0.507241,positive,0.452234,,"Person, Person","Key Points:
 – Businesses often overlook important issues related to morals and ethics of chatbots and AI
 – Customers need to know when they are communicating with a machine and not an actual human
 – Ownership of information shared with a bot is another key ethical consideration and can create intellectual property issues
 – The privacy and protection of user data is paramount in today’s interconnected world
(Read the full article “Ethics And Artificial Intelligence With IBM Watson’s Rob High” on Forbes.com. You can also listen to The Modern Customer Podcast with Rob High here.)
See how AI is shaping customer service
Businesses are rapidly waking up to the need for chatbots and other self-service technology. From automating basic communications and customer service, to reducing call center costs and providing a platform for conversational commerce, chatots offer many new opportunities to delight and better serve consumers.
Chatbots can offer 24/7 customer service, rapidly engaging users, answering their queries as whenever they arrive. Millennials in particular are impatient when engaging with brands and expect real-time responses. More than 22% of millennials expect a response within 10 minutes of reaching out to a brand via social media, according to a recent Desk.com study. And 52% of them will abandon online purchases if they can’t find a quick answer.
The need for speed in customer service has never been higher. Leading brands like Staples are increasingly turning to chatbots to provide a solution for this need for speed.
The topic of chatbot ethics is complex and spans a wide area including privacy, data ownership, abuse and transparency.
Rob High, CTO of IBM Watson was recently featured in an article on Forbes.com titled “Ethics And Artificial Intelligence With IBM Watson’s Rob High.” In the article, Rob talks about how in order to keep AI ethical, it needs to be transparent. Rob advises that when customers interact with a brand’s chatbot, for example, they need to know they are communicating with a machine and not an actual human.
“AI, like most other technology tools, is most effective when it is used to extend the natural capabilities of humans instead of replacing them. That means that AI and humans are best when they work together and can trust each other.”
 — Rob High, CTO IBM Watson
Ethics form the foundation of how a bot is built, and more importantly, they dictate how a bot interacts with users. How a bot behaves has the potential to influence how an organization can be perceived and unethical behavior can lead to consumer mistrust and litigation issues. Ethical bots can promote brand loyalty and help boost profit margins.
1. Who should a chatbot serve?
When building a chatbot, an organization must decide who it primarily serves: the needs of the business or the needs of a customer. Amir Shevat, Director of Developer Relations at Slack discusses this topic in his blog post “Hard questions about bot ethics.”
Here, you must determine the exact purpose and business value of the chatbot. One built mainly to provide recommendations to customers can only be ethical if it meets the needs of the customer. Whereas a bot built for internal business improvement should be made to suit the company’s need.
In general, where or not a bot is customer-facing, an ethical organization should always put the needs of the customer before the needs of the business. This means providing the product best suited to those customers, rather than the one with the best profit margin or the speediest implementation. An option for users to provide feedback on the service will help detect issues, improve customer satisfaction and maintain ethical behavior. Bots utilizing machine learning and algorithms to display product offerings or recommendations should also have regular health checks built in for this exact purpose.
2. Am I talking to a chatbot or a human?
Building trust between humans and machines is just like building trust between humans. Brands can build trust by being transparent, aligning expectations to reality, learning from mistakes and continually correcting them, and listening to customer feedback.
When building a chatbot, transparency is a critical consideration. This boils down to the question – is it clear whether the user is talking to a bot or a human? Customers are savvy enough to be able to tell the difference and expect brands to be honest with them. Customers don’t expect chatbots to be perfect, but they want to know what they can and cannot do, and that they are reliable — within reason. Transparency about both failure and success can build trust faster than virtually any other approach.
To work on transparency and reliability, start by asking yourself some basic questions like:
Where sensitive information (like bank details) and life-altering interactions (health and finance) is being communicated, you need to build additional checks for transparency and security. This means providing the user with clarity. Be upfront and build into the introduction that the user is talking to a bot and what personal information is being accessed, analyzed, saved or shared and with whom. Also always provide an option where the user can be immediately be connected to a human if they have concerns that a bot cannot address..
3. Who owns the data shared with a chatbot?
Ownership of information shared with a bot is another key ethical consideration and can create intellectual property issues if not handled correctly.
Does the bot service-provider or the user own their favorite custom pizza creation? If a bot builds a playlist based on the users preferences – who owns it? These are the kind of ethical questions that need to be considered and the answer can fluctuate based on the intent of a bot. A personal-assistant bot would lean towards user ownership, while a representative-bot leans towards service-provider ownership.
Whatever the type of bot, this is another question of transparency. Businesses building bots should provide clarity about who owns what and should include language asking users to agree with their terms of service first.
4. Preventing chatbot abuse
When building a chatbot, it is important to consider how a bot handles abuse. This includes both the giving and receiving of abuse. Here, the ethical stance is to follow Isaac Asimov’s Three Laws of Robotics: “a robot may not injure a human being or, through inaction, allow a human being to come to harm”.
A chatbot should be built with profanity recognition. Upon receiving abuse, the developer has two options. The first is to ignore the abuse by building in a non-response situation where the user abuses the bot. Or, add a default neutral response such as “I’m sorry, I don’t understand your request.” Depending on the severity of abuse — for example death threats or racism — it is important to build in a report function, sending the transcript to a relevant party.
It is of critical importance that chatbots do not abuse humans even if it’s learned behavior that’s a result of what the human has been feeding the bot. Requests from users to end communication should have a built in protocol to end the chat, preventing the bot from harassing or spamming a user. Language filters should be applied for any bots utilizing machine learning algorithms. There have been a few instances over the last year where some bots went rogue after being subverted by online trolls and began tweeting racist propaganda.
5. How should chatbots handle privacy?
The privacy and protection of user data is paramount in today’s interconnected world. The launch of the General Data Protection Regulation protecting citizens of the European Union is a reflection of this.
When building a chatbot, developers should consider the ethics of user privacy. This will help answer questions like:
In this situation, businesses can take direction from existing online interactions. Transparency is the best course of action and a publicly-available privacy policy is a must have for any organization. Developers should also build in mechanisms to ensure the privacy of user information in any interaction — an unspoken user-bot confidentiality agreement. This means encryption of all communications and, depending on the sensitivity of the data, transcription deletion after completion of the interaction.
Ethics should be a core consideration of any action taken by a business. With chatbots still in a stage of relative infancy, the discovery of new ethical issues is likely to continue. Businesses should continue to learn from these emerging cases and build their guiding principles and ethical standards. If in doubt, side with the customer, and always provide transparency.
(Read the full article “Ethics And Artificial Intelligence With IBM Watson’s Rob High” on Forbes.com. You can also listen to The Modern Customer Podcast with Rob High here.)
",,Person,light brown,LED display (computer/TV),machine,computer,digital computer
,187446750783_10155314105525784,https://www.facebook.com/ibmwatson/posts/10155314105525784:0,"What do you need to know about AI, machine learning and deep learning in 2018? We’re excited to host IBM Watson CTO Rob High and Professor of Strategic Foresight, NYU Stern School of Business, Amy Webb, for our first-ever Facebook Live on February 8th, as they discuss what business professionals need to know and how companies are transforming their businesses with AI.",Photo,,,1/8/18 18:00, ,14078,14078,0,24551,24551,0,366,264,374,6,6,18548,10808,0,0,254,0,0,0,0,0,0,0,0,0,0,32,143.0,6.0,36,147.0,9.0,210,2.0,82.0,,282,2.0,90.0,,2,4.0,,2,4.0,,,,,joy,0.658381,positive,0.476819,"IBM Watson CTO Rob High, NYU Stern School of Business, business professionals","Person, Organization, Facility, Person, Company",IBM Watson CTO Rob High,Person, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2AGsoNR,187446750783_10155313049105784,https://www.facebook.com/ibmwatson/posts/10155313049105784,IBM and Massachusetts Institute of Technology (MIT) are working on a project that can progress #AI to interpret what is happening in a video.  ,Link,,,1/8/18 8:08, ,12928,12928,0,22078,22078,0,342,241,282,2,2,18549,11247,0,0,295,0,0,0,0,0,0,0,0,0,0,29,123.0,5.0,33,123.0,5.0,107,147.0,2.0,,129,151.0,2.0,,1,1.0,,1,1.0,,Perceiving dynamic actions could be a huge advance in how software makes sense of the world.,https://cdn.technologyreview.com/i/images/videosteachingmachines.png?cx=0&cy=43&cw=4085&ch=2297&sw1200,https://www.technologyreview.com/s/609651/the-next-big-step-for-ai-understanding-video/,joy,0.306418,neutral,0,"Massachusetts Institute of Technology, IBM","Organization, Company, Hashtag, Organization",Massachusetts Institute of Technology,Organization,joy,0.463746,positive,0.725191,"dynamic actions, huge advance",,dynamic actions,,joy,0.60903,positive,0.721154,vast data set of video clips,"Quantity, Organization, Person, Company, Quantity, Person, Company, Company","For a computer, recognizing a cat or a duck in a still image is pretty clever. But a stiffer test for artificial intelligence will be understanding when the cat is riding a Roomba and chasing the duck around a kitchen. 
MIT and IBM this week released a vast data set of video clips painstakingly annotated with details of the action being carried out. The Moments in Time Dataset includes three-second snippets of everything from fishing to break-dancing. 
“A lot of things in the world change from one second to the next,” says Aude Oliva, a principal research scientist at MIT and one of the people behind the project. “If you want to understand why something is happening, motion gives you lot of information that you cannot capture in a single frame.” 
The current boom in artificial intelligence was sparked, in part, by success in teaching computers to recognize the contents of static images by training deep neural networks on large labeled data sets (see “The Revolutionary Technique That Quietly Changed Machine Vision Forever”). 
AI systems that interpret video today, including the systems found in some self-driving cars, often rely on identifying objects in static frames rather than interpreting actions. On Monday Google launched a tool capable of recognizing the objects in video as part of its Cloud Platform, a service that already includes AI tools for processing image, audio, and text. 
The next challenge may be teaching machines to understand not just what a video contains, but what’s happening in the footage as well. That could have some practical benefits, perhaps leading to powerful new ways of searching, annotating, and mining video footage. It also figures to give robots or self-driving cars a better understanding of how the world around them is unfolding. 
The MIT-IBM project is in fact just one of several video data sets designed to spur progress in training machines to understand actions in the physical world. Last year, for example, Google released a set of eight million tagged YouTube videos called YouTube-8M. Facebook is developing an annotated data set of video actions called the Scenes, Actions, and Objects set. 
Olga Russakovsky, an assistant professor at Princeton University who specializes in computer vision, says it has proved difficult to develop useful video data sets because they require more storage and computing power than still images do. “I’m excited to play with this new data,” she says. “I think the three-second length is great—it provides temporal context while keeping the storage and computation requirements low.” 
Others are taking a more creative approach. Twenty Billion Neurons, a startup based in Toronto and Berlin, created a custom data set by paying crowdsourced workers to perform simple tasks. One of the company’s cofounders, Roland Memisevic, says it also uses a neural network designed specifically to process temporal vision information. 
“Networks trained on the other data sets can tell you whether the video shows a soccer match or a party,” he says. “Our networks can tell you whether someone just entered the room.” 
Danny Gutfreund, a researcher at IBM who collaborated on the project, says recognizing actions effectively will require that machines learn about, say, a person taking an action and transfer this knowledge to a case where, say, an animal is performing the same action. Progress in this area, known as transfer learning, will be important for the future of AI. “Let’s see how machines can do this transfer learning, this analogy, that we do very well,” he says. 
Gutfreund adds that the technology could have practical applications. “You could use it for elder care, telling if someone has fallen or if they have taken their medicine,” he says. “You can think of devices that help blind people.” 
",vast data set of video clips,Quantity,sea green,golden hamster,animal,mammal,rodent
https://ibm.co/2qz1WpQ,187446750783_10155309053855784,https://www.facebook.com/ibmwatson/posts/10155309053855784,"By 2025, there will be one trillion gigabytes of global data, and most of it's in the form of text, documents, call logs, social media posts, research papers, feedback comments and more. 

The best way to seek real insight in all this information? Artificial intelligence. ",Link,,,1/6/18 10:50, ,8334,8334,0,14524,14524,0,184,96,119,0,0,10117,5880,0,0,136,0,0,0,0,0,0,0,0,0,0,35,95.0,1.0,40,99.0,1.0,56,46.0,,,73,46.0,,,,,,,,,"Most of the world's data is unstructured. IDC forecasts that by 2025 the global datasphere will grow to 163 zettabytes. That's a trillion gigabytes, and most...",https://i.ytimg.com/vi/LFl_1uKiADk/maxresdefault.jpg,https://www.youtube.com/watch?v=LFl_1uKiADk&t=3s,joy,0.190214,positive,0.614454,"gigabytes of global data, research papers",Quantity,gigabytes of global data,Quantity,joy,0.642031,positive,0.384185,"global datasphere, world's data, IDC","Company, Quantity",global datasphere,Company,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                                              
            

",YouTube,Company,coal black,call center,building,call center,-
https://ibm.co/2lEgeD8,187446750783_10155306457490784,https://www.facebook.com/ibmwatson/posts/10155306457490784,"Suncorp, an Australian insurance company, has introduced IBM Watson into its online claims system that processes more than 500,000 motor claims every year, to help the insurer better understand the circumstances of the claim and determine liability. ",Link,,,1/5/18 10:25, ,14690,14690,0,25355,25355,0,303,198,257,8,10,20806,12394,0,0,248,0,0,0,0,0,0,0,0,0,0,17,125.0,5.0,20,128.0,5.0,118,95.0,,,154,103.0,,,6,4.0,,5,4.0,,IBM Watson has taken up residency with Australia's Suncorp Group to help with its online insurance claims process.,https://zdnet1.cbsistatic.com/hub/i/r/2015/11/24/555f6b8a-fc6a-4d97-b276-10c497f97208/thumbnail/770x578/8c4952233ffbb6e41593c9f28fb4fb45/crash.jpg,https://www.zdnet.com/article/ibm-watson-to-learn-australian-slang-for-suncorp-claims-process/,anger,0.058342,positive,0.831646,"Australian insurance company, online claims system","Company, Company",Australian insurance company,Company,anger,0.077593,positive,0.595796,IBM Watson,"Company, Person, Company, Location",IBM Watson,Company,joy,0.503464,positive,0.548503,IBM Watson,"Company, Person, Company, Person"," 	Suncorp has introduced IBM Watson into its online claims system that processes more than 500,000 motor claims every year, to help the insurer better understand the circumstances of the claim and determine liability.
 	Using IBM Watson's Natural Language Classifier, the system analyses customer descriptions of motor vehicle accidents; however, as the descriptions are often written in a conversational way, IBM said they often include colloquialisms and Australian slang that Watson will need to learn in order to properly assist Suncorp.
 	The technology is being used across Suncorp's Personal Insurance brands comprising AAMI, Suncorp, GIO, and Bingle.
 	The platform relies on Watson to conduct liability analysis and assist in fast-tracking simple claims, such as single vehicle incidents with detailed descriptions. However, if the incident description provided by the customer is limited, or there is a low confidence score from the system in determining liability, the claim is routed to a human to help with the decision.
 	The AI tech began production in June 2017, and since then the proportion of customers who were fast-tracked through the process has tripled, said CEO of Insurance at Suncorp Gary Dransfield, with Watson enabling claims to be lodged, excess paid or waived, and repairs booked within five minutes.
 	""This technology augments our claim consultant's knowledge and expertise, providing data-driven insights and instilling greater confidence in our liability decisions. It has also helped us speed the process for our customers, while improving their experience at a time that's often very stressful,"" Dransfield said in a statement on Wednesday.
 	""Ultimately this enhances our customers' experience by delivering innovative digital solutions to help make the claim process easier.""
 	According to Dransfield, relying on technology to make the decisions will ensure the claims process is streamlined. It will also result in a more consistent approach to liability decisions, as Suncorp hopes Watson will establish a reliable reference point based on historical claims and industry guidelines.
 	Suncorp trained Watson on the complexities associated with determining liability in motor vehicle accidents using nearly 15,000 de-personalised claim scenarios and the resulting liability determination, in line with guidelines from the Australian Prudential Regulatory Authority (APRA). By the end of the trial period, Watson could accurately determine liability for around 90 percent of cases, IBM said.
 	In delivering its results for the 2017 financial year, Suncorp CEO and managing director Michael Cameron told shareholders the group's AU$394 million after-tax profit would have been higher had it not needed to pump further funds into its core banking platform, contracted to Oracle.
 	The bank previously had its eyes set on reaping AU$170 million in benefits by the 2018 financial year from its technology optimisation program after announcing back in May 2014 that it would be dedicating an estimated AU$270 million to changing its core banking system.
 	Cameron explained Suncorp had decided to leave a small group of its products running on the old system, rather than take a risk in launching a new platform.
 	""At the end of the day, the customer experience is what counts; we don't want to be in a situation where we're getting outages so all we're really doing is waiting for a new version of the same software to be released, which incorporates the sorts of things that we want, rather than build them ourselves internally,"" he said.
 	""It will actually cost us a little less, it will de-risk the operations from a customer perspective, and for us it means running two systems for a period of time. While it's not ideal, it's something that we've thought long and hard about.""
 	 	Pip Marlow joins the bank as its new innovation-focused chief executive officer.
 	Woodside Petroleum focused on a data-driven future 
 	 	Heading down a data science path kicked off an innovative culture within Woodside Petroleum, but most importantly it helped solve some business problems the exploration giant was struggling with, its CDO has said.
Stop the hype: The real value of IBM Watson is driving small, incremental business changes (TechRepublic)
IBM's Watson is impressive technology, even if it can't quite cure cancer. It's time the company positioned it accordingly.
 	IBM's Watson Data Platform aims to become data science operating system 
 	 	IBM's plan is to create a data science operating system that can bring together data scientists, analysts, and business leaders.
IBM, Docker grow partnership to drive container adoption across public cloud (TechRepublic)
As part of an expanded partnership, IBM will participate in Docker's Modernize Traditional Applications, and Docker Enterprise Edition will get an integration for IBM Cloud.
",IBM Watson,Company,gray,sedan,vehicle,wheeled vehicle,car
,187446750783_10155303629825784,https://www.facebook.com/ibmwatson/posts/10155303629825784,"Over the next decade, analyst firm Tractica predicts that annual Global AI enterprise software revenue will grow from $644 million in 2016 to nearly $39 billion by 2025. What is the future of #AI revenue? Our latest blog highlights the top 10 use cases for AI in the next decade.",Link,,,1/4/18 6:30, ,7587,7587,0,12360,12360,0,217,155,196,2,2,9660,6160,0,0,154,0,0,0,0,0,0,0,0,0,0,14,75.0,,17,79.0,,69,97.0,,,93,103.0,,,1,1.0,,1,1.0,,,,,sadness,0.504155,negative,-0.281035,"latest blog, next decade","Company, Quantity, Quantity, Hashtag",latest blog,Company, , , , , , , , , , , , , , , , , , , , , , 
https://ibm.co/2jor9NN,187446750783_10155302025710784,https://www.facebook.com/ibmwatson/posts/10155302025710784,"We speak your language: by teaching Watson's Speech-to-Text service key phrases in your industry, you open the doors to uncovering out-of-the-box solutions: ",Link,,,1/3/18 13:11, ,3434,3434,0,5227,5227,0,30,17,20,2,2,4935,3192,0,0,27,0,0,0,0,0,0,0,0,0,0,2,17.0,,2,17.0,,10,9.0,,,11,9.0,,,1,1.0,,1,1.0,,IBM Watson's Speech-to-Text API service helps provide the tooling and functionality to train Watson to learn your business.,https://www.ibm.com/blogs/watson/wp-content/uploads/2017/12/GettyImages-9397220821.jpg,https://www.ibm.com/blogs/watson/2017/12/ibm-watson-speech-to-text-api/,joy,0.321089,positive,0.91439,"Watson's Speech, Text service, key phrases",Person,Watson's Speech,Person,joy,0.080448,positive,0.820473,"IBM Watson's Speech, Text API service",Company,IBM Watson's Speech,Company,joy,0.571298,positive,0.752911,"New language model customization, language of your business, IBM Watson’s Speech","Person, Company","Key points:
 – IBM Watson’s Speech-to-Text service helps you go deeper than out-of-the-box solutions allow by providing the tooling and functionality to train Watson to learn the language of your business
 – New language model customization, customization weighting and acoustic model customization features provide the flexibility you need to create effective solutions for your unique domain needs
Your business is unique. It has its own language and modes of operation that require customizable solutions to help your people leverage their industry expertise and deliver value. When it comes to speech-to-text solutions, an out-of-the-box service isn’t enough. Your business needs the freedom and flexibility to create solutions that account for your unique industry and domain needs. Consider the following examples:
Each of these scenarios requires the expression of words, phrases, terms, product names and domain-specific jargon that an out-of-the-box service might not fully understand. The discrete environments of each scenario also vary greatly, thereby affecting transcription unless environment variations are properly accounted for.
Beyond the everyday vernacular a baseline speech recognition service provides, as well as the assumption that your audio files will be crisply recorded without interference, IBM Watson’s Speech-to-Text service helps provide the tooling and functionality to train Watson to learn your business.What makes Watson your best choice?
The ability to tailor our base language models to suit your specific domain terminology is enormously powerful, because no one knows the language of your business better than you.This is one of your differentiating factors in the market, and therefore having a language model customization interface at your fingertips allows you to train the Watson Speech-to-Text service more precisely to suit your business language and style with great accuracy.
You can get even more precise in customizing your language model with our Watson Speech-to-Text service by weighting specific words that may be spoken frequently(such as product names or specific terminology used in your business),as opposed to words already in the service’s base vocabulary.You can account for this during machine training, and you can do so for each speech recognition request as needed.This setting is optional, but depending on your speech recognition needs, having this level of language tuning could greatly benefit your application accuracy.
As a complement to our language model customization interface, we now also offer a custom model interface that attends to the acoustical side of your business, thereby helping you go even further in tailoring the service to your business.Think of it as fine-tuning ‘the ear’ of our service, by training Watson to adapt to your specific acoustic environment (like the ambient noise in your call center) and speaker styles (like voice pitch, volume and pace). You can even create and train an acoustic model by providing just the audio files, without the need for corresponding transcription.
In addition to these customization capabilities, read more about all of our speech-to-text tooling features below:
",New language model customization,Person,reddish orange,signorina (woman),person,female,woman
https://ibm.co/2A7VsOj,187446750783_10155299753645784,https://www.facebook.com/ibmwatson/posts/10155299753645784,"With tax filing season up ahead, learn how H&amp;R Block partnered with Watson to help clients maximize their tax refund: ",Link,,,1/2/18 14:17, ,12810,12810,0,22982,22982,0,268,205,325,12,12,17482,9691,0,0,143,0,0,0,0,0,0,0,0,0,0,14,72.0,12.0,18,77.0,19.0,167,46.0,,,275,50.0,,,5,7.0,,5,7.0,,"From the Cloud to the Tax Desk, IBM Watson to Help Tax Pros Maximize Tax Outcomes with H&R Block. For more information, visit http://ibm.co/2kseLOj",https://i.ytimg.com/vi/pVK5UeimatQ/maxresdefault.jpg,https://www.youtube.com/watch?v=pVK5UeimatQ,joy,0.266989,positive,0.910553,"tax filing season, R Block",Person,tax filing season,Person,disgust,0.047021,neutral,0,"Tax Desk, Tax Pros Maximize Tax Outcomes, IBM Watson",Company,Tax Desk,Company,sadness,0.0,neutral,0,YouTube,Company,"      YouTube
                                                                                       
                         
   
                      

                                                                                                                                                                                                        
    





                                                                                                                                                                                    
                         
                
         
       
     
   
          
                         
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
                          
                
         
       
     
   
        
                           
                        
             
                              
                 
                 
                 
                 
             
           
         
                                                
                                                 
                                  
               
             
             
           
         
       
     
   
                                                                                                                                                                                                                                                                                                   
            

",YouTube,Company,sage green,classroom,indoors,classroom,-
